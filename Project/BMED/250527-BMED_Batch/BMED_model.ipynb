{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(data_list, max_length=None, pad_value=-100.0):\n",
    "    \"\"\"\n",
    "    Pad variable length sequences to the same length\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of tensors with different sequence lengths\n",
    "        max_length: Maximum length to pad to (default: longest sequence)\n",
    "        pad_value: Value to use for padding\n",
    "    \n",
    "    Returns:\n",
    "        padded_tensor: [batch_size, max_length, ...] - padded sequences\n",
    "        seq_lengths: [batch_size] - original sequence lengths\n",
    "    \"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = max(data.shape[0] for data in data_list) # Auto-calculate the max length\n",
    "\n",
    "    batch_size = len(data_list) # Batch size\n",
    "    seq_lengths = torch.tensor([data.shape[0] for data in data_list]) # Actual sequential length for each experiments\n",
    "    dimensions = data_list[0].shape[1:] # Get shape of individual elements\n",
    "    padded_tensor = torch.full((batch_size, max_length) + dimensions, pad_value, dtype=torch.float32) # generaste padded tensor filled with pad_value\n",
    "\n",
    "\n",
    "    # Fill with actual data\n",
    "    for i, data in enumerate(data_list):\n",
    "        padded_tensor[i, :data.shape[0]] = torch.tensor(data[:data.shape[0]], dtype=torch.float32)\n",
    "    \n",
    "    return padded_tensor, seq_lengths, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(Vt, E, C, Vm, I, seq_lengths=None):\n",
    "    \"\"\"\n",
    "    Prepare input data for the model with padding support\n",
    "    \n",
    "    Args:\n",
    "        voltage: [batch_size, seq_len] - applied voltage\n",
    "        ext_electrolyte: [batch_size, seq_len] - external electrolyte concentration\n",
    "        concentrations: [batch_size, seq_len, 3, 2] - [Feed, Acid, Base] x [LA, K] concentrations\n",
    "        volumes: [batch_size, seq_len, 3] - volumes for each channel\n",
    "        currents: [batch_size, seq_len] - measured currents\n",
    "        seq_lengths: [batch_size] - actual sequence lengths (optional)\n",
    "    \n",
    "    Returns:\n",
    "        input_tensor: [batch_size, seq_len, 3, 6] - formatted input for CNN-LSTM\n",
    "        initial_state: [batch_size, 3, 3] - initial concentrations and volumes\n",
    "        mask: [batch_size, seq_len] - padding mask\n",
    "        seq_lengths: [batch_size] - actual sequence lengths\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = Vt.shape # Get batch size and sequence length for set the size of input tensor\n",
    "    input = torch.zeros(batch_size, seq_len, 3, 6) # Generate input tensor\n",
    "\n",
    "    # Fill input tensor for each channel\n",
    "    for channel in range(3):\n",
    "        input[:, :, channel, 0] = C[:, :, channel, 0] # LA concentration\n",
    "        input[:, :, channel, 1] = C[:, :, channel, 1] # K concentration\n",
    "        input[:, :, channel, 2] = Vm[:, :, channel] # Volume\n",
    "        input[:, :, channel, 3] = Vt # Voltage (same for all)\n",
    "        input[:, :, channel, 4] = E # Ext electrolyte (same for all)\n",
    "        input[:, :, channel, 5] = I # Current (same for all)\n",
    "\n",
    "    # Initial State for each channel\n",
    "    init = torch.zeros(batch_size,3,3)\n",
    "    init[:, :, 0] = C[:, 0, :, 0] # Initial LA concentrations [batch number, sequence length = 0 = initial state, channel number, feature]\n",
    "    init[:, :, 1] = C[:, 0, :, 1] # Initial K concentrations\n",
    "    init[:, :, 2] = Vm[:, 0, :] # Initial volumes\n",
    "\n",
    "    # Create padding mask\n",
    "    mask = torch.zeros(batch_size, seq_len)\n",
    "    for i, length in enumerate(seq_lengths):\n",
    "        mask[i, :length] = 1.0\n",
    "    \n",
    "    return input, init, mask, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BMED_DB_augmented.csv\")\n",
    "df['CA_K'] = 0.0\n",
    "df['CB_LA'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data Preparation\n",
    "Vt_list = []\n",
    "E_list = []\n",
    "C_list = []\n",
    "Vm_list = []\n",
    "I_list = []\n",
    "\n",
    "for exp_num in df['exp'].unique():\n",
    "    Vt_list.append(df[df['exp']==exp_num]['V'].values)\n",
    "    E_list.append(df[df['exp']==exp_num]['E'].values)\n",
    "    \n",
    "    # CF, CA, CB 순으로 묶고 LA, K 순으로 값을 저장\n",
    "    CF_LA = df[df['exp']==exp_num]['CF_LA'].values\n",
    "    CF_K = df[df['exp']==exp_num]['CF_K'].values\n",
    "    CA_LA = df[df['exp']==exp_num]['CA_LA'].values\n",
    "    CA_K = df[df['exp']==exp_num]['CA_K'].values\n",
    "    CB_LA = df[df['exp']==exp_num]['CB_LA'].values\n",
    "    CB_K = df[df['exp']==exp_num]['CB_K'].values\n",
    "    \n",
    "    # 시간순으로 데이터 정렬\n",
    "    C_exp = np.stack([\n",
    "        np.stack([CF_LA, CF_K], axis=1),  # Feed (LA, K)\n",
    "        np.stack([CA_LA, CA_K], axis=1),  # Acid (LA, K)\n",
    "        np.stack([CB_LA, CB_K], axis=1)   # Base (LA, K)\n",
    "    ], axis=1)\n",
    "    \n",
    "    C_list.append(C_exp)\n",
    "    Vm_list.append(df[df['exp']==exp_num][['VF', 'VA', 'VB']].values)\n",
    "    I_list.append(df[df['exp']==exp_num]['I'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt, seq_lengths, max_length = pad_sequences(Vt_list)\n",
    "E, _, _ = pad_sequences(E_list)\n",
    "C, _, _ = pad_sequences(C_list)\n",
    "Vm, _, _ = pad_sequences(Vm_list)\n",
    "I, _, _ = pad_sequences(I_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs\n",
    "input_tensor, initial_state, mask, seq_lengths = prepare_input_data(Vt, E, C, Vm, I, seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.0000e-01,  1.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00]],\n",
       "\n",
       "         [[ 4.9667e-01,  1.0218e+00,  1.0017e+00,  2.0000e+01,  2.5000e-01,\n",
       "            2.5000e-02],\n",
       "          [ 2.0328e-03,  0.0000e+00,  9.9889e-01,  2.0000e+01,  2.5000e-01,\n",
       "            2.5000e-02],\n",
       "          [ 0.0000e+00, -2.4251e-02,  9.9917e-01,  2.0000e+01,  2.5000e-01,\n",
       "            2.5000e-02]],\n",
       "\n",
       "         [[ 4.9335e-01,  1.0370e+00,  1.0062e+00,  2.0000e+01,  2.5000e-01,\n",
       "            5.0000e-02],\n",
       "          [ 3.0767e-03,  0.0000e+00,  9.9662e-01,  2.0000e+01,  2.5000e-01,\n",
       "            5.0000e-02],\n",
       "          [ 0.0000e+00, -4.5457e-02,  9.9697e-01,  2.0000e+01,  2.5000e-01,\n",
       "            5.0000e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.0000e-01,  1.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.0000e-01]],\n",
       "\n",
       "         [[ 4.9645e-01,  9.9946e-01,  1.0086e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.8484e-01],\n",
       "          [ 5.0566e-04,  0.0000e+00,  9.9754e-01,  2.0000e+01,  2.5000e-01,\n",
       "            1.8484e-01],\n",
       "          [ 0.0000e+00, -8.8590e-03,  9.9386e-01,  2.0000e+01,  2.5000e-01,\n",
       "            1.8484e-01]],\n",
       "\n",
       "         [[ 4.9227e-01,  9.9788e-01,  1.0161e+00,  2.0000e+01,  2.5000e-01,\n",
       "            2.6375e-01],\n",
       "          [ 1.8763e-03,  0.0000e+00,  9.9540e-01,  2.0000e+01,  2.5000e-01,\n",
       "            2.6375e-01],\n",
       "          [ 0.0000e+00, -1.3408e-02,  9.8850e-01,  2.0000e+01,  2.5000e-01,\n",
       "            2.6375e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.0000e-01,  1.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  2.0000e+01,  2.5000e-01,\n",
       "            0.0000e+00]],\n",
       "\n",
       "         [[ 4.9777e-01,  9.9830e-01,  1.0094e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.1970e-01],\n",
       "          [ 2.3660e-04,  0.0000e+00,  1.0025e+00,  2.0000e+01,  2.5000e-01,\n",
       "            1.1970e-01],\n",
       "          [ 0.0000e+00, -2.7124e-03,  9.8815e-01,  2.0000e+01,  2.5000e-01,\n",
       "            1.1970e-01]],\n",
       "\n",
       "         [[ 4.9410e-01,  9.9367e-01,  1.0180e+00,  2.0000e+01,  2.5000e-01,\n",
       "            2.3169e-01],\n",
       "          [ 8.9088e-04,  0.0000e+00,  1.0046e+00,  2.0000e+01,  2.5000e-01,\n",
       "            2.3169e-01],\n",
       "          [ 0.0000e+00, -4.1053e-03,  9.7735e-01,  2.0000e+01,  2.5000e-01,\n",
       "            2.3169e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 3.0000e+00,  3.0000e+00,  1.0000e+00,  3.5000e+01,  2.5000e-01,\n",
       "            2.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  3.5000e+01,  2.5000e-01,\n",
       "            2.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  2.0000e+00,  3.5000e+01,  2.5000e-01,\n",
       "            2.0000e-01]],\n",
       "\n",
       "         [[ 2.8885e+00,  2.9806e+00,  1.0287e+00,  3.5000e+01,  2.5000e-01,\n",
       "            7.3622e-01],\n",
       "          [ 4.7920e-02,  0.0000e+00,  9.9502e-01,  3.5000e+01,  2.5000e-01,\n",
       "            7.3622e-01],\n",
       "          [ 0.0000e+00,  1.3955e-03,  1.9786e+00,  3.5000e+01,  2.5000e-01,\n",
       "            7.3622e-01]],\n",
       "\n",
       "         [[ 2.7834e+00,  2.9477e+00,  1.0519e+00,  3.5000e+01,  2.5000e-01,\n",
       "            1.2331e+00],\n",
       "          [ 9.9781e-02,  0.0000e+00,  9.9128e-01,  3.5000e+01,  2.5000e-01,\n",
       "            1.2331e+00],\n",
       "          [ 0.0000e+00,  5.5409e-03,  1.9601e+00,  3.5000e+01,  2.5000e-01,\n",
       "            1.2331e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0000e+00,  3.0000e+00,  1.0000e+00,  3.5000e+01,  1.0000e+00,\n",
       "            4.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  3.5000e+01,  1.0000e+00,\n",
       "            4.0000e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  2.0000e+00,  3.5000e+01,  1.0000e+00,\n",
       "            4.0000e-01]],\n",
       "\n",
       "         [[ 2.8682e+00,  2.9923e+00,  1.0304e+00,  3.5000e+01,  1.0000e+00,\n",
       "            1.1095e+00],\n",
       "          [ 5.8645e-02,  0.0000e+00,  9.9266e-01,  3.5000e+01,  1.0000e+00,\n",
       "            1.1095e+00],\n",
       "          [ 0.0000e+00, -4.0610e-02,  1.9769e+00,  3.5000e+01,  1.0000e+00,\n",
       "            1.1095e+00]],\n",
       "\n",
       "         [[ 2.7440e+00,  2.9718e+00,  1.0569e+00,  3.5000e+01,  1.0000e+00,\n",
       "            1.7712e+00],\n",
       "          [ 1.1986e-01,  0.0000e+00,  9.8714e-01,  3.5000e+01,  1.0000e+00,\n",
       "            1.7712e+00],\n",
       "          [ 0.0000e+00, -6.3711e-02,  1.9559e+00,  3.5000e+01,  1.0000e+00,\n",
       "            1.7712e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0000e+00,  3.0000e+00,  1.0000e+00,  3.5000e+01,  5.0000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  3.5000e+01,  5.0000e-01,\n",
       "            0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  2.0000e+00,  3.5000e+01,  5.0000e-01,\n",
       "            0.0000e+00]],\n",
       "\n",
       "         [[ 2.9154e+00,  2.9822e+00,  1.0256e+00,  3.5000e+01,  5.0000e-01,\n",
       "            5.5152e-01],\n",
       "          [ 2.3626e-02,  0.0000e+00,  9.9667e-01,  3.5000e+01,  5.0000e-01,\n",
       "            5.5152e-01],\n",
       "          [ 0.0000e+00,  2.4492e-03,  1.9793e+00,  3.5000e+01,  5.0000e-01,\n",
       "            5.5152e-01]],\n",
       "\n",
       "         [[ 2.8344e+00,  2.9473e+00,  1.0461e+00,  3.5000e+01,  5.0000e-01,\n",
       "            1.0683e+00],\n",
       "          [ 5.5528e-02,  0.0000e+00,  9.9416e-01,  3.5000e+01,  5.0000e-01,\n",
       "            1.0683e+00],\n",
       "          [ 0.0000e+00,  9.6206e-03,  1.9620e+00,  3.5000e+01,  5.0000e-01,\n",
       "            1.0683e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]],\n",
       "\n",
       "         [[-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02],\n",
       "          [-1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02, -1.0000e+02,\n",
       "           -1.0000e+02]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BMEDModel(nn.Module):\n",
    "    def __init__(self, hidden_nodes = 64, rnn_layers = 2, cnn_channels = 32, max_seq_len = 37):\n",
    "        super(BMEDModel, self).__init__()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fixed Length Example ===\n",
      "Input shape: torch.Size([16, 28, 3, 6])\n",
      "Initial state shape: torch.Size([16, 3, 3])\n",
      "Output shape: torch.Size([16, 28, 3, 3])\n",
      "Fluxes shape: torch.Size([16, 28, 4])\n",
      "Fixed length model created successfully!\n",
      "\n",
      "=== Variable Length (Padded) Example with Different RNN Types ===\n",
      "Creating models with different RNN types...\n",
      "\n",
      "=== Testing LSTM Model ===\n",
      "Input shape: torch.Size([4, 28, 3, 6])\n",
      "Sequence lengths: tensor([28, 20, 25, 15])\n",
      "Output shape: torch.Size([4, 28, 3, 3])\n",
      "Fluxes shape: torch.Size([4, 28, 4])\n",
      "Total parameters: 58,644\n",
      "\n",
      "=== Testing RNN Model ===\n",
      "Input shape: torch.Size([4, 28, 3, 6])\n",
      "Sequence lengths: tensor([28, 20, 25, 15])\n",
      "Output shape: torch.Size([4, 28, 3, 3])\n",
      "Fluxes shape: torch.Size([4, 28, 4])\n",
      "Total parameters: 17,940\n",
      "\n",
      "=== Testing GRU Model ===\n",
      "Input shape: torch.Size([4, 28, 3, 6])\n",
      "Sequence lengths: tensor([28, 20, 25, 15])\n",
      "Output shape: torch.Size([4, 28, 3, 3])\n",
      "Fluxes shape: torch.Size([4, 28, 4])\n",
      "Total parameters: 45,076\n",
      "\n",
      "=== Parameter Comparison ===\n",
      "LSTM: 58,644 parameters\n",
      "RNN: 17,940 parameters\n",
      "GRU: 45,076 parameters\n",
      "All models created successfully!\n",
      "\n",
      "=== Loss Calculation with Masking ===\n",
      "LSTM Output loss (masked): inf\n",
      "LSTM Flux loss (masked): 4.5807\n",
      "LSTM Total loss: inf\n",
      "\n",
      "=== Speed and Complexity Comparison ===\n",
      "RNN Type | Parameters | Relative Speed | Best For\n",
      "-------------------------------------------------------\n",
      "RNN      | Least      | Fastest        | Simple patterns, short sequences\n",
      "GRU      | Medium     | Medium         | Balance of performance & speed\n",
      "LSTM     | Most       | Slowest        | Complex patterns, long sequences\n",
      "\n",
      "For your 28-step BMED system, LSTM is recommended for best performance.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class BMEDModel(nn.Module):\n",
    "    def __init__(self, hidden_size=64, rnn_layers=2, cnn_channels=32, max_seq_len=28, rnn_type='LSTM'):\n",
    "        super(BMEDModel, self).__init__()\n",
    "        \n",
    "        # Input dimensions\n",
    "        # 3 channels (Feed, Acid, Base) x 6 features each\n",
    "        # Features per channel: [LA_conc, K_conc, Volume, Voltage, Ext_electrolyte, Current]\n",
    "        self.input_channels = 3\n",
    "        self.features_per_channel = 6\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.rnn_type = rnn_type\n",
    "        \n",
    "        # CNN layers for spatial (channel-wise) feature extraction\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv1d(self.features_per_channel, cnn_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(cnn_channels, cnn_channels//2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        )\n",
    "        \n",
    "        # RNN layers for temporal dependency (LSTM, RNN, or GRU)\n",
    "        if rnn_type.upper() == 'LSTM':\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=cnn_channels//2, \n",
    "                hidden_size=hidden_size, \n",
    "                num_layers=rnn_layers, \n",
    "                batch_first=True,\n",
    "                dropout=0.2 if rnn_layers > 1 else 0\n",
    "            )\n",
    "        elif rnn_type.upper() == 'GRU':\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=cnn_channels//2, \n",
    "                hidden_size=hidden_size, \n",
    "                num_layers=rnn_layers, \n",
    "                batch_first=True,\n",
    "                dropout=0.2 if rnn_layers > 1 else 0\n",
    "            )\n",
    "        elif rnn_type.upper() == 'RNN':\n",
    "            self.rnn = nn.RNN(\n",
    "                input_size=cnn_channels//2, \n",
    "                hidden_size=hidden_size, \n",
    "                num_layers=rnn_layers, \n",
    "                batch_first=True,\n",
    "                dropout=0.2 if rnn_layers > 1 else 0,\n",
    "                nonlinearity='tanh'\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported RNN type: {rnn_type}. Choose from 'LSTM', 'GRU', or 'RNN'.\")\n",
    "        \n",
    "        # Output layers for flux prediction\n",
    "        self.flux_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size//2, 4)  # [Water_flux, LA_flux, K_flux, Current]\n",
    "        )\n",
    "        \n",
    "        # Physical layer for mass balance\n",
    "        self.physical_layer = PhysicalLayer()\n",
    "    \n",
    "    def forward(self, x, initial_state, seq_lengths=None, mask=None):\n",
    "        \"\"\"\n",
    "        x: [batch_size, sequence_length, channels, features]\n",
    "        initial_state: [batch_size, channels, features] - initial concentrations and volumes\n",
    "        seq_lengths: [batch_size] - actual sequence lengths for each sample\n",
    "        mask: [batch_size, sequence_length] - mask for padded positions\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, channels, features = x.shape\n",
    "        \n",
    "        # Reshape for CNN processing\n",
    "        x_cnn = x.view(batch_size * seq_len, features, channels)\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        cnn_features = self.cnn_layers(x_cnn)  # [batch*seq, channels//2, 1]\n",
    "        cnn_features = cnn_features.squeeze(-1)  # [batch*seq, channels//2]\n",
    "        \n",
    "        # Reshape back for RNN\n",
    "        rnn_input = cnn_features.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Pack padded sequence for RNN if sequence lengths are provided\n",
    "        if seq_lengths is not None:\n",
    "            rnn_input = nn.utils.rnn.pack_padded_sequence(\n",
    "                rnn_input, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            rnn_out, _ = self.rnn(rnn_input)\n",
    "            rnn_out, _ = nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(rnn_input)\n",
    "        \n",
    "        # Predict fluxes for each time step\n",
    "        fluxes = self.flux_predictor(rnn_out)  # [batch, seq_len, 4]\n",
    "        \n",
    "        # Apply mask to fluxes if provided\n",
    "        if mask is not None:\n",
    "            fluxes = fluxes * mask.unsqueeze(-1)\n",
    "        \n",
    "        # Apply physical layer to calculate concentrations and volumes\n",
    "        outputs = self.physical_layer(fluxes, initial_state, seq_lengths, mask)\n",
    "        \n",
    "        return outputs, fluxes\n",
    "\n",
    "class PhysicalLayer(nn.Module):\n",
    "    def __init__(self, dt=0.5):  # 0.5 hour time step\n",
    "        super(PhysicalLayer, self).__init__()\n",
    "        self.dt = dt\n",
    "    \n",
    "    def forward(self, fluxes, initial_state, seq_lengths=None, mask=None):\n",
    "        \"\"\"\n",
    "        fluxes: [batch_size, seq_len, 4] - [Water_flux, LA_flux, K_flux, Current]\n",
    "        initial_state: [batch_size, 3, 3] - [Feed, Acid, Base] x [LA_conc, K_conc, Volume]\n",
    "        seq_lengths: [batch_size] - actual sequence lengths for each sample\n",
    "        mask: [batch_size, seq_len] - mask for padded positions\n",
    "        \n",
    "        Returns: [batch_size, seq_len, 3, 3] - time series of [LA_conc, K_conc, Volume] for each channel\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = fluxes.shape\n",
    "        \n",
    "        # Initialize output tensor\n",
    "        outputs = torch.zeros(batch_size, seq_len, 3, 3)  # [batch, time, channel, property]\n",
    "        \n",
    "        # Set initial conditions\n",
    "        current_state = initial_state.clone()  # [batch, channel, property]\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Extract fluxes for current time step\n",
    "            water_flux = fluxes[:, t, 0]  # Water movement\n",
    "            la_flux = fluxes[:, t, 1]     # LA movement (Feed → Acid)\n",
    "            k_flux = fluxes[:, t, 2]      # K movement (Feed → Base)\n",
    "            \n",
    "            # Only update if within actual sequence length\n",
    "            if seq_lengths is not None:\n",
    "                # Create mask for this time step\n",
    "                time_mask = (t < seq_lengths).float()\n",
    "                water_flux = water_flux * time_mask\n",
    "                la_flux = la_flux * time_mask\n",
    "                k_flux = k_flux * time_mask\n",
    "            elif mask is not None:\n",
    "                time_mask = mask[:, t]\n",
    "                water_flux = water_flux * time_mask\n",
    "                la_flux = la_flux * time_mask\n",
    "                k_flux = k_flux * time_mask\n",
    "            \n",
    "            # Mass balance calculations\n",
    "            current_state = self.mass_balance_step(current_state, water_flux, la_flux, k_flux)\n",
    "            \n",
    "            # Store results\n",
    "            outputs[:, t, :, :] = current_state\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def mass_balance_step(self, state, water_flux, la_flux, k_flux):\n",
    "        \"\"\"\n",
    "        Perform one time step of mass balance\n",
    "        state: [batch, 3, 3] - [Feed, Acid, Base] x [LA_conc, K_conc, Volume]\n",
    "        \"\"\"\n",
    "        batch_size = state.shape[0]\n",
    "        new_state = state.clone()\n",
    "        \n",
    "        # Extract current values\n",
    "        # Channel 0: Feed, Channel 1: Acid, Channel 2: Base\n",
    "        # Property 0: LA_conc, Property 1: K_conc, Property 2: Volume\n",
    "        \n",
    "        feed_la_conc = state[:, 0, 0]\n",
    "        feed_k_conc = state[:, 0, 1]\n",
    "        feed_vol = state[:, 0, 2]\n",
    "        \n",
    "        acid_la_conc = state[:, 1, 0]\n",
    "        acid_vol = state[:, 1, 2]\n",
    "        \n",
    "        base_k_conc = state[:, 2, 1]\n",
    "        base_vol = state[:, 2, 2]\n",
    "        \n",
    "        # Volume changes due to water flux\n",
    "        # Assuming positive flux means water moves from feed\n",
    "        new_state[:, 0, 2] = feed_vol - water_flux * self.dt  # Feed volume decreases\n",
    "        new_state[:, 1, 2] = acid_vol + water_flux * self.dt * 0.5  # Acid volume increases\n",
    "        new_state[:, 2, 2] = base_vol + water_flux * self.dt * 0.5  # Base volume increases\n",
    "        \n",
    "        # LA mass balance (Feed → Acid)\n",
    "        la_moles_transferred = la_flux * self.dt\n",
    "        \n",
    "        # Feed LA decreases\n",
    "        feed_la_moles = feed_la_conc * feed_vol\n",
    "        new_feed_la_moles = torch.clamp(feed_la_moles - la_moles_transferred, min=0)\n",
    "        new_state[:, 0, 0] = new_feed_la_moles / torch.clamp(new_state[:, 0, 2], min=1e-6)\n",
    "        \n",
    "        # Acid LA increases\n",
    "        acid_la_moles = acid_la_conc * acid_vol\n",
    "        new_acid_la_moles = acid_la_moles + la_moles_transferred\n",
    "        new_state[:, 1, 0] = new_acid_la_moles / torch.clamp(new_state[:, 1, 2], min=1e-6)\n",
    "        \n",
    "        # K mass balance (Feed → Base)\n",
    "        k_moles_transferred = k_flux * self.dt\n",
    "        \n",
    "        # Feed K decreases\n",
    "        feed_k_moles = feed_k_conc * feed_vol\n",
    "        new_feed_k_moles = torch.clamp(feed_k_moles - k_moles_transferred, min=0)\n",
    "        new_state[:, 0, 1] = new_feed_k_moles / torch.clamp(new_state[:, 0, 2], min=1e-6)\n",
    "        \n",
    "        # Base K increases\n",
    "        base_k_moles = base_k_conc * base_vol\n",
    "        new_base_k_moles = base_k_moles + k_moles_transferred\n",
    "        new_state[:, 2, 1] = new_base_k_moles / torch.clamp(new_state[:, 2, 2], min=1e-6)\n",
    "        \n",
    "        # Acid and Base don't have K and LA respectively (constraint)\n",
    "        new_state[:, 1, 1] = 0  # No K in acid\n",
    "        new_state[:, 2, 0] = 0  # No LA in base\n",
    "        \n",
    "        return new_state\n",
    "\n",
    "def prepare_input_data(voltage, ext_electrolyte, concentrations, volumes, currents, seq_lengths=None):\n",
    "    \"\"\"\n",
    "    Prepare input data for the model with padding support\n",
    "    \n",
    "    Args:\n",
    "        voltage: [batch_size, seq_len] - applied voltage\n",
    "        ext_electrolyte: [batch_size, seq_len] - external electrolyte concentration\n",
    "        concentrations: [batch_size, seq_len, 3, 2] - [Feed, Acid, Base] x [LA, K] concentrations\n",
    "        volumes: [batch_size, seq_len, 3] - volumes for each channel\n",
    "        currents: [batch_size, seq_len] - measured currents\n",
    "        seq_lengths: [batch_size] - actual sequence lengths (optional)\n",
    "    \n",
    "    Returns:\n",
    "        input_tensor: [batch_size, seq_len, 3, 6] - formatted input for CNN-LSTM\n",
    "        initial_state: [batch_size, 3, 3] - initial concentrations and volumes\n",
    "        mask: [batch_size, seq_len] - padding mask\n",
    "        seq_lengths: [batch_size] - actual sequence lengths\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = voltage.shape\n",
    "    \n",
    "    # Create input tensor\n",
    "    input_tensor = torch.zeros(batch_size, seq_len, 3, 6)\n",
    "    \n",
    "    # Fill input tensor for each channel\n",
    "    for channel in range(3):\n",
    "        input_tensor[:, :, channel, 0] = concentrations[:, :, channel, 0]  # LA concentration\n",
    "        input_tensor[:, :, channel, 1] = concentrations[:, :, channel, 1]  # K concentration\n",
    "        input_tensor[:, :, channel, 2] = volumes[:, :, channel]            # Volume\n",
    "        input_tensor[:, :, channel, 3] = voltage                          # Voltage (same for all)\n",
    "        input_tensor[:, :, channel, 4] = ext_electrolyte                  # Ext electrolyte (same for all)\n",
    "        input_tensor[:, :, channel, 5] = currents                        # Current (same for all)\n",
    "    \n",
    "    # Initial state: [LA_conc, K_conc, Volume] for each channel at t=0\n",
    "    initial_state = torch.zeros(batch_size, 3, 3)\n",
    "    initial_state[:, :, 0] = concentrations[:, 0, :, 0]  # Initial LA concentrations\n",
    "    initial_state[:, :, 1] = concentrations[:, 0, :, 1]  # Initial K concentrations\n",
    "    initial_state[:, :, 2] = volumes[:, 0, :]            # Initial volumes\n",
    "    \n",
    "    # Create padding mask\n",
    "    if seq_lengths is None:\n",
    "        seq_lengths = torch.full((batch_size,), seq_len, dtype=torch.long)\n",
    "    \n",
    "    mask = torch.zeros(batch_size, seq_len)\n",
    "    for i, length in enumerate(seq_lengths):\n",
    "        mask[i, :length] = 1.0\n",
    "    \n",
    "    return input_tensor, initial_state, mask, seq_lengths\n",
    "\n",
    "def pad_sequences(data_list, max_length=None, pad_value=0.0):\n",
    "    \"\"\"\n",
    "    Pad variable length sequences to the same length\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of tensors with different sequence lengths\n",
    "        max_length: Maximum length to pad to (default: longest sequence)\n",
    "        pad_value: Value to use for padding\n",
    "    \n",
    "    Returns:\n",
    "        padded_tensor: [batch_size, max_length, ...] - padded sequences\n",
    "        seq_lengths: [batch_size] - original sequence lengths\n",
    "    \"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = max(data.shape[0] for data in data_list)\n",
    "    \n",
    "    batch_size = len(data_list)\n",
    "    seq_lengths = torch.tensor([data.shape[0] for data in data_list])\n",
    "    \n",
    "    # Get shape of individual elements\n",
    "    example_shape = data_list[0].shape[1:]  # Remove time dimension\n",
    "    \n",
    "    # Create padded tensor\n",
    "    padded_tensor = torch.full(\n",
    "        (batch_size, max_length) + example_shape, \n",
    "        pad_value, \n",
    "        dtype=data_list[0].dtype\n",
    "    )\n",
    "    \n",
    "    # Fill with actual data\n",
    "    for i, data in enumerate(data_list):\n",
    "        actual_length = min(data.shape[0], max_length)\n",
    "        padded_tensor[i, :actual_length] = data[:actual_length]\n",
    "    \n",
    "    return padded_tensor, seq_lengths\n",
    "\n",
    "# Example usage with variable length sequences\n",
    "def create_model_with_padding_example():\n",
    "    # Model instantiation with different RNN types\n",
    "    print(\"Creating models with different RNN types...\")\n",
    "    \n",
    "    models = {}\n",
    "    models['LSTM'] = BMEDModel(hidden_size=64, rnn_layers=2, cnn_channels=32, max_seq_len=28, rnn_type='LSTM')\n",
    "    models['RNN'] = BMEDModel(hidden_size=64, rnn_layers=2, cnn_channels=32, max_seq_len=28, rnn_type='RNN')\n",
    "    models['GRU'] = BMEDModel(hidden_size=64, rnn_layers=2, cnn_channels=32, max_seq_len=28, rnn_type='GRU')\n",
    "    \n",
    "    # Example: Create variable length sequences\n",
    "    batch_size = 4\n",
    "    max_seq_len = 28  # Updated to 28 for 14 hours\n",
    "    \n",
    "    # Simulate different experiment durations\n",
    "    actual_lengths = [28, 20, 25, 15]  # Different experiment durations\n",
    "    \n",
    "    # Create variable length data\n",
    "    voltage_list = []\n",
    "    ext_electrolyte_list = []\n",
    "    concentrations_list = []\n",
    "    volumes_list = []\n",
    "    currents_list = []\n",
    "    \n",
    "    for length in actual_lengths:\n",
    "        voltage_list.append(torch.randn(length) * 5 + 10)\n",
    "        ext_electrolyte_list.append(torch.randn(length) * 0.1 + 0.5)\n",
    "        concentrations_list.append(torch.randn(length, 3, 2) * 0.1 + 0.5)\n",
    "        volumes_list.append(torch.randn(length, 3) * 0.05 + 1.0)\n",
    "        currents_list.append(torch.randn(length) * 2 + 5)\n",
    "    \n",
    "    # Pad sequences\n",
    "    voltage_padded, seq_lengths = pad_sequences(voltage_list, max_seq_len)\n",
    "    ext_electrolyte_padded, _ = pad_sequences(ext_electrolyte_list, max_seq_len)\n",
    "    concentrations_padded, _ = pad_sequences(concentrations_list, max_seq_len)\n",
    "    volumes_padded, _ = pad_sequences(volumes_list, max_seq_len)\n",
    "    currents_padded, _ = pad_sequences(currents_list, max_seq_len)\n",
    "    \n",
    "    # Prepare inputs\n",
    "    input_tensor, initial_state, mask, seq_lengths = prepare_input_data(\n",
    "        voltage_padded, ext_electrolyte_padded, concentrations_padded, \n",
    "        volumes_padded, currents_padded, seq_lengths\n",
    "    )\n",
    "    \n",
    "    # Test all models\n",
    "    results = {}\n",
    "    for rnn_type, model in models.items():\n",
    "        print(f\"\\n=== Testing {rnn_type} Model ===\")\n",
    "        \n",
    "        # Forward pass with padding support\n",
    "        outputs, fluxes = model(input_tensor, initial_state, seq_lengths, mask)\n",
    "        \n",
    "        print(f\"Input shape: {input_tensor.shape}\")\n",
    "        print(f\"Sequence lengths: {seq_lengths}\")\n",
    "        print(f\"Output shape: {outputs.shape}\")\n",
    "        print(f\"Fluxes shape: {fluxes.shape}\")\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        \n",
    "        results[rnn_type] = {\n",
    "            'model': model,\n",
    "            'outputs': outputs,\n",
    "            'fluxes': fluxes,\n",
    "            'params': total_params\n",
    "        }\n",
    "    \n",
    "    # Show parameter comparison\n",
    "    print(f\"\\n=== Parameter Comparison ===\")\n",
    "    for rnn_type, result in results.items():\n",
    "        print(f\"{rnn_type}: {result['params']:,} parameters\")\n",
    "    \n",
    "    return results, input_tensor, initial_state, mask, seq_lengths\n",
    "\n",
    "# Example usage and training setup\n",
    "def create_model_and_example():\n",
    "    # Model instantiation with LSTM (default)\n",
    "    model = BMEDModel(hidden_size=64, rnn_layers=2, cnn_channels=32, rnn_type='LSTM')\n",
    "    \n",
    "    # Example data shapes\n",
    "    batch_size = 16\n",
    "    seq_len = 28  # 14 hours / 0.5 hour steps\n",
    "    \n",
    "    # Example input preparation\n",
    "    voltage = torch.randn(batch_size, seq_len) * 5 + 10  # 10±5V\n",
    "    ext_electrolyte = torch.randn(batch_size, seq_len) * 0.1 + 0.5  # 0.5±0.1 M\n",
    "    \n",
    "    # Concentrations [batch, time, channel, component]\n",
    "    concentrations = torch.randn(batch_size, seq_len, 3, 2) * 0.1 + 0.5\n",
    "    volumes = torch.randn(batch_size, seq_len, 3) * 0.05 + 1.0  # 1±0.05 L\n",
    "    currents = torch.randn(batch_size, seq_len) * 2 + 5  # 5±2 A\n",
    "    \n",
    "    # Prepare inputs\n",
    "    input_tensor, initial_state, mask, seq_lengths = prepare_input_data(\n",
    "        voltage, ext_electrolyte, concentrations, volumes, currents\n",
    "    )\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, fluxes = model(input_tensor, initial_state)\n",
    "    \n",
    "    print(f\"Input shape: {input_tensor.shape}\")\n",
    "    print(f\"Initial state shape: {initial_state.shape}\")\n",
    "    print(f\"Output shape: {outputs.shape}\")  # [batch, seq_len, 3, 3]\n",
    "    print(f\"Fluxes shape: {fluxes.shape}\")   # [batch, seq_len, 4]\n",
    "    \n",
    "    return model, input_tensor, initial_state, outputs, fluxes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with fixed length sequences\n",
    "    print(\"=== Fixed Length Example ===\")\n",
    "    model, inputs, initial_state, outputs, fluxes = create_model_and_example()\n",
    "    print(\"Fixed length model created successfully!\\n\")\n",
    "    \n",
    "    # Example with variable length sequences and different RNN types\n",
    "    print(\"=== Variable Length (Padded) Example with Different RNN Types ===\")\n",
    "    results, inputs_padded, initial_state_padded, mask, seq_lengths = create_model_with_padding_example()\n",
    "    print(\"All models created successfully!\")\n",
    "    \n",
    "    # Example of loss calculation with masking\n",
    "    print(\"\\n=== Loss Calculation with Masking ===\")\n",
    "    \n",
    "    # Use LSTM model for loss calculation example\n",
    "    lstm_outputs = results['LSTM']['outputs']\n",
    "    lstm_fluxes = results['LSTM']['fluxes']\n",
    "    \n",
    "    # Dummy target data\n",
    "    target_outputs = torch.randn_like(lstm_outputs)\n",
    "    target_fluxes = torch.randn_like(lstm_fluxes)\n",
    "    \n",
    "    # Masked loss calculation\n",
    "    def masked_mse_loss(predictions, targets, mask):\n",
    "        \"\"\"Calculate MSE loss only for non-padded positions\"\"\"\n",
    "        loss = ((predictions - targets) ** 2) * mask.unsqueeze(-1)\n",
    "        return loss.sum() / mask.sum()\n",
    "    \n",
    "    # Calculate losses for LSTM\n",
    "    output_loss = masked_mse_loss(lstm_outputs.view(lstm_outputs.shape[0], lstm_outputs.shape[1], -1), \n",
    "                                 target_outputs.view(target_outputs.shape[0], target_outputs.shape[1], -1), \n",
    "                                 mask)\n",
    "    flux_loss = masked_mse_loss(lstm_fluxes, target_fluxes, mask)\n",
    "    \n",
    "    print(f\"LSTM Output loss (masked): {output_loss.item():.4f}\")\n",
    "    print(f\"LSTM Flux loss (masked): {flux_loss.item():.4f}\")\n",
    "    print(f\"LSTM Total loss: {(output_loss + flux_loss).item():.4f}\")\n",
    "    \n",
    "    # Speed comparison (rough estimate)\n",
    "    print(f\"\\n=== Speed and Complexity Comparison ===\")\n",
    "    print(\"RNN Type | Parameters | Relative Speed | Best For\")\n",
    "    print(\"-\" * 55)\n",
    "    print(\"RNN      | Least      | Fastest        | Simple patterns, short sequences\")\n",
    "    print(\"GRU      | Medium     | Medium         | Balance of performance & speed\")\n",
    "    print(\"LSTM     | Most       | Slowest        | Complex patterns, long sequences\")\n",
    "    print(\"\\nFor your 28-step BMED system, LSTM is recommended for best performance.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
