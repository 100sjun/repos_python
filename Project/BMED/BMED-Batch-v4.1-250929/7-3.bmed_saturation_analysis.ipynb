{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saturation_title",
   "metadata": {},
   "source": [
    "# Saturation Problem Analysis: rdNALA Prediction Plateau\n",
    "## New Discovery: Different (V, E) combinations converge to identical steady states\n",
    "\n",
    "**Key Finding**:\n",
    "- `10V + E=0.25M` → Low CALA (~0.016 mol/L)\n",
    "- `30V + E=0.25M` → High CALA (~1.47 mol/L)\n",
    "- `10V + E=1.0M` → High CALA (~1.47 mol/L) ← **Same as 30V + 0.25M!**\n",
    "\n",
    "**New Hypothesis**: Model has a **saturation problem** where high separation efficiency conditions all converge to the same plateau, regardless of specific (V, E) combinations.\n",
    "\n",
    "**This notebook investigates**:\n",
    "1. Does 10V+1M really converge to same state as 30V+0.25M?\n",
    "2. What happens in LSTM hidden states across these conditions?\n",
    "3. How does Layer Normalization affect feature discrimination?\n",
    "4. What are the rdNALA prediction patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model_classes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes loaded with hidden state tracking capability\n"
     ]
    }
   ],
   "source": [
    "# Copy model class definitions from 7.bmed_1stage_simulator.ipynb\n",
    "# (LayerNormLSTM, StateExtr, PhysRegr, CurrRegr, PhysConstr, BMEDModel)\n",
    "\n",
    "# LSTM with layer normalization\n",
    "class LayerNormLSTM(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "\n",
    "        self.w_i = nn.Linear(input_node, 4*hidden_node, bias=False)\n",
    "        self.w_h = nn.Linear(hidden_node, 4*hidden_node, bias=False)\n",
    "\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)\n",
    "        self.ln_f = nn.LayerNorm(hidden_node)\n",
    "        self.ln_w = nn.LayerNorm(hidden_node)\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        gi = self.w_i(input)\n",
    "        gh = self.w_h(h_prev)\n",
    "        i_i, i_f, i_w, i_o = gi.chunk(4, dim=-1)\n",
    "        h_i, h_f, h_w, h_o = gh.chunk(4, dim=-1)\n",
    "\n",
    "        i_g = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_g = torch.sigmoid(self.ln_f(i_f + h_f))\n",
    "        w_g = torch.tanh(self.ln_w(i_w + h_w))\n",
    "        o_g = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "\n",
    "        c_new = f_g * c_prev + i_g * w_g\n",
    "        c_new = self.ln_c(c_new)\n",
    "\n",
    "        h_new = o_g * torch.tanh(c_new)\n",
    "\n",
    "        return h_new, c_new\n",
    "\n",
    "# State feature extractor using LayerNorm LSTM\n",
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.n_layer = n_layer\n",
    "        self.input_node = input_node\n",
    "\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        self.lstm_cells.append(LayerNormLSTM(input_node, hidden_node))\n",
    "\n",
    "        for i in range(n_layer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTM(hidden_node, hidden_node))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layernorm = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        batch_size, max_len, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "\n",
    "        for _ in range(self.n_layer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            layer_input = x_t\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                \n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "\n",
    "                if layer_idx < len(self.lstm_cells) - 1:\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "\n",
    "            outputs.append(layer_input)\n",
    "\n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)\n",
    "\n",
    "        masked_output = output_tensor * mask\n",
    "        normed_output = self.layernorm(masked_output)\n",
    "        return self.dropout(normed_output)\n",
    "\n",
    "# Physical change regressor\n",
    "class PhysRegr(nn.Module):\n",
    "    def __init__(self, input_node, output_node, n_layer, hidden_node, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(input_node, hidden_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "\n",
    "        for _ in range(n_layer - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_node, hidden_node),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_node, output_node))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.layers(hidden_states)\n",
    "\n",
    "# Current regressor\n",
    "class CurrRegr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(input_node, hidden_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "\n",
    "        for _ in range(n_layer - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_node, hidden_node),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_node, 1))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.layers(hidden_states)\n",
    "\n",
    "# Physical Constraint Layer\n",
    "class PhysConstr(nn.Module):\n",
    "    def __init__(self, range_mm, curr_regr, eps=1e-2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.eps = eps\n",
    "        self.curr_regr = curr_regr\n",
    "        self.register_buffer('range_mm_tensor',self._range2tensor(range_mm))\n",
    "\n",
    "    def _range2tensor(self, range_mm):\n",
    "        feature_names = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "        ranges = torch.zeros(len(feature_names), 2)\n",
    "\n",
    "        for i, name in enumerate(feature_names):\n",
    "            ranges[i, 0] = range_mm[name]['min']\n",
    "            ranges[i, 1] = range_mm[name]['max']\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    def _norm_tensor(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    def _denorm_tensor(self, norm_data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return norm_data * (max_val - min_val) + min_val\n",
    "\n",
    "    def forward(self, phys_chng, cur_state, fin, initV):\n",
    "        V_idx, E_idx, VF_idx, VA_idx, VB_idx = 0, 1, 2, 3, 4\n",
    "        CFLA_idx, CALA_idx, CFK_idx, CBK_idx, I_idx = 5, 6, 7, 8, 9\n",
    "\n",
    "        VF = self._denorm_tensor(cur_state[..., 2:3], VF_idx)\n",
    "        VA = self._denorm_tensor(cur_state[..., 3:4], VA_idx)\n",
    "        VB = self._denorm_tensor(cur_state[..., 4:5], VB_idx)\n",
    "        CFLA = self._denorm_tensor(cur_state[..., 5:6], CFLA_idx)\n",
    "        CALA = self._denorm_tensor(cur_state[..., 6:7], CALA_idx)\n",
    "        CFK = self._denorm_tensor(cur_state[..., 7:8], CFK_idx)\n",
    "        CBK = self._denorm_tensor(cur_state[..., 8:9], CBK_idx)\n",
    "\n",
    "        FvF, FvA, FvB, CiLA, CiK = fin\n",
    "        VFi, VAi, VBi = initV\n",
    "\n",
    "        dVF_in, dVA_in, dVB_in = FvF, FvA, FvB\n",
    "        dNFLA_in, dNFK_in = FvF * CiLA, FvF * CiK\n",
    "\n",
    "        rdVA = phys_chng[..., 0:1]\n",
    "        rdVB = phys_chng[..., 1:2]\n",
    "        rdNALA = phys_chng[..., 2:3]\n",
    "        rdNBK = phys_chng[..., 3:4]\n",
    "\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA\n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        VF_after_feed = VF + dVF_in\n",
    "        VA_after_feed = VA + dVA_in\n",
    "        VB_after_feed = VB + dVB_in\n",
    "        NFLA_after_feed = NFLA + dNFLA_in\n",
    "        NALA_after_feed = NALA\n",
    "        NFK_after_feed = NFK + dNFK_in\n",
    "        NBK_after_feed = NBK\n",
    "\n",
    "        dVA = VF_after_feed * (rdVA - 0.5)\n",
    "        dVB = VF_after_feed * (rdVB - 0.5)\n",
    "        dNALA = NFLA_after_feed * rdNALA\n",
    "        dNBK = NFK_after_feed * rdNBK\n",
    "\n",
    "        nVF_bf = VF_after_feed - dVA - dVB\n",
    "        nVA_bf = VA_after_feed + dVA\n",
    "        nVB_bf = VB_after_feed + dVB\n",
    "\n",
    "        nNFLA_bf = NFLA_after_feed - dNALA\n",
    "        nNALA_bf = NALA_after_feed + dNALA\n",
    "        nNFK_bf = NFK_after_feed - dNBK\n",
    "        nNBK_bf = NBK_after_feed + dNBK\n",
    "\n",
    "        nCFLA = nNFLA_bf / nVF_bf\n",
    "        nCALA = nNALA_bf / nVA_bf\n",
    "        nCFK = nNFK_bf / nVF_bf\n",
    "        nCBK = nNBK_bf / nVB_bf\n",
    "\n",
    "        dVF_out = nVF_bf - VFi\n",
    "        dVA_out = nVA_bf - VAi\n",
    "        dVB_out = nVB_bf - VBi\n",
    "\n",
    "        nVF = torch.where(dVF_out > 0, nVF_bf - dVF_out, nVF_bf)\n",
    "        nVA = torch.where(dVA_out > 0, nVA_bf - dVA_out, nVA_bf)\n",
    "        nVB = torch.where(dVB_out > 0, nVB_bf - dVB_out, nVB_bf)\n",
    "        \n",
    "        dNFLA_out = torch.where(dVF_out > 0, nCFLA * dVF_out, torch.zeros_like(dVF_out))\n",
    "        dNFK_out = torch.where(dVF_out > 0, nCFK * dVF_out, torch.zeros_like(dVF_out))\n",
    "        dNALA_out = torch.where(dVA_out > 0, nCALA * dVA_out, torch.zeros_like(dVA_out))\n",
    "        dNBK_out = torch.where(dVB_out > 0, nCBK * dVB_out, torch.zeros_like(dVB_out))\n",
    "\n",
    "        nNFLA = nNFLA_bf - dNFLA_out\n",
    "        nNALA = nNALA_bf - dNALA_out\n",
    "        nNFK = nNFK_bf - dNFK_out\n",
    "        nNBK = nNBK_bf - dNBK_out\n",
    "\n",
    "        V = cur_state[..., 0:1]\n",
    "        E = cur_state[..., 1:2]\n",
    "\n",
    "        nVF_norm = self._norm_tensor(nVF, VF_idx)\n",
    "        nVA_norm = self._norm_tensor(nVA, VA_idx)\n",
    "        nVB_norm = self._norm_tensor(nVB, VB_idx)\n",
    "        nCFLA_norm = self._norm_tensor(nCFLA, CFLA_idx)\n",
    "        nCALA_norm = self._norm_tensor(nCALA, CALA_idx)\n",
    "        nCFK_norm = self._norm_tensor(nCFK, CFK_idx)\n",
    "        nCBK_norm = self._norm_tensor(nCBK, CBK_idx)\n",
    "\n",
    "        temp_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm\n",
    "        ], dim=-1)\n",
    "\n",
    "        nI_pred = self.curr_regr(temp_state)\n",
    "        nI_real = self._denorm_tensor(nI_pred, I_idx)\n",
    "        nI_real = torch.clamp(nI_real, min=0.0)\n",
    "        nI_norm = self._norm_tensor(nI_real, I_idx)\n",
    "\n",
    "        next_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm, nI_norm\n",
    "        ], dim=-1)\n",
    "\n",
    "        discharge = {\n",
    "            'VF': dVF_out,\n",
    "            'VA': dVA_out,\n",
    "            'VB': dVB_out,\n",
    "            'NFLA': dNFLA_out,\n",
    "            'NALA': dNALA_out,\n",
    "            'NFK': dNFK_out,\n",
    "            'NBK': dNBK_out,\n",
    "            'CFLA': nCFLA,\n",
    "            'CALA': nCALA,\n",
    "            'CFK': nCFK,\n",
    "            'CBK': nCBK\n",
    "        }\n",
    "\n",
    "        return next_state, discharge\n",
    "\n",
    "# BMED model with hidden state tracking\n",
    "class BMEDModelWithTracking(nn.Module):\n",
    "    def __init__(self, state_extr_params, phys_regr_params, curr_regr_params, range_mm):\n",
    "        super().__init__()\n",
    "        self.state_extr = StateExtr(**state_extr_params)\n",
    "        self.phys_regr = PhysRegr(**phys_regr_params)\n",
    "        self.curr_regr = CurrRegr(**curr_regr_params)\n",
    "        self.phys_constr = PhysConstr(range_mm, self.curr_regr)\n",
    "\n",
    "        self._hidden_states = None\n",
    "        self._cell_states = None\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.tracked_hidden_states = []\n",
    "        self.tracked_phys_regr_inputs = []\n",
    "        self.tracked_phys_chng = []\n",
    "\n",
    "    def _reset_hidden_states(self, batch_size, device):\n",
    "        self._hidden_states = []\n",
    "        self._cell_states = []\n",
    "        for _ in range(self.state_extr.n_layer):\n",
    "            self._hidden_states.append(torch.zeros(batch_size, self.state_extr.hidden_node, device=device))\n",
    "            self._cell_states.append(torch.zeros(batch_size, self.state_extr.hidden_node, device=device))\n",
    "\n",
    "    def cont_sim(self, init_state, target_len, fin, initV, track=False):\n",
    "        batch_size = init_state.size(0)\n",
    "        feature_size = init_state.size(1)\n",
    "        device = init_state.device\n",
    "\n",
    "        self._reset_hidden_states(batch_size, device)\n",
    "        \n",
    "        if track:\n",
    "            self.tracked_hidden_states = []\n",
    "            self.tracked_phys_regr_inputs = []\n",
    "            self.tracked_phys_chng = []\n",
    "\n",
    "        pred = torch.zeros(batch_size, target_len, feature_size, device=device)\n",
    "        discharge_record = []\n",
    "        cur_state = init_state.clone()\n",
    "\n",
    "        for t in range(target_len):\n",
    "            pred[:, t, :] = cur_state\n",
    "\n",
    "            if t < target_len - 1:\n",
    "                lstm_input = cur_state[:, :-1]\n",
    "                hidden_output = self._lstm_single_step(lstm_input)\n",
    "                \n",
    "                if track:\n",
    "                    self.tracked_hidden_states.append(hidden_output.detach().cpu())\n",
    "                    self.tracked_phys_regr_inputs.append(hidden_output.detach().cpu())\n",
    "\n",
    "                phys_chng = self.phys_regr(hidden_output.unsqueeze(1))\n",
    "                \n",
    "                if track:\n",
    "                    self.tracked_phys_chng.append(phys_chng.detach().cpu())\n",
    "                \n",
    "                cur_state_expanded = cur_state.unsqueeze(1)\n",
    "\n",
    "                next_state, discharge = self.phys_constr(\n",
    "                    phys_chng, cur_state_expanded, fin, initV\n",
    "                )\n",
    "\n",
    "                cur_state = next_state.squeeze(1)\n",
    "                discharge_record.append(discharge)\n",
    "        return pred, discharge_record\n",
    "\n",
    "    def _lstm_single_step(self, x_t):\n",
    "        layer_input = x_t\n",
    "\n",
    "        for layer_idx, lstm_cell in enumerate(self.state_extr.lstm_cells):\n",
    "            h_new, c_new = lstm_cell(layer_input, (self._hidden_states[layer_idx], self._cell_states[layer_idx]))\n",
    "            \n",
    "            self._hidden_states[layer_idx] = h_new\n",
    "            self._cell_states[layer_idx] = c_new\n",
    "\n",
    "            if layer_idx < len(self.state_extr.lstm_cells) - 1:\n",
    "                layer_input = self.state_extr.dropout(h_new)\n",
    "            else:\n",
    "                layer_input = h_new\n",
    "\n",
    "        normed_output = self.state_extr.layernorm(layer_input)\n",
    "        return self.state_extr.dropout(normed_output)\n",
    "\n",
    "    def forward(self, init_state, target_len, fin, initV, track=False):\n",
    "        return self.cont_sim(init_state, target_len, fin, initV, track=track)\n",
    "\n",
    "print('Model classes loaded with hidden state tracking capability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "utility_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inputs, range_mm):\n",
    "    features = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK']\n",
    "    norm = []\n",
    "    for _, (name, value) in enumerate(zip(features, inputs)):\n",
    "        min_val = range_mm[name]['min']\n",
    "        max_val = range_mm[name]['max']\n",
    "        norm_val = (value - min_val) / (max_val - min_val)\n",
    "        norm.append(norm_val)\n",
    "    return norm\n",
    "\n",
    "def denormalize(outputs, range_mm):\n",
    "    feature_names = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    denormalized = np.zeros_like(outputs)\n",
    "    for i, name in enumerate(feature_names):\n",
    "        if name in range_mm:\n",
    "            min_val = range_mm[name]['min']\n",
    "            max_val = range_mm[name]['max']\n",
    "            denormalized[:, :, i] = outputs[:, :, i] * (max_val - min_val) + min_val\n",
    "        else:\n",
    "            denormalized[:, :, i] = outputs[:, :, i]\n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BMED_FR_250930.pth\n",
      "Device: cuda\n",
      "Load model parameters with tracking capability\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "model_path = 'BMED_FR_250930.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Model: {model_path}')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model_config = model['model_config']\n",
    "state_extr_params = model_config['state_extr_params']\n",
    "phys_regr_params = model_config['phys_regr_params']\n",
    "curr_regr_params = model_config['curr_regr_params']\n",
    "model_range_mm = model_config['range_mm']\n",
    "\n",
    "simulator = BMEDModelWithTracking(\n",
    "    state_extr_params = state_extr_params,\n",
    "    phys_regr_params = phys_regr_params,\n",
    "    curr_regr_params = curr_regr_params,\n",
    "    range_mm = model_range_mm\n",
    ").to(device)\n",
    "\n",
    "simulator.load_state_dict(model['model_state_dict'], strict=False)\n",
    "simulator.eval()\n",
    "\n",
    "print('Load model parameters with tracking capability')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_cases",
   "metadata": {},
   "source": [
    "## Test Cases: Three Conditions\n",
    "\n",
    "**Case 1**: `10V + E=0.25M` (Low driving force)\n",
    "- Expected: Low CALA (~0.016 mol/L)\n",
    "\n",
    "**Case 2**: `30V + E=0.25M` (High driving force from voltage)\n",
    "- Expected: High CALA (~1.47 mol/L)\n",
    "\n",
    "**Case 3**: `10V + E=1.0M` (High driving force from electrolyte)\n",
    "- User discovery: Converges to **same** CALA as Case 2 (~1.47 mol/L)\n",
    "- **This suggests saturation problem**\n",
    "\n",
    "All use:\n",
    "- CFLA = 3 mol/L\n",
    "- QF = QA = QB = 10 mL/min\n",
    "- Simulation time = 200 timesteps (50 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "run_case1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Case 1: 10V + E=0.25M (Low driving force) ===\n",
      "Case 1 Steady State CALA: 0.016107 mol/L\n",
      "Case 1 Steady State Current: 0.695053 A\n",
      "Hidden states tracked: 199 timesteps\n"
     ]
    }
   ],
   "source": [
    "# === Case 1: 10V + E=0.25M ===\n",
    "print('=== Case 1: 10V + E=0.25M (Low driving force) ===')\n",
    "input_init_case1 = [10, 0.25, 3, 10, 10, 10]  # [V, E, CFLA, QF, QA, QB]\n",
    "cond_init_case1 = [input_init_case1[0], input_init_case1[1], 0.7, 0.7, 0.7, \n",
    "                   input_init_case1[2], 0, input_init_case1[1]*2, 0]\n",
    "simulation_time = 200\n",
    "\n",
    "QF, QA, QB = input_init_case1[3], input_init_case1[4], input_init_case1[5]\n",
    "cond_flow = [QF*60/1000*0.25, QA*60/1000*0.25, QB*60/1000*0.25, input_init_case1[2], 2*input_init_case1[2]]\n",
    "initV = [0.7, 0.7, 0.7]\n",
    "\n",
    "norm_inputs_case1 = normalize(cond_init_case1, model_range_mm)\n",
    "init_state_case1 = torch.tensor([norm_inputs_case1 + [0.0]]).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_case1, discharge_case1 = simulator(init_state_case1, simulation_time, cond_flow, initV, track=True)\n",
    "\n",
    "pred_case1_real = denormalize(pred_case1.cpu().numpy(), model_range_mm)\n",
    "hidden_case1 = simulator.tracked_hidden_states\n",
    "phys_chng_case1 = simulator.tracked_phys_chng\n",
    "\n",
    "print(f'Case 1 Steady State CALA: {pred_case1_real[0, -1, 6]:.6f} mol/L')\n",
    "print(f'Case 1 Steady State Current: {pred_case1_real[0, -1, 9]:.6f} A')\n",
    "print(f'Hidden states tracked: {len(hidden_case1)} timesteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "run_case2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Case 2: 30V + E=0.25M (High voltage) ===\n",
      "Case 2 Steady State CALA: 1.480612 mol/L\n",
      "Case 2 Steady State Current: 2.184147 A\n",
      "Hidden states tracked: 199 timesteps\n"
     ]
    }
   ],
   "source": [
    "# === Case 2: 30V + E=0.25M ===\n",
    "print('\\n=== Case 2: 30V + E=0.25M (High voltage) ===')\n",
    "input_init_case2 = [30, 0.25, 3, 10, 10, 10]  # [V, E, CFLA, QF, QA, QB]\n",
    "cond_init_case2 = [input_init_case2[0], input_init_case2[1], 0.7, 0.7, 0.7, \n",
    "                   input_init_case2[2], 0, input_init_case2[1]*2, 0]\n",
    "\n",
    "norm_inputs_case2 = normalize(cond_init_case2, model_range_mm)\n",
    "init_state_case2 = torch.tensor([norm_inputs_case2 + [0.0]]).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_case2, discharge_case2 = simulator(init_state_case2, simulation_time, cond_flow, initV, track=True)\n",
    "\n",
    "pred_case2_real = denormalize(pred_case2.cpu().numpy(), model_range_mm)\n",
    "hidden_case2 = simulator.tracked_hidden_states\n",
    "phys_chng_case2 = simulator.tracked_phys_chng\n",
    "\n",
    "print(f'Case 2 Steady State CALA: {pred_case2_real[0, -1, 6]:.6f} mol/L')\n",
    "print(f'Case 2 Steady State Current: {pred_case2_real[0, -1, 9]:.6f} A')\n",
    "print(f'Hidden states tracked: {len(hidden_case2)} timesteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "run_case3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Case 3: 10V + E=1.0M (High electrolyte) ===\n",
      "Case 3 Steady State CALA: 1.483344 mol/L\n",
      "Case 3 Steady State Current: 1.787252 A\n",
      "Hidden states tracked: 199 timesteps\n"
     ]
    }
   ],
   "source": [
    "# === Case 3: 10V + E=1.0M ===\n",
    "print('\\n=== Case 3: 10V + E=1.0M (High electrolyte) ===')\n",
    "input_init_case3 = [10, 1.0, 3, 10, 10, 10]  # [V, E, CFLA, QF, QA, QB]\n",
    "cond_init_case3 = [input_init_case3[0], input_init_case3[1], 0.7, 0.7, 0.7, \n",
    "                   input_init_case3[2], 0, input_init_case3[1]*2, 0]\n",
    "\n",
    "norm_inputs_case3 = normalize(cond_init_case3, model_range_mm)\n",
    "init_state_case3 = torch.tensor([norm_inputs_case3 + [0.0]]).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_case3, discharge_case3 = simulator(init_state_case3, simulation_time, cond_flow, initV, track=True)\n",
    "\n",
    "pred_case3_real = denormalize(pred_case3.cpu().numpy(), model_range_mm)\n",
    "hidden_case3 = simulator.tracked_hidden_states\n",
    "phys_chng_case3 = simulator.tracked_phys_chng\n",
    "\n",
    "print(f'Case 3 Steady State CALA: {pred_case3_real[0, -1, 6]:.6f} mol/L')\n",
    "print(f'Case 3 Steady State Current: {pred_case3_real[0, -1, 9]:.6f} A')\n",
    "print(f'Hidden states tracked: {len(hidden_case3)} timesteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comparison_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SATURATION PROBLEM DIAGNOSIS\n",
      "======================================================================\n",
      "\n",
      "Case 1 (10V + 0.25M): CALA=0.016107 mol/L, I=0.6951 A\n",
      "Case 2 (30V + 0.25M): CALA=1.480633 mol/L, I=2.1841 A\n",
      "Case 3 (10V + 1.0M):  CALA=1.483366 mol/L, I=1.7873 A\n",
      "\n",
      "🔍 Case 2 vs Case 3 (SATURATION CHECK):\n",
      "   CALA Difference: 0.002733 mol/L (0.18%)\n",
      "   ❌ SATURATION CONFIRMED: Different (V,E) → Same CALA\n",
      "      30V + 0.25M ≈ 10V + 1.0M (both high efficiency → plateau)\n",
      "\n",
      "📊 Case 1 vs High-Efficiency Cases:\n",
      "   Case 1 vs Case 2: 1.464526 mol/L (98.91%)\n",
      "   Case 1 vs Case 3: 1.467259 mol/L (98.91%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# === Three-Way Comparison Summary ===\n",
    "print('\\n' + '='*70)\n",
    "print('SATURATION PROBLEM DIAGNOSIS')\n",
    "print('='*70)\n",
    "\n",
    "time_steps = np.arange(simulation_time) * 0.25\n",
    "ss_start, ss_end = 160, 200\n",
    "\n",
    "# Steady state values\n",
    "CALA_case1_ss = np.mean(pred_case1_real[0, ss_start:ss_end, 6])\n",
    "CALA_case2_ss = np.mean(pred_case2_real[0, ss_start:ss_end, 6])\n",
    "CALA_case3_ss = np.mean(pred_case3_real[0, ss_start:ss_end, 6])\n",
    "\n",
    "I_case1_ss = np.mean(pred_case1_real[0, ss_start:ss_end, 9])\n",
    "I_case2_ss = np.mean(pred_case2_real[0, ss_start:ss_end, 9])\n",
    "I_case3_ss = np.mean(pred_case3_real[0, ss_start:ss_end, 9])\n",
    "\n",
    "print(f'\\nCase 1 (10V + 0.25M): CALA={CALA_case1_ss:.6f} mol/L, I={I_case1_ss:.4f} A')\n",
    "print(f'Case 2 (30V + 0.25M): CALA={CALA_case2_ss:.6f} mol/L, I={I_case2_ss:.4f} A')\n",
    "print(f'Case 3 (10V + 1.0M):  CALA={CALA_case3_ss:.6f} mol/L, I={I_case3_ss:.4f} A')\n",
    "\n",
    "# Case 2 vs Case 3 comparison (should be similar according to user's discovery)\n",
    "CALA_diff_2_3 = abs(CALA_case2_ss - CALA_case3_ss)\n",
    "CALA_diff_2_3_pct = (CALA_diff_2_3 / CALA_case2_ss) * 100\n",
    "\n",
    "print(f'\\n🔍 Case 2 vs Case 3 (SATURATION CHECK):')\n",
    "print(f'   CALA Difference: {CALA_diff_2_3:.6f} mol/L ({CALA_diff_2_3_pct:.2f}%)')\n",
    "\n",
    "if CALA_diff_2_3_pct < 5.0:\n",
    "    print('   ❌ SATURATION CONFIRMED: Different (V,E) → Same CALA')\n",
    "    print('      30V + 0.25M ≈ 10V + 1.0M (both high efficiency → plateau)')\n",
    "else:\n",
    "    print('   ✅ Saturation NOT observed (>5% difference)')\n",
    "\n",
    "# Case 1 vs Case 2/3\n",
    "print(f'\\n📊 Case 1 vs High-Efficiency Cases:')\n",
    "CALA_diff_1_2 = abs(CALA_case1_ss - CALA_case2_ss)\n",
    "CALA_diff_1_2_pct = (CALA_diff_1_2 / CALA_case2_ss) * 100\n",
    "print(f'   Case 1 vs Case 2: {CALA_diff_1_2:.6f} mol/L ({CALA_diff_1_2_pct:.2f}%)')\n",
    "\n",
    "CALA_diff_1_3 = abs(CALA_case1_ss - CALA_case3_ss)\n",
    "CALA_diff_1_3_pct = (CALA_diff_1_3 / CALA_case3_ss) * 100\n",
    "print(f'   Case 1 vs Case 3: {CALA_diff_1_3:.6f} mol/L ({CALA_diff_1_3_pct:.2f}%)')\n",
    "\n",
    "print('\\n' + '='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden_state_analysis",
   "metadata": {},
   "source": [
    "## Hidden State Analysis: Why do Case 2 and Case 3 converge to same CALA?\n",
    "\n",
    "**Key Question**: Case 2 (30V+0.25M) and Case 3 (10V+1M) have different (V, E) inputs but produce identical CALA (~1.48 mol/L).\n",
    "\n",
    "**Hypothesis**: LSTM hidden states become similar over time, causing PhysRegr to predict similar rdNALA values despite different inputs.\n",
    "\n",
    "**This section investigates**:\n",
    "1. **Cosine similarity** between hidden states (Case 2 vs Case 3)\n",
    "2. **Euclidean distance** between hidden states over time\n",
    "3. **rdNALA prediction patterns** across all three cases\n",
    "4. **Early vs Late** timestep comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hidden_similarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HIDDEN STATE SIMILARITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "📊 Case 2 (30V+0.25M) vs Case 3 (10V+1M):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "🔹 Early Timesteps (t=0-20):\n",
      "   t=  0: Cosine Sim=0.9976, Euclidean Dist=0.4741\n",
      "   t=  5: Cosine Sim=0.9853, Euclidean Dist=0.9803\n",
      "   t= 10: Cosine Sim=0.9944, Euclidean Dist=0.6097\n",
      "   t= 20: Cosine Sim=0.9977, Euclidean Dist=0.3853\n",
      "   Average: Cosine Sim=0.9938, Euclidean Dist=0.6124\n",
      "\n",
      "🔹 Late Timesteps (t=100-195):\n",
      "   t=100: Cosine Sim=1.0000, Euclidean Dist=0.0361\n",
      "   t=120: Cosine Sim=1.0000, Euclidean Dist=0.0304\n",
      "   t=140: Cosine Sim=1.0000, Euclidean Dist=0.0289\n",
      "   t=160: Cosine Sim=1.0000, Euclidean Dist=0.0285\n",
      "   t=180: Cosine Sim=1.0000, Euclidean Dist=0.0284\n",
      "   t=195: Cosine Sim=1.0000, Euclidean Dist=0.0284\n",
      "   Average: Cosine Sim=1.0000, Euclidean Dist=0.0301\n",
      "\n",
      "🔍 Convergence Analysis:\n",
      "   ✅ Hidden states CONVERGE over time\n",
      "      Similarity: 0.9938 → 1.0000 (+0.0062)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# === Hidden State Similarity Analysis ===\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('HIDDEN STATE SIMILARITY ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "# Select key timesteps\n",
    "early_t = [0, 5, 10, 20]\n",
    "late_t = [100, 120, 140, 160, 180, 195]\n",
    "\n",
    "def compute_similarity(h1_list, h2_list, timesteps):\n",
    "    similarities = []\n",
    "    distances = []\n",
    "    for t in timesteps:\n",
    "        if t >= len(h1_list) or t >= len(h2_list):\n",
    "            continue\n",
    "        h1 = h1_list[t].numpy().flatten()\n",
    "        h2 = h2_list[t].numpy().flatten()\n",
    "        cos_sim = 1 - cosine(h1, h2)\n",
    "        euc_dist = euclidean(h1, h2)\n",
    "        similarities.append(cos_sim)\n",
    "        distances.append(euc_dist)\n",
    "    return similarities, distances\n",
    "\n",
    "print('\\n📊 Case 2 (30V+0.25M) vs Case 3 (10V+1M):')\n",
    "print('-' * 70)\n",
    "\n",
    "# Early timesteps\n",
    "early_sims, early_dists = compute_similarity(hidden_case2, hidden_case3, early_t)\n",
    "print('\\n🔹 Early Timesteps (t=0-20):')\n",
    "for t, sim, dist in zip(early_t[:len(early_sims)], early_sims, early_dists):\n",
    "    print(f'   t={t:3d}: Cosine Sim={sim:.4f}, Euclidean Dist={dist:.4f}')\n",
    "\n",
    "avg_early_sim = np.mean(early_sims)\n",
    "avg_early_dist = np.mean(early_dists)\n",
    "print(f'   Average: Cosine Sim={avg_early_sim:.4f}, Euclidean Dist={avg_early_dist:.4f}')\n",
    "\n",
    "# Late timesteps\n",
    "late_sims, late_dists = compute_similarity(hidden_case2, hidden_case3, late_t)\n",
    "print('\\n🔹 Late Timesteps (t=100-195):')\n",
    "for t, sim, dist in zip(late_t[:len(late_sims)], late_sims, late_dists):\n",
    "    print(f'   t={t:3d}: Cosine Sim={sim:.4f}, Euclidean Dist={dist:.4f}')\n",
    "\n",
    "avg_late_sim = np.mean(late_sims)\n",
    "avg_late_dist = np.mean(late_dists)\n",
    "print(f'   Average: Cosine Sim={avg_late_sim:.4f}, Euclidean Dist={avg_late_dist:.4f}')\n",
    "\n",
    "print('\\n🔍 Convergence Analysis:')\n",
    "if avg_late_sim > avg_early_sim:\n",
    "    print(f'   ✅ Hidden states CONVERGE over time')\n",
    "    print(f'      Similarity: {avg_early_sim:.4f} → {avg_late_sim:.4f} (+{(avg_late_sim - avg_early_sim):.4f})')\n",
    "else:\n",
    "    print(f'   ⚠️  Hidden states do NOT converge')\n",
    "\n",
    "print('\\n' + '='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
