{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f38071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2a8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM with layer normalization\n",
    "class LayerNormLSTM(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "\n",
    "        self.w_i = nn.Linear(input_node, 4*hidden_node, bias=False)\n",
    "        self.w_h = nn.Linear(hidden_node, 4*hidden_node, bias=False)\n",
    "\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)\n",
    "        self.ln_f = nn.LayerNorm(hidden_node)\n",
    "        self.ln_w = nn.LayerNorm(hidden_node)\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        gi = self.w_i(input)\n",
    "        gh = self.w_h(h_prev)\n",
    "        i_i, i_f, i_w, i_o = gi.chunk(4, dim=-1)\n",
    "        h_i, h_f, h_w, h_o = gh.chunk(4, dim=-1)\n",
    "\n",
    "        i_g = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_g = torch.sigmoid(self.ln_f(i_f + h_f))\n",
    "        w_g = torch.tanh(self.ln_w(i_w + h_w))\n",
    "        o_g = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "        \n",
    "\n",
    "        c_new = f_g * c_prev + i_g * w_g\n",
    "        c_new = self.ln_c(c_new)\n",
    "\n",
    "        h_new = o_g * torch.tanh(c_new)\n",
    "\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State feature extractor using LayerNorm LSTM\n",
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.n_layer = n_layer\n",
    "        self.input_node = input_node\n",
    "\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        self.lstm_cells.append(LayerNormLSTM(input_node, hidden_node))\n",
    "\n",
    "        for i in range(n_layer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTM(hidden_node, hidden_node))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layernorm = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        batch_size, max_len, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "\n",
    "        for _ in range(self.n_layer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            layer_input = x_t # initialize layer input with input tensor\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                \n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "\n",
    "                if layer_idx < len(self.lstm_cells) - 1:\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "\n",
    "                outputs.append(layer_input)\n",
    "\n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)\n",
    "\n",
    "        masked_output = output_tensor * mask\n",
    "        normed_output = self.layernorm(masked_output)\n",
    "        return self.dropout(normed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "843575d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical change regressor\n",
    "class PhysRegr(nn.Module):\n",
    "    def __init__(self, input_node, output_node, n_layer, hidden_node, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(input_node, hidden_node),\n",
    "            nn.LayerNorm(hidden_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "\n",
    "        for _ in range(n_layer - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_node, hidden_node),\n",
    "                nn.LayerNorm(hidden_node),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_node, output_node))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.layers(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf5c7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current regressor\n",
    "class CurrRegr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(input_node, hidden_node),\n",
    "            nn.LayerNorm(hidden_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "\n",
    "        for _ in range(n_layer - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_node, hidden_node),\n",
    "                nn.LayerNorm(hidden_node),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_node, 1))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.layers(hidden_states)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "095dea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical Constraint Layer\n",
    "class PhysConstr(nn.Module):\n",
    "    def __init__(self, range_mm, curr_regr, eps=1e-2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.eps = eps\n",
    "        self.curr_regr = curr_regr\n",
    "        self.register_buffer('range_mm_tensor',self._range2tensor(range_mm))\n",
    "\n",
    "    def _range2tensor(self, range_mm):\n",
    "        feature_names = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK']\n",
    "        ranges = torch.zeros(len(feature_names), 2)\n",
    "\n",
    "        for i, name in enumerate(feature_names):\n",
    "            ranges[i, 0] = range_mm[name]['min']\n",
    "            ranges[i, 1] = range_mm[name]['max']\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    def _norm_tensor(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    def _denorm_tensor(self, norm_data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return norm_data * (max_val - min_val) + min_val\n",
    "\n",
    "    def forward(self, phys_chng, cur_state, fin, initV):\n",
    "        V_idx, E_idx, VF_idx, VA_idx, VB_idx = 0, 1, 2, 3, 4\n",
    "        CFLA_idx, CALA_idx, CFK_idx, CBK_idx, I_idx = 5, 6, 7, 8, 9\n",
    "\n",
    "        VF = self._denorm_tensor(cur_state[..., 2:3], VF_idx)\n",
    "        VA = self._denorm_tensor(cur_state[..., 3:4], VA_idx)\n",
    "        VB = self._denorm_tensor(cur_state[..., 4:5], VB_idx)\n",
    "        CFLA = self._denorm_tensor(cur_state[..., 5:6], CFLA_idx)\n",
    "        CALA = self._denorm_tensor(cur_state[..., 6:7], CALA_idx)\n",
    "        CFK = self._denorm_tensor(cur_state[..., 7:8], CFK_idx)\n",
    "        CBK = self._denorm_tensor(cur_state[..., 8:9], CBK_idx)\n",
    "\n",
    "        ## Flow in parameters\n",
    "        FvF, FvA, FvB, CiLA, CiK = fin\n",
    "\n",
    "        VFi, VAi, VBi = initV\n",
    "\n",
    "        dVF_in, dVA_in, dVB_in = FvF, FvA, FvB\n",
    "        dNFLA_in, dNFK_in = FvF * CiLA, FvF * CiK\n",
    "\n",
    "        dVA = phys_chng[..., 0:1]\n",
    "        dVB = phys_chng[..., 1:2]\n",
    "        rratio = phys_chng[..., 2:3]\n",
    "        dNBK = phys_chng[..., 3:4]\n",
    "\n",
    "        ## physical boundary: dNALA <= dNBK\n",
    "        ratio = torch.sigmoid(rratio)\n",
    "        dNALA = ratio * dNBK\n",
    "\n",
    "        ## Mass Balance\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA\n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        ### conservation\n",
    "        dVA = torch.where(VF < dVA + dVB, torch.zeros_like(dVA), dVA),\n",
    "        dVB = torch.where(VF < dVA + dVB, torch.zeros_like(dVB), dVB)\n",
    "        dNALA = torch.where(NFLA < dNALA, torch.zeros_like(dNALA), dNALA)\n",
    "        dNBK = torch.where(NFK < dNBK, torch.zeros_like(dNBK), dNBK)\n",
    "\n",
    "        ### new states before discharge\n",
    "        nVF_bf = VF - dVA - dVB + dVF_in\n",
    "        nVA_bf = VA + dVA + dVA_in\n",
    "        nVB_bf = VB + dVB + dVB_in\n",
    "\n",
    "        nNFLA_bf = NFLA - dNALA + dNFLA_in\n",
    "        nNALA_bf = NALA + dNALA\n",
    "        nNFK_bf = NFK - dNBK + dNFK_in\n",
    "        nNBK_bf = NBK + dNBK\n",
    "\n",
    "        dVF_out = torch.clamp(nVF_bf - VFi, min=0.0)\n",
    "        dVA_out = torch.clamp(nVA_bf - VAi, min=0.0)\n",
    "        dVB_out = torch.clamp(nVB_bf - VBi, min=0.0)\n",
    "\n",
    "        nVF = nVF_bf - dVF_out\n",
    "        nVA = nVA_bf - dVA_out\n",
    "        nVB = nVB_bf - dVB_out\n",
    "        \n",
    "        Vout_ratioF =  dVF_out / nVF_bf\n",
    "        dNFLA_out, dNFK_out = nNFLA_bf * Vout_ratioF, nNFK_bf * Vout_ratioF\n",
    "\n",
    "        Vout_ratioA = dVA_out / nVA_bf\n",
    "        dNALA_out = nNALA_bf * Vout_ratioA\n",
    "\n",
    "        Vout_ratioB = dVB_out / nVB_bf\n",
    "        dNBK_out = nNBK_bf * Vout_ratioB\n",
    "\n",
    "        ### Final new states\n",
    "        nNFLA = nNFLA_bf - dNFLA_out\n",
    "        nNALA = nNALA_bf - dNALA_out\n",
    "        nNFK = nNFK_bf - dNFK_out\n",
    "        nNBK = nNBK_bf - dNBK_out\n",
    "\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCFK = nNFK / nVF\n",
    "        nCBK = nNBK / nVB\n",
    "\n",
    "        V = cur_state[..., 0:1]\n",
    "        E = cur_state[..., 1:2]\n",
    "\n",
    "        nVF_norm = self._norm_tensor(nVF, VF_idx)\n",
    "        nVA_norm = self._norm_tensor(nVA, VA_idx)\n",
    "        nVB_norm = self._norm_tensor(nVB, VB_idx)\n",
    "        nCFLA_norm = self._norm_tensor(nCFLA, CFLA_idx)\n",
    "        nCALA_norm = self._norm_tensor(nCALA, CALA_idx)\n",
    "        nCFK_norm = self._norm_tensor(nCFK, CFK_idx)\n",
    "        nCBK_norm = self._norm_tensor(nCBK, CBK_idx)\n",
    "\n",
    "        temp_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm\n",
    "        ], dim=-1)\n",
    "\n",
    "        nI_pred = self.curr_regr(temp_state)\n",
    "        nI_real = self._denorm_tensor(nI_pred, I_idx)\n",
    "        nI_real = torch.clamp(nI_real, min=0.0)\n",
    "        nI_norm = self._norm_tensor(nI_real, I_idx)\n",
    "\n",
    "        next_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm, nI_norm\n",
    "        ], dim=-1)\n",
    "\n",
    "        ### discharge\n",
    "        discharge = {\n",
    "            'VF': dVF_out,\n",
    "            'VA': dVA_out,\n",
    "            'VB': dVB_out,\n",
    "            'NFLA': dNFLA_out,\n",
    "            'NALA': dNALA_out,\n",
    "            'NFK': dNFK_out,\n",
    "            'NBK': dNBK_out,\n",
    "            'CFLA': dNFLA_out/dVF_out,\n",
    "            'CALA': dNALA_out/dVA_out,\n",
    "            'CFK': dNFK_out/dVF_out,\n",
    "            'CBK': dNBK_out/dVB_out\n",
    "        }\n",
    "\n",
    "        return next_state, discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b30255df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMED model\n",
    "class BMEDModel(nn.Module):\n",
    "    def __init__(self, state_extr_params, phys_regr_params, curr_regr_params, range_mm):\n",
    "        super().__init__()\n",
    "        self.state_extr = StateExtr(**state_extr_params)\n",
    "        self.phys_regr = PhysRegr(**phys_regr_params)\n",
    "        self.curr_regr = CurrRegr(**curr_regr_params)\n",
    "        self.phys_constr = PhysConstr(range_mm, self.curr_regr)\n",
    "\n",
    "        self._hidden_states = None\n",
    "        self._cell_states = None\n",
    "\n",
    "    def _reset_hidden_states(self, batch_size, device):\n",
    "        self._hidden_states = []\n",
    "        self._cell_states = []\n",
    "        for _ in range(self.state_extr.n_layer):\n",
    "            self._hidden_states.append(torch.zeros(batch_size, self.state_extr.hidden_node, device=device))\n",
    "            self._cell_states.append(torch.zeros(batch_size, self.state_extr.hidden_node, device=device))\n",
    "\n",
    "    def cont_sim(self, init_state, target_len, fin, initV):\n",
    "        batch_size = init_state.size(0)\n",
    "        feature_size = init_state.size(1)\n",
    "        device = init_state.device\n",
    "\n",
    "        self._reset_hidden_states(batch_size, device)\n",
    "\n",
    "        pred = torch.zeros(batch_size, target_len, feature_size, device=device)\n",
    "        discharge_record = []\n",
    "        cur_state = init_state.clone()\n",
    "\n",
    "        for t in range(target_len):\n",
    "            pred[:, t, :] = cur_state\n",
    "\n",
    "            if t < target_len - 1:\n",
    "                lstm_input = cur_state[:, :-1] # except current\n",
    "                hidden_output = self._lstm_single_step(lstm_input)\n",
    "\n",
    "                phys_chng = self.phys_regr(hidden_output.unsqueeze(1))\n",
    "                cur_state_expanded = cur_state.unsqueeze(1)\n",
    "\n",
    "                next_state, discharge = self.phys_constr(\n",
    "                    phys_chng, cur_state_expanded, fin, initV\n",
    "                )\n",
    "\n",
    "                cur_state = next_state.squeeze(1)\n",
    "                discharge_record.append(discharge)\n",
    "        return pred, discharge_record\n",
    "\n",
    "    def _lstm_single_step(self, x_t):\n",
    "        layer_input = x_t\n",
    "\n",
    "        for layer_idx, lstm_cell in enumerate(self.state_extr.lstm_cells):\n",
    "            h_new, c_new = lstm_cell(layer_input, (self._hidden_states[layer_idx], self._cell_states[layer_idx]))\n",
    "            \n",
    "            self._hidden_states[layer_idx] = h_new\n",
    "            self._cell_states[layer_idx] = c_new\n",
    "\n",
    "            if layer_idx < len(self.state_extr.lstm_cells) - 1:\n",
    "                layer_input = self.state_extr.dropout(h_new)\n",
    "            else:\n",
    "                layer_input = h_new # last layer output\n",
    "\n",
    "        normed_output = self.state_extr.layernorm(layer_input)\n",
    "        return self.state_extr.dropout(normed_output)\n",
    "\n",
    "    def forward(self, init_state, target_len, fin, initV):\n",
    "        return self.cont_sim(init_state, target_len, fin, initV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8d406e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "## Normalize input data with the min-max normalization range of pre-trained model\n",
    "def normalize(inputs, range_mm):\n",
    "    features = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK']\n",
    "    norm = []\n",
    "\n",
    "    for _, (name, value) in enumerate(zip(features, inputs)):\n",
    "        min_val = range_mm[name]['min']\n",
    "        max_val = range_mm[name]['max']\n",
    "        norm_val = (value - min_val) / (max_val - min_val)\n",
    "        norm.append(norm_val)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def denormalize(outputs, range_mm):\n",
    "    \"\"\"출력값들을 실제 물리적 값으로 변환\"\"\"\n",
    "    feature_names = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    denormalized = np.zeros_like(outputs)\n",
    "    \n",
    "    for i, name in enumerate(feature_names):\n",
    "        if name in range_mm:\n",
    "            min_val = range_mm[name]['min']\n",
    "            max_val = range_mm[name]['max']\n",
    "            denormalized[:, :, i] = outputs[:, :, i] * (max_val - min_val) + min_val\n",
    "        else:\n",
    "            denormalized[:, :, i] = outputs[:, :, i]\n",
    "    \n",
    "    return denormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e8242d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BMED_FR_250910.pth\n",
      "Device: cuda\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'phys_regr_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m model_config = model[\u001b[33m'\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m state_extr_params = model_config[\u001b[33m'\u001b[39m\u001b[33mstate_extr_params\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m phys_regr_params = \u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphys_regr_params\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m curr_regr_params = model_config[\u001b[33m'\u001b[39m\u001b[33mcurr_regr_params\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m model_range_mm = model_config[\u001b[33m'\u001b[39m\u001b[33mrange_mm\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'phys_regr_params'"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "model_path = 'BMED_FR_250910.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Model: {model_path}')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model_config = model['model_config']\n",
    "state_extr_params = model_config['state_extr_params']\n",
    "phys_regr_params = model_config['phys_regr_params']\n",
    "curr_regr_params = model_config['curr_regr_params']\n",
    "model_range_mm = model_config['range_mm']\n",
    "\n",
    "simulator = BMEDModel(\n",
    "    state_extr_params = state_extr_params,\n",
    "    phys_regr_params = phys_regr_params,\n",
    "    curr_regr_params = curr_regr_params,\n",
    "    range_mm = model_range_mm\n",
    ").to(device)\n",
    "\n",
    "simulator.load_state_dict(model['model_state_dict'])\n",
    "simulator.eval()\n",
    "\n",
    "print('Load model parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15fb4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_range_mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m initV = [\u001b[32m0.7\u001b[39m, \u001b[32m0.7\u001b[39m, \u001b[32m0.7\u001b[39m] \u001b[38;5;66;03m# L\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m## Normalize\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m norm_inputs = normalize(cond_init, \u001b[43mmodel_range_mm\u001b[49m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m## initial state\u001b[39;00m\n\u001b[32m     20\u001b[39m init_normI = \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'model_range_mm' is not defined"
     ]
    }
   ],
   "source": [
    "# Continuous Simulation Conditions\n",
    "\n",
    "## cond_init = [V, E, VF, VA, VB, CFLA, CALA, CFK, CBK]\n",
    "### units = [V, mol/L, L, L, L, mol/L, mol/L, mol/L, mol/L]\n",
    "cond_init = [20, 0.25, 0.7, 0.7, 0.7, 1, 0, 2, 0]\n",
    "simulation_time = 81 # time step to simulate\n",
    "\n",
    "## cond_flow = [QF, QA, QB, CFLA, CFK]\n",
    "### units = [L/step, L/step, L/step, mol/L, mol/L]\n",
    "### 1 time step  = 0.25 hr\n",
    "QF, QA, QB = 10, 10, 10 # mL/min\n",
    "cond_flow = [QF*60/1000*0.25, QA*60/1000*0.25, QB*60/1000*0.25, 1, 2]\n",
    "\n",
    "## initial volume = Overflooding volumes\n",
    "initV = [0.7, 0.7, 0.7] # L\n",
    "\n",
    "## Normalize\n",
    "norm_inputs = normalize(cond_init, model_range_mm)\n",
    "\n",
    "## initial state\n",
    "init_normI = 0.0\n",
    "init_state_values = norm_inputs + [init_normI]\n",
    "init_state_tensor = torch.tensor([init_state_values]).float().to(device)\n",
    "\n",
    "print('Start Continuous BMED Simulation...')\n",
    "print(f'   - initial state: V={cond_init[0]}V, E={cond_init[1]}M')  \n",
    "print(f'   - Overflooding Volume: VF={cond_init[2]}L, VA={cond_init[3]}L, VB={cond_init[4]}L')\n",
    "print(f'   - Flow-in: Feed={QF} mL/min, Acid={QA} mL/min, Base={QB} mL/min')\n",
    "print(f'   - Feed Concentration: LA={cond_flow[3]}M, K={cond_flow[4]}M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a57b47d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Continuous Simulation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     pred, discharge_record = \u001b[43msimulator\u001b[49m(init_state_tensor,simulation_time,cond_flow,initV)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Post processing\u001b[39;00m\n\u001b[32m      6\u001b[39m pred_norm = pred.cpu().numpy()\n",
      "\u001b[31mNameError\u001b[39m: name 'simulator' is not defined"
     ]
    }
   ],
   "source": [
    "# Continuous Simulation\n",
    "with torch.no_grad():\n",
    "    pred, discharge_record = simulator(init_state_tensor,simulation_time,cond_flow,initV)\n",
    "\n",
    "# Post processing\n",
    "pred_norm = pred.cpu().numpy()\n",
    "pred_real = denormalize(pred_norm, model_range_mm)\n",
    "\n",
    "time_steps = np.arange(simulation_time)\n",
    "\n",
    "print('Continuous BMED Simulation Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23fe5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
