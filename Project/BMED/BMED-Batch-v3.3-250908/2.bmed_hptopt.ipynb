{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9342def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from optuna.trial import TrialState\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bbeb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormLSTM(nn.Module):\n",
    "    \"\"\"LSTM layer with layer normalization applied to gates\"\"\"\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "\n",
    "        self.w_i = nn.Linear(input_node, 4 * hidden_node, bias=False)\n",
    "        self.w_h = nn.Linear(hidden_node, 4 * hidden_node, bias=False)\n",
    "\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)\n",
    "        self.ln_h = nn.LayerNorm(hidden_node)\n",
    "        self.ln_g = nn.LayerNorm(hidden_node)\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        gi = self.w_i(input)\n",
    "        gh = self.w_h(h_prev)\n",
    "        i_i, i_f, i_g, i_o = gi.chunk(4, dim=-1)\n",
    "        h_i, h_f, h_g, h_o = gh.chunk(4, dim=-1)\n",
    "\n",
    "        i_g = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_g = torch.sigmoid(self.ln_h(i_f + h_f))\n",
    "        g_g = torch.tanh(self.ln_g(i_g + h_g))\n",
    "        o_g = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "\n",
    "        c_new = f_g * c_prev + i_g * g_g\n",
    "        c_new = self.ln_c(c_new)\n",
    "        h_new = o_g * torch.tanh(c_new)\n",
    "\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8de49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.n_layer = n_layer\n",
    "        self.input_node = input_node\n",
    "\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        self.lstm_cells.append(LayerNormLSTM(input_node, hidden_node))\n",
    "        for _ in range(n_layer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTM(hidden_node, hidden_node))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(hidden_node)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        batch_size, max_len, input_node = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "        for _ in range(self.n_layer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]\n",
    "            layer_input = x_t\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "\n",
    "                if layer_idx < len(self.lstm_cells) - 1:\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "            outputs.append(layer_input)\n",
    "        \n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)\n",
    "        masked_output = output_tensor * mask\n",
    "        normalized = self.final_layer_norm(masked_output)\n",
    "        return self.final_dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adf624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    def __init__(self, input_node, output_node, n_layer, hidden_node, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_node, hidden_node))\n",
    "        self.layers.append(nn.LayerNorm(hidden_node))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        for i in range(n_layer - 1):\n",
    "            self.layers.append(nn.Linear(hidden_node, hidden_node))\n",
    "            self.layers.append(nn.LayerNorm(hidden_node))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Linear(hidden_node, output_node))\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "564cd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentPredictor(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_node, hidden_node))\n",
    "        self.layers.append(nn.LayerNorm(hidden_node))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        for i in range(n_layer - 1):\n",
    "            self.layers.append(nn.Linear(hidden_node, hidden_node))\n",
    "            self.layers.append(nn.LayerNorm(hidden_node))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_node, 1))\n",
    "    \n",
    "    def forward(self, new_state):\n",
    "        x = new_state\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f65d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    def __init__(self, range_mm, current_predictor, eps=1e-2):\n",
    "        super().__init__()\n",
    "        self.sps = eps\n",
    "        self.current_predictor = current_predictor\n",
    "        self.register_buffer('range_mm_tensor', self._convert_range_to_tensor(range_mm))\n",
    "\n",
    "    def _convert_range_to_tensor(self, range_mm):\n",
    "        feature_names = ['V','E','VF','VA','VB','CFLA','CALA','CFK','CBK','I']\n",
    "        ranges = torch.zeros(len(feature_names),2)\n",
    "        for i, name in enumerate(feature_names):\n",
    "            if name in range_mm:\n",
    "                ranges[i, 0] = range_mm[name]['min']\n",
    "                ranges[i, 1] = range_mm[name]['max']\n",
    "        return ranges\n",
    "    \n",
    "    def normalize(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    def denormalize(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return data * (max_val - min_val) + min_val\n",
    "\n",
    "    def forward(self, physical_changes, current_state):\n",
    "        V_idx, E_idx, VF_idx, VA_idx, VB_idx = 0, 1, 2, 3, 4\n",
    "        CFLA_idx, CALA_idx, CFK_idx, CBK_idx, I_idx = 5, 6, 7, 8, 9\n",
    "\n",
    "        VF = self.denormalize(current_state[..., 2:3], VF_idx)\n",
    "        VA = self.denormalize(current_state[..., 3:4], VA_idx)\n",
    "        VB = self.denormalize(current_state[..., 4:5], VB_idx)\n",
    "        CFLA = self.denormalize(current_state[..., 5:6], CFLA_idx)\n",
    "        CALA = self.denormalize(current_state[..., 6:7], CALA_idx)\n",
    "        CFK = self.denormalize(current_state[..., 7:8], CFK_idx)\n",
    "        CBK = self.denormalize(current_state[..., 8:9], CBK_idx)\n",
    "\n",
    "        dVA = physical_changes[..., 0:1]\n",
    "        dVB = physical_changes[..., 1:2]\n",
    "        rratio = physical_changes[..., 2:3]\n",
    "        dNBK = physical_changes[..., 3:4]\n",
    "\n",
    "        ratio = torch.sigmoid(rratio)\n",
    "        dNALA = ratio * dNBK\n",
    "\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA\n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        nVF = VF - dVA - dVB\n",
    "        nVA = VA + dVA\n",
    "        nVB = VB + dVB\n",
    "\n",
    "        nVF = torch.clamp(nVF, min=self.sps)\n",
    "        nVA = torch.clamp(nVA, min=self.sps)\n",
    "        nVB = torch.clamp(nVB, min=self.sps)\n",
    "        \n",
    "        nNFLA = NFLA - torch.clamp(dNALA, min=0.0)\n",
    "        nNALA = NALA + torch.clamp(dNALA, min=0.0)\n",
    "        nNFK = NFK - torch.clamp(dNBK, min=0.0)\n",
    "        nNBK = NBK + torch.clamp(dNBK, min=0.0)\n",
    "\n",
    "        nNFLA = torch.clamp(nNFLA, min=0.0)\n",
    "        nNALA = torch.clamp(nNALA, min=0.0)\n",
    "        nNFK = torch.clamp(nNFK, min=0.0)\n",
    "        nNBK = torch.clamp(nNBK, min=0.0)\n",
    "\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCFK = nNFK / nVF\n",
    "        nCBK = nNBK / nVB\n",
    "\n",
    "        V = current_state[..., 0:1]\n",
    "        E = current_state[..., 1:2]\n",
    "        nVF_norm = self.normalize(nVF, VF_idx)\n",
    "        nVA_norm = self.normalize(nVA, VA_idx)\n",
    "        nVB_norm = self.normalize(nVB, VB_idx)\n",
    "        nCFLA_norm = self.normalize(nCFLA, CFLA_idx)\n",
    "        nCALA_norm = self.normalize(nCALA, CALA_idx)\n",
    "        nCFK_norm = self.normalize(nCFK, CFK_idx)\n",
    "        nCBK_norm = self.normalize(nCBK, CBK_idx)\n",
    "\n",
    "        temp_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm\n",
    "        ], dim=-1)\n",
    "        \n",
    "        nI_pred_norm = self.current_predictor(temp_state)\n",
    "        nI_real = self.denormalize(nI_pred_norm, I_idx)\n",
    "        nI_real = torch.clamp(nI_real, min=0.0)\n",
    "        nI_norm = self.normalize(nI_real, I_idx)\n",
    "\n",
    "        next_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm, nI_norm\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a77ec51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    def __init__(self, state_extr_params, decoder_params, current_predictor_params, range_mm):\n",
    "        super().__init__()\n",
    "        self.state_extr = StateExtr(**state_extr_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.current_predictor = CurrentPredictor(**current_predictor_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer(range_mm, self.current_predictor)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        hidden_states = self.state_extr(x, seq_len)\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        new_x = self.physics_constraint(physical_changes, x)\n",
    "        return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3917c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamScheduler:\n",
    "    def __init__(self, optimizer, model_size, warmup_epochs, factor=1.0):\n",
    "        self.optimizer = optimizer\n",
    "        self.model_size = model_size\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.factor = factor\n",
    "        self.epoch_num = 0\n",
    "\n",
    "    def step_epoch(self):\n",
    "        self.epoch_num += 1\n",
    "        lr = self.factor * (\n",
    "            self.model_size ** (-0.5) *\n",
    "            min(self.epoch_num ** (-0.5), self.epoch_num * self.warmup_epochs ** (-1.5))\n",
    "        )\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b1c08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수들\n",
    "def df_treat(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "\n",
    "    exp_num_list = sorted(ndf['exp'].unique())\n",
    "    return df, ndf, range_mm, exp_num_list\n",
    "\n",
    "def seq_data(ndf, exp_num_list):\n",
    "    seq = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    for exp in exp_num_list:\n",
    "        exp_df = ndf[ndf['exp'] == exp]\n",
    "        seq.append(exp_df[feature_cols].values)\n",
    "    return seq\n",
    "\n",
    "def pad_seq(seq):\n",
    "    max_len = max([len(s) for s in seq])\n",
    "    seq_len = [len(s) for s in seq]\n",
    "    pad_seq = pad_sequence([torch.tensor(s) for s in seq], batch_first=True, padding_value=-1)\n",
    "    return pad_seq, seq_len, max_len\n",
    "\n",
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset\n",
    "\n",
    "def masked_mse_loss(pred, target, seq_len):\n",
    "    batch_size, max_len, features = pred.shape\n",
    "    seq_len_cpu = seq_len.detach().cpu().long()\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "    mask = mask.float().to(pred.device)\n",
    "    loss = F.mse_loss(pred, target, reduction='none')\n",
    "    masked_loss = loss * mask.unsqueeze(-1)\n",
    "    total_loss = masked_loss.sum()\n",
    "    total_elements = mask.sum()\n",
    "    masked_loss = total_loss / total_elements\n",
    "    return masked_loss\n",
    "\n",
    "def tf_data(input_seq, seq_len):\n",
    "    inputs = input_seq[:, :-1, :-1]\n",
    "    targets = input_seq[:, 1:, :]\n",
    "    target_seq_len = seq_len - 1\n",
    "    return inputs, targets, target_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816cee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna trial을 위한 목적 함수\n",
    "    K-fold cross validation을 사용하여 하이퍼파라미터 최적화\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 하이퍼파라미터 제안\n",
    "    # LSTM StateExtractor 파라미터\n",
    "    lstm_hidden_size = trial.suggest_categorical('lstm_hidden_size', [16, 32, 48, 64, 72, 96, 128])\n",
    "    lstm_n_layers = trial.suggest_int('lstm_n_layers', 2, 6, step=1)\n",
    "    lstm_dropout = trial.suggest_float('lstm_dropout', 0.1, 0.5, step=0.1)\n",
    "    \n",
    "    # PhysicalChangeDecoder 파라미터\n",
    "    decoder_hidden_size = trial.suggest_categorical('decoder_hidden_size', [16, 32, 48, 64, 72, 96, 128])\n",
    "    decoder_n_layers = trial.suggest_int('decoder_n_layers', 2, 6, step=1)\n",
    "    decoder_dropout = trial.suggest_float('decoder_dropout', 0.1, 0.6, step=0.1)\n",
    "    \n",
    "    # CurrentPredictor 파라미터\n",
    "    current_hidden_size = trial.suggest_categorical('current_hidden_size', [16, 32, 48, 64, 72, 96, 128])\n",
    "    current_n_layers = trial.suggest_int('current_n_layers', 2, 6, step=1)\n",
    "    current_dropout = trial.suggest_float('current_dropout', 0.1, 0.6, step=0.1)\n",
    "    \n",
    "    # NoamScheduler 파라미터\n",
    "    noam_factor = trial.suggest_float('noam_factor', 0.5, 2.0, step=0.1)\n",
    "    warmup_ratio = trial.suggest_float('warmup_ratio', 0.05, 0.3, step=0.05)\n",
    "    \n",
    "    # Batch size 파라미터\n",
    "    batch_size = trial.suggest_categorical('batch_size', [3, 5, 15])\n",
    "    \n",
    "    # 2. K-fold Cross Validation\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    n_splits = 5\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_losses = []\n",
    "    \n",
    "    # 데이터 로드 (global 변수 사용)\n",
    "    indices = list(range(len(dataset)))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "        print(f\"  🔄 Trial {trial.number}, Fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # 폴드별 데이터셋 준비\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 3. 모델 파라미터 설정\n",
    "        state_extr_params = {\n",
    "            'input_node': 9,\n",
    "            'hidden_node': lstm_hidden_size,\n",
    "            'n_layer': lstm_n_layers,\n",
    "            'dropout': lstm_dropout\n",
    "        }\n",
    "        \n",
    "        decoder_params = {\n",
    "            'input_node': lstm_hidden_size,\n",
    "            'hidden_node': decoder_hidden_size,\n",
    "            'n_layer': decoder_n_layers,\n",
    "            'dropout': decoder_dropout,\n",
    "            'output_node': 4\n",
    "        }\n",
    "        \n",
    "        current_predictor_params = {\n",
    "            'input_node': 9,\n",
    "            'hidden_node': current_hidden_size,\n",
    "            'n_layer': current_n_layers,\n",
    "            'dropout': current_dropout\n",
    "        }\n",
    "        \n",
    "        # 4. 모델 초기화\n",
    "        model = BMEDAutoregressiveModel(state_extr_params, decoder_params, current_predictor_params, range_mm)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 5. 옵티마이저 및 스케줄러 설정\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1.0)\n",
    "        \n",
    "        # 총 에포크 수와 warmup 에포크 계산\n",
    "        total_epochs = 100  # Optuna 최적화를 위해 에포크 수 감소\n",
    "        warmup_epochs = int(total_epochs * warmup_ratio)\n",
    "        \n",
    "        scheduler = NoamScheduler(\n",
    "            optimizer, \n",
    "            model_size=lstm_hidden_size,\n",
    "            warmup_epochs=warmup_epochs,\n",
    "            factor=noam_factor\n",
    "        )\n",
    "        \n",
    "        # 6. 훈련\n",
    "        best_total_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(total_epochs):\n",
    "            # Learning rate 업데이트\n",
    "            current_lr = scheduler.step_epoch()\n",
    "            \n",
    "            # 훈련\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for input_seq, seq_len in train_loader:\n",
    "                try:\n",
    "                    input_seq = input_seq.to(device)\n",
    "                    seq_len = seq_len.to(device)\n",
    "                    \n",
    "                    inputs, targets, target_seq_len = tf_data(input_seq, seq_len)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(inputs, target_seq_len)\n",
    "                    loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                    train_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if train_batches == 0:\n",
    "                break\n",
    "                \n",
    "            train_loss = train_loss / train_batches\n",
    "            \n",
    "            # 검증\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for input_seq, seq_len in val_loader:\n",
    "                    try:\n",
    "                        input_seq = input_seq.to(device)\n",
    "                        seq_len = seq_len.to(device)\n",
    "                        \n",
    "                        inputs, targets, target_seq_len = tf_data(input_seq, seq_len)\n",
    "                        \n",
    "                        pred = model(inputs, target_seq_len)\n",
    "                        loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "                        \n",
    "                        val_loss += loss.item()\n",
    "                        val_batches += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            \n",
    "            if val_batches == 0:\n",
    "                break\n",
    "                \n",
    "            val_loss = val_loss / val_batches\n",
    "            \n",
    "            # Calculate total loss\n",
    "            total_loss = train_loss + val_loss\n",
    "            \n",
    "            # Early stopping\n",
    "            if total_loss < best_total_loss:\n",
    "                best_total_loss = total_loss\n",
    "        \n",
    "        fold_losses.append(best_total_loss)\n",
    "        print(f\"    Fold {fold+1} best total loss: {best_total_loss:.6f}\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del model, optimizer, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 7. K-fold 평균 손실 반환\n",
    "    avg_loss = np.mean(fold_losses)\n",
    "    std_loss = np.std(fold_losses)\n",
    "    \n",
    "    print(f\"  📊 Trial {trial.number} - Average CV Loss: {avg_loss:.6f} (±{std_loss:.6f})\")\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17421f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:25:47,057] A new study created in RDB with name: bmed_tf_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 BMED TF Model Hyperparameter Optimization with Optuna\n",
      "================================================================================\n",
      "📋 데이터 로드 중...\n",
      "   - 총 실험 개수: 15\n",
      "   - 총 데이터 포인트: 15\n",
      "   - 최대 시퀀스 길이: 37\n",
      "🔍 최적화 시작 (총 100 trials)\n",
      "  🔄 Trial 0, Fold 1/5\n",
      "    Fold 1 best total loss: 0.297867\n",
      "  🔄 Trial 0, Fold 2/5\n",
      "    Fold 2 best total loss: 0.300687\n",
      "  🔄 Trial 0, Fold 3/5\n",
      "    Fold 3 best total loss: 0.025844\n",
      "  🔄 Trial 0, Fold 4/5\n",
      "    Fold 4 best total loss: 0.171848\n",
      "  🔄 Trial 0, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:33:01,680] Trial 0 finished with value: 0.22576341001937789 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 6, 'lstm_dropout': 0.4, 'decoder_hidden_size': 48, 'decoder_n_layers': 3, 'decoder_dropout': 0.4, 'current_hidden_size': 48, 'current_n_layers': 5, 'current_dropout': 0.2, 'noam_factor': 1.3, 'warmup_ratio': 0.2, 'batch_size': 5}. Best is trial 0 with value: 0.22576341001937789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.332571\n",
      "  📊 Trial 0 - Average CV Loss: 0.225763 (±0.114101)\n",
      "  🔄 Trial 1, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008599\n",
      "  🔄 Trial 1, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024000\n",
      "  🔄 Trial 1, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019576\n",
      "  🔄 Trial 1, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012959\n",
      "  🔄 Trial 1, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:37:56,473] Trial 1 finished with value: 0.016060342127457262 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.0, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015168\n",
      "  📊 Trial 1 - Average CV Loss: 0.016060 (±0.005320)\n",
      "  🔄 Trial 2, Fold 1/5\n",
      "    Fold 1 best total loss: 0.296965\n",
      "  🔄 Trial 2, Fold 2/5\n",
      "    Fold 2 best total loss: 0.298020\n",
      "  🔄 Trial 2, Fold 3/5\n",
      "    Fold 3 best total loss: 0.200516\n",
      "  🔄 Trial 2, Fold 4/5\n",
      "    Fold 4 best total loss: 0.173378\n",
      "  🔄 Trial 2, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:40:37,943] Trial 2 finished with value: 0.25978163542846844 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 6, 'decoder_dropout': 0.4, 'current_hidden_size': 128, 'current_n_layers': 4, 'current_dropout': 0.1, 'noam_factor': 1.6, 'warmup_ratio': 0.25, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.330029\n",
      "  📊 Trial 2 - Average CV Loss: 0.259782 (±0.061249)\n",
      "  🔄 Trial 3, Fold 1/5\n",
      "    Fold 1 best total loss: 0.324544\n",
      "  🔄 Trial 3, Fold 2/5\n",
      "    Fold 2 best total loss: 0.327052\n",
      "  🔄 Trial 3, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234401\n",
      "  🔄 Trial 3, Fold 4/5\n",
      "    Fold 4 best total loss: 0.213981\n",
      "  🔄 Trial 3, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:42:38,467] Trial 3 finished with value: 0.2911373309791088 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 4, 'lstm_dropout': 0.5, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.5, 'current_hidden_size': 72, 'current_n_layers': 6, 'current_dropout': 0.2, 'noam_factor': 0.6, 'warmup_ratio': 0.1, 'batch_size': 15}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.355709\n",
      "  📊 Trial 3 - Average CV Loss: 0.291137 (±0.056120)\n",
      "  🔄 Trial 4, Fold 1/5\n",
      "    Fold 1 best total loss: 0.018738\n",
      "  🔄 Trial 4, Fold 2/5\n",
      "    Fold 2 best total loss: 0.028830\n",
      "  🔄 Trial 4, Fold 3/5\n",
      "    Fold 3 best total loss: 0.034731\n",
      "  🔄 Trial 4, Fold 4/5\n",
      "    Fold 4 best total loss: 0.028867\n",
      "  🔄 Trial 4, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:47:36,224] Trial 4 finished with value: 0.02819486283697188 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 3, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 48, 'decoder_n_layers': 3, 'decoder_dropout': 0.1, 'current_hidden_size': 72, 'current_n_layers': 4, 'current_dropout': 0.6, 'noam_factor': 0.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.029808\n",
      "  📊 Trial 4 - Average CV Loss: 0.028195 (±0.005208)\n",
      "  🔄 Trial 5, Fold 1/5\n",
      "    Fold 1 best total loss: 0.106601\n",
      "  🔄 Trial 5, Fold 2/5\n",
      "    Fold 2 best total loss: 0.113648\n",
      "  🔄 Trial 5, Fold 3/5\n",
      "    Fold 3 best total loss: 0.079170\n",
      "  🔄 Trial 5, Fold 4/5\n",
      "    Fold 4 best total loss: 0.092028\n",
      "  🔄 Trial 5, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:48:38,923] Trial 5 finished with value: 0.10318072065711022 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 32, 'decoder_n_layers': 5, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 16, 'current_n_layers': 5, 'current_dropout': 0.5, 'noam_factor': 1.3, 'warmup_ratio': 0.2, 'batch_size': 15}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.124456\n",
      "  📊 Trial 5 - Average CV Loss: 0.103181 (±0.015967)\n",
      "  🔄 Trial 6, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317850\n",
      "  🔄 Trial 6, Fold 2/5\n",
      "    Fold 2 best total loss: 0.238262\n",
      "  🔄 Trial 6, Fold 3/5\n",
      "    Fold 3 best total loss: 0.224433\n",
      "  🔄 Trial 6, Fold 4/5\n",
      "    Fold 4 best total loss: 0.089120\n",
      "  🔄 Trial 6, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:56:27,142] Trial 6 finished with value: 0.24337829556316137 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 5, 'lstm_dropout': 0.4, 'decoder_hidden_size': 48, 'decoder_n_layers': 2, 'decoder_dropout': 0.1, 'current_hidden_size': 72, 'current_n_layers': 5, 'current_dropout': 0.4, 'noam_factor': 1.8, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.347226\n",
      "  📊 Trial 6 - Average CV Loss: 0.243378 (±0.090012)\n",
      "  🔄 Trial 7, Fold 1/5\n",
      "    Fold 1 best total loss: 0.324394\n",
      "  🔄 Trial 7, Fold 2/5\n",
      "    Fold 2 best total loss: 0.327049\n",
      "  🔄 Trial 7, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234337\n",
      "  🔄 Trial 7, Fold 4/5\n",
      "    Fold 4 best total loss: 0.213723\n",
      "  🔄 Trial 7, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 22:58:28,590] Trial 7 finished with value: 0.2910341702401638 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.6, 'current_hidden_size': 96, 'current_n_layers': 6, 'current_dropout': 0.2, 'noam_factor': 1.1, 'warmup_ratio': 0.3, 'batch_size': 15}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.355668\n",
      "  📊 Trial 7 - Average CV Loss: 0.291034 (±0.056177)\n",
      "  🔄 Trial 8, Fold 1/5\n",
      "    Fold 1 best total loss: 0.324481\n",
      "  🔄 Trial 8, Fold 2/5\n",
      "    Fold 2 best total loss: 0.327135\n",
      "  🔄 Trial 8, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234403\n",
      "  🔄 Trial 8, Fold 4/5\n",
      "    Fold 4 best total loss: 0.213954\n",
      "  🔄 Trial 8, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:00:26,155] Trial 8 finished with value: 0.29115027114748954 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 4, 'lstm_dropout': 0.5, 'decoder_hidden_size': 128, 'decoder_n_layers': 6, 'decoder_dropout': 0.6, 'current_hidden_size': 128, 'current_n_layers': 3, 'current_dropout': 0.30000000000000004, 'noam_factor': 0.6, 'warmup_ratio': 0.2, 'batch_size': 15}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.355779\n",
      "  📊 Trial 8 - Average CV Loss: 0.291150 (±0.056147)\n",
      "  🔄 Trial 9, Fold 1/5\n",
      "    Fold 1 best total loss: 0.285348\n",
      "  🔄 Trial 9, Fold 2/5\n",
      "    Fold 2 best total loss: 0.325334\n",
      "  🔄 Trial 9, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234461\n",
      "  🔄 Trial 9, Fold 4/5\n",
      "    Fold 4 best total loss: 8.377290\n",
      "  🔄 Trial 9, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:02:22,977] Trial 9 finished with value: 1.9152314707636833 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 4, 'lstm_dropout': 0.4, 'decoder_hidden_size': 128, 'decoder_n_layers': 5, 'decoder_dropout': 0.6, 'current_hidden_size': 48, 'current_n_layers': 6, 'current_dropout': 0.6, 'noam_factor': 1.6, 'warmup_ratio': 0.15000000000000002, 'batch_size': 15}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.353725\n",
      "  📊 Trial 9 - Average CV Loss: 1.915231 (±3.231278)\n",
      "  🔄 Trial 10, Fold 1/5\n",
      "    Fold 1 best total loss: 4.594150\n",
      "  🔄 Trial 10, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018593\n",
      "  🔄 Trial 10, Fold 3/5\n",
      "    Fold 3 best total loss: 0.199501\n",
      "  🔄 Trial 10, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013941\n",
      "  🔄 Trial 10, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:09:26,925] Trial 10 finished with value: 0.968204159848392 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 6, 'lstm_dropout': 0.2, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.1, 'warmup_ratio': 0.05, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014836\n",
      "  📊 Trial 10 - Average CV Loss: 0.968204 (±1.814369)\n",
      "  🔄 Trial 11, Fold 1/5\n",
      "    Fold 1 best total loss: 0.019652\n",
      "  🔄 Trial 11, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024776\n",
      "  🔄 Trial 11, Fold 3/5\n",
      "    Fold 3 best total loss: 0.027485\n",
      "  🔄 Trial 11, Fold 4/5\n",
      "    Fold 4 best total loss: 0.023500\n",
      "  🔄 Trial 11, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:14:21,089] Trial 11 finished with value: 0.0248192482162267 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 3, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.6, 'noam_factor': 0.8, 'warmup_ratio': 0.3, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.028683\n",
      "  📊 Trial 11 - Average CV Loss: 0.024819 (±0.003177)\n",
      "  🔄 Trial 12, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009664\n",
      "  🔄 Trial 12, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020942\n",
      "  🔄 Trial 12, Fold 3/5\n",
      "    Fold 3 best total loss: 0.022193\n",
      "  🔄 Trial 12, Fold 4/5\n",
      "    Fold 4 best total loss: 0.023272\n",
      "  🔄 Trial 12, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:19:14,774] Trial 12 finished with value: 0.018885088921524584 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 0.9, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.018354\n",
      "  📊 Trial 12 - Average CV Loss: 0.018885 (±0.004894)\n",
      "  🔄 Trial 13, Fold 1/5\n",
      "    Fold 1 best total loss: 0.316381\n",
      "  🔄 Trial 13, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021336\n",
      "  🔄 Trial 13, Fold 3/5\n",
      "    Fold 3 best total loss: 0.223397\n",
      "  🔄 Trial 13, Fold 4/5\n",
      "    Fold 4 best total loss: 0.200010\n",
      "  🔄 Trial 13, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:24:07,874] Trial 13 finished with value: 0.22150124390609563 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 72, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 64, 'current_n_layers': 3, 'current_dropout': 0.4, 'noam_factor': 1.0, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.346382\n",
      "  📊 Trial 13 - Average CV Loss: 0.221501 (±0.114131)\n",
      "  🔄 Trial 14, Fold 1/5\n",
      "    Fold 1 best total loss: 0.295806\n",
      "  🔄 Trial 14, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020641\n",
      "  🔄 Trial 14, Fold 3/5\n",
      "    Fold 3 best total loss: 0.205355\n",
      "  🔄 Trial 14, Fold 4/5\n",
      "    Fold 4 best total loss: 0.018460\n",
      "  🔄 Trial 14, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:30:05,443] Trial 14 finished with value: 0.11117777686255674 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 2, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 0.9, 'warmup_ratio': 0.1, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015626\n",
      "  📊 Trial 14 - Average CV Loss: 0.111178 (±0.117372)\n",
      "  🔄 Trial 15, Fold 1/5\n",
      "    Fold 1 best total loss: 0.315273\n",
      "  🔄 Trial 15, Fold 2/5\n",
      "    Fold 2 best total loss: 0.307139\n",
      "  🔄 Trial 15, Fold 3/5\n",
      "    Fold 3 best total loss: 0.033421\n",
      "  🔄 Trial 15, Fold 4/5\n",
      "    Fold 4 best total loss: 0.197569\n",
      "  🔄 Trial 15, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:34:56,164] Trial 15 finished with value: 0.23945311047136783 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.5, 'noam_factor': 1.4, 'warmup_ratio': 0.05, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.343862\n",
      "  📊 Trial 15 - Average CV Loss: 0.239453 (±0.114398)\n",
      "  🔄 Trial 16, Fold 1/5\n",
      "    Fold 1 best total loss: 0.020053\n",
      "  🔄 Trial 16, Fold 2/5\n",
      "    Fold 2 best total loss: 0.026035\n",
      "  🔄 Trial 16, Fold 3/5\n",
      "    Fold 3 best total loss: 0.027117\n",
      "  🔄 Trial 16, Fold 4/5\n",
      "    Fold 4 best total loss: 0.021202\n",
      "  🔄 Trial 16, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:40:50,177] Trial 16 finished with value: 0.023704127377520007 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 3, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 0.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.024115\n",
      "  📊 Trial 16 - Average CV Loss: 0.023704 (±0.002714)\n",
      "  🔄 Trial 17, Fold 1/5\n",
      "    Fold 1 best total loss: 0.295481\n",
      "  🔄 Trial 17, Fold 2/5\n",
      "    Fold 2 best total loss: 0.299948\n",
      "  🔄 Trial 17, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017680\n",
      "  🔄 Trial 17, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011888\n",
      "  🔄 Trial 17, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:43:28,793] Trial 17 finished with value: 0.19116326981845 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 32, 'decoder_n_layers': 5, 'decoder_dropout': 0.2, 'current_hidden_size': 96, 'current_n_layers': 3, 'current_dropout': 0.30000000000000004, 'noam_factor': 0.8, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.330819\n",
      "  📊 Trial 17 - Average CV Loss: 0.191163 (±0.144538)\n",
      "  🔄 Trial 18, Fold 1/5\n",
      "    Fold 1 best total loss: 0.318050\n",
      "  🔄 Trial 18, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024385\n",
      "  🔄 Trial 18, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021074\n",
      "  🔄 Trial 18, Fold 4/5\n",
      "    Fold 4 best total loss: 0.198803\n",
      "  🔄 Trial 18, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:48:16,380] Trial 18 finished with value: 0.18204652338754385 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 64, 'current_n_layers': 2, 'current_dropout': 0.5, 'noam_factor': 1.1, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.347920\n",
      "  📊 Trial 18 - Average CV Loss: 0.182047 (±0.139328)\n",
      "  🔄 Trial 19, Fold 1/5\n",
      "    Fold 1 best total loss: 0.296316\n",
      "  🔄 Trial 19, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024961\n",
      "  🔄 Trial 19, Fold 3/5\n",
      "    Fold 3 best total loss: 0.030342\n",
      "  🔄 Trial 19, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013002\n",
      "  🔄 Trial 19, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 23:55:07,490] Trial 19 finished with value: 0.07746099115659794 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 5, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 72, 'decoder_n_layers': 3, 'decoder_dropout': 0.4, 'current_hidden_size': 16, 'current_n_layers': 4, 'current_dropout': 0.1, 'noam_factor': 0.7, 'warmup_ratio': 0.05, 'batch_size': 5}. Best is trial 1 with value: 0.016060342127457262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.022684\n",
      "  📊 Trial 19 - Average CV Loss: 0.077461 (±0.109571)\n",
      "  🔄 Trial 20, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010686\n",
      "  🔄 Trial 20, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021828\n",
      "  🔄 Trial 20, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018276\n",
      "  🔄 Trial 20, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014285\n",
      "  🔄 Trial 20, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:00:56,288] Trial 20 finished with value: 0.01600659122923389 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 20 with value: 0.01600659122923389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014958\n",
      "  📊 Trial 20 - Average CV Loss: 0.016007 (±0.003779)\n",
      "  🔄 Trial 21, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012517\n",
      "  🔄 Trial 21, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318701\n",
      "  🔄 Trial 21, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015580\n",
      "  🔄 Trial 21, Fold 4/5\n",
      "    Fold 4 best total loss: 4.714937\n",
      "  🔄 Trial 21, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:06:41,418] Trial 21 finished with value: 1.966023700265214 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 2.0, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 20 with value: 0.01600659122923389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 4.768384\n",
      "  📊 Trial 21 - Average CV Loss: 1.966024 (±2.269090)\n",
      "  🔄 Trial 22, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009513\n",
      "  🔄 Trial 22, Fold 2/5\n",
      "    Fold 2 best total loss: 0.320064\n",
      "  🔄 Trial 22, Fold 3/5\n",
      "    Fold 3 best total loss: 0.224359\n",
      "  🔄 Trial 22, Fold 4/5\n",
      "    Fold 4 best total loss: 4.699104\n",
      "  🔄 Trial 22, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:14:19,073] Trial 22 finished with value: 1.1198883177479728 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.6, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 20 with value: 0.01600659122923389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.346402\n",
      "  📊 Trial 22 - Average CV Loss: 1.119888 (±1.793527)\n",
      "  🔄 Trial 23, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008635\n",
      "  🔄 Trial 23, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020152\n",
      "  🔄 Trial 23, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017114\n",
      "  🔄 Trial 23, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011654\n",
      "  🔄 Trial 23, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:18:16,600] Trial 23 finished with value: 0.014941661176271737 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.4, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017154\n",
      "  📊 Trial 23 - Average CV Loss: 0.014942 (±0.004180)\n",
      "  🔄 Trial 24, Fold 1/5\n",
      "    Fold 1 best total loss: 0.013651\n",
      "  🔄 Trial 24, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019599\n",
      "  🔄 Trial 24, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018254\n",
      "  🔄 Trial 24, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014591\n",
      "  🔄 Trial 24, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:22:21,518] Trial 24 finished with value: 0.01724691520212218 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.020139\n",
      "  📊 Trial 24 - Average CV Loss: 0.017247 (±0.002642)\n",
      "  🔄 Trial 25, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009901\n",
      "  🔄 Trial 25, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018289\n",
      "  🔄 Trial 25, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020910\n",
      "  🔄 Trial 25, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013141\n",
      "  🔄 Trial 25, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:26:26,254] Trial 25 finished with value: 0.015392155782319606 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014718\n",
      "  📊 Trial 25 - Average CV Loss: 0.015392 (±0.003860)\n",
      "  🔄 Trial 26, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011043\n",
      "  🔄 Trial 26, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020642\n",
      "  🔄 Trial 26, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021087\n",
      "  🔄 Trial 26, Fold 4/5\n",
      "    Fold 4 best total loss: 0.021018\n",
      "  🔄 Trial 26, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:30:34,985] Trial 26 finished with value: 0.017632700805552303 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 4, 'current_dropout': 0.2, 'noam_factor': 1.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014373\n",
      "  📊 Trial 26 - Average CV Loss: 0.017633 (±0.004159)\n",
      "  🔄 Trial 27, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011417\n",
      "  🔄 Trial 27, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317965\n",
      "  🔄 Trial 27, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020854\n",
      "  🔄 Trial 27, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016433\n",
      "  🔄 Trial 27, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:34:43,813] Trial 27 finished with value: 0.076582099404186 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 64, 'current_n_layers': 3, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016242\n",
      "  📊 Trial 27 - Average CV Loss: 0.076582 (±0.120728)\n",
      "  🔄 Trial 28, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317180\n",
      "  🔄 Trial 28, Fold 2/5\n",
      "    Fold 2 best total loss: 4.466065\n",
      "  🔄 Trial 28, Fold 3/5\n",
      "    Fold 3 best total loss: 0.226520\n",
      "  🔄 Trial 28, Fold 4/5\n",
      "    Fold 4 best total loss: 0.202863\n",
      "  🔄 Trial 28, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:38:44,912] Trial 28 finished with value: 1.1119010254275055 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 128, 'current_n_layers': 4, 'current_dropout': 0.1, 'noam_factor': 2.0, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 23 with value: 0.014941661176271737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.346878\n",
      "  📊 Trial 28 - Average CV Loss: 1.111901 (±1.677945)\n",
      "  🔄 Trial 29, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009705\n",
      "  🔄 Trial 29, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022907\n",
      "  🔄 Trial 29, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017617\n",
      "  🔄 Trial 29, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010752\n",
      "  🔄 Trial 29, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:41:58,059] Trial 29 finished with value: 0.014544721913989634 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 96, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.3, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011743\n",
      "  📊 Trial 29 - Average CV Loss: 0.014545 (±0.005001)\n",
      "  🔄 Trial 30, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009897\n",
      "  🔄 Trial 30, Fold 2/5\n",
      "    Fold 2 best total loss: 0.025612\n",
      "  🔄 Trial 30, Fold 3/5\n",
      "    Fold 3 best total loss: 0.025587\n",
      "  🔄 Trial 30, Fold 4/5\n",
      "    Fold 4 best total loss: 0.015730\n",
      "  🔄 Trial 30, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:45:17,043] Trial 30 finished with value: 0.01915533172432333 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 16, 'decoder_n_layers': 3, 'decoder_dropout': 0.4, 'current_hidden_size': 48, 'current_n_layers': 5, 'current_dropout': 0.2, 'noam_factor': 1.3, 'warmup_ratio': 0.3, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.018950\n",
      "  📊 Trial 30 - Average CV Loss: 0.019155 (±0.006009)\n",
      "  🔄 Trial 31, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011590\n",
      "  🔄 Trial 31, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016196\n",
      "  🔄 Trial 31, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021661\n",
      "  🔄 Trial 31, Fold 4/5\n",
      "    Fold 4 best total loss: 0.205474\n",
      "  🔄 Trial 31, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:48:36,330] Trial 31 finished with value: 0.054561087884940206 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 96, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.4, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017884\n",
      "  📊 Trial 31 - Average CV Loss: 0.054561 (±0.075526)\n",
      "  🔄 Trial 32, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008202\n",
      "  🔄 Trial 32, Fold 2/5\n",
      "    Fold 2 best total loss: 0.017565\n",
      "  🔄 Trial 32, Fold 3/5\n",
      "    Fold 3 best total loss: 0.224468\n",
      "  🔄 Trial 32, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011916\n",
      "  🔄 Trial 32, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:51:54,705] Trial 32 finished with value: 0.05459297182969749 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010814\n",
      "  📊 Trial 32 - Average CV Loss: 0.054593 (±0.084993)\n",
      "  🔄 Trial 33, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010955\n",
      "  🔄 Trial 33, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024247\n",
      "  🔄 Trial 33, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021782\n",
      "  🔄 Trial 33, Fold 4/5\n",
      "    Fold 4 best total loss: 0.015842\n",
      "  🔄 Trial 33, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:56:39,678] Trial 33 finished with value: 0.01844671805156395 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 48, 'current_n_layers': 4, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.2000000000000002, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.019407\n",
      "  📊 Trial 33 - Average CV Loss: 0.018447 (±0.004661)\n",
      "  🔄 Trial 34, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009785\n",
      "  🔄 Trial 34, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024053\n",
      "  🔄 Trial 34, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017350\n",
      "  🔄 Trial 34, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016693\n",
      "  🔄 Trial 34, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 00:59:55,087] Trial 34 finished with value: 0.016511898033786564 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 72, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014679\n",
      "  📊 Trial 34 - Average CV Loss: 0.016512 (±0.004609)\n",
      "  🔄 Trial 35, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317680\n",
      "  🔄 Trial 35, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319469\n",
      "  🔄 Trial 35, Fold 3/5\n",
      "    Fold 3 best total loss: 0.225759\n",
      "  🔄 Trial 35, Fold 4/5\n",
      "    Fold 4 best total loss: 0.196867\n",
      "  🔄 Trial 35, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:04:37,284] Trial 35 finished with value: 0.21467932417290286 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 128, 'decoder_n_layers': 3, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 96, 'current_n_layers': 4, 'current_dropout': 0.2, 'noam_factor': 1.4, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013622\n",
      "  📊 Trial 35 - Average CV Loss: 0.214679 (±0.111762)\n",
      "  🔄 Trial 36, Fold 1/5\n",
      "    Fold 1 best total loss: 0.316824\n",
      "  🔄 Trial 36, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319132\n",
      "  🔄 Trial 36, Fold 3/5\n",
      "    Fold 3 best total loss: 0.223100\n",
      "  🔄 Trial 36, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012668\n",
      "  🔄 Trial 36, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:07:54,001] Trial 36 finished with value: 0.17666960114147515 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 32, 'decoder_n_layers': 2, 'decoder_dropout': 0.5, 'current_hidden_size': 72, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.2000000000000002, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011624\n",
      "  📊 Trial 36 - Average CV Loss: 0.176670 (±0.138731)\n",
      "  🔄 Trial 37, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011665\n",
      "  🔄 Trial 37, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020214\n",
      "  🔄 Trial 37, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017485\n",
      "  🔄 Trial 37, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016392\n",
      "  🔄 Trial 37, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:11:16,201] Trial 37 finished with value: 0.01638549685012549 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016172\n",
      "  📊 Trial 37 - Average CV Loss: 0.016385 (±0.002764)\n",
      "  🔄 Trial 38, Fold 1/5\n",
      "    Fold 1 best total loss: 0.324392\n",
      "  🔄 Trial 38, Fold 2/5\n",
      "    Fold 2 best total loss: 0.327046\n",
      "  🔄 Trial 38, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234302\n",
      "  🔄 Trial 38, Fold 4/5\n",
      "    Fold 4 best total loss: 0.213753\n",
      "  🔄 Trial 38, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:12:43,096] Trial 38 finished with value: 0.29104147776961325 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 48, 'current_n_layers': 4, 'current_dropout': 0.2, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 15}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.355715\n",
      "  📊 Trial 38 - Average CV Loss: 0.291041 (±0.056185)\n",
      "  🔄 Trial 39, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317246\n",
      "  🔄 Trial 39, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319768\n",
      "  🔄 Trial 39, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016386\n",
      "  🔄 Trial 39, Fold 4/5\n",
      "    Fold 4 best total loss: 0.202172\n",
      "  🔄 Trial 39, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:16:01,188] Trial 39 finished with value: 0.1740022792830132 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 16, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 128, 'current_n_layers': 3, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014439\n",
      "  📊 Trial 39 - Average CV Loss: 0.174002 (±0.136282)\n",
      "  🔄 Trial 40, Fold 1/5\n",
      "    Fold 1 best total loss: 0.024275\n",
      "  🔄 Trial 40, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022371\n",
      "  🔄 Trial 40, Fold 3/5\n",
      "    Fold 3 best total loss: 0.031920\n",
      "  🔄 Trial 40, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012409\n",
      "  🔄 Trial 40, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:17:27,007] Trial 40 finished with value: 0.022771335393190383 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.5, 'decoder_hidden_size': 48, 'decoder_n_layers': 4, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 32, 'current_n_layers': 5, 'current_dropout': 0.1, 'noam_factor': 1.6, 'warmup_ratio': 0.25, 'batch_size': 15}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.022881\n",
      "  📊 Trial 40 - Average CV Loss: 0.022771 (±0.006221)\n",
      "  🔄 Trial 41, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009447\n",
      "  🔄 Trial 41, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021105\n",
      "  🔄 Trial 41, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020687\n",
      "  🔄 Trial 41, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016289\n",
      "  🔄 Trial 41, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:22:11,279] Trial 41 finished with value: 0.016806533777465424 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.2000000000000002, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016505\n",
      "  📊 Trial 41 - Average CV Loss: 0.016807 (±0.004197)\n",
      "  🔄 Trial 42, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011384\n",
      "  🔄 Trial 42, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019877\n",
      "  🔄 Trial 42, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020695\n",
      "  🔄 Trial 42, Fold 4/5\n",
      "    Fold 4 best total loss: 0.023083\n",
      "  🔄 Trial 42, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:26:54,759] Trial 42 finished with value: 0.018482477683573962 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.2, 'noam_factor': 1.3, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017373\n",
      "  📊 Trial 42 - Average CV Loss: 0.018482 (±0.003991)\n",
      "  🔄 Trial 43, Fold 1/5\n",
      "    Fold 1 best total loss: 0.295817\n",
      "  🔄 Trial 43, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018144\n",
      "  🔄 Trial 43, Fold 3/5\n",
      "    Fold 3 best total loss: 0.195076\n",
      "  🔄 Trial 43, Fold 4/5\n",
      "    Fold 4 best total loss: 0.174412\n",
      "  🔄 Trial 43, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:33:48,829] Trial 43 finished with value: 0.139532830628256 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 72, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.0, 'warmup_ratio': 0.2, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014215\n",
      "  📊 Trial 43 - Average CV Loss: 0.139533 (±0.108781)\n",
      "  🔄 Trial 44, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010161\n",
      "  🔄 Trial 44, Fold 2/5\n",
      "    Fold 2 best total loss: 0.301134\n",
      "  🔄 Trial 44, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018695\n",
      "  🔄 Trial 44, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013100\n",
      "  🔄 Trial 44, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:36:19,001] Trial 44 finished with value: 0.07141417941699425 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 4, 'decoder_dropout': 0.5, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013981\n",
      "  📊 Trial 44 - Average CV Loss: 0.071414 (±0.114893)\n",
      "  🔄 Trial 45, Fold 1/5\n",
      "    Fold 1 best total loss: 0.106049\n",
      "  🔄 Trial 45, Fold 2/5\n",
      "    Fold 2 best total loss: 0.049768\n",
      "  🔄 Trial 45, Fold 3/5\n",
      "    Fold 3 best total loss: 0.234378\n",
      "  🔄 Trial 45, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014781\n",
      "  🔄 Trial 45, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:37:45,831] Trial 45 finished with value: 0.08869002889841796 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 128, 'decoder_n_layers': 4, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.4, 'warmup_ratio': 0.1, 'batch_size': 15}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.038475\n",
      "  📊 Trial 45 - Average CV Loss: 0.088690 (±0.078772)\n",
      "  🔄 Trial 46, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011830\n",
      "  🔄 Trial 46, Fold 2/5\n",
      "    Fold 2 best total loss: 0.026048\n",
      "  🔄 Trial 46, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015658\n",
      "  🔄 Trial 46, Fold 4/5\n",
      "    Fold 4 best total loss: 0.019634\n",
      "  🔄 Trial 46, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:41:01,736] Trial 46 finished with value: 0.017703988775610923 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 32, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 4, 'current_dropout': 0.2, 'noam_factor': 1.0, 'warmup_ratio': 0.3, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015350\n",
      "  📊 Trial 46 - Average CV Loss: 0.017704 (±0.004849)\n",
      "  🔄 Trial 47, Fold 1/5\n",
      "    Fold 1 best total loss: 0.006688\n",
      "  🔄 Trial 47, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318914\n",
      "  🔄 Trial 47, Fold 3/5\n",
      "    Fold 3 best total loss: 0.224443\n",
      "  🔄 Trial 47, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010932\n",
      "  🔄 Trial 47, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:47:17,300] Trial 47 finished with value: 0.11399698656750842 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 4, 'lstm_dropout': 0.4, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 96, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 1.1, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.009008\n",
      "  📊 Trial 47 - Average CV Loss: 0.113997 (±0.132174)\n",
      "  🔄 Trial 48, Fold 1/5\n",
      "    Fold 1 best total loss: 0.295751\n",
      "  🔄 Trial 48, Fold 2/5\n",
      "    Fold 2 best total loss: 0.299367\n",
      "  🔄 Trial 48, Fold 3/5\n",
      "    Fold 3 best total loss: 0.027372\n",
      "  🔄 Trial 48, Fold 4/5\n",
      "    Fold 4 best total loss: 0.171279\n",
      "  🔄 Trial 48, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:50:54,105] Trial 48 finished with value: 0.22470373790711165 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 48, 'current_n_layers': 4, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.329750\n",
      "  📊 Trial 48 - Average CV Loss: 0.224704 (±0.112651)\n",
      "  🔄 Trial 49, Fold 1/5\n",
      "    Fold 1 best total loss: 0.315746\n",
      "  🔄 Trial 49, Fold 2/5\n",
      "    Fold 2 best total loss: 0.320902\n",
      "  🔄 Trial 49, Fold 3/5\n",
      "    Fold 3 best total loss: 0.014109\n",
      "  🔄 Trial 49, Fold 4/5\n",
      "    Fold 4 best total loss: 0.199945\n",
      "  🔄 Trial 49, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 01:58:28,715] Trial 49 finished with value: 0.2393215410062112 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 5, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 64, 'decoder_n_layers': 3, 'decoder_dropout': 0.2, 'current_hidden_size': 128, 'current_n_layers': 2, 'current_dropout': 0.2, 'noam_factor': 1.2000000000000002, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.345905\n",
      "  📊 Trial 49 - Average CV Loss: 0.239322 (±0.123392)\n",
      "  🔄 Trial 50, Fold 1/5\n",
      "    Fold 1 best total loss: 0.029075\n",
      "  🔄 Trial 50, Fold 2/5\n",
      "    Fold 2 best total loss: 0.327007\n",
      "  🔄 Trial 50, Fold 3/5\n",
      "    Fold 3 best total loss: 0.097670\n",
      "  🔄 Trial 50, Fold 4/5\n",
      "    Fold 4 best total loss: 0.023543\n",
      "  🔄 Trial 50, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:00:20,224] Trial 50 finished with value: 0.16402089316397905 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.2, 'decoder_hidden_size': 96, 'decoder_n_layers': 2, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.3, 'warmup_ratio': 0.1, 'batch_size': 15}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.342810\n",
      "  📊 Trial 50 - Average CV Loss: 0.164021 (±0.142040)\n",
      "  🔄 Trial 51, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011677\n",
      "  🔄 Trial 51, Fold 2/5\n",
      "    Fold 2 best total loss: 0.251614\n",
      "  🔄 Trial 51, Fold 3/5\n",
      "    Fold 3 best total loss: 0.025528\n",
      "  🔄 Trial 51, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013930\n",
      "  🔄 Trial 51, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:03:37,607] Trial 51 finished with value: 0.06397097813896835 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017106\n",
      "  📊 Trial 51 - Average CV Loss: 0.063971 (±0.093939)\n",
      "  🔄 Trial 52, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011403\n",
      "  🔄 Trial 52, Fold 2/5\n",
      "    Fold 2 best total loss: 0.023063\n",
      "  🔄 Trial 52, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020360\n",
      "  🔄 Trial 52, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014357\n",
      "  🔄 Trial 52, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:06:53,386] Trial 52 finished with value: 0.016862348862923683 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.5, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015128\n",
      "  📊 Trial 52 - Average CV Loss: 0.016862 (±0.004237)\n",
      "  🔄 Trial 53, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012066\n",
      "  🔄 Trial 53, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019194\n",
      "  🔄 Trial 53, Fold 3/5\n",
      "    Fold 3 best total loss: 0.022622\n",
      "  🔄 Trial 53, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014895\n",
      "  🔄 Trial 53, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:10:06,355] Trial 53 finished with value: 0.017333247419446706 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017890\n",
      "  📊 Trial 53 - Average CV Loss: 0.017333 (±0.003618)\n",
      "  🔄 Trial 54, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012686\n",
      "  🔄 Trial 54, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319048\n",
      "  🔄 Trial 54, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018692\n",
      "  🔄 Trial 54, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013266\n",
      "  🔄 Trial 54, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:13:19,584] Trial 54 finished with value: 0.07643508678302169 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.018485\n",
      "  📊 Trial 54 - Average CV Loss: 0.076435 (±0.121332)\n",
      "  🔄 Trial 55, Fold 1/5\n",
      "    Fold 1 best total loss: 0.315788\n",
      "  🔄 Trial 55, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319090\n",
      "  🔄 Trial 55, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016558\n",
      "  🔄 Trial 55, Fold 4/5\n",
      "    Fold 4 best total loss: 0.202222\n",
      "  🔄 Trial 55, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:18:01,894] Trial 55 finished with value: 0.24003451981116086 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 72, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 64, 'current_n_layers': 2, 'current_dropout': 0.1, 'noam_factor': 2.0, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.346515\n",
      "  📊 Trial 55 - Average CV Loss: 0.240035 (±0.122228)\n",
      "  🔄 Trial 56, Fold 1/5\n",
      "    Fold 1 best total loss: 0.097056\n",
      "  🔄 Trial 56, Fold 2/5\n",
      "    Fold 2 best total loss: 1.085958\n",
      "  🔄 Trial 56, Fold 3/5\n",
      "    Fold 3 best total loss: 0.033701\n",
      "  🔄 Trial 56, Fold 4/5\n",
      "    Fold 4 best total loss: 0.026497\n",
      "  🔄 Trial 56, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:20:33,346] Trial 56 finished with value: 0.2719079023227095 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 5, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.4, 'warmup_ratio': 0.25, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.116328\n",
      "  📊 Trial 56 - Average CV Loss: 0.271908 (±0.408516)\n",
      "  🔄 Trial 57, Fold 1/5\n",
      "    Fold 1 best total loss: 0.013738\n",
      "  🔄 Trial 57, Fold 2/5\n",
      "    Fold 2 best total loss: 0.151306\n",
      "  🔄 Trial 57, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018689\n",
      "  🔄 Trial 57, Fold 4/5\n",
      "    Fold 4 best total loss: 0.021470\n",
      "  🔄 Trial 57, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:25:13,722] Trial 57 finished with value: 0.044436062895692886 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 128, 'decoder_n_layers': 3, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2, 'noam_factor': 1.8, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016978\n",
      "  📊 Trial 57 - Average CV Loss: 0.044436 (±0.053494)\n",
      "  🔄 Trial 58, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007674\n",
      "  🔄 Trial 58, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319473\n",
      "  🔄 Trial 58, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016766\n",
      "  🔄 Trial 58, Fold 4/5\n",
      "    Fold 4 best total loss: 0.196507\n",
      "  🔄 Trial 58, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:28:30,095] Trial 58 finished with value: 0.17800884788739496 and parameters: {'lstm_hidden_size': 96, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 16, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 72, 'current_n_layers': 4, 'current_dropout': 0.1, 'noam_factor': 0.9, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.349623\n",
      "  📊 Trial 58 - Average CV Loss: 0.178009 (±0.144789)\n",
      "  🔄 Trial 59, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317557\n",
      "  🔄 Trial 59, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319782\n",
      "  🔄 Trial 59, Fold 3/5\n",
      "    Fold 3 best total loss: 0.037455\n",
      "  🔄 Trial 59, Fold 4/5\n",
      "    Fold 4 best total loss: 0.026245\n",
      "  🔄 Trial 59, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:33:11,471] Trial 59 finished with value: 0.14721536273136734 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.6, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.035037\n",
      "  📊 Trial 59 - Average CV Loss: 0.147215 (±0.140043)\n",
      "  🔄 Trial 60, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012472\n",
      "  🔄 Trial 60, Fold 2/5\n",
      "    Fold 2 best total loss: 0.023078\n",
      "  🔄 Trial 60, Fold 3/5\n",
      "    Fold 3 best total loss: 0.028660\n",
      "  🔄 Trial 60, Fold 4/5\n",
      "    Fold 4 best total loss: 0.019439\n",
      "  🔄 Trial 60, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:35:43,509] Trial 60 finished with value: 0.028082722689335548 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 4, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 32, 'current_n_layers': 6, 'current_dropout': 0.2, 'noam_factor': 1.1, 'warmup_ratio': 0.15000000000000002, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.056765\n",
      "  📊 Trial 60 - Average CV Loss: 0.028083 (±0.015274)\n",
      "  🔄 Trial 61, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008838\n",
      "  🔄 Trial 61, Fold 2/5\n",
      "    Fold 2 best total loss: 3.431604\n",
      "  🔄 Trial 61, Fold 3/5\n",
      "    Fold 3 best total loss: 0.025349\n",
      "  🔄 Trial 61, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013844\n",
      "  🔄 Trial 61, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:38:58,957] Trial 61 finished with value: 0.7652774012065493 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 72, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.346751\n",
      "  📊 Trial 61 - Average CV Loss: 0.765277 (±1.339314)\n",
      "  🔄 Trial 62, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011778\n",
      "  🔄 Trial 62, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022478\n",
      "  🔄 Trial 62, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019859\n",
      "  🔄 Trial 62, Fold 4/5\n",
      "    Fold 4 best total loss: 0.015159\n",
      "  🔄 Trial 62, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:42:09,466] Trial 62 finished with value: 0.01664476814912632 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 72, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.5, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013949\n",
      "  📊 Trial 62 - Average CV Loss: 0.016645 (±0.003938)\n",
      "  🔄 Trial 63, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009547\n",
      "  🔄 Trial 63, Fold 2/5\n",
      "    Fold 2 best total loss: 0.023330\n",
      "  🔄 Trial 63, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021438\n",
      "  🔄 Trial 63, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012238\n",
      "  🔄 Trial 63, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:45:21,459] Trial 63 finished with value: 0.016526608949061484 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 96, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.4, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016080\n",
      "  📊 Trial 63 - Average CV Loss: 0.016527 (±0.005248)\n",
      "  🔄 Trial 64, Fold 1/5\n",
      "    Fold 1 best total loss: 0.037022\n",
      "  🔄 Trial 64, Fold 2/5\n",
      "    Fold 2 best total loss: 0.111102\n",
      "  🔄 Trial 64, Fold 3/5\n",
      "    Fold 3 best total loss: 0.042885\n",
      "  🔄 Trial 64, Fold 4/5\n",
      "    Fold 4 best total loss: 0.037175\n",
      "  🔄 Trial 64, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:52:51,001] Trial 64 finished with value: 0.05576459188014269 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 5, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 72, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.5, 'noam_factor': 1.6, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.050638\n",
      "  📊 Trial 64 - Average CV Loss: 0.055765 (±0.028111)\n",
      "  🔄 Trial 65, Fold 1/5\n",
      "    Fold 1 best total loss: 0.316736\n",
      "  🔄 Trial 65, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318861\n",
      "  🔄 Trial 65, Fold 3/5\n",
      "    Fold 3 best total loss: 0.228676\n",
      "  🔄 Trial 65, Fold 4/5\n",
      "    Fold 4 best total loss: 4.616171\n",
      "  🔄 Trial 65, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:56:05,136] Trial 65 finished with value: 1.1652799908071756 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 72, 'decoder_n_layers': 3, 'decoder_dropout': 0.4, 'current_hidden_size': 48, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.1, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.345955\n",
      "  📊 Trial 65 - Average CV Loss: 1.165280 (±1.725898)\n",
      "  🔄 Trial 66, Fold 1/5\n",
      "    Fold 1 best total loss: 0.316021\n",
      "  🔄 Trial 66, Fold 2/5\n",
      "    Fold 2 best total loss: 0.320511\n",
      "  🔄 Trial 66, Fold 3/5\n",
      "    Fold 3 best total loss: 0.226116\n",
      "  🔄 Trial 66, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012122\n",
      "  🔄 Trial 66, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 02:59:18,350] Trial 66 finished with value: 0.2446511778049171 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.2, 'decoder_hidden_size': 32, 'decoder_n_layers': 4, 'decoder_dropout': 0.2, 'current_hidden_size': 96, 'current_n_layers': 4, 'current_dropout': 0.2, 'noam_factor': 1.3, 'warmup_ratio': 0.3, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.348487\n",
      "  📊 Trial 66 - Average CV Loss: 0.244651 (±0.123324)\n",
      "  🔄 Trial 67, Fold 1/5\n",
      "    Fold 1 best total loss: 0.006632\n",
      "  🔄 Trial 67, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319142\n",
      "  🔄 Trial 67, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017142\n",
      "  🔄 Trial 67, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011263\n",
      "  🔄 Trial 67, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:02:33,420] Trial 67 finished with value: 0.1404793354740832 and parameters: {'lstm_hidden_size': 128, 'lstm_n_layers': 2, 'lstm_dropout': 0.4, 'decoder_hidden_size': 96, 'decoder_n_layers': 3, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 64, 'current_n_layers': 3, 'current_dropout': 0.1, 'noam_factor': 0.7, 'warmup_ratio': 0.15000000000000002, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.348218\n",
      "  📊 Trial 67 - Average CV Loss: 0.140479 (±0.158050)\n",
      "  🔄 Trial 68, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011583\n",
      "  🔄 Trial 68, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018945\n",
      "  🔄 Trial 68, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017878\n",
      "  🔄 Trial 68, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013893\n",
      "  🔄 Trial 68, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:05:44,832] Trial 68 finished with value: 0.015597015246748924 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 2, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015687\n",
      "  📊 Trial 68 - Average CV Loss: 0.015597 (±0.002662)\n",
      "  🔄 Trial 69, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010649\n",
      "  🔄 Trial 69, Fold 2/5\n",
      "    Fold 2 best total loss: 0.015521\n",
      "  🔄 Trial 69, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019662\n",
      "  🔄 Trial 69, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012871\n",
      "  🔄 Trial 69, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:10:26,141] Trial 69 finished with value: 0.014644752640742808 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014521\n",
      "  📊 Trial 69 - Average CV Loss: 0.014645 (±0.003002)\n",
      "  🔄 Trial 70, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011769\n",
      "  🔄 Trial 70, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022132\n",
      "  🔄 Trial 70, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020392\n",
      "  🔄 Trial 70, Fold 4/5\n",
      "    Fold 4 best total loss: 0.017399\n",
      "  🔄 Trial 70, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:11:53,515] Trial 70 finished with value: 0.02004068745300174 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.25, 'batch_size': 15}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.028512\n",
      "  📊 Trial 70 - Average CV Loss: 0.020041 (±0.005507)\n",
      "  🔄 Trial 71, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012444\n",
      "  🔄 Trial 71, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020026\n",
      "  🔄 Trial 71, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021450\n",
      "  🔄 Trial 71, Fold 4/5\n",
      "    Fold 4 best total loss: 0.017221\n",
      "  🔄 Trial 71, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:17:57,572] Trial 71 finished with value: 0.018248679162934423 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.8, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.020102\n",
      "  📊 Trial 71 - Average CV Loss: 0.018249 (±0.003212)\n",
      "  🔄 Trial 72, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010958\n",
      "  🔄 Trial 72, Fold 2/5\n",
      "    Fold 2 best total loss: 0.023348\n",
      "  🔄 Trial 72, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021831\n",
      "  🔄 Trial 72, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014574\n",
      "  🔄 Trial 72, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:22:40,845] Trial 72 finished with value: 0.017296925699338318 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015774\n",
      "  📊 Trial 72 - Average CV Loss: 0.017297 (±0.004628)\n",
      "  🔄 Trial 73, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011613\n",
      "  🔄 Trial 73, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024038\n",
      "  🔄 Trial 73, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019527\n",
      "  🔄 Trial 73, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016075\n",
      "  🔄 Trial 73, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:25:52,034] Trial 73 finished with value: 0.017842931649647654 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 2, 'lstm_dropout': 0.5, 'decoder_hidden_size': 64, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 2.0, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017962\n",
      "  📊 Trial 73 - Average CV Loss: 0.017843 (±0.004079)\n",
      "  🔄 Trial 74, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012090\n",
      "  🔄 Trial 74, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020233\n",
      "  🔄 Trial 74, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019006\n",
      "  🔄 Trial 74, Fold 4/5\n",
      "    Fold 4 best total loss: 0.019372\n",
      "  🔄 Trial 74, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:29:04,338] Trial 74 finished with value: 0.01696825264953077 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 4, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.2, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014142\n",
      "  📊 Trial 74 - Average CV Loss: 0.016968 (±0.003236)\n",
      "  🔄 Trial 75, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011813\n",
      "  🔄 Trial 75, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018540\n",
      "  🔄 Trial 75, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019044\n",
      "  🔄 Trial 75, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013955\n",
      "  🔄 Trial 75, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:38:11,514] Trial 75 finished with value: 0.0160360521171242 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.6, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016829\n",
      "  📊 Trial 75 - Average CV Loss: 0.016036 (±0.002761)\n",
      "  🔄 Trial 76, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010088\n",
      "  🔄 Trial 76, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021638\n",
      "  🔄 Trial 76, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019308\n",
      "  🔄 Trial 76, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013779\n",
      "  🔄 Trial 76, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:45:07,091] Trial 76 finished with value: 0.016072901431471106 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.6, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015553\n",
      "  📊 Trial 76 - Average CV Loss: 0.016073 (±0.004069)\n",
      "  🔄 Trial 77, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011837\n",
      "  🔄 Trial 77, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020180\n",
      "  🔄 Trial 77, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020484\n",
      "  🔄 Trial 77, Fold 4/5\n",
      "    Fold 4 best total loss: 0.017813\n",
      "  🔄 Trial 77, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 03:54:08,149] Trial 77 finished with value: 0.018592908792197705 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.6, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.022652\n",
      "  📊 Trial 77 - Average CV Loss: 0.018593 (±0.003710)\n",
      "  🔄 Trial 78, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010897\n",
      "  🔄 Trial 78, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022702\n",
      "  🔄 Trial 78, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019391\n",
      "  🔄 Trial 78, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014349\n",
      "  🔄 Trial 78, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:00:16,144] Trial 78 finished with value: 0.016150994366034864 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013416\n",
      "  📊 Trial 78 - Average CV Loss: 0.016151 (±0.004284)\n",
      "  🔄 Trial 79, Fold 1/5\n",
      "    Fold 1 best total loss: 0.013100\n",
      "  🔄 Trial 79, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022548\n",
      "  🔄 Trial 79, Fold 3/5\n",
      "    Fold 3 best total loss: 0.023022\n",
      "  🔄 Trial 79, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016289\n",
      "  🔄 Trial 79, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:07:54,082] Trial 79 finished with value: 0.019161436357535422 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.5, 'warmup_ratio': 0.25, 'batch_size': 3}. Best is trial 29 with value: 0.014544721913989634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.020848\n",
      "  📊 Trial 79 - Average CV Loss: 0.019161 (±0.003853)\n",
      "  🔄 Trial 80, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010310\n",
      "  🔄 Trial 80, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018577\n",
      "  🔄 Trial 80, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016855\n",
      "  🔄 Trial 80, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011445\n",
      "  🔄 Trial 80, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:13:36,534] Trial 80 finished with value: 0.014023609009260932 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012931\n",
      "  📊 Trial 80 - Average CV Loss: 0.014024 (±0.003175)\n",
      "  🔄 Trial 81, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007457\n",
      "  🔄 Trial 81, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018366\n",
      "  🔄 Trial 81, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018377\n",
      "  🔄 Trial 81, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014620\n",
      "  🔄 Trial 81, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:19:24,329] Trial 81 finished with value: 0.014301489340141416 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012688\n",
      "  📊 Trial 81 - Average CV Loss: 0.014301 (±0.004067)\n",
      "  🔄 Trial 82, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009409\n",
      "  🔄 Trial 82, Fold 2/5\n",
      "    Fold 2 best total loss: 0.017745\n",
      "  🔄 Trial 82, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015711\n",
      "  🔄 Trial 82, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012144\n",
      "  🔄 Trial 82, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:26:18,245] Trial 82 finished with value: 0.014344193010280528 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016711\n",
      "  📊 Trial 82 - Average CV Loss: 0.014344 (±0.003106)\n",
      "  🔄 Trial 83, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007984\n",
      "  🔄 Trial 83, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018726\n",
      "  🔄 Trial 83, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020358\n",
      "  🔄 Trial 83, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010762\n",
      "  🔄 Trial 83, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:32:05,702] Trial 83 finished with value: 0.014171965249503652 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013030\n",
      "  📊 Trial 83 - Average CV Loss: 0.014172 (±0.004695)\n",
      "  🔄 Trial 84, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009396\n",
      "  🔄 Trial 84, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022538\n",
      "  🔄 Trial 84, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018365\n",
      "  🔄 Trial 84, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014815\n",
      "  🔄 Trial 84, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:38:59,909] Trial 84 finished with value: 0.016108598994712037 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 6, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015428\n",
      "  📊 Trial 84 - Average CV Loss: 0.016109 (±0.004327)\n",
      "  🔄 Trial 85, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011972\n",
      "  🔄 Trial 85, Fold 2/5\n",
      "    Fold 2 best total loss: 0.017106\n",
      "  🔄 Trial 85, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018301\n",
      "  🔄 Trial 85, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013052\n",
      "  🔄 Trial 85, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:44:45,994] Trial 85 finished with value: 0.014239849631364149 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010768\n",
      "  📊 Trial 85 - Average CV Loss: 0.014240 (±0.002943)\n",
      "  🔄 Trial 86, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010580\n",
      "  🔄 Trial 86, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021563\n",
      "  🔄 Trial 86, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021057\n",
      "  🔄 Trial 86, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012486\n",
      "  🔄 Trial 86, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:50:33,279] Trial 86 finished with value: 0.016176906041800977 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015198\n",
      "  📊 Trial 86 - Average CV Loss: 0.016177 (±0.004444)\n",
      "  🔄 Trial 87, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009277\n",
      "  🔄 Trial 87, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020438\n",
      "  🔄 Trial 87, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017987\n",
      "  🔄 Trial 87, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011742\n",
      "  🔄 Trial 87, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 04:56:21,364] Trial 87 finished with value: 0.0142298663345476 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011705\n",
      "  📊 Trial 87 - Average CV Loss: 0.014230 (±0.004237)\n",
      "  🔄 Trial 88, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008783\n",
      "  🔄 Trial 88, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019053\n",
      "  🔄 Trial 88, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016970\n",
      "  🔄 Trial 88, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016455\n",
      "  🔄 Trial 88, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:02:07,915] Trial 88 finished with value: 0.01540397279895842 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015759\n",
      "  📊 Trial 88 - Average CV Loss: 0.015404 (±0.003488)\n",
      "  🔄 Trial 89, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007793\n",
      "  🔄 Trial 89, Fold 2/5\n",
      "    Fold 2 best total loss: 0.024521\n",
      "  🔄 Trial 89, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021135\n",
      "  🔄 Trial 89, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014275\n",
      "  🔄 Trial 89, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:07:55,870] Trial 89 finished with value: 0.015661131000767152 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010582\n",
      "  📊 Trial 89 - Average CV Loss: 0.015661 (±0.006294)\n",
      "  🔄 Trial 90, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011988\n",
      "  🔄 Trial 90, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020300\n",
      "  🔄 Trial 90, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018954\n",
      "  🔄 Trial 90, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016563\n",
      "  🔄 Trial 90, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:13:39,677] Trial 90 finished with value: 0.017419634324808912 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.019293\n",
      "  📊 Trial 90 - Average CV Loss: 0.017420 (±0.002980)\n",
      "  🔄 Trial 91, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010879\n",
      "  🔄 Trial 91, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016934\n",
      "  🔄 Trial 91, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019402\n",
      "  🔄 Trial 91, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011500\n",
      "  🔄 Trial 91, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:19:26,057] Trial 91 finished with value: 0.014285211606572073 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012711\n",
      "  📊 Trial 91 - Average CV Loss: 0.014285 (±0.003318)\n",
      "  🔄 Trial 92, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010963\n",
      "  🔄 Trial 92, Fold 2/5\n",
      "    Fold 2 best total loss: 0.017683\n",
      "  🔄 Trial 92, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017490\n",
      "  🔄 Trial 92, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013393\n",
      "  🔄 Trial 92, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:25:08,163] Trial 92 finished with value: 0.015016302916531759 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015553\n",
      "  📊 Trial 92 - Average CV Loss: 0.015016 (±0.002553)\n",
      "  🔄 Trial 93, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009703\n",
      "  🔄 Trial 93, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020439\n",
      "  🔄 Trial 93, Fold 3/5\n",
      "    Fold 3 best total loss: 0.198981\n",
      "  🔄 Trial 93, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011872\n",
      "  🔄 Trial 93, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:30:58,466] Trial 93 finished with value: 0.051088450476527214 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014447\n",
      "  📊 Trial 93 - Average CV Loss: 0.051088 (±0.074034)\n",
      "  🔄 Trial 94, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009253\n",
      "  🔄 Trial 94, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018843\n",
      "  🔄 Trial 94, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019429\n",
      "  🔄 Trial 94, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010406\n",
      "  🔄 Trial 94, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:36:43,517] Trial 94 finished with value: 0.014625430029506484 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015196\n",
      "  📊 Trial 94 - Average CV Loss: 0.014625 (±0.004192)\n",
      "  🔄 Trial 95, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011035\n",
      "  🔄 Trial 95, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018483\n",
      "  🔄 Trial 95, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017997\n",
      "  🔄 Trial 95, Fold 4/5\n",
      "    Fold 4 best total loss: 0.018318\n",
      "  🔄 Trial 95, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:42:30,803] Trial 95 finished with value: 0.016819270110378662 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.30000000000000004, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.018264\n",
      "  📊 Trial 95 - Average CV Loss: 0.016819 (±0.002897)\n",
      "  🔄 Trial 96, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008101\n",
      "  🔄 Trial 96, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020049\n",
      "  🔄 Trial 96, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019603\n",
      "  🔄 Trial 96, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012286\n",
      "  🔄 Trial 96, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:48:16,366] Trial 96 finished with value: 0.014084919836993018 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.8, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010385\n",
      "  📊 Trial 96 - Average CV Loss: 0.014085 (±0.004873)\n",
      "  🔄 Trial 97, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010911\n",
      "  🔄 Trial 97, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016297\n",
      "  🔄 Trial 97, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018637\n",
      "  🔄 Trial 97, Fold 4/5\n",
      "    Fold 4 best total loss: 4.363938\n",
      "  🔄 Trial 97, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:54:00,597] Trial 97 finished with value: 0.8840188292476038 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 2.0, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010311\n",
      "  📊 Trial 97 - Average CV Loss: 0.884019 (±1.739963)\n",
      "  🔄 Trial 98, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011798\n",
      "  🔄 Trial 98, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019961\n",
      "  🔄 Trial 98, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021190\n",
      "  🔄 Trial 98, Fold 4/5\n",
      "    Fold 4 best total loss: 0.019500\n",
      "  🔄 Trial 98, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 05:59:47,227] Trial 98 finished with value: 0.0179111762282749 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.4, 'noam_factor': 1.7000000000000002, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017108\n",
      "  📊 Trial 98 - Average CV Loss: 0.017911 (±0.003332)\n",
      "  🔄 Trial 99, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010135\n",
      "  🔄 Trial 99, Fold 2/5\n",
      "    Fold 2 best total loss: 0.299125\n",
      "  🔄 Trial 99, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017179\n",
      "  🔄 Trial 99, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012743\n",
      "  🔄 Trial 99, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 06:05:30,154] Trial 99 finished with value: 0.07125218901783228 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 5, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 2, 'decoder_dropout': 0.2, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004, 'noam_factor': 1.9000000000000001, 'warmup_ratio': 0.3, 'batch_size': 5}. Best is trial 80 with value: 0.014023609009260932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017079\n",
      "  📊 Trial 99 - Average CV Loss: 0.071252 (±0.113968)\n",
      "\n",
      "================================================================================\n",
      "📊 OPTIMIZATION RESULTS\n",
      "================================================================================\n",
      "✅ 완료된 trials: 100\n",
      "🏆 최고 성능 trial: 80\n",
      "💯 최고 성능 값: 0.014024\n",
      "\n",
      "🎯 최적 하이퍼파라미터:\n",
      "   lstm_hidden_size: 64\n",
      "   lstm_n_layers: 5\n",
      "   lstm_dropout: 0.1\n",
      "   decoder_hidden_size: 16\n",
      "   decoder_n_layers: 2\n",
      "   decoder_dropout: 0.2\n",
      "   current_hidden_size: 48\n",
      "   current_n_layers: 2\n",
      "   current_dropout: 0.30000000000000004\n",
      "   noam_factor: 1.7000000000000002\n",
      "   warmup_ratio: 0.3\n",
      "   batch_size: 5\n",
      "\n",
      "📈 상위 5개 Trials:\n",
      "   1. Trial 80: 0.014024\n",
      "   2. Trial 96: 0.014085\n",
      "   3. Trial 83: 0.014172\n",
      "   4. Trial 87: 0.014230\n",
      "   5. Trial 85: 0.014240\n",
      "💾 모든 trials 결과가 저장되었습니다: bmed_optuna_trials_20250909_060530.csv\n",
      "💾 SQLite 데이터베이스에 실시간 저장됨: sqlite:///bmed_optuna_study_20250908_222546.db\n",
      "   - 중단 후 재시작 시 자동으로 기존 결과를 불러옵니다\n",
      "   - 다른 프로세스에서 진행상황 모니터링 가능합니다\n",
      "================================================================================\n",
      "🎉 하이퍼파라미터 최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 메인 최적화 함수\n",
    "def run_optuna_optimization():\n",
    "    \"\"\"Optuna를 사용한 하이퍼파라미터 최적화 실행\"\"\"\n",
    "    \n",
    "    print(\"🚀 BMED TF Model Hyperparameter Optimization with Optuna\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 전역 데이터 로드\n",
    "    global dataset, range_mm\n",
    "    \n",
    "    print(\"📋 데이터 로드 중...\")\n",
    "    df, ndf, range_mm, exp_num_list = df_treat('BMED_DATA_AG.csv')\n",
    "    seq = seq_data(ndf, exp_num_list)\n",
    "    pad, seq_len, max_len = pad_seq(seq)\n",
    "    dataset = gen_dataset(pad, seq_len)\n",
    "    \n",
    "    print(f\"   - 총 실험 개수: {len(exp_num_list)}\")\n",
    "    print(f\"   - 총 데이터 포인트: {len(dataset)}\")\n",
    "    print(f\"   - 최대 시퀀스 길이: {max_len}\")\n",
    "    \n",
    "    # SQLite 데이터베이스를 사용한 Optuna study 생성\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    db_url = f\"sqlite:///bmed_optuna_study_{timestamp}.db\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name='bmed_tf_optimization',\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        storage=db_url,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    # 최적화 실행\n",
    "    n_trials = 100\n",
    "    print(f\"🔍 최적화 시작 (총 {n_trials} trials)\")\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=n_trials, timeout=None)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⚠️ 최적화가 사용자에 의해 중단되었습니다.\")\n",
    "    \n",
    "    # 결과 분석\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"✅ 완료된 trials: {len(study.trials)}\")\n",
    "    print(f\"🏆 최고 성능 trial: {study.best_trial.number}\")\n",
    "    print(f\"💯 최고 성능 값: {study.best_value:.6f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 최적 하이퍼파라미터:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # 상위 5개 trial 정보\n",
    "    print(f\"\\n📈 상위 5개 Trials:\")\n",
    "    trials_df = study.trials_dataframe().sort_values('value').head(5)\n",
    "    for idx, (_, trial) in enumerate(trials_df.iterrows()):\n",
    "        print(f\"   {idx+1}. Trial {int(trial['number'])}: {trial['value']:.6f}\")\n",
    "    \n",
    "    # 결과 저장\n",
    "    result_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Trials 결과 CSV로 저장\n",
    "    trials_file = f\"bmed_optuna_trials_{result_timestamp}.csv\"\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_df.to_csv(trials_file, index=False)\n",
    "    print(f\"💾 모든 trials 결과가 저장되었습니다: {trials_file}\")\n",
    "    \n",
    "    # SQLite 데이터베이스 정보\n",
    "    print(f\"💾 SQLite 데이터베이스에 실시간 저장됨: {db_url}\")\n",
    "    print(f\"   - 중단 후 재시작 시 자동으로 기존 결과를 불러옵니다\")\n",
    "    print(f\"   - 다른 프로세스에서 진행상황 모니터링 가능합니다\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"🎉 하이퍼파라미터 최적화 완료!\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = run_optuna_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
