{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7299bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca099116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c7439571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CBLA': {'min':0, 'max': df['CBLA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CAK': {'min':0, 'max': df['CAK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6ef616b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_const(ndf):\n",
    "    sequences = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        sequences.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "15a9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(sequences):\n",
    "    max_seq_len = max([len(seq) for seq in sequences])\n",
    "    seq_len = [len(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return padded_sequences, seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f52012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor= pad_seq.float()\n",
    "    seq_len_tensor= torch.tensor(seq_len)\n",
    "\n",
    "    device = set_device()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    seq_len_tensor = seq_len_tensor.to(device)\n",
    "\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "21e82b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_dataloaders(dataset, k_folds=5, batch_size=8, random_state=42):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "    dataloaders = []\n",
    "    batch_size = math.ceil(len(dataset)/k_folds)\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(kfold.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}: Train size = {len(train_indices)}, Val size = {len(val_indices)}\")\n",
    "        \n",
    "        # Create subsets for train and validation\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        val_subset = Subset(dataset, val_indices)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "16dd4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers,dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, sel_len):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        norm = self.layer_norm(last_output)\n",
    "        return self.dropout(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "084b3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout = 0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "    # 첫 번째 레이어: hidden_size → num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 중간 은닉층들: num_nodes → num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes,num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 마지막 출력층: num_nodes → output_size\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, lstm_layers=2, mlp_layers=2, mlp_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = LSTMEncoder(input_size, hidden_size,lstm_layers)\n",
    "        self.decoder = MLPDecoder(hidden_size, output_size,mlp_layers, mlp_nodes, dropout)\n",
    "\n",
    "    def forward(self, x, seq_lengths):\n",
    "        encoded = self.encoder(x, seq_lengths)\n",
    "        output = self.decoder(encoded)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fc0e6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Fold 1: Train size = 31, Val size = 8\n",
      "Fold 2: Train size = 31, Val size = 8\n",
      "Fold 3: Train size = 31, Val size = 8\n",
      "Fold 4: Train size = 31, Val size = 8\n",
      "Fold 5: Train size = 32, Val size = 7\n",
      "\n",
      "Created 5 fold dataloaders\n",
      "Each fold contains (train_loader, val_loader) tuple\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('BMED_DATA_AG.csv')\n",
    "feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "ndf = norm_data('BMED_DATA_AG.csv')\n",
    "seq = seq_data_const(ndf)\n",
    "pad_seq,seq_len,max_seq_len = padded_sequences(seq)\n",
    "dataset = gen_dataset(pad_seq, seq_len)\n",
    "dataloaders = kfold_dataloaders(dataset, k_folds=5, batch_size=8, random_state=42)\n",
    "print(f\"\\nCreated {len(dataloaders)} fold dataloaders\")\n",
    "print(f\"Each fold contains (train_loader, val_loader) tuple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7582a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
