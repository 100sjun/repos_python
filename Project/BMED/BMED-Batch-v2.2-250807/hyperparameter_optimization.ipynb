{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7299bf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\NNenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "import math\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca099116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7439571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CBLA': {'min':0, 'max': df['CBLA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CAK': {'min':0, 'max': df['CAK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef616b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_const(ndf):\n",
    "    sequences = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        sequences.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(sequences):\n",
    "    max_seq_len = max([len(seq) for seq in sequences])\n",
    "    seq_len = [len(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return padded_sequences, seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f52012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e82b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_dataloaders(dataset, k_folds=5, batch_size=8, random_state=42):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "    dataloaders = []\n",
    "    batch_size = math.ceil(len(dataset)/k_folds)\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(kfold.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}: Train size = {len(train_indices)}, Val size = {len(val_indices)}\")\n",
    "        \n",
    "        # Create subsets for train and validation\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        val_subset = Subset(dataset, val_indices)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16dd4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialStateExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED 시스템의 시계열 패턴에서 숨겨진 dynamics를 추출하는 LSTM 기반 모듈\n",
    "    각 시점의 hidden state에는 해당 시점까지의 모든 과거 정보가 누적됨\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with improved error handling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        시계열 상태 시퀀스를 처리하여 각 시점의 hidden state 추출\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size] - BMED 시스템 상태 시퀀스\n",
    "            seq_len: [batch_size] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 각 시점의 누적된 hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        # 입력 검증\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        # seq_len을 CPU로 이동하고 정수형으로 변환\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        \n",
    "        # 시퀀스 길이 유효성 검사\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "        \n",
    "        # 패딩된 시퀀스를 pack하여 효율적 처리\n",
    "        packed_input = pack_padded_sequence(\n",
    "            x, seq_len_cpu, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # 다시 패딩된 형태로 복원\n",
    "        lstm_out, output_lengths = pad_packed_sequence(\n",
    "            packed_output, batch_first=True, total_length=x.size(1)\n",
    "        )\n",
    "        \n",
    "        # Normalization and dropout\n",
    "        normalized = self.layer_norm(lstm_out)\n",
    "        return self.dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084b3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden state로부터 BMED 시스템의 물리적 변화량과 새로운 전류값을 디코딩하는 MLP\n",
    "    출력: [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI] - 7개 물리적 변화량\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # 첫 번째 레이어: hidden_size → num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 중간 은닉층들: num_nodes → num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 마지막 출력층: num_nodes → output_size (7개 물리적 변화량)\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Hidden state를 물리적 변화량으로 디코딩\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 시점별 hidden state\n",
    "            \n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, 7] - 물리적 변화량\n",
    "                [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea1ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    물리적 변화량을 실제 시스템 상태로 변환하면서 물리적 제약 조건을 적용\n",
    "    Bipolar membrane electrodialysis 시스템의 물리 법칙 기반 상태 업데이트\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # division by zero 방지\n",
    "        \n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        물리적 변화량을 현재 상태에 적용하여 다음 상태 계산\n",
    "        \n",
    "        Args:\n",
    "            physical_changes: [batch, seq, 7] - [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "            current_state: [batch, seq, 12] - 현재 BMED 시스템 상태\n",
    "                V: 전압 (Voltage) - 실험 세트별 고정값\n",
    "                E: 외부 전해질 농도 (External electrolyte concentration) - 실험 세트별 고정값  \n",
    "                VF, VA, VB: Feed, Acid, Base 부피\n",
    "                CFLA, CALA, CBLA: Feed, Acid, Base의 LA 농도\n",
    "                CFK, CAK, CBK: Feed, Acid, Base의 K 농도\n",
    "                I: 전류\n",
    "                \n",
    "        Returns:\n",
    "            next_state: [batch, seq, 12] - 물리 제약이 적용된 다음 상태\n",
    "        \"\"\"\n",
    "        # 입력 차원 검증\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 12:\n",
    "            raise ValueError(f\"Expected 12 state features, got {current_state.size(-1)}\")\n",
    "            \n",
    "        if physical_changes.size(-1) != 7:\n",
    "            raise ValueError(f\"Expected 7 physical changes, got {physical_changes.size(-1)}\")\n",
    "        \n",
    "        # 현재 상태 변수 추출 (차원 유지)\n",
    "        V = current_state[..., 0:1]     # 전압 (고정값)\n",
    "        E = current_state[..., 1:2]     # 외부 전해질 농도 (고정값)\n",
    "        VF = current_state[..., 2:3]    # Feed 부피\n",
    "        VA = current_state[..., 3:4]    # Acid 부피\n",
    "        VB = current_state[..., 4:5]    # Base 부피\n",
    "        CFLA = current_state[..., 5:6]  # Feed LA 농도\n",
    "        CALA = current_state[..., 6:7]  # Acid LA 농도\n",
    "        CBLA = current_state[..., 7:8]  # Base LA 농도\n",
    "        CFK = current_state[..., 8:9]   # Feed K 농도\n",
    "        CAK = current_state[..., 9:10]  # Acid K 농도\n",
    "        CBK = current_state[..., 10:11] # Base K 농도\n",
    "        I = current_state[..., 11:12]   # 전류\n",
    "\n",
    "        # 물질량 계산 (농도 × 부피)\n",
    "        NFLA = CFLA * VF; NALA = CALA * VA; NBLA = CBLA * VB\n",
    "        NFK = CFK * VF; NAK = CAK * VA; NBK = CBK * VB\n",
    "\n",
    "        # 물리적 변화량 추출\n",
    "        dVA = physical_changes[..., 0:1]    # Acid 부피 변화량 (양방향 가능: 음수면 A→F)\n",
    "        dVB = physical_changes[..., 1:2]    # Base 부피 변화량 (양방향 가능: 음수면 B→F)\n",
    "        dNALA = physical_changes[..., 2:3]  # Acid LA 물질량 변화량 (일방향: F→A만)\n",
    "        dNBLA = physical_changes[..., 3:4]  # Base LA 물질량 변화량 (일방향: F→B만)\n",
    "        dNAK = physical_changes[..., 4:5]   # Acid K 물질량 변화량 (일방향: F→A만)\n",
    "        dNBK = physical_changes[..., 5:6]   # Base K 물질량 변화량 (일방향: F→B만)\n",
    "        nI = physical_changes[..., 6:7]     # 새로운 전류값\n",
    "\n",
    "        # 새로운 부피 계산 (양방향 흐름 허용)\n",
    "        nVF = VF - dVA - dVB  # dVA, dVB가 음수면 F로 역유입\n",
    "        nVA = VA + dVA        # dVA가 음수면 A에서 F로 유출\n",
    "        nVB = VB + dVB        # dVB가 음수면 B에서 F로 유출\n",
    "        \n",
    "        # 물질 이동량을 일방향으로 제한 (F→A, F→B만 허용)\n",
    "        dNALA_clipped = torch.clamp(dNALA, min=0)  # 음수 제거 (역방향 불가)\n",
    "        dNBLA_clipped = torch.clamp(dNBLA, min=0)\n",
    "        dNAK_clipped = torch.clamp(dNAK, min=0)\n",
    "        dNBK_clipped = torch.clamp(dNBK, min=0)\n",
    "        \n",
    "        # 새로운 물질량 계산 (일방향 이동만)\n",
    "        nNFLA = NFLA - dNALA_clipped - dNBLA_clipped  # Feed에서 유출만\n",
    "        nNALA = NALA + dNALA_clipped                  # Acid로 유입만\n",
    "        nNBLA = NBLA + dNBLA_clipped                  # Base로 유입만\n",
    "        nNFK = NFK - dNAK_clipped - dNBK_clipped      # K도 마찬가지\n",
    "        nNAK = NAK + dNAK_clipped\n",
    "        nNBK = NBK + dNBK_clipped\n",
    "        \n",
    "        # 물리적 제약 조건 적용 (양수 유지)\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        \n",
    "        # 물질량 음수 방지\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNBLA = torch.clamp(nNBLA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNAK = torch.clamp(nNAK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        \n",
    "        # 새로운 농도 계산 (농도 = 물질량 / 부피)\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCBLA = nNBLA / nVB\n",
    "        nCFK = nNFK / nVF\n",
    "        nCAK = nNAK / nVA\n",
    "        nCBK = nNBK / nVB\n",
    "        \n",
    "        # 전류는 양수 제약\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # 새로운 상태 조립 (V, E는 고정값이므로 그대로 유지)\n",
    "        next_state = torch.cat([\n",
    "            V, E,  # 고정값: 전압, 외부 전해질 농도\n",
    "            nVF, nVA, nVB,  # 새로운 부피 (양방향 흐름 반영)\n",
    "            nCFLA, nCALA, nCBLA,  # 새로운 LA 농도\n",
    "            nCFK, nCAK, nCBK,     # 새로운 K 농도\n",
    "            nI  # 새로운 전류\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9d4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED 시스템의 시계열 상태 예측을 위한 자기회귀 모델\n",
    "    \n",
    "    구조:\n",
    "    1. SequentialStateExtractor: LSTM으로 시계열 패턴의 hidden state 추출\n",
    "    2. PhysicalChangeDecoder: Hidden state를 물리적 변화량으로 디코딩  \n",
    "    3. PhysicsConstraintLayer: 물리 법칙 적용하여 다음 상태 계산\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = SequentialStateExtractor(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_states, seq_lengths):\n",
    "        \"\"\"\n",
    "        현재 시점까지의 상태들로부터 다음 상태들 예측\n",
    "        \n",
    "        Args:\n",
    "            current_states: [batch, seq_len, 12] - 현재까지의 BMED 시스템 상태들\n",
    "            seq_lengths: [batch] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            next_states: [batch, seq_len, 12] - 예측된 다음 시점 상태들\n",
    "        \"\"\"\n",
    "        # 1. LSTM으로 각 시점의 hidden state 추출 (과거 정보 누적)\n",
    "        hidden_states = self.state_extractor(current_states, seq_lengths)\n",
    "        \n",
    "        # 2. Hidden state를 물리적 변화량으로 디코딩\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        \n",
    "        # 3. 물리적 제약 조건을 적용하여 다음 상태 계산\n",
    "        next_states = self.physics_constraint(physical_changes, current_states)\n",
    "        \n",
    "        return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824ead56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(predictions, targets, seq_lengths):\n",
    "    \"\"\"\n",
    "    개선된 마스킹된 MSE 손실 함수 - device 호환성 및 안정성 강화\n",
    "    \n",
    "    Args:\n",
    "        predictions: 모델 예측값 [batch_size, seq_len, features]\n",
    "        targets: 실제 타겟값 [batch_size, seq_len, features]  \n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        masked_loss: 패딩 부분을 제외한 평균 MSE 손실\n",
    "    \"\"\"\n",
    "    # 입력 검증\n",
    "    if predictions.shape != targets.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {predictions.shape} vs targets {targets.shape}\")\n",
    "    \n",
    "    if predictions.size(0) != seq_lengths.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {predictions.size(0)} vs seq_lengths {seq_lengths.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = predictions.shape\n",
    "    \n",
    "    # seq_lengths를 CPU로 이동하여 arange와 호환되도록 처리\n",
    "    seq_lengths_cpu = seq_lengths.detach().cpu().long()\n",
    "    \n",
    "    # 시퀀스 길이 유효성 검사 - 데이터 구조 오류는 중단해야 함\n",
    "    if (seq_lengths_cpu <= 0).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu <= 0]\n",
    "        raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "    \n",
    "    # 최대 길이 초과 검사\n",
    "    if (seq_lengths_cpu > max_len).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu > max_len]\n",
    "        raise ValueError(f\"Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}\")\n",
    "    \n",
    "    # 마스크 생성: 실제 시퀀스 길이만큼만 True\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_lengths_cpu[:, None]\n",
    "    mask = mask.float().to(predictions.device)\n",
    "    \n",
    "    # 각 요소별 MSE 계산 (reduction='none')\n",
    "    loss = F.mse_loss(predictions, targets, reduction='none')\n",
    "    \n",
    "    # 마스크 적용하여 패딩 부분 제거\n",
    "    masked_loss_sum = (loss * mask.unsqueeze(-1)).sum()\n",
    "    valid_elements = mask.sum() * features\n",
    "    \n",
    "    # 0으로 나누기 방지\n",
    "    if valid_elements == 0:\n",
    "        raise ValueError(\"No valid elements found after masking. Check sequence lengths and data.\")\n",
    "    \n",
    "    masked_loss = masked_loss_sum / valid_elements\n",
    "    \n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8315b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_teacher_forcing_data(input_sequences, seq_lengths):\n",
    "    \"\"\"\n",
    "    Teacher Forcing을 위한 입력-타겟 데이터 준비\n",
    "    \n",
    "    Args:\n",
    "        input_sequences: 전체 시퀀스 [batch_size, seq_len, features]\n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        inputs: [t0, t1, ..., t_{n-1}] 현재 상태들\n",
    "        targets: [t1, t2, ..., t_n] 다음 상태들  \n",
    "        target_seq_lengths: 타겟 시퀀스 길이 (1씩 감소)\n",
    "    \"\"\"\n",
    "    # 입력: 마지막 시점 제외 [:-1]\n",
    "    inputs = input_sequences[:, :-1, :]\n",
    "    \n",
    "    # 타겟: 첫 번째 시점 제외 [1:]  \n",
    "    targets = input_sequences[:, 1:, :]\n",
    "    \n",
    "    # **타겟 시퀀스 길이는 1씩 감소 (마지막 시점 예측 불가)**\n",
    "    if (seq_lengths - 1 < 1).any():\n",
    "        invalid_lengths = seq_lengths[seq_lengths - 1 < 1]\n",
    "        raise ValueError(f\"타겟 시퀀스 길이가 0보다 작아질 수 없습니다. 잘못된 seq_lengths: {invalid_lengths.tolist()}\")\n",
    "    target_seq_lengths = seq_lengths - 1\n",
    "    \n",
    "    return inputs, targets, target_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a097d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (input_seq, seq_lengths) in enumerate(train_loader):\n",
    "        # 데이터를 디바이스로 이동\n",
    "        input_seq = input_seq.to(device)\n",
    "        seq_lengths = seq_lengths.to(device)\n",
    "        \n",
    "        # Teacher Forcing 데이터 준비\n",
    "        inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(inputs, target_seq_lengths)\n",
    "        \n",
    "        # Loss 계산 (마스크 적용)\n",
    "        loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(train_loader)\n",
    "\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_seq, seq_lengths in val_loader:\n",
    "            # 데이터를 디바이스로 이동\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_lengths = seq_lengths.to(device)\n",
    "            \n",
    "            # Teacher Forcing 데이터 준비\n",
    "            inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(inputs, target_seq_lengths)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90952eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDHyperparameterOptimizer:\n",
    "    \"\"\"\n",
    "    BMED 자기회귀 모델을 위한 K-fold CV 기반 하이퍼파라미터 최적화 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloaders, device=None):\n",
    "        self.dataloaders = dataloaders\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 하이퍼파라미터 범위 정의\n",
    "        self.param_ranges = {\n",
    "            'hidden_size': {'low': 16, 'high': 256, 'step': 16},\n",
    "            'num_layers': {'low': 1, 'high': 10},\n",
    "            'extractor_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'decoder_layers': {'low': 1, 'high': 10},\n",
    "            'decoder_nodes': {'low': 16, 'high': 256, 'step': 16},\n",
    "            'decoder_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'learning_rate': {'low': 1e-4, 'high': 1e-1, 'log': True},\n",
    "            'weight_decay': {'low': 1e-6, 'high': 1e-3, 'log': True}\n",
    "        }\n",
    "        \n",
    "        # 학습 설정 - 작은 데이터셋에 최적화\n",
    "        self.train_config = {\n",
    "            'epochs': 500,      # 더 많은 기회 제공\n",
    "            'patience': 50,     # 더 관대한 early stopping\n",
    "            'min_epochs': 100    # 충분한 학습 보장\n",
    "        }\n",
    "    \n",
    "    def create_model(self, trial):\n",
    "        \"\"\"하이퍼파라미터 샘플링 및 모델 생성\"\"\"\n",
    "        # 하이퍼파라미터 샘플링\n",
    "        params = {}\n",
    "        params['hidden_size'] = trial.suggest_int('hidden_size', **self.param_ranges['hidden_size'])\n",
    "        params['num_layers'] = trial.suggest_int('num_layers', **self.param_ranges['num_layers'])\n",
    "        params['extractor_dropout'] = trial.suggest_float('extractor_dropout', **self.param_ranges['extractor_dropout'])\n",
    "        params['decoder_layers'] = trial.suggest_int('decoder_layers', **self.param_ranges['decoder_layers'])\n",
    "        params['decoder_nodes'] = trial.suggest_int('decoder_nodes', **self.param_ranges['decoder_nodes'])\n",
    "        params['decoder_dropout'] = trial.suggest_float('decoder_dropout', **self.param_ranges['decoder_dropout'])\n",
    "        params['learning_rate'] = trial.suggest_float('learning_rate', **self.param_ranges['learning_rate'])\n",
    "        params['weight_decay'] = trial.suggest_float('weight_decay', **self.param_ranges['weight_decay'])\n",
    "        \n",
    "        # 모델 파라미터 구성\n",
    "        model_params = {\n",
    "            'state_extractor': {\n",
    "                'input_size': 12,\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'num_layers': params['num_layers'],\n",
    "                'dropout': params['extractor_dropout']\n",
    "            },\n",
    "            'decoder': {\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'output_size': 7,\n",
    "                'num_layers': params['decoder_layers'],\n",
    "                'num_nodes': params['decoder_nodes'],\n",
    "                'dropout': params['decoder_dropout']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 옵티마이저 파라미터\n",
    "        optimizer_params = {\n",
    "            'lr': params['learning_rate'],\n",
    "            'weight_decay': params['weight_decay']\n",
    "        }\n",
    "        \n",
    "        return model_params, optimizer_params\n",
    "    \n",
    "    def train_single_fold(self, model_params, optimizer_params, train_loader, val_loader):\n",
    "        \"\"\"단일 fold 학습\"\"\"\n",
    "        try:\n",
    "            # 모델 초기화\n",
    "            model = BMEDAutoregressiveModel(model_params['state_extractor'], model_params['decoder']).to(self.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            \n",
    "            for epoch in range(self.train_config['epochs']):\n",
    "                # 학습\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                train_batches = 0\n",
    "                \n",
    "                for input_seq, seq_lengths in train_loader:\n",
    "                    try:\n",
    "                        input_seq = input_seq.to(self.device)\n",
    "                        seq_lengths = seq_lengths.to(self.device)\n",
    "                        \n",
    "                        # Teacher forcing 데이터 준비\n",
    "                        inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "                        \n",
    "                        # Forward pass\n",
    "                        optimizer.zero_grad()\n",
    "                        predictions = model(inputs, target_seq_lengths)\n",
    "                        loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                        \n",
    "                        # Backward pass\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 그래디언트 클리핑\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        train_loss += loss.item()\n",
    "                        train_batches += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Training batch error: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                if train_batches == 0:\n",
    "                    return float('inf')\n",
    "                \n",
    "                train_loss = train_loss / train_batches\n",
    "                \n",
    "                # 검증\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                val_batches = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for input_seq, seq_lengths in val_loader:\n",
    "                        try:\n",
    "                            input_seq = input_seq.to(self.device)\n",
    "                            seq_lengths = seq_lengths.to(self.device)\n",
    "                            \n",
    "                            inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "                            predictions = model(inputs, target_seq_lengths)\n",
    "                            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                            \n",
    "                            val_loss += loss.item()\n",
    "                            val_batches += 1\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Validation batch error: {str(e)}\")\n",
    "                            continue\n",
    "                \n",
    "                if val_batches == 0:\n",
    "                    return float('inf')\n",
    "                \n",
    "                val_loss = val_loss / val_batches\n",
    "                \n",
    "                # Early stopping\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                # 최소 에포크 후 early stopping 적용\n",
    "                if epoch >= self.train_config['min_epochs'] and patience_counter >= self.train_config['patience']:\n",
    "                    break\n",
    "            \n",
    "            return best_val_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fold training error: {str(e)}\")\n",
    "            return float('inf')\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna objective 함수 - 모든 fold 완료 후 평균 반환\"\"\"\n",
    "        try:\n",
    "            # 모델 및 옵티마이저 파라미터 생성\n",
    "            model_params, optimizer_params = self.create_model(trial)\n",
    "            \n",
    "            # K-fold 교차검증 - 모든 fold 실행\n",
    "            fold_losses = []\n",
    "            for fold_idx, (train_loader, val_loader) in enumerate(self.dataloaders):\n",
    "                fold_loss = self.train_single_fold(\n",
    "                    model_params, optimizer_params, \n",
    "                    train_loader, val_loader\n",
    "                )\n",
    "                \n",
    "                if fold_loss == float('inf'):\n",
    "                    return float('inf')\n",
    "                \n",
    "                fold_losses.append(fold_loss)\n",
    "            \n",
    "            # 평균 검증 손실 반환 (모든 fold 완료)\n",
    "            mean_loss = sum(fold_losses) / len(fold_losses)\n",
    "            return mean_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Trial error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return float('inf')\n",
    "\n",
    "def optimize_bmed_hyperparameters(trial, dataloaders):\n",
    "    \"\"\"Optuna를 위한 래퍼 함수\"\"\"\n",
    "    optimizer = BMEDHyperparameterOptimizer(dataloaders)\n",
    "    return optimizer.objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc0e6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 및 전처리 중...\n",
      "Fold 1: Train size = 31, Val size = 8\n",
      "Fold 2: Train size = 31, Val size = 8\n",
      "Fold 3: Train size = 31, Val size = 8\n",
      "Fold 4: Train size = 31, Val size = 8\n",
      "Fold 5: Train size = 32, Val size = 7\n",
      "\n",
      "데이터 전처리 완료!\n",
      "- 시퀀스 개수: 39\n",
      "- 최대 시퀀스 길이: 37\n",
      "- K-fold 수: 5\n",
      "- 각 fold는 (train_loader, val_loader) 튜플\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "print(\"데이터 로드 및 전처리 중...\")\n",
    "\n",
    "# 데이터 로드 및 정규화\n",
    "ndf = norm_data('BMED_DATA_AG.csv')\n",
    "\n",
    "# 시퀀스 데이터 구성\n",
    "seq = seq_data_const(ndf)\n",
    "pad_seq, seq_len, max_seq_len = padded_sequences(seq)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = gen_dataset(pad_seq, seq_len)\n",
    "\n",
    "# K-fold 데이터로더 생성\n",
    "dataloaders = kfold_dataloaders(dataset, k_folds=5, batch_size=8, random_state=42)\n",
    "\n",
    "print(f\"\\n데이터 전처리 완료!\")\n",
    "print(f\"- 시퀀스 개수: {len(seq)}\")\n",
    "print(f\"- 최대 시퀀스 길이: {max_seq_len}\")\n",
    "print(f\"- K-fold 수: {len(dataloaders)}\")\n",
    "print(f\"- 각 fold는 (train_loader, val_loader) 튜플\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b7582a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMED 하이퍼파라미터 최적화 준비 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 14:52:39,516] A new study created in RDB with name: bmed_autoregressive_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMED 자기회귀 모델 하이퍼파라미터 최적화 시작...\n",
      "Study 이름: bmed_autoregressive_optimization\n",
      "저장 위치: sqlite:///bmed_optuna_study.db\n",
      "최적화 방식: K-fold Cross Validation\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-06 14:54:30,312] Trial 0 finished with value: 0.03228123662993312 and parameters: {'hidden_size': 96, 'num_layers': 10, 'extractor_dropout': 0.39279757672456206, 'decoder_layers': 6, 'decoder_nodes': 48, 'decoder_dropout': 0.16239780813448107, 'learning_rate': 0.00014936568554617635, 'weight_decay': 0.0003967605077052988}. Best is trial 0 with value: 0.03228123662993312.\n",
      "[I 2025-08-06 14:56:05,867] Trial 1 finished with value: 0.0034867063164710998 and parameters: {'hidden_size': 160, 'num_layers': 8, 'extractor_dropout': 0.10823379771832098, 'decoder_layers': 10, 'decoder_nodes': 224, 'decoder_dropout': 0.18493564427131048, 'learning_rate': 0.0003511356313970409, 'weight_decay': 3.549878832196506e-06}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 14:57:41,849] Trial 2 finished with value: 0.021498407935723662 and parameters: {'hidden_size': 80, 'num_layers': 6, 'extractor_dropout': 0.2727780074568463, 'decoder_layers': 3, 'decoder_nodes': 160, 'decoder_dropout': 0.15579754426081674, 'learning_rate': 0.0007523742884534858, 'weight_decay': 1.2562773503807034e-05}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 14:58:56,625] Trial 3 finished with value: 0.007797485124319792 and parameters: {'hidden_size': 128, 'num_layers': 8, 'extractor_dropout': 0.1798695128633439, 'decoder_layers': 6, 'decoder_nodes': 160, 'decoder_dropout': 0.1185801650879991, 'learning_rate': 0.006647135865318032, 'weight_decay': 3.247673570627449e-06}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:00:03,429] Trial 4 finished with value: 0.006939580990001559 and parameters: {'hidden_size': 32, 'num_layers': 10, 'extractor_dropout': 0.4862528132298237, 'decoder_layers': 9, 'decoder_nodes': 80, 'decoder_dropout': 0.13906884560255356, 'learning_rate': 0.01129013355909268, 'weight_decay': 2.091498132903561e-05}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:01:04,350] Trial 5 finished with value: 0.004499907465651631 and parameters: {'hidden_size': 32, 'num_layers': 5, 'extractor_dropout': 0.11375540844608736, 'decoder_layers': 10, 'decoder_nodes': 80, 'decoder_dropout': 0.36500891374159283, 'learning_rate': 0.0008612579192594886, 'weight_decay': 3.632486956676606e-05}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:01:53,857] Trial 6 finished with value: 0.007314190734177828 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.48783385110582345, 'decoder_layers': 8, 'decoder_nodes': 256, 'decoder_dropout': 0.4579309401710595, 'learning_rate': 0.00621870472776908, 'weight_decay': 0.0005829384542994739}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:02:30,395] Trial 7 finished with value: 0.008365337364375591 and parameters: {'hidden_size': 32, 'num_layers': 2, 'extractor_dropout': 0.11809091556421523, 'decoder_layers': 4, 'decoder_nodes': 112, 'decoder_dropout': 0.20853961270955837, 'learning_rate': 0.030634622106220845, 'weight_decay': 1.1756010900231857e-05}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:03:24,074] Trial 8 finished with value: 0.006254279753193259 and parameters: {'hidden_size': 80, 'num_layers': 6, 'extractor_dropout': 0.15636968998990508, 'decoder_layers': 9, 'decoder_nodes': 32, 'decoder_dropout': 0.4947547746402069, 'learning_rate': 0.020736445177905044, 'weight_decay': 3.9459088110999995e-06}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:05:31,406] Trial 9 finished with value: 0.004156421590596438 and parameters: {'hidden_size': 16, 'num_layers': 9, 'extractor_dropout': 0.38274293753904687, 'decoder_layers': 8, 'decoder_nodes': 208, 'decoder_dropout': 0.12961786069363615, 'learning_rate': 0.0011895896737553553, 'weight_decay': 2.2264204303769692e-06}. Best is trial 1 with value: 0.0034867063164710998.\n",
      "[I 2025-08-06 15:06:54,579] Trial 10 finished with value: 0.0030517271254211662 and parameters: {'hidden_size': 240, 'num_layers': 4, 'extractor_dropout': 0.247491509088439, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.2689964257681106, 'learning_rate': 0.00011137414908293505, 'weight_decay': 1.0887361498353545e-06}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:08:40,441] Trial 11 finished with value: 17573.417341031367 and parameters: {'hidden_size': 240, 'num_layers': 4, 'extractor_dropout': 0.22350238988452584, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.2673936252831768, 'learning_rate': 0.00011250263109869326, 'weight_decay': 1.0783755793860253e-06}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:10:18,868] Trial 12 finished with value: 0.003383751166984439 and parameters: {'hidden_size': 240, 'num_layers': 7, 'extractor_dropout': 0.3061251577822067, 'decoder_layers': 1, 'decoder_nodes': 208, 'decoder_dropout': 0.31111155721201295, 'learning_rate': 0.00026780412138500905, 'weight_decay': 9.079116747274293e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:10:53,905] Trial 13 finished with value: 0.006338914856314659 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.32150790588199796, 'decoder_layers': 1, 'decoder_nodes': 208, 'decoder_dropout': 0.3245581948726233, 'learning_rate': 0.0995605566065905, 'weight_decay': 0.00011877607368926173}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:12:44,377] Trial 14 finished with value: 0.0035716401878744366 and parameters: {'hidden_size': 208, 'num_layers': 7, 'extractor_dropout': 0.2818556188718077, 'decoder_layers': 3, 'decoder_nodes': 176, 'decoder_dropout': 0.25838046802844766, 'learning_rate': 0.0002815717869071264, 'weight_decay': 9.504901069527972e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:13:34,143] Trial 15 finished with value: 0.006258971680654213 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.34216615618280094, 'decoder_layers': 2, 'decoder_nodes': 224, 'decoder_dropout': 0.3846350292513693, 'learning_rate': 0.001875758351817269, 'weight_decay': 0.00011898835505485919}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:14:46,201] Trial 16 finished with value: 0.003428960917517543 and parameters: {'hidden_size': 208, 'num_layers': 4, 'extractor_dropout': 0.22986362363239785, 'decoder_layers': 4, 'decoder_nodes': 256, 'decoder_dropout': 0.3075695365705463, 'learning_rate': 0.00032823337554912515, 'weight_decay': 5.009879509475048e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:15:56,752] Trial 17 finished with value: 0.07177929356694221 and parameters: {'hidden_size': 176, 'num_layers': 5, 'extractor_dropout': 0.23479150753927625, 'decoder_layers': 1, 'decoder_nodes': 192, 'decoder_dropout': 0.236620037974197, 'learning_rate': 0.00010953114890618479, 'weight_decay': 0.00032732538322400375}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:16:47,082] Trial 18 finished with value: 0.008604962565004825 and parameters: {'hidden_size': 240, 'num_layers': 3, 'extractor_dropout': 0.37490045283509044, 'decoder_layers': 5, 'decoder_nodes': 144, 'decoder_dropout': 0.3614838463376575, 'learning_rate': 0.0003936399964708049, 'weight_decay': 0.00024515235346094394}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:17:56,525] Trial 19 finished with value: 0.0521618319209665 and parameters: {'hidden_size': 192, 'num_layers': 7, 'extractor_dropout': 0.4518005107400369, 'decoder_layers': 2, 'decoder_nodes': 224, 'decoder_dropout': 0.4283035574074348, 'learning_rate': 0.00021486725664350497, 'weight_decay': 1.1205191518978514e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:19:06,827] Trial 20 finished with value: 0.0034488838631659747 and parameters: {'hidden_size': 256, 'num_layers': 7, 'extractor_dropout': 0.2672335099798459, 'decoder_layers': 2, 'decoder_nodes': 112, 'decoder_dropout': 0.2886436575517387, 'learning_rate': 0.0021825591646033437, 'weight_decay': 5.580367289643466e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:20:25,542] Trial 21 finished with value: 0.004726667620707304 and parameters: {'hidden_size': 224, 'num_layers': 4, 'extractor_dropout': 0.233975824658518, 'decoder_layers': 4, 'decoder_nodes': 256, 'decoder_dropout': 0.3233045984809048, 'learning_rate': 0.0003966337587558511, 'weight_decay': 5.0576850783980835e-05}. Best is trial 10 with value: 0.0030517271254211662.\n",
      "[I 2025-08-06 15:22:12,856] Trial 22 finished with value: 0.0008790765888988972 and parameters: {'hidden_size': 224, 'num_layers': 3, 'extractor_dropout': 0.18466998754935043, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.3292349289197707, 'learning_rate': 0.0006135140629206839, 'weight_decay': 2.2048096213369614e-05}. Best is trial 22 with value: 0.0008790765888988972.\n",
      "[I 2025-08-06 15:22:43,308] Trial 23 finished with value: 0.09874144564382732 and parameters: {'hidden_size': 224, 'num_layers': 3, 'extractor_dropout': 0.18207859527149786, 'decoder_layers': 3, 'decoder_nodes': 224, 'decoder_dropout': 0.400436785687205, 'learning_rate': 0.00018360802212250186, 'weight_decay': 0.0009297876355960259}. Best is trial 22 with value: 0.0008790765888988972.\n",
      "[I 2025-08-06 15:24:29,638] Trial 24 finished with value: 0.0019004602479981258 and parameters: {'hidden_size': 176, 'num_layers': 3, 'extractor_dropout': 0.3095675711987696, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.3425407731239834, 'learning_rate': 0.0006707628907695263, 'weight_decay': 6.617848737218718e-06}. Best is trial 22 with value: 0.0008790765888988972.\n",
      "[I 2025-08-06 15:26:11,664] Trial 25 finished with value: 0.0002952375449240208 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.19583707575076773, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3536051970294886, 'learning_rate': 0.0006401993856655885, 'weight_decay': 1.0092463065901874e-06}. Best is trial 25 with value: 0.0002952375449240208.\n",
      "[I 2025-08-06 15:27:45,869] Trial 26 finished with value: 0.00028346199105726554 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.19943223935220428, 'decoder_layers': 2, 'decoder_nodes': 192, 'decoder_dropout': 0.34256587966079083, 'learning_rate': 0.0008443325131696053, 'weight_decay': 5.767534003255642e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:29:01,297] Trial 27 finished with value: 0.028798890678444877 and parameters: {'hidden_size': 128, 'num_layers': 1, 'extractor_dropout': 0.18513373099387567, 'decoder_layers': 5, 'decoder_nodes': 192, 'decoder_dropout': 0.41349324186959024, 'learning_rate': 0.001440949290230246, 'weight_decay': 1.6713529208962702e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:30:08,437] Trial 28 finished with value: 0.0022578227246413006 and parameters: {'hidden_size': 160, 'num_layers': 2, 'extractor_dropout': 0.1430417456553454, 'decoder_layers': 3, 'decoder_nodes': 176, 'decoder_dropout': 0.4402027921411633, 'learning_rate': 0.0031597006009612518, 'weight_decay': 1.9896981104402497e-05}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:31:24,238] Trial 29 finished with value: 0.0031385504582431166 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.1964633833055682, 'decoder_layers': 6, 'decoder_nodes': 192, 'decoder_dropout': 0.3560762164992275, 'learning_rate': 0.0005476648575728333, 'weight_decay': 6.508298421627595e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:33:00,915] Trial 30 finished with value: 0.0003378094668732956 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.15196351383163934, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3752653150467858, 'learning_rate': 0.0009204227175251317, 'weight_decay': 6.4075280745522376e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:34:22,159] Trial 31 finished with value: 0.0012747020024107768 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.14741995013570636, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.38153953470688556, 'learning_rate': 0.0010590100346080662, 'weight_decay': 5.874125777454502e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:35:58,984] Trial 32 finished with value: 0.00033152803080156447 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.19647855755764393, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3364012123396346, 'learning_rate': 0.0005236390617288538, 'weight_decay': 1.9702807453233006e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:36:53,960] Trial 33 finished with value: 0.005712859958293848 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.2091755515338692, 'decoder_layers': 2, 'decoder_nodes': 224, 'decoder_dropout': 0.2912504603834338, 'learning_rate': 0.0030810525967371973, 'weight_decay': 1.9833699279890556e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:38:43,169] Trial 34 finished with value: 0.0003132003446808085 and parameters: {'hidden_size': 144, 'num_layers': 1, 'extractor_dropout': 0.13494389910518045, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3914058771564305, 'learning_rate': 0.0005509597058649408, 'weight_decay': 3.0543799374501115e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:39:54,417] Trial 35 finished with value: 0.0026029692206066104 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.10316606778851987, 'decoder_layers': 4, 'decoder_nodes': 176, 'decoder_dropout': 0.402850089094646, 'learning_rate': 0.0004905290871283898, 'weight_decay': 2.730321723921733e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:41:27,395] Trial 36 finished with value: 0.002548152720555663 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.13070085991587577, 'decoder_layers': 3, 'decoder_nodes': 208, 'decoder_dropout': 0.3442867642408569, 'learning_rate': 0.0017906880416509406, 'weight_decay': 4.204545945523702e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:41:52,482] Trial 37 finished with value: 0.06817041020840406 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.16193587965317996, 'decoder_layers': 2, 'decoder_nodes': 128, 'decoder_dropout': 0.47186901941945086, 'learning_rate': 0.00017633219243381036, 'weight_decay': 1.4005872014923445e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:42:32,706] Trial 38 finished with value: 0.008291888516396284 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.2601994943119849, 'decoder_layers': 6, 'decoder_nodes': 160, 'decoder_dropout': 0.10106718451091268, 'learning_rate': 0.0052206921261517695, 'weight_decay': 2.845809822448103e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:43:37,565] Trial 39 finished with value: 0.0040584280446637425 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.20659082207088653, 'decoder_layers': 5, 'decoder_nodes': 80, 'decoder_dropout': 0.4300056455539847, 'learning_rate': 0.0008533227208566355, 'weight_decay': 1.4847835956245977e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:44:44,143] Trial 40 finished with value: 0.002986483764834702 and parameters: {'hidden_size': 128, 'num_layers': 3, 'extractor_dropout': 0.16596031283861623, 'decoder_layers': 7, 'decoder_nodes': 240, 'decoder_dropout': 0.1846926858314791, 'learning_rate': 0.0004649450061597162, 'weight_decay': 4.522071586608342e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:46:32,448] Trial 41 finished with value: 0.00029269114311318843 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.13392915050011564, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.38129254728232537, 'learning_rate': 0.0008718910438598732, 'weight_decay': 7.87949407736352e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:48:00,442] Trial 42 finished with value: 0.001609489828115329 and parameters: {'hidden_size': 64, 'num_layers': 1, 'extractor_dropout': 0.11807797185705747, 'decoder_layers': 3, 'decoder_nodes': 224, 'decoder_dropout': 0.3936650749804722, 'learning_rate': 0.0013010140243841463, 'weight_decay': 9.816061524547862e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:49:39,069] Trial 43 finished with value: 0.0003347482037497684 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.13035646512600846, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.34913660029842636, 'learning_rate': 0.0006247469423832147, 'weight_decay': 3.054407801399693e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:50:59,521] Trial 44 finished with value: 0.003474544553318992 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.21022922683678513, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.37005507364839935, 'learning_rate': 0.0007748325161086474, 'weight_decay': 2.3711272072977526e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:52:01,923] Trial 45 finished with value: 0.006408290565013885 and parameters: {'hidden_size': 192, 'num_layers': 2, 'extractor_dropout': 0.13451145352385924, 'decoder_layers': 4, 'decoder_nodes': 208, 'decoder_dropout': 0.46832824296201836, 'learning_rate': 0.002346826540868939, 'weight_decay': 1.011582642189517e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:53:20,098] Trial 46 finished with value: 0.03843110067537055 and parameters: {'hidden_size': 64, 'num_layers': 1, 'extractor_dropout': 0.16372287243925449, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.4172841936493707, 'learning_rate': 0.00026887843335355585, 'weight_decay': 8.578093381352545e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:54:19,470] Trial 47 finished with value: 0.002550881783827208 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.17117717642780148, 'decoder_layers': 1, 'decoder_nodes': 192, 'decoder_dropout': 0.2999247424125988, 'learning_rate': 0.004269398572908616, 'weight_decay': 1.533181162797754e-05}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:56:16,854] Trial 48 finished with value: 0.00469082067720592 and parameters: {'hidden_size': 96, 'num_layers': 9, 'extractor_dropout': 0.10824807572764202, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.36830665900143605, 'learning_rate': 0.0014059977586855944, 'weight_decay': 1.9531923515592286e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:57:14,925] Trial 49 finished with value: 0.008365926612168551 and parameters: {'hidden_size': 128, 'num_layers': 1, 'extractor_dropout': 0.19533688858538076, 'decoder_layers': 7, 'decoder_nodes': 224, 'decoder_dropout': 0.33175004408962394, 'learning_rate': 0.008802534796756306, 'weight_decay': 4.685742128570654e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 15:58:41,347] Trial 50 finished with value: 0.001850284618558362 and parameters: {'hidden_size': 176, 'num_layers': 3, 'extractor_dropout': 0.24777756330417292, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.4429423285617696, 'learning_rate': 0.0010494216137528214, 'weight_decay': 1.3849528853524277e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 16:00:33,444] Trial 51 finished with value: 0.0003155983256874606 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.13149457317580407, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.35416583552276876, 'learning_rate': 0.0006692547322168585, 'weight_decay': 3.516017174596109e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 16:01:57,044] Trial 52 finished with value: 0.006682313984492793 and parameters: {'hidden_size': 80, 'num_layers': 2, 'extractor_dropout': 0.12368176249839638, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3917682332498563, 'learning_rate': 0.00042636948705984234, 'weight_decay': 3.7911815408887508e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 16:03:23,128] Trial 53 finished with value: 0.00028717748064082115 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.10230198344806966, 'decoder_layers': 3, 'decoder_nodes': 256, 'decoder_dropout': 0.3185212299335788, 'learning_rate': 0.0007866455387682494, 'weight_decay': 3.1363248875858517e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 16:04:50,923] Trial 54 finished with value: 0.00500352077651769 and parameters: {'hidden_size': 96, 'num_layers': 2, 'extractor_dropout': 0.1095719932814365, 'decoder_layers': 3, 'decoder_nodes': 256, 'decoder_dropout': 0.3093686221378562, 'learning_rate': 0.0003139945113734447, 'weight_decay': 8.284268408277747e-06}. Best is trial 26 with value: 0.00028346199105726554.\n",
      "[I 2025-08-06 16:06:30,501] Trial 55 finished with value: 0.0002329566588741727 and parameters: {'hidden_size': 112, 'num_layers': 1, 'extractor_dropout': 0.1487579223899451, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.3573535882705787, 'learning_rate': 0.0007544307843162699, 'weight_decay': 5.286127770333081e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:08:03,711] Trial 56 finished with value: 0.0023121941077988593 and parameters: {'hidden_size': 80, 'num_layers': 1, 'extractor_dropout': 0.1460134331796657, 'decoder_layers': 1, 'decoder_nodes': 208, 'decoder_dropout': 0.28701710140419073, 'learning_rate': 0.00175378124132855, 'weight_decay': 1.3096960953722318e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:08:34,731] Trial 57 finished with value: 0.0063643826637417075 and parameters: {'hidden_size': 64, 'num_layers': 1, 'extractor_dropout': 0.10446832555502308, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.31776752902035477, 'learning_rate': 0.09211722054179744, 'weight_decay': 3.18179188356727e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:09:56,126] Trial 58 finished with value: 0.002962446538731456 and parameters: {'hidden_size': 128, 'num_layers': 6, 'extractor_dropout': 0.2894328247930115, 'decoder_layers': 1, 'decoder_nodes': 224, 'decoder_dropout': 0.24599392624927843, 'learning_rate': 0.0010229000966195624, 'weight_decay': 5.78508756173229e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:10:53,680] Trial 59 finished with value: 0.005165880697313696 and parameters: {'hidden_size': 48, 'num_layers': 3, 'extractor_dropout': 0.45824996985182964, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.4108708634647755, 'learning_rate': 0.0003619130281405318, 'weight_decay': 5.009323383928849e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:12:30,650] Trial 60 finished with value: 0.0003464157227426767 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.2218687456322004, 'decoder_layers': 4, 'decoder_nodes': 208, 'decoder_dropout': 0.2725154167523024, 'learning_rate': 0.0007276589478287629, 'weight_decay': 2.486737428445063e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:13:53,782] Trial 61 finished with value: 0.019335870491340758 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.1394956117305982, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.359911078065527, 'learning_rate': 0.00022209996852869758, 'weight_decay': 3.453656568893113e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:15:11,151] Trial 62 finished with value: 0.022630995931103827 and parameters: {'hidden_size': 112, 'num_layers': 5, 'extractor_dropout': 0.11948161535008565, 'decoder_layers': 10, 'decoder_nodes': 256, 'decoder_dropout': 0.3544548466371222, 'learning_rate': 0.0006183411625773694, 'weight_decay': 7.834567919952507e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:16:45,546] Trial 63 finished with value: 0.0023778632676112466 and parameters: {'hidden_size': 144, 'num_layers': 1, 'extractor_dropout': 0.15142577415617783, 'decoder_layers': 2, 'decoder_nodes': 224, 'decoder_dropout': 0.38092626683008607, 'learning_rate': 0.0008117999733491568, 'weight_decay': 3.5068824246695923e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:18:28,287] Trial 64 finished with value: 0.0002694132665055804 and parameters: {'hidden_size': 96, 'num_layers': 2, 'extractor_dropout': 0.17492700326286145, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.3391210005836695, 'learning_rate': 0.0012136667713306686, 'weight_decay': 1.4356381937547632e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:19:38,133] Trial 65 finished with value: 0.00490113758132793 and parameters: {'hidden_size': 80, 'num_layers': 2, 'extractor_dropout': 0.1773863516988808, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.3243176917901903, 'learning_rate': 0.0023830186072885205, 'weight_decay': 1.7183594459065673e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:20:49,264] Trial 66 finished with value: 0.0018257655610796064 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.3514483646741619, 'decoder_layers': 1, 'decoder_nodes': 224, 'decoder_dropout': 0.3427318849959153, 'learning_rate': 0.0015349350451886552, 'weight_decay': 1.3545851012550131e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:22:00,988] Trial 67 finished with value: 0.018418354052118956 and parameters: {'hidden_size': 128, 'num_layers': 3, 'extractor_dropout': 0.15519439107312283, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.37336353805835915, 'learning_rate': 0.0012463589323024069, 'weight_decay': 1.0548788388354371e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:24:14,177] Trial 68 finished with value: 0.0033366712741553783 and parameters: {'hidden_size': 192, 'num_layers': 10, 'extractor_dropout': 0.18938199100001865, 'decoder_layers': 9, 'decoder_nodes': 208, 'decoder_dropout': 0.3045886834071207, 'learning_rate': 0.000923766453936739, 'weight_decay': 2.421748073277766e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:25:26,044] Trial 69 finished with value: 39718384435.20556 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.17184193258170738, 'decoder_layers': 2, 'decoder_nodes': 192, 'decoder_dropout': 0.3904333722015911, 'learning_rate': 0.0005332585839397154, 'weight_decay': 5.489103878120011e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:26:33,184] Trial 70 finished with value: 0.04498642368707806 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.21893163171717647, 'decoder_layers': 3, 'decoder_nodes': 144, 'decoder_dropout': 0.3352929098988694, 'learning_rate': 0.00013664623006428802, 'weight_decay': 6.813137564021292e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:28:21,599] Trial 71 finished with value: 0.00036895567318424584 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.1279204533798009, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.3602259531016273, 'learning_rate': 0.0006431259722313514, 'weight_decay': 3.960143641580361e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:29:18,539] Trial 72 finished with value: 0.015346555650467053 and parameters: {'hidden_size': 112, 'num_layers': 1, 'extractor_dropout': 0.1365941527264255, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.31683567779037003, 'learning_rate': 0.0003964590660898972, 'weight_decay': 9.538047064648996e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:30:44,390] Trial 73 finished with value: 0.0016527485830010846 and parameters: {'hidden_size': 128, 'num_layers': 2, 'extractor_dropout': 0.11813460949588107, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.35100584196249324, 'learning_rate': 0.0012033269098112107, 'weight_decay': 7.446595059602238e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:32:40,172] Trial 74 finished with value: 0.0007369539758656174 and parameters: {'hidden_size': 96, 'num_layers': 4, 'extractor_dropout': 0.10091411214339792, 'decoder_layers': 2, 'decoder_nodes': 224, 'decoder_dropout': 0.4051796709275827, 'learning_rate': 0.0007397905249409496, 'weight_decay': 1.2221315651704423e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:34:12,419] Trial 75 finished with value: 0.00034376786497887225 and parameters: {'hidden_size': 112, 'num_layers': 1, 'extractor_dropout': 0.15674408470818377, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.3787141196545759, 'learning_rate': 0.000505882384037378, 'weight_decay': 1.7367194324360547e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:35:56,685] Trial 76 finished with value: 0.0003061676281504333 and parameters: {'hidden_size': 176, 'num_layers': 2, 'extractor_dropout': 0.1406872145551077, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.33649911620678985, 'learning_rate': 0.000900156169594448, 'weight_decay': 3.0185805603686004e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:37:39,826] Trial 77 finished with value: 0.00032633565133437513 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.17506645294150108, 'decoder_layers': 3, 'decoder_nodes': 96, 'decoder_dropout': 0.2779366201763895, 'learning_rate': 0.0009900562664814654, 'weight_decay': 4.919870721085985e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:38:44,423] Trial 78 finished with value: 0.0035390739882132038 and parameters: {'hidden_size': 208, 'num_layers': 3, 'extractor_dropout': 0.14140546318193675, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.2952641993033249, 'learning_rate': 0.0016050939189138783, 'weight_decay': 2.9812067891298598e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:39:33,605] Trial 79 finished with value: 0.004521742626093328 and parameters: {'hidden_size': 160, 'num_layers': 2, 'extractor_dropout': 0.19854749971673047, 'decoder_layers': 1, 'decoder_nodes': 224, 'decoder_dropout': 0.33894850696135354, 'learning_rate': 0.0020215352857695604, 'weight_decay': 2.500716843670002e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:40:12,765] Trial 80 finished with value: 0.00646202233619988 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.2459987684524267, 'decoder_layers': 4, 'decoder_nodes': 240, 'decoder_dropout': 0.3259198339016164, 'learning_rate': 0.0026659434246403277, 'weight_decay': 1.6908475437819923e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:41:45,362] Trial 81 finished with value: 0.0003170159499859437 and parameters: {'hidden_size': 176, 'num_layers': 2, 'extractor_dropout': 0.1280002734855753, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.3665015596683327, 'learning_rate': 0.0007565370784529625, 'weight_decay': 3.499668122039537e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:43:39,033] Trial 82 finished with value: 0.0003341906180139631 and parameters: {'hidden_size': 128, 'num_layers': 2, 'extractor_dropout': 0.16144523234646466, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.3489828121665462, 'learning_rate': 0.0005698568824128691, 'weight_decay': 4.31281663927916e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:45:06,237] Trial 83 finished with value: 0.008595156826777384 and parameters: {'hidden_size': 160, 'num_layers': 3, 'extractor_dropout': 0.11371956855867174, 'decoder_layers': 3, 'decoder_nodes': 224, 'decoder_dropout': 0.3892407399778113, 'learning_rate': 0.000450338433008067, 'weight_decay': 2.1974359267686727e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:46:31,897] Trial 84 finished with value: 0.008169105247361585 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.14881382735725213, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.31333423780156827, 'learning_rate': 0.00031815706178319093, 'weight_decay': 1.7020015903292038e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:47:32,548] Trial 85 finished with value: 0.00320609575137496 and parameters: {'hidden_size': 112, 'num_layers': 8, 'extractor_dropout': 0.18162288825731432, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.33143533504047856, 'learning_rate': 0.0011720054545711468, 'weight_decay': 5.846331692805491e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:49:14,588] Trial 86 finished with value: 0.00029681619489565494 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.13637680380560993, 'decoder_layers': 3, 'decoder_nodes': 256, 'decoder_dropout': 0.3624988920970355, 'learning_rate': 0.000802903647355673, 'weight_decay': 2.766657473062042e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:50:43,422] Trial 87 finished with value: 0.0004217329056700692 and parameters: {'hidden_size': 144, 'num_layers': 1, 'extractor_dropout': 0.1668848055300191, 'decoder_layers': 4, 'decoder_nodes': 224, 'decoder_dropout': 0.4211972580961659, 'learning_rate': 0.0008841196277589916, 'weight_decay': 2.9492823789496223e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:53:02,747] Trial 88 finished with value: 0.00029716237622778863 and parameters: {'hidden_size': 176, 'num_layers': 4, 'extractor_dropout': 0.14194240738898575, 'decoder_layers': 3, 'decoder_nodes': 176, 'decoder_dropout': 0.3661479332484354, 'learning_rate': 0.0011189641124138051, 'weight_decay': 2.035778202235456e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:54:49,959] Trial 89 finished with value: 0.025557634231518023 and parameters: {'hidden_size': 192, 'num_layers': 5, 'extractor_dropout': 0.14457240626199994, 'decoder_layers': 4, 'decoder_nodes': 176, 'decoder_dropout': 0.3635973131866878, 'learning_rate': 0.0015000727398145476, 'weight_decay': 1.3330688112167793e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:56:51,134] Trial 90 finished with value: 0.00034864788758568464 and parameters: {'hidden_size': 176, 'num_layers': 3, 'extractor_dropout': 0.4063171557174499, 'decoder_layers': 3, 'decoder_nodes': 144, 'decoder_dropout': 0.34308942582626395, 'learning_rate': 0.0011156240750042187, 'weight_decay': 1.886479288562895e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 16:58:20,997] Trial 91 finished with value: 0.027154416116536594 and parameters: {'hidden_size': 176, 'num_layers': 2, 'extractor_dropout': 0.11393045945904338, 'decoder_layers': 3, 'decoder_nodes': 160, 'decoder_dropout': 0.39965465653198345, 'learning_rate': 0.0008762104899186881, 'weight_decay': 2.4072678609195187e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:00:01,106] Trial 92 finished with value: 0.0029132336261682213 and parameters: {'hidden_size': 144, 'num_layers': 4, 'extractor_dropout': 0.13773056551180587, 'decoder_layers': 3, 'decoder_nodes': 128, 'decoder_dropout': 0.3723397680265395, 'learning_rate': 0.0006781869707349936, 'weight_decay': 1.2398264957605823e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:01:41,910] Trial 93 finished with value: 0.0030841830186545847 and parameters: {'hidden_size': 160, 'num_layers': 6, 'extractor_dropout': 0.12451827072069727, 'decoder_layers': 4, 'decoder_nodes': 240, 'decoder_dropout': 0.3839402883543278, 'learning_rate': 0.0013088995259376232, 'weight_decay': 4.1700189740421334e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:02:13,613] Trial 94 finished with value: 0.007823302829638123 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.15792182934501967, 'decoder_layers': 2, 'decoder_nodes': 192, 'decoder_dropout': 0.3575302549395467, 'learning_rate': 0.018597467794699195, 'weight_decay': 1.5163137456314963e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:04:00,072] Trial 95 finished with value: 0.001241390500217676 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.18738795412911158, 'decoder_layers': 5, 'decoder_nodes': 256, 'decoder_dropout': 0.33563662457421517, 'learning_rate': 0.001009937749162943, 'weight_decay': 2.1790573587722642e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:06:06,969] Trial 96 finished with value: 0.0002730857697315514 and parameters: {'hidden_size': 192, 'num_layers': 2, 'extractor_dropout': 0.10035432996275676, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.34818925996987826, 'learning_rate': 0.0005690859013199536, 'weight_decay': 5.107383423335794e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:07:38,226] Trial 97 finished with value: 0.0029484412109013645 and parameters: {'hidden_size': 192, 'num_layers': 3, 'extractor_dropout': 0.1085325865650519, 'decoder_layers': 3, 'decoder_nodes': 208, 'decoder_dropout': 0.32082993438845875, 'learning_rate': 0.00045076522193458486, 'weight_decay': 5.220513898144485e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:09:19,570] Trial 98 finished with value: 0.0008887709962436929 and parameters: {'hidden_size': 176, 'num_layers': 2, 'extractor_dropout': 0.10174980017373156, 'decoder_layers': 4, 'decoder_nodes': 256, 'decoder_dropout': 0.34790959444020314, 'learning_rate': 0.0007983365437953566, 'weight_decay': 8.902182672406782e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:11:17,950] Trial 99 finished with value: 0.0003008900908753276 and parameters: {'hidden_size': 208, 'num_layers': 2, 'extractor_dropout': 0.12154389913218304, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.30082800997800746, 'learning_rate': 0.0005905332929569512, 'weight_decay': 1.147992565416184e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:13:19,359] Trial 100 finished with value: 0.0008743836137000471 and parameters: {'hidden_size': 224, 'num_layers': 4, 'extractor_dropout': 0.12137888519066393, 'decoder_layers': 3, 'decoder_nodes': 208, 'decoder_dropout': 0.3076036239436181, 'learning_rate': 0.0005996736843351739, 'weight_decay': 1.1587912733862922e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:15:01,563] Trial 101 finished with value: 0.0010024847753811628 and parameters: {'hidden_size': 192, 'num_layers': 2, 'extractor_dropout': 0.14890235306205746, 'decoder_layers': 3, 'decoder_nodes': 240, 'decoder_dropout': 0.3307332721604473, 'learning_rate': 0.00036876592379520565, 'weight_decay': 7.607492554711055e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:16:35,633] Trial 102 finished with value: 0.0013787746196612717 and parameters: {'hidden_size': 208, 'num_layers': 2, 'extractor_dropout': 0.13136743049604716, 'decoder_layers': 3, 'decoder_nodes': 224, 'decoder_dropout': 0.2815318434550405, 'learning_rate': 0.0007391584349023858, 'weight_decay': 6.979714433221214e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:17:53,958] Trial 103 finished with value: 0.003346215473720804 and parameters: {'hidden_size': 208, 'num_layers': 2, 'extractor_dropout': 0.11423499123639788, 'decoder_layers': 4, 'decoder_nodes': 240, 'decoder_dropout': 0.3012387563249706, 'learning_rate': 0.0008799023692602841, 'weight_decay': 1.4253158640074702e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:19:45,353] Trial 104 finished with value: 0.0009161039139144123 and parameters: {'hidden_size': 192, 'num_layers': 3, 'extractor_dropout': 0.20380537779276126, 'decoder_layers': 3, 'decoder_nodes': 256, 'decoder_dropout': 0.3695755799844343, 'learning_rate': 0.0004848131702125851, 'weight_decay': 2.678135360163465e-06}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:21:17,080] Trial 105 finished with value: 0.00024430093908449634 and parameters: {'hidden_size': 224, 'num_layers': 2, 'extractor_dropout': 0.16757315947426318, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.2549191237184654, 'learning_rate': 0.001106349032126829, 'weight_decay': 1.0741770310297478e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:22:45,778] Trial 106 finished with value: 0.0033445596229285 and parameters: {'hidden_size': 224, 'num_layers': 3, 'extractor_dropout': 0.1771937024443566, 'decoder_layers': 1, 'decoder_nodes': 224, 'decoder_dropout': 0.20736689608342587, 'learning_rate': 0.0017560544744266117, 'weight_decay': 1.1614004028810511e-05}. Best is trial 55 with value: 0.0002329566588741727.\n",
      "[I 2025-08-06 17:24:22,150] Trial 107 finished with value: 0.00020923341653542594 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.16499519899608778, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.2588789015557631, 'learning_rate': 0.0013343509515327903, 'weight_decay': 2.1587225039585835e-05}. Best is trial 107 with value: 0.00020923341653542594.\n",
      "[I 2025-08-06 17:25:56,259] Trial 108 finished with value: 0.00021409469918580725 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1681552033074369, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.26084391509665894, 'learning_rate': 0.0013649564422050747, 'weight_decay': 2.0864433677933678e-05}. Best is trial 107 with value: 0.00020923341653542594.\n",
      "[I 2025-08-06 17:27:05,771] Trial 109 finished with value: 0.0027707137283869087 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19130053742448663, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.24813078754312842, 'learning_rate': 0.0038014714709026054, 'weight_decay': 2.7873177810157798e-05}. Best is trial 107 with value: 0.00020923341653542594.\n",
      "[I 2025-08-06 17:28:34,070] Trial 110 finished with value: 0.0001974653816432692 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21618800378966113, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.22636559229219505, 'learning_rate': 0.0013946662081344243, 'weight_decay': 1.9020689805880687e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:29:44,995] Trial 111 finished with value: 0.005176856418256648 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21049292360357533, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.22377485468105873, 'learning_rate': 0.0014123660206816447, 'weight_decay': 2.317615984274062e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:30:44,945] Trial 112 finished with value: 0.004971319682954345 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.17184519346511923, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.25792264711873986, 'learning_rate': 0.0020834620553253917, 'weight_decay': 1.7995459820910077e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:31:49,334] Trial 113 finished with value: 0.0026149421755690128 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.16564668148980916, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.21768998797163586, 'learning_rate': 0.001646900071307029, 'weight_decay': 4.1860939769658416e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:32:41,390] Trial 114 finished with value: 0.006592363910749554 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.231157278072154, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.2618719801389915, 'learning_rate': 0.0025980210141362562, 'weight_decay': 2.708393905898409e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:33:50,942] Trial 115 finished with value: 0.007669038948370144 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2179426113433982, 'decoder_layers': 2, 'decoder_nodes': 256, 'decoder_dropout': 0.22917699561156613, 'learning_rate': 0.0013208374138752965, 'weight_decay': 2.00085127015465e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:34:45,442] Trial 116 finished with value: 0.003277923540736083 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2013062930722347, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.23830961571128922, 'learning_rate': 0.001064368786361355, 'weight_decay': 3.3522972582776544e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:35:39,326] Trial 117 finished with value: 0.006596131762489676 and parameters: {'hidden_size': 240, 'num_layers': 9, 'extractor_dropout': 0.15815857378885106, 'decoder_layers': 2, 'decoder_nodes': 240, 'decoder_dropout': 0.19880537801030684, 'learning_rate': 0.0018865942517672595, 'weight_decay': 1.5848578250640992e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:37:15,833] Trial 118 finished with value: 0.00022338910639518872 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18454574206853158, 'decoder_layers': 1, 'decoder_nodes': 256, 'decoder_dropout': 0.2563892161470986, 'learning_rate': 0.0006791440921121866, 'weight_decay': 3.845527860958721e-05}. Best is trial 110 with value: 0.0001974653816432692.\n",
      "[I 2025-08-06 17:38:40,732] Trial 119 finished with value: 0.0001931106555275619 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18214204194499464, 'decoder_layers': 1, 'decoder_nodes': 240, 'decoder_dropout': 0.2531727626923674, 'learning_rate': 0.0012005833363172296, 'weight_decay': 4.0970999870288835e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:40:20,656] Trial 120 finished with value: 0.00023289028176805006 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.1899190797687802, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2523825808639064, 'learning_rate': 0.0012750667095512993, 'weight_decay': 4.030228239831392e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:41:24,121] Trial 121 finished with value: 0.015776053874287755 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18210216028683793, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.25225464220763205, 'learning_rate': 0.001266367103642782, 'weight_decay': 6.772737526040863e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:43:02,659] Trial 122 finished with value: 0.00023199094866868108 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.1916711944491129, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2359615775322809, 'learning_rate': 0.0014669142965562645, 'weight_decay': 4.073201658075705e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:44:43,273] Trial 123 finished with value: 0.0002207558252848685 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19124453545484651, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2415734249336142, 'learning_rate': 0.001459573136389107, 'weight_decay': 4.0398863039100914e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:46:17,484] Trial 124 finished with value: 0.00022783160966355354 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.18857017655492403, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.23977433704787038, 'learning_rate': 0.0015075058359099885, 'weight_decay': 4.235713541064021e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:47:47,296] Trial 125 finished with value: 0.00020635974360629916 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.190801547778314, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23802504868077382, 'learning_rate': 0.0022944677824456674, 'weight_decay': 3.9942094038534824e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:48:46,768] Trial 126 finished with value: 0.007623100696946494 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2112099270777309, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2391312939951158, 'learning_rate': 0.0029398652410246966, 'weight_decay': 4.142986093784032e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:50:19,495] Trial 127 finished with value: 0.0002481091025401838 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.19174515822739138, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2675904703887536, 'learning_rate': 0.002129692724472609, 'weight_decay': 6.0617710329693204e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:51:31,649] Trial 128 finished with value: 0.00021325405832612888 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18682725524823304, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.27113753575546456, 'learning_rate': 0.003862050506862795, 'weight_decay': 7.013470284648998e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:52:25,812] Trial 129 finished with value: 0.0011841471219668164 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.1876664456841674, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23085038921231707, 'learning_rate': 0.005232056498905105, 'weight_decay': 4.577411785322798e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:53:44,028] Trial 130 finished with value: 0.00022336133843054996 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18290988012340156, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2573835268255585, 'learning_rate': 0.0038847252055402323, 'weight_decay': 8.368156475890131e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:55:03,108] Trial 131 finished with value: 0.0002370696616708301 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.18320667833623175, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2564037300312088, 'learning_rate': 0.003771888868587216, 'weight_decay': 7.541140893592902e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:56:13,457] Trial 132 finished with value: 0.00021456306567415595 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.18078127620878215, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.24323322978027204, 'learning_rate': 0.00355420249181645, 'weight_decay': 8.64790907146465e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:57:04,685] Trial 133 finished with value: 0.00023421604128088803 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19833689019909048, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.24107428236932754, 'learning_rate': 0.006553415052290469, 'weight_decay': 0.00011898645905138671}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:58:03,311] Trial 134 finished with value: 0.0015644637678633444 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21324946805984102, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2639558623145831, 'learning_rate': 0.003522586350553334, 'weight_decay': 0.0001410703920002464}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 17:59:27,363] Trial 135 finished with value: 0.0002224053328973241 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20508316800418536, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2711762996844631, 'learning_rate': 0.0029866013458774306, 'weight_decay': 3.643008617879553e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:00:32,945] Trial 136 finished with value: 0.00023007503332337365 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22742330526379367, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2779953150266883, 'learning_rate': 0.004171909486349379, 'weight_decay': 8.591467380695858e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:01:40,255] Trial 137 finished with value: 0.0002164568388252519 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23697436538450517, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2747252482238955, 'learning_rate': 0.005195730881574118, 'weight_decay': 9.785012999766754e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:02:38,083] Trial 138 finished with value: 0.0023531373459263704 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20511807003883215, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2788272519486964, 'learning_rate': 0.004909197610294564, 'weight_decay': 9.743497164614838e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:03:40,730] Trial 139 finished with value: 0.001198828307678923 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24739517743550477, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.27511907243115635, 'learning_rate': 0.004421569896778817, 'weight_decay': 0.00014922601136625825}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:04:33,334] Trial 140 finished with value: 0.00022926040401216596 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22709443687223563, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2882951381487925, 'learning_rate': 0.0074396960513815275, 'weight_decay': 5.115287885190429e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:05:27,860] Trial 141 finished with value: 0.00022731026547262445 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22981263984206918, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2842702118341489, 'learning_rate': 0.007959293340533004, 'weight_decay': 5.385463132735639e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:06:21,993] Trial 142 finished with value: 0.00023999775003176184 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22634002929119268, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.28999196548636624, 'learning_rate': 0.008271377440289326, 'weight_decay': 5.298983804639698e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:07:26,751] Trial 143 finished with value: 0.00022389121586456894 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2388371903157226, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.26711285190617373, 'learning_rate': 0.008263450003122726, 'weight_decay': 6.182327006231299e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:08:37,072] Trial 144 finished with value: 0.00022047050297260284 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24045115382554375, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2693471804514975, 'learning_rate': 0.006098872229144063, 'weight_decay': 6.142353486116641e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:09:22,314] Trial 145 finished with value: 0.002033526152081322 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23858756165787906, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2674942679940882, 'learning_rate': 0.009295938536364826, 'weight_decay': 6.364517458011346e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:10:08,211] Trial 146 finished with value: 0.0009545692679239437 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2582520400551372, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.2477950788306625, 'learning_rate': 0.012386801734666834, 'weight_decay': 7.720882783657922e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:11:07,287] Trial 147 finished with value: 0.00021850935590919107 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24043495736085976, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2659400749389787, 'learning_rate': 0.0056634317735527, 'weight_decay': 0.00010319725249457464}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:12:20,060] Trial 148 finished with value: 0.00023190184438135475 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.24050303279300164, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.21698865866103817, 'learning_rate': 0.005019365651491217, 'weight_decay': 9.293728936894835e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:13:22,278] Trial 149 finished with value: 0.00022769014467485249 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2787846675004213, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.269569651595265, 'learning_rate': 0.006181041038357975, 'weight_decay': 3.519467443384759e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:14:37,895] Trial 150 finished with value: 0.00021159074240131303 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.22000637081098365, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.26233827147178196, 'learning_rate': 0.003314485760646374, 'weight_decay': 0.000178895610451865}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:15:33,727] Trial 151 finished with value: 0.025588527065701784 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2580970734138067, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2614178440585139, 'learning_rate': 0.0030541891183088147, 'weight_decay': 0.00017203333595409322}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:16:17,036] Trial 152 finished with value: 0.0014467952845734545 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.218586743247993, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.24661617225336435, 'learning_rate': 0.005810022984352042, 'weight_decay': 0.00010535939276202498}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:17:24,295] Trial 153 finished with value: 0.00021800550166517496 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.27164931960276395, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.27178150198100526, 'learning_rate': 0.01035800310814184, 'weight_decay': 2.741376083583542e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:18:26,570] Trial 154 finished with value: 0.00022684878058498725 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.26803944964189585, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.2282624924253378, 'learning_rate': 0.0032993977290650387, 'weight_decay': 0.00020846902218866974}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:19:25,936] Trial 155 finished with value: 0.05354712645639666 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.20536962815708645, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.27336414348466537, 'learning_rate': 0.002626543561832026, 'weight_decay': 3.202900686881624e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:20:14,774] Trial 156 finished with value: 0.0023614538135007025 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.3084325548913689, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2580874217261491, 'learning_rate': 0.0042215900084298635, 'weight_decay': 0.00033498102118298666}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:21:16,388] Trial 157 finished with value: 0.00020933380437782034 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.25572830729588086, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.244865531447947, 'learning_rate': 0.011341864141934943, 'weight_decay': 2.5281308242786212e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:22:00,802] Trial 158 finished with value: 0.004458869028894696 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.2909779413518668, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.24923900032543467, 'learning_rate': 0.01345378611788122, 'weight_decay': 2.6638300507906677e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:23:41,413] Trial 159 finished with value: 0.00020137309475103392 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2573906363311339, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21757068672137145, 'learning_rate': 0.0023601082809885277, 'weight_decay': 2.1329420091196213e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:24:16,553] Trial 160 finished with value: 0.004423033958300948 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2518774966436949, 'decoder_layers': 7, 'decoder_nodes': 64, 'decoder_dropout': 0.20874655272750542, 'learning_rate': 0.01028730437407431, 'weight_decay': 2.1051419351293232e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:25:04,180] Trial 161 finished with value: 0.007087311428040266 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2659101807675714, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21999936457616356, 'learning_rate': 0.015455206331862661, 'weight_decay': 2.931963604007637e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:26:37,321] Trial 162 finished with value: 0.00020664726907853036 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2520326830799692, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23399728362044997, 'learning_rate': 0.0024324618285053168, 'weight_decay': 2.497111268092058e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:28:08,415] Trial 163 finished with value: 0.0001982998612220399 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24894340093764566, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.19186557609337765, 'learning_rate': 0.0022282676548416197, 'weight_decay': 2.4478898705611562e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:29:44,474] Trial 164 finished with value: 0.0001938428293215111 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2520459182813904, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16416505493969408, 'learning_rate': 0.002298055527812772, 'weight_decay': 2.446758957184342e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:31:07,071] Trial 165 finished with value: 0.0023317489307373763 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.27579018888273926, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17442951945830076, 'learning_rate': 0.0023731259457166268, 'weight_decay': 2.4484621618747824e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:32:22,273] Trial 166 finished with value: 0.0002932014060206711 and parameters: {'hidden_size': 16, 'num_layers': 1, 'extractor_dropout': 0.2507282363358999, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.1439991328882194, 'learning_rate': 0.0024190131825511116, 'weight_decay': 1.8508538262573144e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:34:00,636] Trial 167 finished with value: 0.0002170446328818798 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2649832945836195, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.19048490639566312, 'learning_rate': 0.0020753253197444642, 'weight_decay': 2.2891760609120214e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:35:26,848] Trial 168 finished with value: 0.00020612548833014442 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2617999578172184, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1724802478821495, 'learning_rate': 0.0019737757915650606, 'weight_decay': 2.112038590131671e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:36:13,592] Trial 169 finished with value: 0.00835698125883937 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2872244845488689, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.16283205504526627, 'learning_rate': 0.025207180518945303, 'weight_decay': 2.2269098395814344e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:37:46,828] Trial 170 finished with value: 0.0002585809372249059 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2686346394969941, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.19119207586551748, 'learning_rate': 0.0019231460344961164, 'weight_decay': 2.2995305896403245e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:39:13,822] Trial 171 finished with value: 0.002330039681692142 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2588032724324356, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17609337652644957, 'learning_rate': 0.0021722149330854305, 'weight_decay': 1.8991950270831504e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:40:37,307] Trial 172 finished with value: 0.0036567235045367854 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2496171978872062, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.18240390299358683, 'learning_rate': 0.0027940134059710534, 'weight_decay': 2.5778449533974264e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:42:19,143] Trial 173 finished with value: 0.00019535010796971618 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.25962436717735454, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.16309815235731512, 'learning_rate': 0.0019161758719509212, 'weight_decay': 2.9676971535626144e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:43:50,912] Trial 174 finished with value: 0.00020780445483978838 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2978455829745503, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.16295972516928198, 'learning_rate': 0.0019007850209222497, 'weight_decay': 3.074022393878634e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:45:20,473] Trial 175 finished with value: 0.00020740855834446847 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3329871239419674, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15995604827098955, 'learning_rate': 0.0017528069168789948, 'weight_decay': 2.981694498793865e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:46:43,268] Trial 176 finished with value: 0.00021288265415932983 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.34969795746873145, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1322939579306538, 'learning_rate': 0.0018013053573825212, 'weight_decay': 3.0452941241622918e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:48:20,642] Trial 177 finished with value: 0.00019994372123619542 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.33160818721701885, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.15420603913407468, 'learning_rate': 0.001731911885628471, 'weight_decay': 3.0920820321215966e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:49:50,393] Trial 178 finished with value: 0.00022656254441244528 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3219658560583189, 'decoder_layers': 2, 'decoder_nodes': 128, 'decoder_dropout': 0.12885569270206532, 'learning_rate': 0.0017296404227831821, 'weight_decay': 3.359295244998561e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:51:25,141] Trial 179 finished with value: 0.00020089376048417761 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3396739636322484, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1588504996608599, 'learning_rate': 0.001793726492572754, 'weight_decay': 2.897209200537253e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:52:44,500] Trial 180 finished with value: 0.0002230124780908227 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.35772920140826964, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.15699073886442388, 'learning_rate': 0.001926640186948554, 'weight_decay': 2.916478993897902e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:54:05,347] Trial 181 finished with value: 0.0002167195561924018 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3264563175990438, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.16274445460180284, 'learning_rate': 0.0016599355695069247, 'weight_decay': 3.0142866122083627e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:54:34,423] Trial 182 finished with value: 0.008363496325910092 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3323781359990289, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.14634579843504097, 'learning_rate': 0.04563232719870833, 'weight_decay': 2.0679169787611162e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:56:04,254] Trial 183 finished with value: 0.00020641371957026423 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.34620079591646835, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17256862687441626, 'learning_rate': 0.0023859698345267727, 'weight_decay': 1.646481608205012e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:57:27,735] Trial 184 finished with value: 0.00021149700332898647 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.36136500815271294, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1678602862369875, 'learning_rate': 0.002282632868052088, 'weight_decay': 1.6726889017323163e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 18:59:12,619] Trial 185 finished with value: 0.00019844444905174895 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.36603455063965884, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17049318100354244, 'learning_rate': 0.0023120319189599927, 'weight_decay': 1.7451583002861465e-05}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 19:00:00,227] Trial 186 finished with value: 0.00022835650597698986 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.36368112353580045, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17018863675060109, 'learning_rate': 0.0023318691004113106, 'weight_decay': 0.0008341969709812099}. Best is trial 119 with value: 0.0001931106555275619.\n",
      "[I 2025-08-06 19:01:39,074] Trial 187 finished with value: 0.00018861601856769993 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.34107021987855646, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1518731994976925, 'learning_rate': 0.002585263836733156, 'weight_decay': 1.6205876947028674e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:02:53,080] Trial 188 finished with value: 0.0002227887569461018 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.3823799242235982, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15270846662657656, 'learning_rate': 0.0025319973325098307, 'weight_decay': 1.512455095372212e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:04:07,856] Trial 189 finished with value: 0.0029497598763555287 and parameters: {'hidden_size': 208, 'num_layers': 7, 'extractor_dropout': 0.33810365712744844, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16786835296410194, 'learning_rate': 0.002190894653980332, 'weight_decay': 1.740323261049483e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:05:31,743] Trial 190 finished with value: 0.0011894913826836274 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.34211050752184097, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15219426685359785, 'learning_rate': 0.001970015797483219, 'weight_decay': 1.3721895490622857e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:06:54,315] Trial 191 finished with value: 0.0015548590396065264 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.36829413813942696, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17901198283546385, 'learning_rate': 0.0025996539665568636, 'weight_decay': 1.6920586369192883e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:08:22,879] Trial 192 finished with value: 0.00023617316328454762 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.4006062459617793, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16123954357191986, 'learning_rate': 0.0017198803193891623, 'weight_decay': 2.484639185807963e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:09:46,659] Trial 193 finished with value: 0.00020108216413063928 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3144663576378345, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.14611306554741846, 'learning_rate': 0.002243196520189458, 'weight_decay': 1.960707051863925e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:10:53,829] Trial 194 finished with value: 0.004752938915044069 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.30099387558463125, 'decoder_layers': 9, 'decoder_nodes': 112, 'decoder_dropout': 0.14332615866604284, 'learning_rate': 0.002232143744069556, 'weight_decay': 1.9677254359748184e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:12:36,284] Trial 195 finished with value: 0.00019978194904979318 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.31463754897220886, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.170825034900756, 'learning_rate': 0.0016037074517492172, 'weight_decay': 1.5874062476370022e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:13:51,488] Trial 196 finished with value: 0.003569378747488372 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.33296519240326583, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.15237666006484768, 'learning_rate': 0.0015792887929388284, 'weight_decay': 2.5642045184525337e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:15:06,476] Trial 197 finished with value: 0.0011639652657322586 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.313864630809528, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.13581352167376073, 'learning_rate': 0.0019589917988695658, 'weight_decay': 3.4377844025895825e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:16:22,397] Trial 198 finished with value: 0.0017844218760728835 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.31572954016368604, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18919602236485508, 'learning_rate': 0.0027438293356946393, 'weight_decay': 1.2975869912543332e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:17:42,600] Trial 199 finished with value: 0.00021813653293065727 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.34642709700125374, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.12405791671872735, 'learning_rate': 0.0016847683861410236, 'weight_decay': 2.1231213050110476e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:19:27,927] Trial 200 finished with value: 0.00018938338616862892 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29647295188864164, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.1978642697251844, 'learning_rate': 0.0019564303212844165, 'weight_decay': 1.5309369251593364e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:20:48,734] Trial 201 finished with value: 0.00023049624287523328 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3303839514308375, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2013286690953744, 'learning_rate': 0.001909706210894239, 'weight_decay': 1.8648086564820726e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:22:29,166] Trial 202 finished with value: 0.00019196972134523095 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29787510203646606, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17366473693922124, 'learning_rate': 0.0015208657236219455, 'weight_decay': 1.4741220320995556e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:24:09,526] Trial 203 finished with value: 0.00027458432887215165 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2959968479884525, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1730548732884257, 'learning_rate': 0.0015616124969234535, 'weight_decay': 1.5496976448078673e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:25:45,857] Trial 204 finished with value: 0.00020029762090416624 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.31655236537349113, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18245024932040155, 'learning_rate': 0.0020613081875716747, 'weight_decay': 1.5113258817896178e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:27:27,291] Trial 205 finished with value: 0.00020544680155580862 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3021730799391933, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17959463761328834, 'learning_rate': 0.0021163099805123903, 'weight_decay': 1.2592927391163232e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:29:00,905] Trial 206 finished with value: 0.0001917950256029144 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3069639111616692, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1986355748936706, 'learning_rate': 0.002802384359728347, 'weight_decay': 1.4494665059738345e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:30:11,333] Trial 207 finished with value: 0.024788434963556937 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3180598531013677, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21038212921630345, 'learning_rate': 0.0029887872268749465, 'weight_decay': 1.2750192170785635e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:31:40,653] Trial 208 finished with value: 0.00019783665047725662 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.28540422147063993, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1966891647007851, 'learning_rate': 0.002536316026006903, 'weight_decay': 1.4764170753213997e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:32:47,140] Trial 209 finished with value: 0.0017320441373158246 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3065785236093567, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1961290815221567, 'learning_rate': 0.0027762010775218785, 'weight_decay': 1.4305627668059839e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:34:10,769] Trial 210 finished with value: 0.0012020510039292276 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.32369911092831394, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18827860793071954, 'learning_rate': 0.0021858031517454674, 'weight_decay': 1.2049401416404107e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:35:41,394] Trial 211 finished with value: 0.0017772325460100546 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.28421127809049823, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.1779085986772289, 'learning_rate': 0.002416746153433975, 'weight_decay': 1.0100777929596617e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:37:23,356] Trial 212 finished with value: 0.0002062936662696302 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29861994273983306, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18312302884910026, 'learning_rate': 0.002494379122488649, 'weight_decay': 1.56838812718004e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:38:42,707] Trial 213 finished with value: 0.0015466241238755174 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.30571143293695763, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1836245346322575, 'learning_rate': 0.003067142251522675, 'weight_decay': 1.5186813508146023e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:40:29,045] Trial 214 finished with value: 0.0002196096975239925 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.291317931131223, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1997887567270135, 'learning_rate': 0.0021216621445620957, 'weight_decay': 1.6203520200681363e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:41:49,462] Trial 215 finished with value: 0.001563914367579855 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.31216530554358224, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.182341502308216, 'learning_rate': 0.002660590802702415, 'weight_decay': 1.3645737554378592e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:43:24,599] Trial 216 finished with value: 0.00019594929472077638 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3010765323071497, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.1959225600394595, 'learning_rate': 0.0020768360299479203, 'weight_decay': 1.8065389610774707e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:45:09,944] Trial 217 finished with value: 0.00020167260518064723 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3010511390455501, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20530491025262596, 'learning_rate': 0.001535557030365108, 'weight_decay': 1.8913572388090786e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:46:56,407] Trial 218 finished with value: 0.0002041452331468463 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29893671891113965, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.19880293932252538, 'learning_rate': 0.001467290690576753, 'weight_decay': 1.8727446779596428e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:47:47,925] Trial 219 finished with value: 0.0034240428823977707 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.30252166601201735, 'decoder_layers': 10, 'decoder_nodes': 96, 'decoder_dropout': 0.20714159472180974, 'learning_rate': 0.001422071692932425, 'weight_decay': 1.840350417672217e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:49:03,342] Trial 220 finished with value: 0.002986108744516969 and parameters: {'hidden_size': 240, 'num_layers': 8, 'extractor_dropout': 0.2834116586653002, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.19558807071514947, 'learning_rate': 0.00155624523927298, 'weight_decay': 1.887782395928986e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:50:20,787] Trial 221 finished with value: 0.023147109690762592 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3006611932975394, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20292272041061699, 'learning_rate': 0.0019350663772773732, 'weight_decay': 1.432775219717607e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:51:45,650] Trial 222 finished with value: 0.00022316824179142715 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29207147113765675, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2152905700696759, 'learning_rate': 0.0017198020252928397, 'weight_decay': 1.2445439888092511e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:53:16,510] Trial 223 finished with value: 0.00020919950766256078 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.31327832954092466, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.18941563562556143, 'learning_rate': 0.002047773584113911, 'weight_decay': 2.0929978973467923e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:54:37,566] Trial 224 finished with value: 0.00022939309128560125 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3079850490436903, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1953143591212181, 'learning_rate': 0.0012455074563277092, 'weight_decay': 1.6191843591403304e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:56:13,072] Trial 225 finished with value: 0.00019935203599743545 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2795451273606312, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18323924820208615, 'learning_rate': 0.0014513527912765063, 'weight_decay': 1.8386441694626905e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:57:29,462] Trial 226 finished with value: 0.002479584765387699 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.28570194691927786, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.14811470479782846, 'learning_rate': 0.0015657063203789103, 'weight_decay': 1.806938048401673e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 19:59:06,312] Trial 227 finished with value: 0.0002068517787847668 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2794333800144765, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.16493591056488957, 'learning_rate': 0.0013439138727563164, 'weight_decay': 2.246965802096378e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:00:48,765] Trial 228 finished with value: 0.00019285486923763527 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3186047874917502, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17703000379837938, 'learning_rate': 0.0018022682985523865, 'weight_decay': 1.8856115625452247e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:02:14,154] Trial 229 finished with value: 0.0002718780800933018 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3209245778060865, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20758671078669688, 'learning_rate': 0.0011590341915674555, 'weight_decay': 1.1299155867457551e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:03:45,218] Trial 230 finished with value: 0.00021817769593326374 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.31924075571158755, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17895811244477616, 'learning_rate': 0.0014470167645644007, 'weight_decay': 1.817780537103995e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:05:23,313] Trial 231 finished with value: 0.00019523045339155942 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2947462548246097, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15592322996219096, 'learning_rate': 0.0017003985766692496, 'weight_decay': 2.0100378829805013e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:07:05,499] Trial 232 finished with value: 0.00020882978715235366 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.29678334657441263, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.15327187226517083, 'learning_rate': 0.0017712268004004398, 'weight_decay': 1.3690233835934966e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:08:44,584] Trial 233 finished with value: 0.0015505100323935038 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3034252728624522, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.19518945972084942, 'learning_rate': 0.0016038109665775628, 'weight_decay': 1.9132251881612883e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:10:19,905] Trial 234 finished with value: 0.00019932593422709033 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.312347730931013, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18724836047425064, 'learning_rate': 0.0018357940526128713, 'weight_decay': 1.628494104717699e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:11:52,255] Trial 235 finished with value: 0.00020085982832824812 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3126748412572483, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18684267362067017, 'learning_rate': 0.0017970531145003123, 'weight_decay': 1.6128944724290824e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:13:29,690] Trial 236 finished with value: 0.0002100836340105161 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3264142505327491, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1578555093891994, 'learning_rate': 0.001766512797675577, 'weight_decay': 1.533892862826951e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:14:26,821] Trial 237 finished with value: 0.003324880450963974 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.31198600293974893, 'decoder_layers': 8, 'decoder_nodes': 128, 'decoder_dropout': 0.18778773298598656, 'learning_rate': 0.0018494834466382603, 'weight_decay': 2.317689011395471e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:15:47,360] Trial 238 finished with value: 0.003644002487999387 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3395145487949638, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.13796502491196758, 'learning_rate': 0.0021520013753995398, 'weight_decay': 1.6153869955092135e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:17:31,024] Trial 239 finished with value: 0.00019994271860923618 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2766411173031832, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1677941806071502, 'learning_rate': 0.0012901033453042356, 'weight_decay': 2.0946595389036117e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:18:55,623] Trial 240 finished with value: 0.0023395357275148854 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27455684417974935, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.1681257169333165, 'learning_rate': 0.0012619538665361032, 'weight_decay': 2.1678742751341468e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:20:27,620] Trial 241 finished with value: 0.00020302633056417106 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2908408720280623, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1693083540089242, 'learning_rate': 0.0014278601125989727, 'weight_decay': 1.7095918031760282e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:21:43,064] Trial 242 finished with value: 0.00155413221946219 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3173107537669641, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.15829274003333874, 'learning_rate': 0.0017182643174261279, 'weight_decay': 2.065334104013844e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:23:17,827] Trial 243 finished with value: 0.00019227329466957598 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2747375551578923, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1757106164403036, 'learning_rate': 0.0019656984236102936, 'weight_decay': 1.4328850867170093e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:24:46,733] Trial 244 finished with value: 0.0002033286713412963 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2863765312997796, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17737137698293673, 'learning_rate': 0.0020067920850367488, 'weight_decay': 1.4437257534341796e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:26:08,173] Trial 245 finished with value: 0.0023138108110288156 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27440138480342235, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18489474597007963, 'learning_rate': 0.0026384190902454386, 'weight_decay': 1.4890946057711717e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:27:18,422] Trial 246 finished with value: 0.0011858583224238829 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2809462816308073, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.17019688062648167, 'learning_rate': 0.002231489027287578, 'weight_decay': 2.658031546723284e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:28:47,758] Trial 247 finished with value: 0.00019680644036270678 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.32496476460863855, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.14736982926003808, 'learning_rate': 0.0018613153455417522, 'weight_decay': 1.725499856035906e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:30:17,412] Trial 248 finished with value: 0.0002045997855020687 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.32563338622284665, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1437645681271362, 'learning_rate': 0.0018269027820892556, 'weight_decay': 1.714120542010705e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:31:49,030] Trial 249 finished with value: 0.00021970162051729858 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3337459653016709, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15099699913479606, 'learning_rate': 0.0010833389532591386, 'weight_decay': 1.3277261368555923e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:33:12,511] Trial 250 finished with value: 0.00021252670849207788 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.31038803821876004, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.16167254313033555, 'learning_rate': 0.0016381193214772402, 'weight_decay': 1.0207772961279251e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:34:44,030] Trial 251 finished with value: 0.0002024373592576012 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3195908190670247, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1753250682888015, 'learning_rate': 0.001957131484140236, 'weight_decay': 1.6693681600743766e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:36:28,525] Trial 252 finished with value: 0.0002091392598231323 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.31071969713068975, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.15666327269489388, 'learning_rate': 0.0013539330468094954, 'weight_decay': 1.3929433272346012e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:37:49,539] Trial 253 finished with value: 0.003651772874582093 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.29242450755423083, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1138493692972776, 'learning_rate': 0.002979542345468599, 'weight_decay': 1.14806365056618e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:39:27,632] Trial 254 finished with value: 0.0001944843548699282 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3556566228582016, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18688495509927466, 'learning_rate': 0.0021246991870721528, 'weight_decay': 2.39117841660406e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:41:06,389] Trial 255 finished with value: 0.00020812168950214981 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.34705616264890177, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.18901431501175214, 'learning_rate': 0.0016743070997648022, 'weight_decay': 2.426691283387941e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:42:35,858] Trial 256 finished with value: 0.0017812979727750643 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3365709892777813, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.18154437945635235, 'learning_rate': 0.0019241285787120182, 'weight_decay': 2.765482026825602e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:44:22,600] Trial 257 finished with value: 0.0002053390329820104 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3255385989580551, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.16678641939164285, 'learning_rate': 0.0011565040323992526, 'weight_decay': 1.5764301662711053e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:46:01,930] Trial 258 finished with value: 0.00021911995572736486 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3543759098227942, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.19226697616932015, 'learning_rate': 0.0015095553997368715, 'weight_decay': 2.3544730510121202e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:46:49,312] Trial 259 finished with value: 0.004406284587457776 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3785183039264639, 'decoder_layers': 6, 'decoder_nodes': 96, 'decoder_dropout': 0.1747418592798956, 'learning_rate': 0.002604753556074676, 'weight_decay': 1.8125423385794285e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:48:29,565] Trial 260 finished with value: 0.00020198404672555625 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.37078765278609843, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18425068700788153, 'learning_rate': 0.002041003928150577, 'weight_decay': 2.0423846077935608e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:49:56,569] Trial 261 finished with value: 0.00022410088713513686 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.26847432561730333, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.16900249469390308, 'learning_rate': 0.0017532924724702795, 'weight_decay': 1.4709484044174926e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:51:06,866] Trial 262 finished with value: 0.012328269178397022 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2774907037459366, 'decoder_layers': 1, 'decoder_nodes': 160, 'decoder_dropout': 0.16090409232196815, 'learning_rate': 0.002393513674802739, 'weight_decay': 1.2273042302050103e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:52:38,161] Trial 263 finished with value: 0.00021666852990165353 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.34142259728822505, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.19260205404831923, 'learning_rate': 0.0013454317251329546, 'weight_decay': 3.543364098173518e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:54:18,347] Trial 264 finished with value: 0.0001996752427658066 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.35872041965745566, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.18034289250239255, 'learning_rate': 0.0021358184494354496, 'weight_decay': 1.7722385825003447e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:55:43,827] Trial 265 finished with value: 0.0013466723772580735 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.3572650085255585, 'decoder_layers': 2, 'decoder_nodes': 96, 'decoder_dropout': 0.1818817147589389, 'learning_rate': 0.002211548256785148, 'weight_decay': 1.7857406977103594e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:57:13,359] Trial 266 finished with value: 0.002390715788351372 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.28851598302027204, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.19877325334365287, 'learning_rate': 0.0028372961804545177, 'weight_decay': 1.6180300135336402e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 20:58:25,156] Trial 267 finished with value: 0.00021072588860988618 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3548632747068996, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17379039578274033, 'learning_rate': 0.0033756919015095464, 'weight_decay': 1.3473218484599863e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:00:00,025] Trial 268 finished with value: 0.00020075414213351905 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.29420916068413955, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.18859836160134308, 'learning_rate': 0.0020242359906918494, 'weight_decay': 2.022864046593286e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:01:12,681] Trial 269 finished with value: 0.0035241061821579935 and parameters: {'hidden_size': 256, 'num_layers': 9, 'extractor_dropout': 0.36747123988100744, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.20119741783046027, 'learning_rate': 0.0021267603520995636, 'weight_decay': 2.2762960127985936e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:02:43,800] Trial 270 finished with value: 0.00019876667793141677 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2800613525439614, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17738024657034565, 'learning_rate': 0.002495474867298245, 'weight_decay': 2.1268567602288965e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:04:01,055] Trial 271 finished with value: 0.00021833157807122917 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.3909198538346724, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17723014646702584, 'learning_rate': 0.002607734975815518, 'weight_decay': 2.4918283842798567e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:05:30,613] Trial 272 finished with value: 0.0002207455414463766 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.26977717512087884, 'decoder_layers': 2, 'decoder_nodes': 112, 'decoder_dropout': 0.16721500489907698, 'learning_rate': 0.0031068268790761418, 'weight_decay': 1.9402027023260215e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:07:10,921] Trial 273 finished with value: 0.00019199795642634853 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2774023790848368, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17700248733915808, 'learning_rate': 0.002475433346300967, 'weight_decay': 2.2834265788842946e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:08:48,373] Trial 274 finished with value: 0.00020584345620591193 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2803424996734028, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.17346897110343695, 'learning_rate': 0.002533814781442713, 'weight_decay': 2.1933003403437723e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:10:33,652] Trial 275 finished with value: 0.0002141332734026946 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2663999713484056, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16647729217174587, 'learning_rate': 0.0010151506589372373, 'weight_decay': 2.511233163209849e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:11:48,338] Trial 276 finished with value: 0.0023322064225794747 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2754167762442836, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.14784557265990897, 'learning_rate': 0.0023700535726127727, 'weight_decay': 1.80089314256701e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:13:02,391] Trial 277 finished with value: 0.001998847028880846 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.28597638378325224, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1547739978480749, 'learning_rate': 0.00296828120889135, 'weight_decay': 3.198993591080092e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:14:34,348] Trial 278 finished with value: 0.00020166371832601725 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2603978887391627, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.17741209251509216, 'learning_rate': 0.0015447464079299093, 'weight_decay': 2.770267516398421e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:16:07,452] Trial 279 finished with value: 0.00026517021615291014 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2812870913199886, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21119696431342908, 'learning_rate': 0.001299590278585488, 'weight_decay': 2.1126122110550588e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:17:29,446] Trial 280 finished with value: 0.00020743623026646673 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.29452100601766223, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1937233380672867, 'learning_rate': 0.0023935125900667177, 'weight_decay': 2.3341717647689148e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:18:58,996] Trial 281 finished with value: 0.0029819680843502284 and parameters: {'hidden_size': 256, 'num_layers': 10, 'extractor_dropout': 0.27359538539034356, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.13870282151410662, 'learning_rate': 0.001614616291445321, 'weight_decay': 1.7745481818057766e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:20:12,815] Trial 282 finished with value: 0.00021254779421724378 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.36246884823835496, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.1850929365648873, 'learning_rate': 0.0027697324052934225, 'weight_decay': 4.6505047225347937e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:21:21,904] Trial 283 finished with value: 0.002325789591122884 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.28455996830968544, 'decoder_layers': 2, 'decoder_nodes': 112, 'decoder_dropout': 0.16101225012953577, 'learning_rate': 0.003474055591524642, 'weight_decay': 1.2709829645431788e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:23:06,184] Trial 284 finished with value: 0.00021218760375631973 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.30331784931572103, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.170238495259234, 'learning_rate': 0.001912745335665445, 'weight_decay': 1.9767085930338243e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:24:35,975] Trial 285 finished with value: 0.00020946354634361343 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.26424341597258516, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1781663249175695, 'learning_rate': 0.0011729212408707718, 'weight_decay': 1.6215683551040894e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:25:45,826] Trial 286 finished with value: 0.0018161075553507545 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2913257493793431, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16393913918764913, 'learning_rate': 0.0022373278172566568, 'weight_decay': 2.7445238915463394e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:27:01,481] Trial 287 finished with value: 0.0018986624316312372 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3488412621837705, 'decoder_layers': 7, 'decoder_nodes': 112, 'decoder_dropout': 0.15251508957957938, 'learning_rate': 0.0014674903241619723, 'weight_decay': 1.4372407862694795e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:28:13,817] Trial 288 finished with value: 0.0002295747719472274 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.27597223455882486, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1965013744225079, 'learning_rate': 0.0018307072395111234, 'weight_decay': 2.3636719736218434e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:29:08,116] Trial 289 finished with value: 0.003355767671018839 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.32651737874957865, 'decoder_layers': 8, 'decoder_nodes': 96, 'decoder_dropout': 0.2034319105788351, 'learning_rate': 0.002470495072199768, 'weight_decay': 1.9498867362938504e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:30:36,528] Trial 290 finished with value: 0.0003027006328920834 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.307378991198325, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.4877996398907565, 'learning_rate': 0.001621850358095771, 'weight_decay': 9.668196186650783e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:32:07,627] Trial 291 finished with value: 0.001577527508197818 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.29851141002270837, 'decoder_layers': 2, 'decoder_nodes': 112, 'decoder_dropout': 0.18871391402843843, 'learning_rate': 0.0020821066036048395, 'weight_decay': 1.7524142762678554e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:33:03,116] Trial 292 finished with value: 0.002978937979787588 and parameters: {'hidden_size': 240, 'num_layers': 6, 'extractor_dropout': 0.4424454149961843, 'decoder_layers': 1, 'decoder_nodes': 128, 'decoder_dropout': 0.1715265308149247, 'learning_rate': 0.0027760848124998676, 'weight_decay': 2.1316825912139038e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:34:38,344] Trial 293 finished with value: 0.0002283577006892301 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.3745188328309545, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.18246798325523148, 'learning_rate': 0.0013050918784901467, 'weight_decay': 3.200600186703199e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:36:11,264] Trial 294 finished with value: 0.0002441395161440596 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.2842585391000276, 'decoder_layers': 1, 'decoder_nodes': 112, 'decoder_dropout': 0.1563130754290376, 'learning_rate': 0.0018504797407326366, 'weight_decay': 1.1906607269538602e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:37:43,801] Trial 295 finished with value: 0.00019072415889240802 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27002187863803206, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22445084192128198, 'learning_rate': 0.003322628977634691, 'weight_decay': 1.483546895563474e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:38:53,061] Trial 296 finished with value: 0.0018808762746630237 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26979698695659204, 'decoder_layers': 5, 'decoder_nodes': 96, 'decoder_dropout': 0.22160490869128913, 'learning_rate': 0.003322178479917778, 'weight_decay': 1.4519867720766857e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:40:22,453] Trial 297 finished with value: 0.0001956154519575648 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24534735769141774, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21144116607431948, 'learning_rate': 0.0029338648297251033, 'weight_decay': 1.078139962783326e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:41:41,930] Trial 298 finished with value: 0.0014036289241630584 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24691559488233247, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21578571630883517, 'learning_rate': 0.003374500381049447, 'weight_decay': 1.0861747860865737e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:42:58,449] Trial 299 finished with value: 0.0011677431350108237 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25645238669132814, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20880157494136356, 'learning_rate': 0.003834289486832157, 'weight_decay': 9.093316213021153e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:44:34,404] Trial 300 finished with value: 0.0001934556625201367 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2619341837855383, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22575817748887858, 'learning_rate': 0.0030677925035731716, 'weight_decay': 1.1642827428558346e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:46:00,765] Trial 301 finished with value: 0.0023009522890788505 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25010455993748665, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2044796216064569, 'learning_rate': 0.003112234489034715, 'weight_decay': 1.0585346000008614e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:47:32,799] Trial 302 finished with value: 0.001820551379933022 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.264677793147211, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.22493557171189096, 'learning_rate': 0.0028157357024857907, 'weight_decay': 1.2591217917858817e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:49:05,037] Trial 303 finished with value: 0.013543570155161434 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2583506151524445, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2131413011395278, 'learning_rate': 0.003150038155380694, 'weight_decay': 1.1411136891256598e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:50:44,727] Trial 304 finished with value: 0.00019279062980785965 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24497067381709925, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2279989512086755, 'learning_rate': 0.0025904429500540884, 'weight_decay': 1.3437423830914609e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:52:17,004] Trial 305 finished with value: 0.00021955932897981255 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.24507437276684615, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22023888691844706, 'learning_rate': 0.002640759319198577, 'weight_decay': 8.885180968078014e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:53:33,343] Trial 306 finished with value: 0.0023635073244804516 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.231906299536686, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22606886565853856, 'learning_rate': 0.0035716117029456662, 'weight_decay': 1.287621656603319e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:55:01,265] Trial 307 finished with value: 0.00019105850369669498 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24549962255362462, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23053884850534026, 'learning_rate': 0.0028903487194186788, 'weight_decay': 1.3900982129118154e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:56:25,173] Trial 308 finished with value: 0.00019798432185780257 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2462408861379874, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22865770364623073, 'learning_rate': 0.0038309256903831693, 'weight_decay': 1.0262495760667713e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:57:53,697] Trial 309 finished with value: 0.00018915601685876027 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.24574169884792016, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2268351588792713, 'learning_rate': 0.003119609274552428, 'weight_decay': 9.535193311102143e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 21:59:31,912] Trial 310 finished with value: 0.002311042632209137 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.24077172707167846, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23367645442006604, 'learning_rate': 0.003948798291576716, 'weight_decay': 7.479048659664845e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:01:03,371] Trial 311 finished with value: 0.0002430805267067626 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2506613184143184, 'decoder_layers': 2, 'decoder_nodes': 96, 'decoder_dropout': 0.22472862654684686, 'learning_rate': 0.003936651344985196, 'weight_decay': 9.591945790356851e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:02:30,241] Trial 312 finished with value: 0.00019921929051633925 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.23513395620969466, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23069629894080673, 'learning_rate': 0.0033567092781067683, 'weight_decay': 8.708657280271106e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:03:44,461] Trial 313 finished with value: 0.00023193673696368932 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.24378884660224978, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2250685815003918, 'learning_rate': 0.0043375553991100895, 'weight_decay': 1.111016562990941e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:05:17,360] Trial 314 finished with value: 0.0002001474582357332 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2506451159712595, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21369818425917883, 'learning_rate': 0.004521665532499282, 'weight_decay': 1.088095574874484e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:06:51,665] Trial 315 finished with value: 0.00021251754951663316 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2558652540286215, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23135655210833464, 'learning_rate': 0.002954621885668805, 'weight_decay': 8.369154971998314e-06}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:08:17,103] Trial 316 finished with value: 0.00019719831907423214 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23412548207315761, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23552378320284442, 'learning_rate': 0.0035399920071710945, 'weight_decay': 1.3258997799958208e-05}. Best is trial 187 with value: 0.00018861601856769993.\n",
      "[I 2025-08-06 22:09:42,764] Trial 317 finished with value: 0.0001873562578111887 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23566286288002403, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23480103043757597, 'learning_rate': 0.003354949422642079, 'weight_decay': 9.761491543354963e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:11:10,614] Trial 318 finished with value: 0.00019330526265548542 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22223774655827427, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23895488393726483, 'learning_rate': 0.0036957825298651044, 'weight_decay': 9.862183216082406e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:12:33,222] Trial 319 finished with value: 0.0002545681389165111 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2316589168660218, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23543292672010727, 'learning_rate': 0.004737730192618165, 'weight_decay': 9.46382099769588e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:14:01,344] Trial 320 finished with value: 0.0002368965302594006 and parameters: {'hidden_size': 48, 'num_layers': 1, 'extractor_dropout': 0.222975859824609, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23345224124265276, 'learning_rate': 0.003396050239981107, 'weight_decay': 6.75769545465288e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:15:27,101] Trial 321 finished with value: 0.00024142242764355615 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23813030188547182, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.24235729821562255, 'learning_rate': 0.0036352442867900493, 'weight_decay': 1.2108574832601205e-05}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:16:57,401] Trial 322 finished with value: 0.0001935205567860976 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2236183779986556, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2182458371595205, 'learning_rate': 0.002945208398771309, 'weight_decay': 7.885322620047788e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:18:26,059] Trial 323 finished with value: 0.00019672348134918137 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22442845148960194, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22051692206053672, 'learning_rate': 0.0030849690287554294, 'weight_decay': 8.507201781482885e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:19:20,748] Trial 324 finished with value: 0.0027710398950148373 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21594402030933052, 'decoder_layers': 5, 'decoder_nodes': 80, 'decoder_dropout': 0.2212232879734752, 'learning_rate': 0.003298452816414865, 'weight_decay': 8.150141733705444e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:20:56,192] Trial 325 finished with value: 0.00020408413984114305 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2240587555764469, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23937787113662531, 'learning_rate': 0.002940598029590042, 'weight_decay': 8.501446018059143e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:22:36,778] Trial 326 finished with value: 0.0002007560135098174 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23023522771834662, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22455608153075224, 'learning_rate': 0.004077691047023482, 'weight_decay': 7.92264068530808e-06}. Best is trial 317 with value: 0.0001873562578111887.\n",
      "[I 2025-08-06 22:24:10,252] Trial 327 finished with value: 0.00018381327536189928 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23708723476180485, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2180316253611584, 'learning_rate': 0.0031754487467080105, 'weight_decay': 6.454288023456877e-06}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:25:55,428] Trial 328 finished with value: 0.00019633752235677094 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2385729736488671, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21288298173542988, 'learning_rate': 0.002948823895634584, 'weight_decay': 1.0010032286758217e-05}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:27:32,523] Trial 329 finished with value: 0.0002008176423260011 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24228571484817435, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2156948630238222, 'learning_rate': 0.0028860616037001807, 'weight_decay': 7.1731312137838464e-06}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:29:08,859] Trial 330 finished with value: 0.00024053217348409816 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22617480560120456, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2120513605188447, 'learning_rate': 0.003319741484896563, 'weight_decay': 6.527081776825149e-06}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:30:39,963] Trial 331 finished with value: 0.00024032113142311574 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23844266841057987, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21794785770506495, 'learning_rate': 0.0030714649526255825, 'weight_decay': 6.052950409034817e-06}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:31:46,775] Trial 332 finished with value: 0.0003349775011884049 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23380374177767677, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.221976062533164, 'learning_rate': 0.0029568062782483738, 'weight_decay': 9.722451895742126e-06}. Best is trial 327 with value: 0.00018381327536189928.\n",
      "[I 2025-08-06 22:33:24,502] Trial 333 finished with value: 0.0001831027999287471 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22088296203948127, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20778327172672253, 'learning_rate': 0.004331333763697928, 'weight_decay': 7.4569701257923975e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:34:49,846] Trial 334 finished with value: 0.006764784222468734 and parameters: {'hidden_size': 256, 'num_layers': 8, 'extractor_dropout': 0.2585176153801806, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.21416811435079033, 'learning_rate': 0.003982692470069063, 'weight_decay': 7.715363480597585e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:36:29,435] Trial 335 finished with value: 0.0001870264924946241 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2464385885693383, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20603411475381855, 'learning_rate': 0.004591155031738128, 'weight_decay': 5.6550356207803605e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:38:03,117] Trial 336 finished with value: 0.0007905011647380888 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2453826888956629, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20704694922198927, 'learning_rate': 0.004863854662515861, 'weight_decay': 4.630756256127261e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:39:17,115] Trial 337 finished with value: 0.0005801935491035693 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2574721906965251, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2466058964205865, 'learning_rate': 0.005177019654454831, 'weight_decay': 5.6127539961606875e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:41:01,471] Trial 338 finished with value: 0.00232002031407319 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2519583385611852, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2041201107003328, 'learning_rate': 0.004815806349247463, 'weight_decay': 5.3207191792143645e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:42:21,562] Trial 339 finished with value: 0.0005962660972727463 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21798053838459844, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22791725604181193, 'learning_rate': 0.003620420838698135, 'weight_decay': 6.2414808367476605e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:43:41,528] Trial 340 finished with value: 0.000606202325434424 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24141647277568695, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20489857728518612, 'learning_rate': 0.004127211431628767, 'weight_decay': 7.4165288935101296e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:45:12,824] Trial 341 finished with value: 0.0001894146393169649 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21055978316160912, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2317219666028606, 'learning_rate': 0.004264585776479612, 'weight_decay': 6.453873718309537e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:46:32,198] Trial 342 finished with value: 0.0023054197154124267 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2142854950175662, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23823116496486554, 'learning_rate': 0.004314076460014241, 'weight_decay': 6.561400111265243e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:48:03,962] Trial 343 finished with value: 0.0022969242229009977 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22775148933621103, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2349282411361031, 'learning_rate': 0.004332863929936252, 'weight_decay': 5.6532352168512895e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:49:17,989] Trial 344 finished with value: 0.006543264495849144 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.21110956903131842, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.24573856976977643, 'learning_rate': 0.005705460475850939, 'weight_decay': 6.832443412850379e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:50:51,081] Trial 345 finished with value: 0.0002027128022746183 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2621184428514759, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22904127417118503, 'learning_rate': 0.0037952625684308187, 'weight_decay': 9.051152797020567e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:52:05,821] Trial 346 finished with value: 0.00021950905065750703 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22282470535589133, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2196583790384356, 'learning_rate': 0.003582782239964958, 'weight_decay': 1.0803346229448237e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:53:07,298] Trial 347 finished with value: 0.005119279236532747 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.49806309739797466, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22735718847099073, 'learning_rate': 0.005196195002689565, 'weight_decay': 7.564869252221227e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:54:21,293] Trial 348 finished with value: 0.0027686112021910957 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23218744324796015, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21226358580141486, 'learning_rate': 0.0026341171171574817, 'weight_decay': 4.583032330065349e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:55:52,631] Trial 349 finished with value: 0.0023204137934953904 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.251459286458554, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23878710029643285, 'learning_rate': 0.006994269468171641, 'weight_decay': 6.3123294178915445e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:57:14,129] Trial 350 finished with value: 0.0011695540844812058 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24285753888605202, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22051530937146469, 'learning_rate': 0.004497430658162875, 'weight_decay': 9.866389401148355e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:58:24,446] Trial 351 finished with value: 0.00252997258794494 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.26600302005928694, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23154925572833832, 'learning_rate': 0.0033674471576492127, 'weight_decay': 5.132993604798609e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 22:59:47,880] Trial 352 finished with value: 0.006229373533278704 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25154703784856375, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20748174000573244, 'learning_rate': 0.002728546858810234, 'weight_decay': 1.0927761482479388e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:01:12,834] Trial 353 finished with value: 0.00023868760908953845 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23740898889852036, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.24947302648751046, 'learning_rate': 0.0038761405644526727, 'weight_decay': 1.2479641957693198e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:02:47,654] Trial 354 finished with value: 0.00021166940277907997 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20769471838084674, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2213333424810549, 'learning_rate': 0.002640905036049139, 'weight_decay': 7.912216198606645e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:04:20,848] Trial 355 finished with value: 0.0002152067929273471 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23041591891441876, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20148157116819382, 'learning_rate': 0.0032188954564437862, 'weight_decay': 9.28587609216645e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:05:26,313] Trial 356 finished with value: 0.0014363824942847715 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21930115726358476, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22826753744239708, 'learning_rate': 0.004496916417002624, 'weight_decay': 1.2247978903773928e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:06:36,220] Trial 357 finished with value: 0.001552645601623226 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26402819890792284, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21430200053491869, 'learning_rate': 0.0024823704182240338, 'weight_decay': 5.883679098045303e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:07:52,125] Trial 358 finished with value: 0.0008256384608102962 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24545351880222221, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23986344487788147, 'learning_rate': 0.003666591912560583, 'weight_decay': 1.1206416205603679e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:09:27,866] Trial 359 finished with value: 0.0001890334126073867 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20132114062097417, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20981050661682404, 'learning_rate': 0.0030757407311756487, 'weight_decay': 1.370276750630339e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:10:32,530] Trial 360 finished with value: 0.0009274419717257842 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20393016133988484, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23051232962820756, 'learning_rate': 0.0032115376940730815, 'weight_decay': 1.3549945962646372e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:11:56,189] Trial 361 finished with value: 0.002374380550463684 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2094590632518911, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19971287995617584, 'learning_rate': 0.002624532624871977, 'weight_decay': 1.4147559857879176e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:13:32,120] Trial 362 finished with value: 0.00023337781894952058 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2201917377469689, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.2182526741219939, 'learning_rate': 0.003975984273449226, 'weight_decay': 7.006561324586282e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:13:54,861] Trial 363 finished with value: 0.00836392855271697 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1997142504145364, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20657781003448578, 'learning_rate': 0.06919523817500517, 'weight_decay': 8.656003992931248e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:15:14,871] Trial 364 finished with value: 0.003509196685627103 and parameters: {'hidden_size': 240, 'num_layers': 7, 'extractor_dropout': 0.2138423086409397, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.24222749762217563, 'learning_rate': 0.002328598734409963, 'weight_decay': 4.0487002627935405e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:16:16,878] Trial 365 finished with value: 0.0010031484591308982 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.261862914566978, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22370626856762274, 'learning_rate': 0.0057612829198043685, 'weight_decay': 1.3572490013696169e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:17:55,295] Trial 366 finished with value: 0.00019080684141954408 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27026207244592165, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23462227074021322, 'learning_rate': 0.0031887061324801917, 'weight_decay': 1.197800035926003e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:19:00,541] Trial 367 finished with value: 0.005845112446695566 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2723881959700708, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2531309797646221, 'learning_rate': 0.003427904526668178, 'weight_decay': 1.1679027878870952e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:20:43,531] Trial 368 finished with value: 0.00021859178668819367 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22964737406869165, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23441268444968344, 'learning_rate': 0.003036810840273174, 'weight_decay': 1.2927312873011888e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:22:05,492] Trial 369 finished with value: 0.021126435005862733 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19999124617154915, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.24431901308945486, 'learning_rate': 0.003639671291628494, 'weight_decay': 9.154298805907583e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:23:17,272] Trial 370 finished with value: 0.02436132778530009 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22619570217021526, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22913904163062754, 'learning_rate': 0.004477200088361114, 'weight_decay': 1.4616603320623756e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:24:52,079] Trial 371 finished with value: 0.0011657171475235374 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2681244110112768, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21786207222408496, 'learning_rate': 0.0027940290277834513, 'weight_decay': 7.396435716815405e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:26:25,016] Trial 372 finished with value: 0.00018632320570759474 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2169826889789706, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.233622999609551, 'learning_rate': 0.003278702091072997, 'weight_decay': 1.1965833473425188e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:27:39,246] Trial 373 finished with value: 0.014901093333901373 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21217345626931589, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23793082089306916, 'learning_rate': 0.0033160049109865037, 'weight_decay': 1.2356689232066065e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:29:00,596] Trial 374 finished with value: 0.0022266364641836843 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2208050169159166, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.23226943652581428, 'learning_rate': 0.004321680060515017, 'weight_decay': 1.0880478844003895e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:29:51,255] Trial 375 finished with value: 0.003310758247971535 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20554187421245212, 'decoder_layers': 10, 'decoder_nodes': 80, 'decoder_dropout': 0.24544047506851963, 'learning_rate': 0.0030687480124454132, 'weight_decay': 1.0455113151183007e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:31:32,881] Trial 376 finished with value: 0.0001936550615937449 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21705269508775474, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21131598386437944, 'learning_rate': 0.003511213176693322, 'weight_decay': 9.388507659881157e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:32:31,171] Trial 377 finished with value: 0.0019109741755528376 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19642908381369628, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22619151868965512, 'learning_rate': 0.003886250943248061, 'weight_decay': 8.291070396987446e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:33:46,042] Trial 378 finished with value: 0.0022994028724497182 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21188451507697018, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2167729977845445, 'learning_rate': 0.005069778248754, 'weight_decay': 9.764872436784286e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:35:15,837] Trial 379 finished with value: 0.00021139748278073967 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22328833986842508, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21063665769988324, 'learning_rate': 0.003687360623079852, 'weight_decay': 1.1831148778230642e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:36:53,687] Trial 380 finished with value: 0.00019701619021361694 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2160444174908273, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2502310432633704, 'learning_rate': 0.0032396634176392117, 'weight_decay': 6.393311722368833e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:38:14,490] Trial 381 finished with value: 0.009759754838887602 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23327361515739856, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2251000942614386, 'learning_rate': 0.004035034254901229, 'weight_decay': 9.692390528887243e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:39:04,065] Trial 382 finished with value: 0.00023620002903044224 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.2384568025285037, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.23737196080759745, 'learning_rate': 0.002857242227208081, 'weight_decay': 0.0005646946672483087}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:39:53,218] Trial 383 finished with value: 0.0021620532585075124 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.25306372853739156, 'decoder_layers': 2, 'decoder_nodes': 176, 'decoder_dropout': 0.2205889536178402, 'learning_rate': 0.0034848165059217693, 'weight_decay': 8.529607830763106e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:41:11,684] Trial 384 finished with value: 0.0023293980018934237 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.19939561127956057, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.20850000389908047, 'learning_rate': 0.0026409078572388915, 'weight_decay': 1.4183672016306065e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:42:40,219] Trial 385 finished with value: 0.00019661242695292457 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2202325823912621, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23225408328443528, 'learning_rate': 0.00461991359881535, 'weight_decay': 7.146546587148253e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:44:13,916] Trial 386 finished with value: 0.00018683773814700543 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20644065213032087, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21532173449990968, 'learning_rate': 0.0031933893710617022, 'weight_decay': 1.2058391526693394e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:45:43,375] Trial 387 finished with value: 0.0010270372295053676 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20832197711742606, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.20089482110414147, 'learning_rate': 0.003613503560838941, 'weight_decay': 1.1636171689896922e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:47:07,501] Trial 388 finished with value: 0.00019497173925628886 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21546814309449944, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21288599804651165, 'learning_rate': 0.0031852667374616854, 'weight_decay': 1.318563886828197e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:48:21,361] Trial 389 finished with value: 0.00018735366465989501 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19753699388801904, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22220522419104977, 'learning_rate': 0.004245126117270304, 'weight_decay': 1.0119112572537015e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:49:32,263] Trial 390 finished with value: 0.004045414648135193 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.19364872610587336, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22396867500740222, 'learning_rate': 0.0052956218485212415, 'weight_decay': 1.076043147966403e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:50:59,012] Trial 391 finished with value: 0.00019109568529529497 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19551001945664873, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23415147790932148, 'learning_rate': 0.004061167187188375, 'weight_decay': 1.4575577312286557e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:52:15,494] Trial 392 finished with value: 0.00019875013385899364 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18161492391226863, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2432456525783283, 'learning_rate': 0.004633804295270008, 'weight_decay': 1.4191524560454313e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:53:33,593] Trial 393 finished with value: 0.0011195862054591999 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19048943313554872, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23629011817106543, 'learning_rate': 0.004328058652538553, 'weight_decay': 1.4986800572786766e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:54:58,330] Trial 394 finished with value: 0.00022614905465161427 and parameters: {'hidden_size': 80, 'num_layers': 1, 'extractor_dropout': 0.1772664090256139, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23085928476255482, 'learning_rate': 0.003954904148542308, 'weight_decay': 1.3290691042365202e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:56:07,893] Trial 395 finished with value: 0.0023359561106190085 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.197453338661331, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22761915180886413, 'learning_rate': 0.006101584426105659, 'weight_decay': 1.1996727657021308e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:57:14,280] Trial 396 finished with value: 0.0006371045034029521 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2005984278873547, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23463864657785796, 'learning_rate': 0.004878323763306334, 'weight_decay': 1.5228548973059926e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:58:08,501] Trial 397 finished with value: 0.003801978047704324 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19213995140744286, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22267399423411802, 'learning_rate': 0.0041121099614650075, 'weight_decay': 1.1976509944420405e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-06 23:59:03,442] Trial 398 finished with value: 0.023460988933220506 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20011323066235426, 'decoder_layers': 8, 'decoder_nodes': 80, 'decoder_dropout': 0.25113502981399505, 'learning_rate': 0.004084897307936325, 'weight_decay': 1.0468333060130996e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:00:14,679] Trial 399 finished with value: 0.001736308675026521 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2036184098045941, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.24105744763511874, 'learning_rate': 0.0051556659553392515, 'weight_decay': 1.3272427812457268e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:01:40,300] Trial 400 finished with value: 0.0015462954645045102 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18664266067318175, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.44918894961031597, 'learning_rate': 0.003533522361045969, 'weight_decay': 1.5427236385400142e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:02:21,620] Trial 401 finished with value: 0.0067417987156659365 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20823643687724666, 'decoder_layers': 6, 'decoder_nodes': 80, 'decoder_dropout': 0.20364051694720745, 'learning_rate': 0.006367558955668474, 'weight_decay': 1.1858201563735436e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:03:56,228] Trial 402 finished with value: 0.00019534763123374432 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.17360255377297784, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22067834642023793, 'learning_rate': 0.0031867094102677133, 'weight_decay': 1.0119884115242221e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:05:01,160] Trial 403 finished with value: 0.022800971518154255 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2068783974750488, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.25433332971330563, 'learning_rate': 0.002745202327336135, 'weight_decay': 5.123789386186267e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:06:05,569] Trial 404 finished with value: 0.005253420141525566 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2722310271856402, 'decoder_layers': 1, 'decoder_nodes': 192, 'decoder_dropout': 0.23425306815333802, 'learning_rate': 0.004491295412052812, 'weight_decay': 1.5417287043883293e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:07:21,840] Trial 405 finished with value: 1943166156.802979 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18385417840831447, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.24401688476471986, 'learning_rate': 0.0001381452879462979, 'weight_decay': 1.3493064030002054e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:08:33,521] Trial 406 finished with value: 0.0015857632679399103 and parameters: {'hidden_size': 16, 'num_layers': 1, 'extractor_dropout': 0.19430090144555676, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22702883036276914, 'learning_rate': 0.0036579423639282356, 'weight_decay': 1.1733729039593425e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:10:11,579] Trial 407 finished with value: 0.00018925838958239183 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23428341724853752, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21331938604283954, 'learning_rate': 0.0031265068776772796, 'weight_decay': 1.4813376754149188e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:11:55,675] Trial 408 finished with value: 0.00021103558538015932 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23136448733455872, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1982529799577143, 'learning_rate': 0.0026146444922552706, 'weight_decay': 1.609748543595978e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:13:33,497] Trial 409 finished with value: 0.00018883030279539525 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23756197236323223, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21668242767646068, 'learning_rate': 0.0040382101001997, 'weight_decay': 1.4310754417378249e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:14:26,984] Trial 410 finished with value: 0.0036914527110639027 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2360462664637958, 'decoder_layers': 2, 'decoder_nodes': 96, 'decoder_dropout': 0.2060089100390986, 'learning_rate': 0.004242007896574922, 'weight_decay': 1.6081858442396358e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:15:56,108] Trial 411 finished with value: 0.00020040049421368166 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24205669967830182, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21299516156096882, 'learning_rate': 0.0031788026156255775, 'weight_decay': 1.4572360590028755e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:16:58,121] Trial 412 finished with value: 0.0064569826703518626 and parameters: {'hidden_size': 256, 'num_layers': 6, 'extractor_dropout': 0.23120822696002757, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21550418980841252, 'learning_rate': 0.005341047013965902, 'weight_decay': 1.2475320333563311e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:18:34,765] Trial 413 finished with value: 0.00022973031736910342 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.24417625193767328, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.11382871520033525, 'learning_rate': 0.002531293628705271, 'weight_decay': 1.4073827451439136e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:19:22,600] Trial 414 finished with value: 0.003338010888546705 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.207180914641386, 'decoder_layers': 9, 'decoder_nodes': 48, 'decoder_dropout': 0.20481161995008026, 'learning_rate': 0.004081602047934171, 'weight_decay': 1.4845166526164468e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:20:26,666] Trial 415 finished with value: 0.0017758055269951 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2378783193474293, 'decoder_layers': 1, 'decoder_nodes': 160, 'decoder_dropout': 0.19660809803581353, 'learning_rate': 0.004781590988686931, 'weight_decay': 1.6887066652313984e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:21:51,895] Trial 416 finished with value: 0.00019388659420656041 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22738024552519093, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.2154538208276601, 'learning_rate': 0.002896503913347295, 'weight_decay': 5.756550603678994e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:23:27,421] Trial 417 finished with value: 0.00020626240875571967 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.19005808911790342, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2076288867092897, 'learning_rate': 0.003753387190957312, 'weight_decay': 1.333138436208625e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:24:49,719] Trial 418 finished with value: 0.00019882614142261446 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2526997667204237, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21671443750985978, 'learning_rate': 0.0033470195153209818, 'weight_decay': 1.614419248536635e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:25:59,308] Trial 419 finished with value: 0.0002063995329081081 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23628787153420788, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19466772717614428, 'learning_rate': 0.005668283129480752, 'weight_decay': 1.3444189265531435e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:27:29,693] Trial 420 finished with value: 0.00019336081022629513 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19953049212058438, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.22165874407414105, 'learning_rate': 0.0024152149706744594, 'weight_decay': 1.630751853627103e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:28:25,585] Trial 421 finished with value: 0.002191070097615011 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.46376551117648784, 'decoder_layers': 2, 'decoder_nodes': 96, 'decoder_dropout': 0.2085725633593248, 'learning_rate': 0.002853605933078623, 'weight_decay': 1.2249787887142422e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:29:54,373] Trial 422 finished with value: 0.00019186506688129157 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21164262603191805, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.199705376618538, 'learning_rate': 0.0033031434640961787, 'weight_decay': 1.1057277610264015e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:31:09,738] Trial 423 finished with value: 0.00020287899242248385 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20873229718927855, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19910060716164096, 'learning_rate': 0.003272310637034091, 'weight_decay': 1.086719226181602e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:32:20,860] Trial 424 finished with value: 0.015182648075278849 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2124588380603804, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1907032393104923, 'learning_rate': 0.00400487025159753, 'weight_decay': 9.212294824107316e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:33:40,891] Trial 425 finished with value: 0.00023001413646852597 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.2217614714561254, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20103011103000518, 'learning_rate': 0.0034782906815627583, 'weight_decay': 1.1033988620655827e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:35:09,510] Trial 426 finished with value: 0.00019222447590436787 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21556949703363443, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20960519718741633, 'learning_rate': 0.004556349149090297, 'weight_decay': 1.349582640506988e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:36:32,977] Trial 427 finished with value: 0.017986486451991367 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.42315180967776017, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21103892903303437, 'learning_rate': 0.005199503007763321, 'weight_decay': 1.3097888103707371e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:38:01,615] Trial 428 finished with value: 0.00018457981932442635 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21827879813965742, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20278002272544354, 'learning_rate': 0.004487711128244425, 'weight_decay': 8.222800919572341e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:39:29,721] Trial 429 finished with value: 0.022967432989389636 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21647077402698534, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20001383507557075, 'learning_rate': 0.004566844431831919, 'weight_decay': 8.34068686153599e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:40:57,038] Trial 430 finished with value: 0.0007589989560074173 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21295642267912177, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20659744293050966, 'learning_rate': 0.005590301587267394, 'weight_decay': 8.526165433011597e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:42:31,645] Trial 431 finished with value: 0.00020994103688281028 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2060256625640899, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19440467875366568, 'learning_rate': 0.004660691064579544, 'weight_decay': 6.849055637099437e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:44:04,340] Trial 432 finished with value: 0.00019060726044699549 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22498572973735198, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20872546549252896, 'learning_rate': 0.006715477062638057, 'weight_decay': 1.014968100421707e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:45:08,506] Trial 433 finished with value: 0.002327664646145422 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22751394045863604, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2075845283326263, 'learning_rate': 0.007502978037925456, 'weight_decay': 9.686101650121036e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:46:27,859] Trial 434 finished with value: 0.00021207462559686975 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2201657242896808, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2152442167323696, 'learning_rate': 0.006176057013099168, 'weight_decay': 7.811691761567437e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:47:22,450] Trial 435 finished with value: 0.0021406031446531415 and parameters: {'hidden_size': 240, 'num_layers': 4, 'extractor_dropout': 0.22647067015563863, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20222266895899252, 'learning_rate': 0.008229094227290176, 'weight_decay': 1.0098861604531491e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:48:47,584] Trial 436 finished with value: 0.002989019779488444 and parameters: {'hidden_size': 240, 'num_layers': 10, 'extractor_dropout': 0.2149305693102242, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21470400693080022, 'learning_rate': 0.00419305144645274, 'weight_decay': 5.995557792256422e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:49:56,542] Trial 437 finished with value: 0.002332496739109047 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20110954167448228, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1945599036341632, 'learning_rate': 0.004994539468401943, 'weight_decay': 7.607093940427644e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:51:21,286] Trial 438 finished with value: 0.0001922044059028849 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21765035971291125, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20731186646380292, 'learning_rate': 0.005901696401710083, 'weight_decay': 8.68009668271892e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:52:14,833] Trial 439 finished with value: 0.0009412106577656232 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.22923486187953943, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21934229508271547, 'learning_rate': 0.006664276760244015, 'weight_decay': 6.669586732096906e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:53:31,164] Trial 440 finished with value: 0.0026742562535218895 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2063352619917095, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2037717834203837, 'learning_rate': 0.006700332578280373, 'weight_decay': 8.352119242247533e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:54:52,851] Trial 441 finished with value: 0.0029551330488175155 and parameters: {'hidden_size': 240, 'num_layers': 5, 'extractor_dropout': 0.22434325897910626, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.21898027080921856, 'learning_rate': 0.006743231751522287, 'weight_decay': 8.888966114651143e-06}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:56:02,124] Trial 442 finished with value: 0.004378923054900952 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23461892447782334, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1985328225960968, 'learning_rate': 0.00565817568622557, 'weight_decay': 1.0166711402914971e-05}. Best is trial 333 with value: 0.0001831027999287471.\n",
      "[I 2025-08-07 00:57:41,781] Trial 443 finished with value: 0.00018157572485506536 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22103356310373592, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2097932619350602, 'learning_rate': 0.004022119173668477, 'weight_decay': 6.638861795370161e-06}. Best is trial 443 with value: 0.00018157572485506536.\n",
      "[I 2025-08-07 00:58:30,746] Trial 444 finished with value: 0.002829670155188069 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.22439354557001998, 'decoder_layers': 5, 'decoder_nodes': 64, 'decoder_dropout': 0.22391227412163067, 'learning_rate': 0.0037127760637226098, 'weight_decay': 5.0815327729900064e-06}. Best is trial 443 with value: 0.00018157572485506536.\n",
      "[I 2025-08-07 01:00:12,642] Trial 445 finished with value: 0.00017998211551457645 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2339508556986844, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21422323752930544, 'learning_rate': 0.0039135093430379495, 'weight_decay': 5.669318567567254e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:01:47,723] Trial 446 finished with value: 0.00022231403272598982 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.23647960545085167, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21343138682699347, 'learning_rate': 0.003965902461454714, 'weight_decay': 4.8488316208692184e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:03:27,946] Trial 447 finished with value: 0.00018248128908453508 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23092746291267624, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.221486921564854, 'learning_rate': 0.0037038067825227233, 'weight_decay': 5.840253376625272e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:04:54,053] Trial 448 finished with value: 0.002191035529540386 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23136595855312753, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22402849295971614, 'learning_rate': 0.004176130131087813, 'weight_decay': 5.718983637291069e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:06:18,342] Trial 449 finished with value: 0.027756294308346696 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22563306129142396, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21440028622458696, 'learning_rate': 0.0036588584039933298, 'weight_decay': 6.152973863340428e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:07:48,522] Trial 450 finished with value: 0.00020294667338021098 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24355257898148303, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2282962176243504, 'learning_rate': 0.00484544389652583, 'weight_decay': 5.500826674469061e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:08:45,004] Trial 451 finished with value: 0.003340997314080596 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2301156781497598, 'decoder_layers': 6, 'decoder_nodes': 64, 'decoder_dropout': 0.21925106128450828, 'learning_rate': 0.0033090490612906463, 'weight_decay': 6.652527897379317e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:09:52,873] Trial 452 finished with value: 0.036871944555605295 and parameters: {'hidden_size': 224, 'num_layers': 2, 'extractor_dropout': 0.23719313110450752, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.2093178716155173, 'learning_rate': 0.0040323776020763325, 'weight_decay': 3.762851985991339e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:11:38,505] Trial 453 finished with value: 0.00019113508169539274 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21254886231832112, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22923134601154, 'learning_rate': 0.0036424988049614, 'weight_decay': 4.48286264699895e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:12:37,911] Trial 454 finished with value: 0.004133685103442986 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2213343027061817, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23224726193140455, 'learning_rate': 0.009263485321780816, 'weight_decay': 4.301050881839552e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:14:00,858] Trial 455 finished with value: 0.002356447918282356 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23149457801516082, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.23121486117828488, 'learning_rate': 0.004454324676679866, 'weight_decay': 4.503611110239819e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:15:15,815] Trial 456 finished with value: 0.004492772463709116 and parameters: {'hidden_size': 256, 'num_layers': 8, 'extractor_dropout': 0.2167633231626948, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22200328341496944, 'learning_rate': 0.0037816333952091466, 'weight_decay': 5.124952703910206e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:16:31,723] Trial 457 finished with value: 0.007325527747161687 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24334172688712621, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.22509523997387235, 'learning_rate': 0.00023614476605191752, 'weight_decay': 3.531550424924138e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:17:31,399] Trial 458 finished with value: 0.0047484181355685 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.20429682078603612, 'decoder_layers': 7, 'decoder_nodes': 64, 'decoder_dropout': 0.23325777865412026, 'learning_rate': 0.0048716555864447555, 'weight_decay': 4.20400490975264e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:19:16,117] Trial 459 finished with value: 0.00018334324850002303 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19736715537133317, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21806340823910828, 'learning_rate': 0.0035840410590586057, 'weight_decay': 6.030112112169097e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:20:23,473] Trial 460 finished with value: 0.0017476174019975589 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19632429464824955, 'decoder_layers': 4, 'decoder_nodes': 64, 'decoder_dropout': 0.21912677248761994, 'learning_rate': 0.004203802588519967, 'weight_decay': 6.0260504462431914e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:21:41,374] Trial 461 finished with value: 0.0002290158867253922 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19182514144755905, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.24110631582664976, 'learning_rate': 0.0036765891098145074, 'weight_decay': 4.914062551887495e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:23:21,156] Trial 462 finished with value: 0.00019838783191516995 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.210120911335296, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.22548397037639814, 'learning_rate': 0.003330582776315782, 'weight_decay': 6.864327670358793e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:24:40,611] Trial 463 finished with value: 0.0029403099324554205 and parameters: {'hidden_size': 64, 'num_layers': 9, 'extractor_dropout': 0.19977138427522884, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2157673662315971, 'learning_rate': 0.00517407331707477, 'weight_decay': 5.983386261167837e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:26:25,469] Trial 464 finished with value: 0.00019768987694988028 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22048947727832752, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23256609251299726, 'learning_rate': 0.004479004313482725, 'weight_decay': 5.498988051563738e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:28:06,807] Trial 465 finished with value: 0.00020492245093919336 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23730185206095894, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21474134952528912, 'learning_rate': 0.0038790757697883234, 'weight_decay': 4.323116386440292e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:29:44,633] Trial 466 finished with value: 0.0002045257671852596 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.2108986608555923, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22601193215803386, 'learning_rate': 0.0033342153945989683, 'weight_decay': 7.137505299780507e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:31:26,182] Trial 467 finished with value: 0.0002028057220741175 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22672547002827959, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.1014177421897495, 'learning_rate': 0.0030215485677856555, 'weight_decay': 5.203822515495601e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:32:54,861] Trial 468 finished with value: 0.00020356132736196742 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1967641087395798, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23781752144052365, 'learning_rate': 0.004220505717714242, 'weight_decay': 7.114313607388095e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:34:28,979] Trial 469 finished with value: 0.00018814533978002147 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24690529525133234, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21829286348759935, 'learning_rate': 0.003592696906656001, 'weight_decay': 5.832669215771578e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:35:38,237] Trial 470 finished with value: 0.01662513984629186 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24487286444547995, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2109074643705882, 'learning_rate': 0.00510111595019241, 'weight_decay': 6.522009148438855e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:37:23,238] Trial 471 finished with value: 0.00018793342023855076 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25196883115781793, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21905191845836536, 'learning_rate': 0.003068307199276058, 'weight_decay': 6.397809547850229e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:38:47,627] Trial 472 finished with value: 0.00023595974780619145 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.25105759531569755, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2188258514528071, 'learning_rate': 0.003073852219026055, 'weight_decay': 6.018042876589518e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:40:13,013] Trial 473 finished with value: 0.014710875635500997 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25515544254959865, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20794875284474929, 'learning_rate': 0.00010517468701383029, 'weight_decay': 7.490686581136335e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:41:44,975] Trial 474 finished with value: 0.00023384618980344386 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24527739620702763, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.211091167366846, 'learning_rate': 0.0030233898844340963, 'weight_decay': 5.6163417647305e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:43:09,885] Trial 475 finished with value: 0.02421138308418449 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24894749196695654, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21958007297888885, 'learning_rate': 0.003478834689299869, 'weight_decay': 6.465841281212759e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:44:45,106] Trial 476 finished with value: 0.0002017973063630052 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23885632140970345, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20740020077475183, 'learning_rate': 0.0028904930130967364, 'weight_decay': 7.558738320817629e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:46:06,615] Trial 477 finished with value: 0.00019233027996961026 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2339645546126039, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21809965807307966, 'learning_rate': 0.0036268391124514845, 'weight_decay': 5.184795453652089e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:47:15,087] Trial 478 finished with value: 0.0028558471240103245 and parameters: {'hidden_size': 256, 'num_layers': 6, 'extractor_dropout': 0.25449452664675165, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2054034155042851, 'learning_rate': 0.0032051602035509455, 'weight_decay': 6.394519062096488e-06}. Best is trial 445 with value: 0.00017998211551457645.\n",
      "[I 2025-08-07 01:48:49,668] Trial 479 finished with value: 0.00017843720997916533 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24064463735518454, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22473556828060615, 'learning_rate': 0.004510433544899872, 'weight_decay': 7.82714791364045e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:50:02,800] Trial 480 finished with value: 0.0025277424952946602 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23578159861653006, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21359654535021128, 'learning_rate': 0.0046386560229116644, 'weight_decay': 7.636910608548878e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:50:48,515] Trial 481 finished with value: 0.00474466122686863 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.22758764352667446, 'decoder_layers': 9, 'decoder_nodes': 80, 'decoder_dropout': 0.22220934817127008, 'learning_rate': 0.005356930476940585, 'weight_decay': 7.188858453964804e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:52:18,718] Trial 482 finished with value: 0.0002490334038157016 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2384955584379617, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22210248171439362, 'learning_rate': 0.0043759981782002435, 'weight_decay': 5.631082844240111e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:53:40,975] Trial 483 finished with value: 0.0011848746114992536 and parameters: {'hidden_size': 128, 'num_layers': 1, 'extractor_dropout': 0.24807223920209767, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2038100302311717, 'learning_rate': 0.005707665383386395, 'weight_decay': 6.672667838761519e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:55:02,458] Trial 484 finished with value: 0.0008219305716920644 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22888350250383088, 'decoder_layers': 2, 'decoder_nodes': 32, 'decoder_dropout': 0.21272540046804525, 'learning_rate': 0.004246453437614418, 'weight_decay': 8.365388724290675e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:56:07,018] Trial 485 finished with value: 0.0008223756856750696 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.240093773781103, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22313243935464552, 'learning_rate': 0.0038067998748596028, 'weight_decay': 5.99272050688115e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:57:14,200] Trial 486 finished with value: 0.0017822764682932756 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2566910174775357, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21286107481926303, 'learning_rate': 0.004804295791491077, 'weight_decay': 7.724521405776095e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 01:58:40,101] Trial 487 finished with value: 0.0017737743590259924 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22301828952108874, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1237626399724347, 'learning_rate': 0.00376200603768285, 'weight_decay': 5.064475202308456e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:00:17,042] Trial 488 finished with value: 0.00018861703720176592 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23366161308874883, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20552137225034997, 'learning_rate': 0.003413424838831438, 'weight_decay': 6.373517868687762e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:01:48,606] Trial 489 finished with value: 0.00020128831820329652 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23657985955321145, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1987683915835497, 'learning_rate': 0.004125722879678086, 'weight_decay': 6.320987278269125e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:03:20,378] Trial 490 finished with value: 0.0002787867240840569 and parameters: {'hidden_size': 240, 'num_layers': 3, 'extractor_dropout': 0.2310772635939208, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20207503673289154, 'learning_rate': 0.003520844118940176, 'weight_decay': 7.100896060138698e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:04:35,553] Trial 491 finished with value: 0.0002443946621497162 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22081893022255955, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.20777019220018977, 'learning_rate': 0.00746929114275841, 'weight_decay': 4.7178250735167195e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:06:07,490] Trial 492 finished with value: 0.001561164073063992 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2457598161890679, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21432960918313732, 'learning_rate': 0.004739405848952223, 'weight_decay': 5.491862698844775e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:07:48,202] Trial 493 finished with value: 0.00023112119088182227 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.228650282254256, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.192262244195542, 'learning_rate': 0.0055986862250298015, 'weight_decay': 8.128073004546695e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:08:14,130] Trial 494 finished with value: 0.03474348615854979 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2378846345901307, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20440534727000956, 'learning_rate': 0.030950583961305837, 'weight_decay': 6.812697540467128e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:09:29,052] Trial 495 finished with value: 0.024072722959681415 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2198985543887556, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21488430321183696, 'learning_rate': 0.003923005108996934, 'weight_decay': 6.453155190290948e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:11:00,510] Trial 496 finished with value: 0.00019165990233886986 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23172413541023795, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22375340700981555, 'learning_rate': 0.0033108967408842014, 'weight_decay': 8.823951983968996e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:12:42,427] Trial 497 finished with value: 0.00021736734051955864 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24668409101238145, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.20191132013050425, 'learning_rate': 0.00455845013824644, 'weight_decay': 5.665516256548538e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:14:20,516] Trial 498 finished with value: 0.0002115627721650526 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.2171145103894391, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20975920660674605, 'learning_rate': 0.003687614733237756, 'weight_decay': 7.635289603170803e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:15:48,375] Trial 499 finished with value: 0.00019732101063709706 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2405786850327729, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21754641964436447, 'learning_rate': 0.002829510897067685, 'weight_decay': 4.8191591418776425e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:17:21,334] Trial 500 finished with value: 0.00019287571776658297 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22662145675465772, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19591285865556066, 'learning_rate': 0.0041359166890266585, 'weight_decay': 8.955068807571076e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:18:43,896] Trial 501 finished with value: 0.00024834662763169036 and parameters: {'hidden_size': 32, 'num_layers': 1, 'extractor_dropout': 0.20513890712049593, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.22387900593936502, 'learning_rate': 0.005142506043876747, 'weight_decay': 5.483383787312044e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:20:17,530] Trial 502 finished with value: 0.00018623705254867674 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2343958265790751, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21002797165916837, 'learning_rate': 0.0032855977877850407, 'weight_decay': 6.968360866129526e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:21:57,270] Trial 503 finished with value: 0.00019247158925281838 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.23355696614107652, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20667508897056538, 'learning_rate': 0.0028465406486441, 'weight_decay': 6.189390333627508e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:23:25,786] Trial 504 finished with value: 0.00019606279383879154 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2217357049604674, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19403956401553632, 'learning_rate': 0.003443753820004368, 'weight_decay': 6.892685416902331e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:24:36,364] Trial 505 finished with value: 0.0006693068862659857 and parameters: {'hidden_size': 224, 'num_layers': 2, 'extractor_dropout': 0.21465604304194869, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.2043156653186679, 'learning_rate': 0.006215021797063908, 'weight_decay': 3.835561063250795e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:25:12,447] Trial 506 finished with value: 0.003315860824659467 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2321832241786, 'decoder_layers': 7, 'decoder_nodes': 64, 'decoder_dropout': 0.21232143503755155, 'learning_rate': 0.004515769647001798, 'weight_decay': 8.203446501598379e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:26:52,689] Trial 507 finished with value: 0.00021406857413239778 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24277783103489448, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.21815521424604764, 'learning_rate': 0.0037963749464413016, 'weight_decay': 7.224003095103271e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:28:20,285] Trial 508 finished with value: 0.00018862901779357344 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22147446092794906, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20332996657133026, 'learning_rate': 0.003097685847056892, 'weight_decay': 5.818554975575332e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:29:49,620] Trial 509 finished with value: 0.0023323734261794017 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2054088384533277, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20072715899573565, 'learning_rate': 0.0030729986003253623, 'weight_decay': 5.773082202789217e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:31:32,129] Trial 510 finished with value: 0.0001986974399187602 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.215571763245425, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1996702739331243, 'learning_rate': 0.0026372861622141306, 'weight_decay': 4.801830526330622e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:33:04,698] Trial 511 finished with value: 0.00019292066572234033 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22466648391548635, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1905571888193013, 'learning_rate': 0.0032343535009789317, 'weight_decay': 6.267847489438311e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:34:24,600] Trial 512 finished with value: 0.00022136368788778783 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2355484415914322, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21267283432812312, 'learning_rate': 0.004033307613280522, 'weight_decay': 5.102721972982641e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:36:00,615] Trial 513 finished with value: 0.002179756644181907 and parameters: {'hidden_size': 144, 'num_layers': 2, 'extractor_dropout': 0.2502728946010704, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.22779555738112178, 'learning_rate': 0.0027760770361954057, 'weight_decay': 5.9020955723588246e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:37:21,342] Trial 514 finished with value: 0.0029363967012614013 and parameters: {'hidden_size': 240, 'num_layers': 7, 'extractor_dropout': 0.21216108217743745, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21629231666674406, 'learning_rate': 0.0035298103781678377, 'weight_decay': 3.973269954476095e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:38:58,141] Trial 515 finished with value: 0.00018446782778482884 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24178011102272337, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20454017748375097, 'learning_rate': 0.0031117497450555845, 'weight_decay': 7.254399675663367e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:40:31,304] Trial 516 finished with value: 0.0002107724198140204 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2425403656560775, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19752045928809875, 'learning_rate': 0.0028943319160862294, 'weight_decay': 8.067773316288381e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:42:07,954] Trial 517 finished with value: 0.0002051134462817572 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2519674091196645, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19172945220897547, 'learning_rate': 0.002555797265246565, 'weight_decay': 7.254348750205163e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:43:31,763] Trial 518 finished with value: 0.0025281638372689486 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.23901400656416757, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20465197194946141, 'learning_rate': 0.003096733218245575, 'weight_decay': 4.387402622215294e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:44:53,282] Trial 519 finished with value: 0.0005475991783896461 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.22914623256182, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20148047786558065, 'learning_rate': 0.0033715395482467594, 'weight_decay': 6.906520140333407e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:46:19,651] Trial 520 finished with value: 0.00020452517055673524 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24458832776074055, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20856264625848722, 'learning_rate': 0.002453778040483108, 'weight_decay': 7.768581451833022e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:47:39,559] Trial 521 finished with value: 0.0017852784047136083 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23465791505280695, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21730891388861245, 'learning_rate': 0.0030273700122695115, 'weight_decay': 5.7355805652098764e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:49:17,756] Trial 522 finished with value: 0.00018091014062520115 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2553934109859152, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19516042603236033, 'learning_rate': 0.003628168660769589, 'weight_decay': 8.81645412290673e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:50:58,245] Trial 523 finished with value: 0.00018519129662308842 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2518394649103375, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19177413807433014, 'learning_rate': 0.003737055595599298, 'weight_decay': 9.200492014972616e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:52:27,057] Trial 524 finished with value: 0.002557329289265908 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.24231693689331107, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1953125934716772, 'learning_rate': 0.003883145543211169, 'weight_decay': 8.893691823349763e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:53:48,245] Trial 525 finished with value: 0.027238611903158017 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2515413882401979, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20418774911947113, 'learning_rate': 0.0037059632813530195, 'weight_decay': 9.078170858854744e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:55:16,035] Trial 526 finished with value: 0.0015923008002573624 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25734632845397254, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19107757915127235, 'learning_rate': 0.004700311902695953, 'weight_decay': 7.68905714522743e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:56:42,976] Trial 527 finished with value: 0.0017899684055009857 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2592419570020912, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18785754665603013, 'learning_rate': 0.004162572105475015, 'weight_decay': 8.786901503861e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:58:15,899] Trial 528 finished with value: 0.00031417861609952526 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.2493512206869587, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19215545022461, 'learning_rate': 0.00368178627103612, 'weight_decay': 6.9103698894029025e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 02:59:55,447] Trial 529 finished with value: 0.00018120143649866805 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2531599123571136, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2065962230400257, 'learning_rate': 0.003461193899158493, 'weight_decay': 7.886389010276344e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:01:26,171] Trial 530 finished with value: 0.00022771700023440644 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26261319116914944, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19845252940399477, 'learning_rate': 0.004713534676528223, 'weight_decay': 6.263505187630361e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:02:59,747] Trial 531 finished with value: 0.00020315716101322324 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2585579046269329, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20656772614956548, 'learning_rate': 0.003480171191728831, 'weight_decay': 7.559666208917386e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:04:29,093] Trial 532 finished with value: 0.0010006102340412327 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2413565749353206, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20410854461321393, 'learning_rate': 0.004008231607341682, 'weight_decay': 5.36507556467016e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:06:06,997] Trial 533 finished with value: 0.00018255734903505072 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24923684286355047, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18950803448996545, 'learning_rate': 0.00514000430009696, 'weight_decay': 6.761345158762575e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:07:49,117] Trial 534 finished with value: 0.00018616315064718948 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.250537980613865, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18474608520865693, 'learning_rate': 0.005509781025301623, 'weight_decay': 6.54202469212007e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:08:43,264] Trial 535 finished with value: 0.0036867453760351054 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25840425836466546, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.19324386386918346, 'learning_rate': 0.005470934834134467, 'weight_decay': 6.622699391134631e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:09:59,368] Trial 536 finished with value: 0.00021741724194725975 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2518514494059923, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18771312613327956, 'learning_rate': 0.005954589933060998, 'weight_decay': 7.710755626691147e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:11:06,505] Trial 537 finished with value: 0.017763436429959256 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2560497157495163, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.187585094248099, 'learning_rate': 0.005432358253194375, 'weight_decay': 6.0974484780831254e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:12:25,522] Trial 538 finished with value: 0.0015426394558744505 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2512454877073717, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18570045336391516, 'learning_rate': 0.004992350680457561, 'weight_decay': 4.891997342529731e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:13:48,294] Trial 539 finished with value: 0.0001972813275642693 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26007364201019706, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18572625364327228, 'learning_rate': 0.0048966581482701175, 'weight_decay': 6.976073141336446e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:14:38,311] Trial 540 finished with value: 0.002772932729567401 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24966752316205706, 'decoder_layers': 5, 'decoder_nodes': 64, 'decoder_dropout': 0.19797906115413705, 'learning_rate': 0.004502028043681114, 'weight_decay': 5.264040032782348e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:15:56,743] Trial 541 finished with value: 0.014123803502297961 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24560921688714754, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1911372207010546, 'learning_rate': 0.005444852192548454, 'weight_decay': 8.279432178261392e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:17:07,659] Trial 542 finished with value: 0.0025644040753832085 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2637224299572289, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19792243622540323, 'learning_rate': 0.006288797434566624, 'weight_decay': 6.098112319458295e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:18:32,009] Trial 543 finished with value: 0.01798181780759478 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2544536441225339, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1940624866347299, 'learning_rate': 0.004300944879258622, 'weight_decay': 7.139353758118471e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:19:38,849] Trial 544 finished with value: 0.00029995373188285157 and parameters: {'hidden_size': 48, 'num_layers': 1, 'extractor_dropout': 0.394288693196503, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20041667798772145, 'learning_rate': 0.0050365727429121715, 'weight_decay': 5.468982515800171e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:21:00,099] Trial 545 finished with value: 0.0004567907759337686 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.24399395809334554, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18641139552517846, 'learning_rate': 0.003592514334979394, 'weight_decay': 8.147493650158198e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:22:41,019] Trial 546 finished with value: 0.00018425590824335813 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24949293369511663, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18295883935337307, 'learning_rate': 0.004410472208087467, 'weight_decay': 6.457853014440793e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:23:58,463] Trial 547 finished with value: 0.00019402905745664613 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2526713554377462, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.18002034383115104, 'learning_rate': 0.006108190024795988, 'weight_decay': 6.624358857238073e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:24:50,264] Trial 548 finished with value: 0.0057269100099802015 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2658256465162356, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.18588084112529102, 'learning_rate': 0.004577488726259178, 'weight_decay': 7.762428048959821e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:26:05,021] Trial 549 finished with value: 0.000193035151460208 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2502470603568184, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17917057087248392, 'learning_rate': 0.005115000556112336, 'weight_decay': 9.030003363456638e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:27:27,170] Trial 550 finished with value: 0.000617569757741876 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24209676548539696, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.19154171270192327, 'learning_rate': 0.004245380367333088, 'weight_decay': 7.176141112908481e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:28:49,404] Trial 551 finished with value: 0.0036487030069110916 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2594574451560412, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20829484529583583, 'learning_rate': 0.00550634677393449, 'weight_decay': 4.56855923598908e-06}. Best is trial 479 with value: 0.00017843720997916533.\n",
      "[I 2025-08-07 03:30:32,477] Trial 552 finished with value: 0.0001757582605932839 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24610658276845615, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13056161377927028, 'learning_rate': 0.004443400247703163, 'weight_decay': 6.663311718546748e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:31:45,953] Trial 553 finished with value: 0.02646048430033261 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.25660104759636004, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19343870543066718, 'learning_rate': 0.004976276633348818, 'weight_decay': 8.495756552864682e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:32:49,629] Trial 554 finished with value: 0.0017834159298217855 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24726278035676338, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.18410097813662357, 'learning_rate': 0.007220731192281905, 'weight_decay': 7.108519953097306e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:33:39,298] Trial 555 finished with value: 0.0002238552042399533 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2456467408330402, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13029997439338603, 'learning_rate': 0.004594566885730487, 'weight_decay': 0.00024733871471170854}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:34:57,184] Trial 556 finished with value: 0.0015368482650956138 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25476265559694083, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.10987841342825681, 'learning_rate': 0.005894380460665717, 'weight_decay': 9.116214284174411e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:36:09,698] Trial 557 finished with value: 0.0009355999733088538 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2660912006659986, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13969227338462675, 'learning_rate': 0.004060348211175853, 'weight_decay': 6.176142748038102e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:37:29,635] Trial 558 finished with value: 0.0032767914439318702 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23901298834089083, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21128398354752068, 'learning_rate': 0.004355789341696167, 'weight_decay': 5.45744400994219e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:38:49,364] Trial 559 finished with value: 0.0027477934287162497 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25176284198625226, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1285615704092511, 'learning_rate': 0.0039284832193316474, 'weight_decay': 7.854376747156377e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:39:46,140] Trial 560 finished with value: 0.015506247477605938 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26108630080999917, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.11135252607016732, 'learning_rate': 0.00016460226195011686, 'weight_decay': 6.787699365157782e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:40:50,836] Trial 561 finished with value: 0.0029599367175251246 and parameters: {'hidden_size': 256, 'num_layers': 7, 'extractor_dropout': 0.23904127250473922, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22033668731648182, 'learning_rate': 0.0048628409141741125, 'weight_decay': 4.673835110144316e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:41:58,667] Trial 562 finished with value: 0.005310638668015599 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.2462615915922258, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.13838512880465248, 'learning_rate': 0.005491493059969736, 'weight_decay': 8.10295828831025e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:43:29,473] Trial 563 finished with value: 0.00018702648958424106 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23165611988181697, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19745199349462536, 'learning_rate': 0.003786125861615366, 'weight_decay': 9.299886886716385e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:44:58,658] Trial 564 finished with value: 0.0011880125617608427 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23055337296056483, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.1964381167100551, 'learning_rate': 0.004228955972494055, 'weight_decay': 8.982032944990795e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:45:56,155] Trial 565 finished with value: 0.004298402988933958 and parameters: {'hidden_size': 256, 'num_layers': 3, 'extractor_dropout': 0.23548366078865368, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.18306577786097078, 'learning_rate': 0.006631239871739829, 'weight_decay': 3.329509605133586e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:47:25,017] Trial 566 finished with value: 0.000274454866303131 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2422566835428818, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19786098787416737, 'learning_rate': 0.0037611843362814227, 'weight_decay': 6.338787508531548e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:48:58,784] Trial 567 finished with value: 0.0002008378942264244 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2285593038983711, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21024358472754373, 'learning_rate': 0.004530341092190214, 'weight_decay': 7.17951379536863e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:50:24,827] Trial 568 finished with value: 0.0012398684804793448 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2494029229375433, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.49845113022834164, 'learning_rate': 0.0037042972338901833, 'weight_decay': 5.443174929641757e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:51:59,075] Trial 569 finished with value: 0.00020408482087077572 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23527885000424856, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20169192972680092, 'learning_rate': 0.004842889085315029, 'weight_decay': 9.596796686849113e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:53:10,199] Trial 570 finished with value: 0.017173493831069208 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22555225396970466, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19065583512979156, 'learning_rate': 0.005529887224012059, 'weight_decay': 7.563226997780114e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:54:32,076] Trial 571 finished with value: 0.0002207931800512597 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24034167649579838, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21991885816756204, 'learning_rate': 0.003946824258714291, 'weight_decay': 6.256451561383243e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:56:05,836] Trial 572 finished with value: 0.0018314452478080056 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26096711274395584, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20894807067835794, 'learning_rate': 0.003601098006272156, 'weight_decay': 9.50658009690178e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:57:22,190] Trial 573 finished with value: 0.00022080067283241077 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24915169549353597, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20310723779162743, 'learning_rate': 0.004396678149960161, 'weight_decay': 8.17624327598305e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 03:58:34,482] Trial 574 finished with value: 0.002096921976772137 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2552581154691733, 'decoder_layers': 4, 'decoder_nodes': 64, 'decoder_dropout': 0.2162122035350338, 'learning_rate': 0.004996492748914515, 'weight_decay': 5.031556102678793e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:00:04,330] Trial 575 finished with value: 0.002293539242236875 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23000623511610604, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1827810981676022, 'learning_rate': 0.003659891574730971, 'weight_decay': 7.003927636207397e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:01:19,071] Trial 576 finished with value: 0.002533456284436397 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2407089468253616, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19668223553461106, 'learning_rate': 0.004287977248853823, 'weight_decay': 4.257347950138114e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:02:43,732] Trial 577 finished with value: 0.0002129880158463493 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2197423225406068, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22678246736305968, 'learning_rate': 0.0034293091031880195, 'weight_decay': 5.608610516118604e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:03:46,375] Trial 578 finished with value: 0.003404073606361635 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.2324227442115525, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.4230129785715623, 'learning_rate': 0.005823890687046866, 'weight_decay': 7.84159438563341e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:05:05,124] Trial 579 finished with value: 0.0005045080062700436 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.2655466735657275, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21133562981115564, 'learning_rate': 0.004106214687592998, 'weight_decay': 6.210536667196149e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:06:23,438] Trial 580 finished with value: 0.0023023928762995636 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24860032760056536, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.18894001923242013, 'learning_rate': 0.004959168770422978, 'weight_decay': 9.99642635696523e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:08:01,591] Trial 581 finished with value: 0.00018977272120537236 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23985310838975088, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20363769210369354, 'learning_rate': 0.003439284529315429, 'weight_decay': 8.310999211896836e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:09:17,432] Trial 582 finished with value: 0.00183072062645806 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2547321908344541, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21718217467586506, 'learning_rate': 0.004027436538507383, 'weight_decay': 6.8193499273104965e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:11:15,508] Trial 583 finished with value: 0.0029721003025770187 and parameters: {'hidden_size': 256, 'num_layers': 9, 'extractor_dropout': 0.22461406619106675, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.47708295640278847, 'learning_rate': 0.0033241267797162032, 'weight_decay': 4.929128789875529e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:12:22,695] Trial 584 finished with value: 0.0009746249081217684 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2434115370698755, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.223402909080887, 'learning_rate': 0.004613934835095365, 'weight_decay': 9.268154642270897e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:13:35,302] Trial 585 finished with value: 0.002324648154899478 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23358581867408673, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19325056272764926, 'learning_rate': 0.006300217412394146, 'weight_decay': 5.746462736160082e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:15:11,085] Trial 586 finished with value: 0.0023024620124488136 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2473737095292482, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21155926677300482, 'learning_rate': 0.0038196619474526383, 'weight_decay': 7.4203253832317975e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:15:36,748] Trial 587 finished with value: 0.0083651308901608 and parameters: {'hidden_size': 64, 'num_layers': 1, 'extractor_dropout': 0.22066995774637882, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20123497778317603, 'learning_rate': 0.08883034517663237, 'weight_decay': 6.435768906156273e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:17:10,499] Trial 588 finished with value: 0.0002107360356603749 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.25782351216634847, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.22911972025422836, 'learning_rate': 0.00530450524216205, 'weight_decay': 8.76505800581529e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:18:47,698] Trial 589 finished with value: 0.0002146537008229643 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22728105443665197, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18342479680365859, 'learning_rate': 0.0030916140224701203, 'weight_decay': 5.644342617996603e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:20:24,126] Trial 590 finished with value: 0.00018745089473668486 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23654011276648737, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2194374799260928, 'learning_rate': 0.004416201540533265, 'weight_decay': 3.9259532232231835e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:22:11,833] Trial 591 finished with value: 0.0011620364559348673 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23566363993538464, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20679285778922715, 'learning_rate': 0.004615442136758938, 'weight_decay': 3.5901932456549194e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:23:44,016] Trial 592 finished with value: 0.0004112957540201023 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21532949439370894, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19684085803585782, 'learning_rate': 0.005308950236796057, 'weight_decay': 2.961901616703108e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:24:58,048] Trial 593 finished with value: 0.00027833087369799614 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22452411469148478, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22237383598333005, 'learning_rate': 0.007764829331871433, 'weight_decay': 4.3515344672166435e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:26:12,116] Trial 594 finished with value: 0.003424633012036793 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23273248997954393, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21172176681433383, 'learning_rate': 0.006612772647233445, 'weight_decay': 3.2328964123092404e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:27:24,142] Trial 595 finished with value: 0.026157665165374055 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.18621725395828648, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23534078278989684, 'learning_rate': 0.004344094978881221, 'weight_decay': 2.414048147502231e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:28:29,649] Trial 596 finished with value: 0.00020808139233849943 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24218376612719825, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20395598645023805, 'learning_rate': 0.005888155681732294, 'weight_decay': 9.706716677340979e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:29:46,069] Trial 597 finished with value: 0.0009965313511202112 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20736379356483037, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.2170928412986011, 'learning_rate': 0.004182273021677357, 'weight_decay': 8.16745459880151e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:31:07,273] Trial 598 finished with value: 0.02348827731329948 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22760370287075155, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19160321444085074, 'learning_rate': 0.005129594511737494, 'weight_decay': 7.188078778519742e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:32:11,720] Trial 599 finished with value: 0.00029564855503849685 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.23636231938950295, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.3136100854058142, 'learning_rate': 0.003918478054139833, 'weight_decay': 3.969573385237774e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:33:25,454] Trial 600 finished with value: 0.0023573122700327074 and parameters: {'hidden_size': 32, 'num_layers': 1, 'extractor_dropout': 0.2193052255947166, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22386053379361856, 'learning_rate': 0.004807776744876824, 'weight_decay': 9.976031281400144e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:35:10,454] Trial 601 finished with value: 0.00021697981137549504 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2537739574715942, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1809370932401675, 'learning_rate': 0.0033446899443930135, 'weight_decay': 8.252596328071246e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:36:31,750] Trial 602 finished with value: 0.00023556389496661722 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26603663477653117, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2989354756525488, 'learning_rate': 0.002839260892264595, 'weight_decay': 6.931541350994097e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:37:43,853] Trial 603 finished with value: 0.00020090123143745586 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2403138510132671, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21140401652297824, 'learning_rate': 0.00437322448641524, 'weight_decay': 9.183239220768232e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:38:23,136] Trial 604 finished with value: 0.015168290724977851 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23132309211840077, 'decoder_layers': 6, 'decoder_nodes': 80, 'decoder_dropout': 0.19775506606321058, 'learning_rate': 0.0036382763216277346, 'weight_decay': 7.4917237697121556e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:40:05,104] Trial 605 finished with value: 0.000186510244384408 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21456592848484857, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.232289723027939, 'learning_rate': 0.003184402941771475, 'weight_decay': 6.424634634939581e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:41:45,245] Trial 606 finished with value: 0.00017997923423536123 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21140516769049386, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22778877151286842, 'learning_rate': 0.005420213888027161, 'weight_decay': 5.040462523685533e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:43:11,070] Trial 607 finished with value: 0.01739031228935346 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19852039167590912, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.24404665361809194, 'learning_rate': 0.0069244581426806924, 'weight_decay': 4.674902681582898e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:44:48,059] Trial 608 finished with value: 0.0017779016503482125 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20913412333544887, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23436382715700768, 'learning_rate': 0.00544957174560239, 'weight_decay': 5.167312759688817e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:46:23,020] Trial 609 finished with value: 0.0007404776217299514 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21180478025139482, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.2456582059528583, 'learning_rate': 0.006214518093645847, 'weight_decay': 5.906966107996119e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:47:30,774] Trial 610 finished with value: 0.00022234601929085329 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20270099890993953, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2385773996043179, 'learning_rate': 0.0055805360871838345, 'weight_decay': 5.151529372764035e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:48:18,457] Trial 611 finished with value: 0.003334805928170681 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21451482653733833, 'decoder_layers': 8, 'decoder_nodes': 64, 'decoder_dropout': 0.12022105781527188, 'learning_rate': 0.004934181486772389, 'weight_decay': 6.690896521365759e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:49:13,766] Trial 612 finished with value: 0.006629828552831896 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.19346362878001258, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2321212622164747, 'learning_rate': 0.003857648299184176, 'weight_decay': 7.964853641039839e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:50:59,531] Trial 613 finished with value: 0.0001969581891898997 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21976421924924341, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.235851145275303, 'learning_rate': 0.0032983312056958417, 'weight_decay': 6.120180620933526e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:52:34,383] Trial 614 finished with value: 0.00020585118763847277 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2028572460391461, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.25585193330590217, 'learning_rate': 0.0027300879026474862, 'weight_decay': 1.0292725897134676e-05}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:53:21,134] Trial 615 finished with value: 0.00022231912007555365 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20885249845573983, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22928252909231156, 'learning_rate': 0.003927927719180133, 'weight_decay': 0.0004657582173898255}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:54:03,585] Trial 616 finished with value: 0.0035245609935373066 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21453553219413085, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2411922960879893, 'learning_rate': 0.007338754092038412, 'weight_decay': 7.332596891138907e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:55:22,866] Trial 617 finished with value: 0.01876328281359747 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22177415229973702, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18803369436640155, 'learning_rate': 0.004701713888351052, 'weight_decay': 5.1162737663105404e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:56:51,416] Trial 618 finished with value: 0.00116315150517039 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20573211123900506, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.10256015362292892, 'learning_rate': 0.005743765731757821, 'weight_decay': 9.232058006174134e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:58:03,790] Trial 619 finished with value: 0.002953731454908848 and parameters: {'hidden_size': 256, 'num_layers': 6, 'extractor_dropout': 0.2156824378605696, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.1777989635786514, 'learning_rate': 0.00336074877436698, 'weight_decay': 6.514760710107581e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 04:59:21,827] Trial 620 finished with value: 0.017704307747771965 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18990650696049644, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2507730224629911, 'learning_rate': 0.004104380917164758, 'weight_decay': 8.132374567081005e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:00:35,400] Trial 621 finished with value: 0.0005534350406378507 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22471613147224703, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22807696894972365, 'learning_rate': 0.0029423479078308002, 'weight_decay': 4.614405097794955e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:01:50,252] Trial 622 finished with value: 0.0049120542855234815 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.17996927004994845, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20187169110952105, 'learning_rate': 0.00507202651185414, 'weight_decay': 5.64123811296167e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:03:14,440] Trial 623 finished with value: 0.0023558691653306598 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19904730435971632, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.22639365093942207, 'learning_rate': 0.00344240155160736, 'weight_decay': 6.709360682504635e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:04:24,977] Trial 624 finished with value: 0.027771105691499542 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2174204456660909, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19434130337660555, 'learning_rate': 0.004335513030736115, 'weight_decay': 1.0205966178004257e-05}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:05:46,236] Trial 625 finished with value: 0.010782881296472624 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22820749682862565, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.20732271087598694, 'learning_rate': 0.0063912875071741124, 'weight_decay': 8.611408680423117e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:07:00,387] Trial 626 finished with value: 0.01104020766215399 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20987421846316318, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20907275724617375, 'learning_rate': 0.00371325709710141, 'weight_decay': 7.840749655842922e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:07:56,222] Trial 627 finished with value: 0.0023499343020375817 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2221269171898032, 'decoder_layers': 4, 'decoder_nodes': 64, 'decoder_dropout': 0.18715933104794466, 'learning_rate': 0.004615995202140028, 'weight_decay': 5.783628627827021e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:09:30,200] Trial 628 finished with value: 0.0001968732467503287 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20429063376753007, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2229341011655448, 'learning_rate': 0.003096440623639364, 'weight_decay': 7.1714948430825526e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:10:46,369] Trial 629 finished with value: 0.000650158102507703 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22895974140206712, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19973604489644767, 'learning_rate': 0.0037278192634007897, 'weight_decay': 5.159943528093021e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:12:20,185] Trial 630 finished with value: 0.00020904210396111012 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2197791855934187, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2122952054958498, 'learning_rate': 0.002779543850464365, 'weight_decay': 9.116425847731319e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:13:50,184] Trial 631 finished with value: 0.0022971341430093163 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19272521219696934, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23966936638858793, 'learning_rate': 0.005565523736815987, 'weight_decay': 6.238334496758444e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:15:27,694] Trial 632 finished with value: 0.00020950469479430467 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22987526654656998, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19428483776047872, 'learning_rate': 0.004161255656086289, 'weight_decay': 7.306873240361009e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:16:58,004] Trial 633 finished with value: 0.00023983577557373792 and parameters: {'hidden_size': 112, 'num_layers': 2, 'extractor_dropout': 0.2119837358764995, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22829341587010019, 'learning_rate': 0.003297566146118147, 'weight_decay': 1.0498116346161214e-05}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:18:30,685] Trial 634 finished with value: 0.0001926043099956587 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24055247733022841, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21594802995296294, 'learning_rate': 0.005090035410109055, 'weight_decay': 4.321771750947665e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:19:39,191] Trial 635 finished with value: 0.0023628268332686274 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22523602263209952, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.20417748313381962, 'learning_rate': 0.003935309326069026, 'weight_decay': 8.502495680937352e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:20:29,106] Trial 636 finished with value: 0.004629767639562488 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20100731661571505, 'decoder_layers': 10, 'decoder_nodes': 64, 'decoder_dropout': 0.18484987522344004, 'learning_rate': 0.0027078766994078273, 'weight_decay': 6.426952514938746e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:21:03,581] Trial 637 finished with value: 0.0016690837423084305 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2154424659477873, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2832813587214477, 'learning_rate': 0.008485002546817423, 'weight_decay': 0.0008630576694846293}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:22:06,163] Trial 638 finished with value: 0.0073780175356660035 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23596961031553645, 'decoder_layers': 1, 'decoder_nodes': 176, 'decoder_dropout': 0.22039094417995603, 'learning_rate': 0.004311863937291424, 'weight_decay': 7.516953979758145e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:23:19,651] Trial 639 finished with value: 0.0051880933708162045 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.24527233446245447, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17657397557742335, 'learning_rate': 0.018857124401801564, 'weight_decay': 5.547101636328797e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:24:53,281] Trial 640 finished with value: 0.0002571144344983622 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2319996614464168, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.23166193945172553, 'learning_rate': 0.0034152467233333657, 'weight_decay': 4.838610199178691e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:25:58,453] Trial 641 finished with value: 0.002233754697954282 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20868242993986247, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.21215053993907626, 'learning_rate': 0.005910228991425618, 'weight_decay': 9.083881770392372e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:27:15,310] Trial 642 finished with value: 0.0017910933660459706 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2213071516708405, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20031122572055812, 'learning_rate': 0.0047989965411058535, 'weight_decay': 6.599492645123901e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:28:54,376] Trial 643 finished with value: 0.00018671752768568696 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24299524388627108, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1912388649198431, 'learning_rate': 0.0036968848112274, 'weight_decay': 7.896104692558668e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:30:17,789] Trial 644 finished with value: 0.0005331196502083912 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26052001707263306, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17541623095610592, 'learning_rate': 0.004703745956500532, 'weight_decay': 5.9120642594005845e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:31:28,253] Trial 645 finished with value: 0.0023577277199365197 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24943923691725814, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18869603166127363, 'learning_rate': 0.0038985153785055476, 'weight_decay': 7.393499851596685e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:32:56,190] Trial 646 finished with value: 0.0001835813789512031 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1857273137107822, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1926329208396116, 'learning_rate': 0.005256723127000017, 'weight_decay': 8.00812875736854e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:34:20,108] Trial 647 finished with value: 0.0063605321905924935 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.16938058953256155, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18557063510701616, 'learning_rate': 0.006315575025481901, 'weight_decay': 6.768814283677253e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:35:16,740] Trial 648 finished with value: 0.0035470404938678255 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.18358348484592235, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17663997524396438, 'learning_rate': 0.007289358878801579, 'weight_decay': 7.784011802412606e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:36:08,231] Trial 649 finished with value: 0.005114343715831637 and parameters: {'hidden_size': 240, 'num_layers': 7, 'extractor_dropout': 0.1713228194671378, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19195192987329768, 'learning_rate': 0.005529160052830548, 'weight_decay': 5.537531650011835e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:37:05,358] Trial 650 finished with value: 0.005114553359453567 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2469430653976695, 'decoder_layers': 2, 'decoder_nodes': 160, 'decoder_dropout': 0.19185854110540793, 'learning_rate': 0.005215752245404542, 'weight_decay': 6.4537402772487524e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:38:25,170] Trial 651 finished with value: 0.0015413658242323437 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25595195330600734, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1790465462072956, 'learning_rate': 0.006236438239458971, 'weight_decay': 7.93030625066068e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:39:44,771] Trial 652 finished with value: 0.001785453743650578 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2431569727123477, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19240407918990127, 'learning_rate': 0.004673536309829202, 'weight_decay': 5.1616212603069684e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:41:04,130] Trial 653 finished with value: 0.00026505929708946495 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.16135724269998558, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17004757659419578, 'learning_rate': 0.003684549806354523, 'weight_decay': 6.9535987467233874e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:42:51,914] Trial 654 finished with value: 0.00019607816939242183 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.267605517045969, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19830697020684726, 'learning_rate': 0.003038648647642189, 'weight_decay': 6.008222252349267e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:43:22,705] Trial 655 finished with value: 0.008361740503460169 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.17864869184509838, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1832647697990447, 'learning_rate': 0.045164619129293294, 'weight_decay': 4.629879396809988e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:44:59,742] Trial 656 finished with value: 0.00020997156389057636 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23912406375062314, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19556678535037883, 'learning_rate': 0.005292134134912214, 'weight_decay': 8.244474862083685e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:46:27,119] Trial 657 finished with value: 0.0002193400767282583 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25014063045376694, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1858389419950078, 'learning_rate': 0.004288965235512037, 'weight_decay': 6.730408895995606e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:47:49,436] Trial 658 finished with value: 0.02888181051239371 and parameters: {'hidden_size': 256, 'num_layers': 8, 'extractor_dropout': 0.2276959622978302, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.202974452824014, 'learning_rate': 0.003681846213226193, 'weight_decay': 8.603304581756706e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:48:36,826] Trial 659 finished with value: 0.003363399486988783 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.1897188996469248, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19846310029325906, 'learning_rate': 0.007223888058188572, 'weight_decay': 5.885566667818148e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:50:21,858] Trial 660 finished with value: 0.00022153215541038663 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2561934757458256, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20606947874388362, 'learning_rate': 0.003114748574234176, 'weight_decay': 7.121407779959069e-06}. Best is trial 552 with value: 0.0001757582605932839.\n",
      "[I 2025-08-07 05:52:03,249] Trial 661 finished with value: 0.00017418565694242715 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23455609091593344, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18198368968312262, 'learning_rate': 0.004713411992955331, 'weight_decay': 5.2125584770707416e-06}. Best is trial 661 with value: 0.00017418565694242715.\n",
      "[I 2025-08-07 05:53:28,146] Trial 662 finished with value: 0.01928249468910508 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23209932551607437, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16733951982014453, 'learning_rate': 0.005944611611746691, 'weight_decay': 4.2328231634920234e-06}. Best is trial 661 with value: 0.00017418565694242715.\n",
      "[I 2025-08-07 05:55:09,813] Trial 663 finished with value: 0.00017342455830657855 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21824408405832693, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17364019436412279, 'learning_rate': 0.005021381083170737, 'weight_decay': 5.028817220893871e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 05:56:28,216] Trial 664 finished with value: 0.0027548134123208 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20889459868984067, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16603918081338745, 'learning_rate': 0.006389556513230435, 'weight_decay': 3.930977673040407e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 05:58:04,759] Trial 665 finished with value: 0.00018383904098300262 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.217519131838369, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16971353563728117, 'learning_rate': 0.005262385996766704, 'weight_decay': 4.828589417595853e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 05:59:40,579] Trial 666 finished with value: 0.0002274018610478379 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.47693482764632555, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17489961546408425, 'learning_rate': 0.005985708891528886, 'weight_decay': 3.876922714825084e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:01:14,022] Trial 667 finished with value: 0.00019362219463801012 and parameters: {'hidden_size': 80, 'num_layers': 1, 'extractor_dropout': 0.2247675956561694, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.16974384149412206, 'learning_rate': 0.009363033113410732, 'weight_decay': 4.595132667975426e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:02:27,988] Trial 668 finished with value: 0.000869048667664174 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21772250774550495, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.17801963520289033, 'learning_rate': 0.007971121736228225, 'weight_decay': 4.422151263439776e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:03:39,837] Trial 669 finished with value: 0.0011918678486836144 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21686076298407958, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17314018570914094, 'learning_rate': 0.005389471494723297, 'weight_decay': 3.6283473368889677e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:04:51,531] Trial 670 finished with value: 0.0013425047392956913 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22241234301277243, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.1785834147192793, 'learning_rate': 0.0050619000521919845, 'weight_decay': 4.8457682826753785e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:05:58,922] Trial 671 finished with value: 0.0027365279383957386 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2154701945778132, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.43391001613554864, 'learning_rate': 0.00630484327135111, 'weight_decay': 4.707099745087507e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:07:10,173] Trial 672 finished with value: 0.0002182962460210547 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2233087783080606, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16761759506647061, 'learning_rate': 0.007135239921392384, 'weight_decay': 5.195877624904481e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:08:29,289] Trial 673 finished with value: 0.0029714140109717846 and parameters: {'hidden_size': 256, 'num_layers': 10, 'extractor_dropout': 0.23456419466349576, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15897446167484078, 'learning_rate': 0.005163853954595533, 'weight_decay': 5.767902270624187e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:09:53,720] Trial 674 finished with value: 0.00021965995110804216 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21260440044392198, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17932414299707067, 'learning_rate': 0.005190390827786712, 'weight_decay': 5.29269334601959e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:11:18,970] Trial 675 finished with value: 0.00019993404566776007 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22746217243179762, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16476929903789167, 'learning_rate': 0.005830188178613294, 'weight_decay': 3.969720116759315e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:12:01,456] Trial 676 finished with value: 0.004265202939859591 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2372264943319322, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18258994743678464, 'learning_rate': 0.006991103841194842, 'weight_decay': 3.3515985063457484e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:13:45,574] Trial 677 finished with value: 0.00019058115285588428 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24127081502363748, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17251392632243942, 'learning_rate': 0.0045499686718587255, 'weight_decay': 4.83266455093026e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:15:12,428] Trial 678 finished with value: 0.0010515120360651054 and parameters: {'hidden_size': 256, 'num_layers': 3, 'extractor_dropout': 0.21910281104848464, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.18238206092970663, 'learning_rate': 0.004613182184027122, 'weight_decay': 5.463795949956415e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:16:46,989] Trial 679 finished with value: 0.00018496218835934998 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2278175426751023, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18045024415505895, 'learning_rate': 0.004714233909311063, 'weight_decay': 6.138276050584514e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:17:21,094] Trial 680 finished with value: 0.003344949008896947 and parameters: {'hidden_size': 16, 'num_layers': 1, 'extractor_dropout': 0.22625932662984596, 'decoder_layers': 7, 'decoder_nodes': 32, 'decoder_dropout': 0.17215320330963166, 'learning_rate': 0.005672313053059021, 'weight_decay': 4.3687838373950275e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:18:46,727] Trial 681 finished with value: 0.00020819618657696992 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20808098437056824, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17292893008020305, 'learning_rate': 0.005234872818529977, 'weight_decay': 6.068686224494425e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:20:05,163] Trial 682 finished with value: 0.00023561396810691803 and parameters: {'hidden_size': 128, 'num_layers': 2, 'extractor_dropout': 0.21632942646444597, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.1575956878301671, 'learning_rate': 0.006465538772385629, 'weight_decay': 5.017043072986731e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:21:37,910] Trial 683 finished with value: 0.0023715333663858473 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.43142920131021933, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18389074726098484, 'learning_rate': 0.004814490455130861, 'weight_decay': 6.170260863774055e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:23:04,645] Trial 684 finished with value: 0.00020600033894879743 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2255980882516645, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16427257046807195, 'learning_rate': 0.005689968648860496, 'weight_decay': 5.743344962773663e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:24:43,716] Trial 685 finished with value: 0.00022771910589654 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20033336053143835, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.18293087575246506, 'learning_rate': 0.004514125992649051, 'weight_decay': 5.121261727653794e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:26:27,184] Trial 686 finished with value: 0.00022219262027647346 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21799215744797587, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17556748076783082, 'learning_rate': 0.004695623922771584, 'weight_decay': 4.328737088329258e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:27:54,923] Trial 687 finished with value: 0.00018982653709826992 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23059960825222686, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18776150075805953, 'learning_rate': 0.006877512068063585, 'weight_decay': 6.510377262864959e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:29:39,525] Trial 688 finished with value: 0.0001891583844553679 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21090955170246375, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16297707505473794, 'learning_rate': 0.005400170020419046, 'weight_decay': 6.277285188481447e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:31:12,442] Trial 689 finished with value: 0.0003072558858548291 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23391223394856558, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.14831506496853528, 'learning_rate': 0.004245782109339125, 'weight_decay': 5.21355655175079e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:32:48,615] Trial 690 finished with value: 0.0002493452557246201 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.22286719506623517, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.18582242709263602, 'learning_rate': 0.004992395787806914, 'weight_decay': 6.831506996373392e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:34:33,371] Trial 691 finished with value: 0.00019021912157768384 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19719072876786067, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.17444332205409235, 'learning_rate': 0.004236094204215896, 'weight_decay': 5.710492329403578e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:35:02,830] Trial 692 finished with value: 0.005859821615740657 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20484490605510988, 'decoder_layers': 5, 'decoder_nodes': 64, 'decoder_dropout': 0.18834056939144453, 'learning_rate': 0.008429422694707195, 'weight_decay': 3.937341738210393e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:36:16,197] Trial 693 finished with value: 0.004434656015655491 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23025406473987162, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1312215665354476, 'learning_rate': 0.005880220450919602, 'weight_decay': 4.740413085835566e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:37:29,006] Trial 694 finished with value: 0.00021463979210238903 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18453567135961504, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1798462480074431, 'learning_rate': 0.004237471337666505, 'weight_decay': 6.9933562189908854e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:39:01,906] Trial 695 finished with value: 0.0001976057086721994 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2165339686206878, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19023643651211078, 'learning_rate': 0.0048797954715550425, 'weight_decay': 5.534724209325013e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:40:15,505] Trial 696 finished with value: 0.001594783975451719 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23748998637859503, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1706785141796996, 'learning_rate': 0.006569686384989023, 'weight_decay': 6.2472385927526204e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:41:50,776] Trial 697 finished with value: 0.00019148905703332276 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.224839561670282, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18058063238056538, 'learning_rate': 0.003991237615125861, 'weight_decay': 7.270492158749912e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:42:41,865] Trial 698 finished with value: 0.0030652872461359947 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24556743715870283, 'decoder_layers': 3, 'decoder_nodes': 64, 'decoder_dropout': 0.1915859475357924, 'learning_rate': 0.005553513931238526, 'weight_decay': 5.598436065418088e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:44:10,668] Trial 699 finished with value: 0.0015408096936880612 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2339939926560606, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19094802465261387, 'learning_rate': 0.004305001455069009, 'weight_decay': 6.6024646640122214e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:45:30,017] Trial 700 finished with value: 0.0006916846381500363 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21155762916540727, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18293592480098916, 'learning_rate': 0.004942963962195526, 'weight_decay': 4.30924121375827e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:46:31,274] Trial 701 finished with value: 0.0006040056177880615 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21822870912068396, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17318188763842393, 'learning_rate': 0.004003561809498327, 'weight_decay': 7.488740467054019e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:48:03,681] Trial 702 finished with value: 0.0002132937777787447 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2613493925404477, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.1601957090768588, 'learning_rate': 0.006057548734532197, 'weight_decay': 5.124534674541127e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:49:40,907] Trial 703 finished with value: 0.00021944703039480373 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2268666975571945, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.19581717945746932, 'learning_rate': 0.004809298071204256, 'weight_decay': 3.483267709381169e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:51:02,435] Trial 704 finished with value: 0.00025942126230802385 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24112913351408977, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18524059955459887, 'learning_rate': 0.0037336166887800932, 'weight_decay': 6.258738024763833e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:52:31,661] Trial 705 finished with value: 0.0011652912449790164 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20397489449697406, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.11972273239279528, 'learning_rate': 0.00540757849663271, 'weight_decay': 7.423621594468751e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:54:02,697] Trial 706 finished with value: 0.0002230315629276447 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2524165283947205, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20057999549107194, 'learning_rate': 0.004512605320212868, 'weight_decay': 4.821319201380491e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:55:36,727] Trial 707 finished with value: 0.00017999073315877467 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19276063492263665, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18909891663749956, 'learning_rate': 0.007555363818244523, 'weight_decay': 6.2120978003626595e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:56:31,430] Trial 708 finished with value: 0.0037856098206248134 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.18335653991378686, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1799944353141355, 'learning_rate': 0.00857993923469612, 'weight_decay': 5.528304808310016e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:57:13,836] Trial 709 finished with value: 0.008361722808331251 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.17476546757211153, 'decoder_layers': 1, 'decoder_nodes': 208, 'decoder_dropout': 0.1879491119828289, 'learning_rate': 0.01596315667529706, 'weight_decay': 8.048182661177103e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:58:26,250] Trial 710 finished with value: 0.004615966990240849 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19393812538112368, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16574660671165073, 'learning_rate': 0.010858077708028243, 'weight_decay': 6.932100578098327e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 06:59:57,478] Trial 711 finished with value: 0.004433990687539335 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1866766763558061, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19438458980692438, 'learning_rate': 0.01096084466012481, 'weight_decay': 5.675242648714578e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:01:14,443] Trial 712 finished with value: 0.0007054406276438385 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.17865187565729285, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17928298582824725, 'learning_rate': 0.0068574401506774855, 'weight_decay': 4.857582742973895e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:02:36,818] Trial 713 finished with value: 0.002333432310842909 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.19357769637351713, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19280294383073476, 'learning_rate': 0.007327660687660096, 'weight_decay': 6.274296672584309e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:03:37,908] Trial 714 finished with value: 0.0021675302792573347 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26938054927804467, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17098715047975396, 'learning_rate': 0.008770414516016425, 'weight_decay': 4.051374466864327e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:04:41,310] Trial 715 finished with value: 0.005955392029136419 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19115167073493539, 'decoder_layers': 9, 'decoder_nodes': 64, 'decoder_dropout': 0.18446165910805826, 'learning_rate': 0.007159054569881292, 'weight_decay': 8.030879127823025e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:05:53,702] Trial 716 finished with value: 0.001092887828417588 and parameters: {'hidden_size': 224, 'num_layers': 2, 'extractor_dropout': 0.24458601446081518, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.19943479321015906, 'learning_rate': 0.009184486740953101, 'weight_decay': 7.091101951674958e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:07:13,900] Trial 717 finished with value: 0.002349129441427067 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2530046436323803, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.3964664397738129, 'learning_rate': 0.006126774024864125, 'weight_decay': 5.760223861690955e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:08:25,797] Trial 718 finished with value: 0.005790578728192486 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2001088271610742, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19010569755111262, 'learning_rate': 0.012333271229682308, 'weight_decay': 8.452898724171248e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:10:07,371] Trial 719 finished with value: 0.00019337467092555015 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23866046429541452, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17654025465746706, 'learning_rate': 0.0053861499458395905, 'weight_decay': 5.169776626312626e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:11:18,974] Trial 720 finished with value: 0.029943863954395057 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2332946959608133, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.20315478833510714, 'learning_rate': 0.007281181886042234, 'weight_decay': 4.409146795676168e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:12:38,925] Trial 721 finished with value: 0.002978245550184511 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2596289464587707, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14418120118530645, 'learning_rate': 0.006136167503171923, 'weight_decay': 6.504208643795691e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:13:57,626] Trial 722 finished with value: 0.000202041570446454 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24813127681897845, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1979085329862349, 'learning_rate': 0.004918156981162239, 'weight_decay': 7.342951685785786e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:15:37,156] Trial 723 finished with value: 0.00023819945636205375 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2276628582559574, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1898688837934393, 'learning_rate': 0.0041464866187261385, 'weight_decay': 6.094560736577606e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:17:05,642] Trial 724 finished with value: 0.00022510154085466638 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.41098325289244253, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20616487653320886, 'learning_rate': 0.00448828885824806, 'weight_decay': 8.260401571670135e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:18:19,301] Trial 725 finished with value: 0.0023394663381623103 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.1663575002921419, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15509297219129578, 'learning_rate': 0.007585975887973134, 'weight_decay': 4.99570403535433e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:19:40,280] Trial 726 finished with value: 0.00021850280900252982 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20553012382119715, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17823049342252484, 'learning_rate': 0.00550735045341899, 'weight_decay': 7.204979779593414e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:21:09,831] Trial 727 finished with value: 0.0001832366586313583 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23758924463856726, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1696980488560906, 'learning_rate': 0.0038209316498860665, 'weight_decay': 5.970922286869816e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:22:39,492] Trial 728 finished with value: 0.00021646289533236996 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2393385425598586, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1611248182331825, 'learning_rate': 0.004847473783663098, 'weight_decay': 5.350262219888444e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:24:10,958] Trial 729 finished with value: 0.00020251579699106514 and parameters: {'hidden_size': 144, 'num_layers': 1, 'extractor_dropout': 0.2486971882352353, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16908953372679644, 'learning_rate': 0.004068131281908, 'weight_decay': 3.7375079931135434e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:25:39,813] Trial 730 finished with value: 0.0005630230909446255 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2416810879031289, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.1660388907617507, 'learning_rate': 0.006327771092802142, 'weight_decay': 4.495898079348961e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:26:43,134] Trial 731 finished with value: 0.0024443614296615125 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2636415662975569, 'decoder_layers': 6, 'decoder_nodes': 64, 'decoder_dropout': 0.1561769513972364, 'learning_rate': 0.0036745583272998917, 'weight_decay': 6.017430735764337e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:28:24,327] Trial 732 finished with value: 0.00021182953787501901 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2553240652598874, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17360520150204853, 'learning_rate': 0.005252963653993147, 'weight_decay': 3.1283814917113525e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:30:05,637] Trial 733 finished with value: 0.0001919756949064322 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2353195944643623, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18095094985237012, 'learning_rate': 0.004266194370929653, 'weight_decay': 5.554125403713128e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:31:26,967] Trial 734 finished with value: 0.0015540088221314362 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2485029989572412, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14926685823417754, 'learning_rate': 0.004674574511993672, 'weight_decay': 6.30414713080949e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:32:57,355] Trial 735 finished with value: 0.00043385830213082954 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2357295798004879, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.1716596531174681, 'learning_rate': 0.005843888949212388, 'weight_decay': 4.428358065036827e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:34:04,690] Trial 736 finished with value: 0.002387265551078599 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24416334826026778, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.18493721462510582, 'learning_rate': 0.009648050908087787, 'weight_decay': 5.202208325587707e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:35:11,195] Trial 737 finished with value: 0.007376541638222989 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23177869741773244, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1613780875378553, 'learning_rate': 0.008051005275377375, 'weight_decay': 6.381217743072878e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:36:25,211] Trial 738 finished with value: 0.0015246800059685484 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.25494890984940555, 'decoder_layers': 4, 'decoder_nodes': 48, 'decoder_dropout': 0.19388343266584565, 'learning_rate': 0.0038606495299666646, 'weight_decay': 6.972119400333534e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:37:38,816] Trial 739 finished with value: 0.0006494157918496057 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22665661403161147, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17679869223124167, 'learning_rate': 0.0036138397542777845, 'weight_decay': 5.559263798951859e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:38:29,221] Trial 740 finished with value: 0.0033159981947392227 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27002680628121006, 'decoder_layers': 8, 'decoder_nodes': 64, 'decoder_dropout': 0.18329666250313767, 'learning_rate': 0.004964178044695162, 'weight_decay': 1.0950616110359124e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:40:09,324] Trial 741 finished with value: 0.0002012186247156933 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2401218428584601, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.168922777654058, 'learning_rate': 0.004302502765629051, 'weight_decay': 4.692436830263182e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:41:40,342] Trial 742 finished with value: 0.00022257998207351193 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.17499825117353185, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.10769919199853845, 'learning_rate': 0.0056270111454442785, 'weight_decay': 6.869850157409701e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:43:13,173] Trial 743 finished with value: 0.0003083887102548033 and parameters: {'hidden_size': 128, 'num_layers': 1, 'extractor_dropout': 0.2484573172446233, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.19044211177053516, 'learning_rate': 0.003448318314872953, 'weight_decay': 1.6877064540170693e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:44:53,245] Trial 744 finished with value: 0.00022399537701858207 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2610994065937004, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19619546793980572, 'learning_rate': 0.004074919581209515, 'weight_decay': 5.865351399104443e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:45:47,726] Trial 745 finished with value: 0.0023823804833227767 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23290090796341956, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.2031029938382102, 'learning_rate': 0.004507682118107631, 'weight_decay': 4.054682874750138e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:47:27,672] Trial 746 finished with value: 0.00018480132275726645 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22600323243139106, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18503992145219356, 'learning_rate': 0.005124334076288106, 'weight_decay': 7.760679111499068e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:48:33,323] Trial 747 finished with value: 0.001726231595966965 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.22354149162296422, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17893336705390878, 'learning_rate': 0.005288542964950631, 'weight_decay': 8.418649556768947e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:49:19,994] Trial 748 finished with value: 0.007759677880676464 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22202796571295147, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.32450056653410453, 'learning_rate': 0.007029123609448137, 'weight_decay': 7.868525520048967e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:50:28,740] Trial 749 finished with value: 0.0018000694690272212 and parameters: {'hidden_size': 256, 'num_layers': 3, 'extractor_dropout': 0.18689339604054747, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16445257185223913, 'learning_rate': 0.006400369425750829, 'weight_decay': 4.928992845916053e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:51:52,103] Trial 750 finished with value: 0.001033865696808789 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.194267252648141, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17391839801931655, 'learning_rate': 0.0061054755576961965, 'weight_decay': 7.604904903495886e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:53:19,029] Trial 751 finished with value: 0.009139758568198885 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2105750227591006, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1864079422758846, 'learning_rate': 0.004985060426847104, 'weight_decay': 2.7355633547111256e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:54:39,708] Trial 752 finished with value: 0.0015828070623683742 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22214086076532108, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18413147146409423, 'learning_rate': 0.005537424494061522, 'weight_decay': 2.033322219741147e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:56:14,332] Trial 753 finished with value: 0.0029948784969747065 and parameters: {'hidden_size': 256, 'num_layers': 9, 'extractor_dropout': 0.24059763255073788, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1705328515044208, 'learning_rate': 0.00796270927066017, 'weight_decay': 6.162407493237699e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:57:48,740] Trial 754 finished with value: 0.00022648976155323908 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22951107659707426, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15244328652948155, 'learning_rate': 0.0048119508992693835, 'weight_decay': 9.176482765435902e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:58:32,244] Trial 755 finished with value: 0.0037438649364048616 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2522164946731767, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17910306777994592, 'learning_rate': 0.006424268570384668, 'weight_decay': 0.0002692746125418764}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 07:59:19,529] Trial 756 finished with value: 0.00023680716258240865 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2042942906294851, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1891551946883162, 'learning_rate': 0.005418077517738996, 'weight_decay': 0.00014717538275049947}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:00:41,475] Trial 757 finished with value: 0.00020628748170565815 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21736972399193613, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1932426121207657, 'learning_rate': 0.004531271799802255, 'weight_decay': 5.227107014137282e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:02:16,847] Trial 758 finished with value: 0.00017907743458636105 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24361824949889185, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1631669345348846, 'learning_rate': 0.004110288350028274, 'weight_decay': 7.246065269220525e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:03:01,646] Trial 759 finished with value: 0.00026318984746467324 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22995226493828178, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.1423923133482006, 'learning_rate': 0.003931961876643742, 'weight_decay': 0.000731246899930326}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:04:32,726] Trial 760 finished with value: 0.0001831050030887127 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2412390235680446, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16166397928727208, 'learning_rate': 0.003914192017124429, 'weight_decay': 8.824333656985245e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:06:06,324] Trial 761 finished with value: 0.00020217929413774983 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2364236315764597, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.16109036615914057, 'learning_rate': 0.004169228364463643, 'weight_decay': 7.86902323267076e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:07:24,816] Trial 762 finished with value: 0.004111737964558415 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22742719532815706, 'decoder_layers': 1, 'decoder_nodes': 192, 'decoder_dropout': 0.16425702486060395, 'learning_rate': 0.004484059605241162, 'weight_decay': 7.290334052943557e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:08:37,242] Trial 763 finished with value: 0.0012204027269035577 and parameters: {'hidden_size': 48, 'num_layers': 1, 'extractor_dropout': 0.23863160114270676, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14644861678109056, 'learning_rate': 0.003882653550800614, 'weight_decay': 8.753825717652164e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:10:05,855] Trial 764 finished with value: 0.0023289661810849795 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22178663890583597, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.12823683822942253, 'learning_rate': 0.004780691232622192, 'weight_decay': 3.5977583123329755e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:11:37,727] Trial 765 finished with value: 0.001170104229822755 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23157612560505905, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15099745691394822, 'learning_rate': 0.003530950425142917, 'weight_decay': 5.815100026036328e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:12:57,991] Trial 766 finished with value: 0.0008498827926814556 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21314629499092608, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13647061266941526, 'learning_rate': 0.004007686630922258, 'weight_decay': 6.785527622610246e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:14:32,073] Trial 767 finished with value: 0.0011683275079121813 and parameters: {'hidden_size': 176, 'num_layers': 1, 'extractor_dropout': 0.24216286850607957, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15416255471285328, 'learning_rate': 0.004452763026773291, 'weight_decay': 7.763239233903436e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:16:05,126] Trial 768 finished with value: 0.00017928664019564166 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22526554142709235, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15856412255429653, 'learning_rate': 0.00495498904845808, 'weight_decay': 6.2437947031927985e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:17:37,402] Trial 769 finished with value: 0.000198355782777071 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21874424611540824, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15784774144650449, 'learning_rate': 0.003455914364630314, 'weight_decay': 4.507861618986835e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:18:44,649] Trial 770 finished with value: 0.00023928778246045112 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.1974802318405227, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.15072316797409074, 'learning_rate': 0.005310068121617268, 'weight_decay': 8.646137317700086e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:20:06,473] Trial 771 finished with value: 0.0015478868983336725 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.15504853256329698, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.4122877533103884, 'learning_rate': 0.004250435080911298, 'weight_decay': 5.39264620862266e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:21:20,505] Trial 772 finished with value: 0.003302954958053306 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21069553172888947, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16233732263612, 'learning_rate': 0.004992289108838959, 'weight_decay': 7.008719879909306e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:22:52,263] Trial 773 finished with value: 0.00018130042735720053 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24304844899582764, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15691328207823668, 'learning_rate': 0.0037569196297306583, 'weight_decay': 6.342352277910871e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:24:31,998] Trial 774 finished with value: 0.00017958679381990805 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24257070645267295, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14473420130042972, 'learning_rate': 0.003378872372275808, 'weight_decay': 4.904302185404868e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:26:10,017] Trial 775 finished with value: 0.0002562495617894456 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2450774293628894, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13601740677737162, 'learning_rate': 0.0032501884087317305, 'weight_decay': 3.786784665384515e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:27:39,919] Trial 776 finished with value: 0.00021150266693439334 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24535022589682356, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13965157313889218, 'learning_rate': 0.0027223893629936134, 'weight_decay': 4.648654150225272e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:29:25,868] Trial 777 finished with value: 0.00018711905868258328 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24660408530804695, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14265453348527754, 'learning_rate': 0.0028799260488242035, 'weight_decay': 4.239144489838746e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:30:29,659] Trial 778 finished with value: 0.003485506819561124 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.2593897721722655, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1518773939254745, 'learning_rate': 0.0034066463845284873, 'weight_decay': 4.946424096304816e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:32:05,677] Trial 779 finished with value: 0.0029342523775994778 and parameters: {'hidden_size': 208, 'num_layers': 8, 'extractor_dropout': 0.2385729533264545, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13114129680285308, 'learning_rate': 0.002943129547621162, 'weight_decay': 3.993640508063366e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:33:28,100] Trial 780 finished with value: 0.00026248575595673175 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2537435463571497, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14513286943438594, 'learning_rate': 0.00344013720127596, 'weight_decay': 1.431150178064612e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:35:15,737] Trial 781 finished with value: 0.00032389234111178665 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23890659194455563, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15028986132262395, 'learning_rate': 0.0003223771396717275, 'weight_decay': 5.179705083987013e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:36:49,215] Trial 782 finished with value: 0.00019179589580744504 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24716626656316498, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14867682246964778, 'learning_rate': 0.003708897552203172, 'weight_decay': 5.449321159917612e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:38:07,853] Trial 783 finished with value: 0.0007139300694689154 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23899894142450026, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.12188265788064806, 'learning_rate': 0.003067858980060199, 'weight_decay': 4.551561051654229e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:38:39,359] Trial 784 finished with value: 0.00836028577759862 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2560012484724874, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16178690421514075, 'learning_rate': 0.025412866276849865, 'weight_decay': 6.007998479237016e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:40:09,424] Trial 785 finished with value: 0.0002210638645919971 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24818306088949563, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15685130001043227, 'learning_rate': 0.003779150408103795, 'weight_decay': 5.585887281827967e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:41:47,855] Trial 786 finished with value: 0.00019048008980462327 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23480432535078777, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13790067654799407, 'learning_rate': 0.0024442606750953804, 'weight_decay': 3.280369652183384e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:43:23,961] Trial 787 finished with value: 0.0001851862674811855 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24502315157598142, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15880349118611595, 'learning_rate': 0.0033407006936288348, 'weight_decay': 4.855915285167145e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:44:57,311] Trial 788 finished with value: 0.00019073268340434878 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.26277927386601685, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14039320136649674, 'learning_rate': 0.0038535699869697857, 'weight_decay': 6.305869051189812e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:46:30,993] Trial 789 finished with value: 0.002574635905330069 and parameters: {'hidden_size': 256, 'num_layers': 6, 'extractor_dropout': 0.177314032086499, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.15526340791940949, 'learning_rate': 0.002662407253453381, 'weight_decay': 4.130421837531564e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:47:38,090] Trial 790 finished with value: 0.023006554525636602 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2395982080509696, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13381873768987573, 'learning_rate': 0.00399150134282785, 'weight_decay': 5.921116275433301e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:49:16,830] Trial 791 finished with value: 0.00018488702917238698 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2547192956420677, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15346296641125692, 'learning_rate': 0.0030802289319007813, 'weight_decay': 5.132539856700757e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:50:59,612] Trial 792 finished with value: 0.00018624509539222345 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18461133037766692, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1642850054694972, 'learning_rate': 0.003661169643523664, 'weight_decay': 6.477075367097957e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:52:25,339] Trial 793 finished with value: 0.0029805899423081426 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23373015800423533, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1540790857765418, 'learning_rate': 0.004175808770685185, 'weight_decay': 5.48609539703696e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:54:05,672] Trial 794 finished with value: 0.00019261848356109113 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24522522136221736, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14296732282310368, 'learning_rate': 0.0032187056084227285, 'weight_decay': 4.750817371040529e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:55:10,311] Trial 795 finished with value: 0.0039186799331218936 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23642702679027777, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14608723109614402, 'learning_rate': 0.0035426952719523966, 'weight_decay': 6.742314148500009e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:56:23,744] Trial 796 finished with value: 0.0006648653215961531 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2517601353664418, 'decoder_layers': 3, 'decoder_nodes': 80, 'decoder_dropout': 0.16200057336849683, 'learning_rate': 0.0043094191339132695, 'weight_decay': 5.808422182969913e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:58:07,178] Trial 797 finished with value: 0.00018485018517822027 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2304256134763806, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.164028238999609, 'learning_rate': 0.003932564382819394, 'weight_decay': 3.673521154546933e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 08:59:38,905] Trial 798 finished with value: 0.00023981507983990015 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24294860960036943, 'decoder_layers': 4, 'decoder_nodes': 80, 'decoder_dropout': 0.15779423794640418, 'learning_rate': 0.0031313296857238266, 'weight_decay': 6.695201744245596e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:01:18,939] Trial 799 finished with value: 0.00019787350174738094 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27029080081781653, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.12621311891565318, 'learning_rate': 0.0026685560819078927, 'weight_decay': 4.246052688234195e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:02:32,353] Trial 800 finished with value: 0.022741341398796067 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.26219379634358103, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14459441892267147, 'learning_rate': 0.0002026696393164138, 'weight_decay': 5.185641360222478e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:03:51,983] Trial 801 finished with value: 0.001171348086791113 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2338250813848651, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1691601708349477, 'learning_rate': 0.003578876060383958, 'weight_decay': 6.043445595144635e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:04:44,628] Trial 802 finished with value: 0.0028747366392053663 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24878693580807026, 'decoder_layers': 5, 'decoder_nodes': 16, 'decoder_dropout': 0.1536887594236428, 'learning_rate': 0.004245935505708531, 'weight_decay': 6.554084500670488e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:06:23,834] Trial 803 finished with value: 0.00019269342883490025 and parameters: {'hidden_size': 112, 'num_layers': 1, 'extractor_dropout': 0.23906889103047974, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15956352599419205, 'learning_rate': 0.004692497966098586, 'weight_decay': 4.730238318072211e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:07:56,901] Trial 804 finished with value: 0.0002135507616912946 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22744393336571245, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1472700259568104, 'learning_rate': 0.0029937631444686423, 'weight_decay': 7.137262296953256e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:09:17,966] Trial 805 finished with value: 0.0007645775622222573 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1902450410968227, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.16897149798696248, 'learning_rate': 0.003908753256559221, 'weight_decay': 5.583331992388792e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:10:38,872] Trial 806 finished with value: 0.0012834611115977168 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2546036240392791, 'decoder_layers': 1, 'decoder_nodes': 160, 'decoder_dropout': 0.13777708819201645, 'learning_rate': 0.0001193115714086138, 'weight_decay': 7.4559938758843e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:12:15,675] Trial 807 finished with value: 0.00021323263354133815 and parameters: {'hidden_size': 64, 'num_layers': 1, 'extractor_dropout': 0.24377300904788535, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16678420852461853, 'learning_rate': 0.0035180353086891264, 'weight_decay': 6.022789532493059e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:13:50,000] Trial 808 finished with value: 0.0011587028813664802 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2316473983726137, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.132494238300335, 'learning_rate': 0.004467169896347072, 'weight_decay': 4.148655892221119e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:15:18,608] Trial 809 finished with value: 0.00021919763821642846 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24067516156529425, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15655549892468618, 'learning_rate': 0.005827401297616391, 'weight_decay': 4.996196698042204e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:16:36,486] Trial 810 finished with value: 0.0015491841579205357 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22514139893614324, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1707846485341111, 'learning_rate': 0.004995020517842383, 'weight_decay': 6.947429590478282e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:18:22,745] Trial 811 finished with value: 0.0002027980357524939 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25941607496674396, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16687834403854407, 'learning_rate': 0.002854092508522556, 'weight_decay': 5.761685329973238e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:19:55,394] Trial 812 finished with value: 0.0001878106952062808 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19947710062290983, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1701727150925045, 'learning_rate': 0.004030802746712468, 'weight_decay': 7.510159093306165e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:21:01,629] Trial 813 finished with value: 0.00033242068602703514 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.2464222900292268, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.12312460325865682, 'learning_rate': 0.0034327558160128346, 'weight_decay': 4.550918211914459e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:22:31,173] Trial 814 finished with value: 0.000659592598094605 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23117354365791745, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15321964429396676, 'learning_rate': 0.004603552966560702, 'weight_decay': 6.467691894772775e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:24:00,878] Trial 815 finished with value: 0.00018334265187149867 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2213779533296354, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1450216354564068, 'learning_rate': 0.002415772334041925, 'weight_decay': 5.203382655037933e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:25:37,637] Trial 816 finished with value: 0.0001909960396005772 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21060988724178875, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14220348828130577, 'learning_rate': 0.002597073621439855, 'weight_decay': 4.665512075970425e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:27:08,755] Trial 817 finished with value: 0.00022491842973977328 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22021117631941148, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13726268477166417, 'learning_rate': 0.002483371107909567, 'weight_decay': 3.6062815803988193e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:28:32,421] Trial 818 finished with value: 0.0005740120497648605 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20428938135374097, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.11621043087874688, 'learning_rate': 0.005937864399737312, 'weight_decay': 4.177613542610123e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:29:58,526] Trial 819 finished with value: 0.00020027972204843535 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21805453470523192, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1415443076871581, 'learning_rate': 0.002273950217791022, 'weight_decay': 5.36803024771638e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:30:42,395] Trial 820 finished with value: 0.004672593623399735 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.2088479122743567, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15267491946417225, 'learning_rate': 0.012697478289338895, 'weight_decay': 5.097661306183488e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:31:56,573] Trial 821 finished with value: 0.0023059924889821557 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2232941342599889, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14756949122664317, 'learning_rate': 0.0049498659563684995, 'weight_decay': 5.419343365929116e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:33:13,559] Trial 822 finished with value: 0.005258829302329104 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18519976524385837, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14739757624734254, 'learning_rate': 0.006922415236167715, 'weight_decay': 3.1142485606250304e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:34:13,540] Trial 823 finished with value: 0.02816492977872258 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22184722289952882, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1294000285816495, 'learning_rate': 0.004343380171798621, 'weight_decay': 4.066242708867917e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:35:33,383] Trial 824 finished with value: 0.014833117958914954 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19594338003797432, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15944681038439962, 'learning_rate': 0.005590626352890695, 'weight_decay': 5.998784316468109e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:36:17,016] Trial 825 finished with value: 0.006619618972763419 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21361564884591072, 'decoder_layers': 10, 'decoder_nodes': 80, 'decoder_dropout': 0.1333426235669354, 'learning_rate': 0.009859433239440924, 'weight_decay': 4.634226269726151e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:38:02,150] Trial 826 finished with value: 0.010383236419875175 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2313351641077817, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16053599449405218, 'learning_rate': 0.00396637384744969, 'weight_decay': 5.2785843139300234e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:39:32,394] Trial 827 finished with value: 0.0011628004023805261 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.22780290224882224, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1454529190166911, 'learning_rate': 0.005003829272357799, 'weight_decay': 6.198034977614354e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:41:05,303] Trial 828 finished with value: 0.00019400892924750223 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22143471284402008, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16150112785871681, 'learning_rate': 0.0023195827767526775, 'weight_decay': 3.705827364596587e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:42:52,108] Trial 829 finished with value: 0.0002026784568442963 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20231511645097033, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16737824484102562, 'learning_rate': 0.0036081883462908957, 'weight_decay': 4.740216558815246e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:44:07,075] Trial 830 finished with value: 0.0002312713593710214 and parameters: {'hidden_size': 80, 'num_layers': 1, 'extractor_dropout': 0.23357907395748873, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14808542489833304, 'learning_rate': 0.006065869249798792, 'weight_decay': 5.800648060981702e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:45:30,195] Trial 831 finished with value: 0.009793982456903905 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.17241755320156552, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.1555643134619584, 'learning_rate': 0.004406573653716927, 'weight_decay': 6.772230593890641e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:47:07,642] Trial 832 finished with value: 0.00018572960107121617 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21589033005724154, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1325541675644019, 'learning_rate': 0.0028782672881565684, 'weight_decay': 5.257373821580312e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:48:04,705] Trial 833 finished with value: 0.0025757469586096702 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20654287973538188, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.4653585900488738, 'learning_rate': 0.003335200722339643, 'weight_decay': 8.306388603776797e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:49:12,491] Trial 834 finished with value: 0.0009922676472342573 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23768629395908583, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.12585025917242848, 'learning_rate': 0.007951262417172941, 'weight_decay': 6.244548088393542e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:50:43,745] Trial 835 finished with value: 0.00020632819650927557 and parameters: {'hidden_size': 96, 'num_layers': 1, 'extractor_dropout': 0.2254773246916206, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16999173648778781, 'learning_rate': 0.0038436572655050597, 'weight_decay': 4.454294124894076e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:51:39,619] Trial 836 finished with value: 0.00501569164916873 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19154581335001714, 'decoder_layers': 6, 'decoder_nodes': 80, 'decoder_dropout': 0.16546054739411634, 'learning_rate': 0.005214592594689666, 'weight_decay': 7.122214083566887e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:53:03,466] Trial 837 finished with value: 0.00023083935084287078 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25051245972679875, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15389613587034034, 'learning_rate': 0.004282021917938823, 'weight_decay': 5.26586121835877e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:54:20,011] Trial 838 finished with value: 0.0023266428455826827 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23326684316625967, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14113835337234168, 'learning_rate': 0.004878389803529185, 'weight_decay': 9.205719838862521e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:56:03,901] Trial 839 finished with value: 0.00018721208180068062 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21160566435684788, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1576686649100941, 'learning_rate': 0.003502423467995323, 'weight_decay': 6.137177302143006e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:57:27,707] Trial 840 finished with value: 0.00019027064699912445 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24180509007782722, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17377657285741968, 'learning_rate': 0.006136970114818832, 'weight_decay': 7.683511797790967e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 09:58:59,578] Trial 841 finished with value: 0.0011636575756710954 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22766864001522996, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15008257701570218, 'learning_rate': 0.004126360263979725, 'weight_decay': 4.187880765537046e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:00:39,486] Trial 842 finished with value: 0.0002509870202629827 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2675656152906715, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17356699465513423, 'learning_rate': 0.0028628201500994228, 'weight_decay': 5.679043584349111e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:01:38,160] Trial 843 finished with value: 0.0019126495026284829 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21983655189678714, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1616224536428393, 'learning_rate': 0.005556290984361909, 'weight_decay': 3.492443529964096e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:02:51,586] Trial 844 finished with value: 0.0011909385793842375 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2562028944558651, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1342727943707761, 'learning_rate': 0.0067357065673034205, 'weight_decay': 4.956912080580201e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:04:26,675] Trial 845 finished with value: 0.00020000209624413401 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.18071791649872462, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16290554131059906, 'learning_rate': 0.003790806776617043, 'weight_decay': 6.5541856741578744e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:05:22,429] Trial 846 finished with value: 0.00333090634085238 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19795230400614663, 'decoder_layers': 9, 'decoder_nodes': 64, 'decoder_dropout': 0.17525147398400137, 'learning_rate': 0.004625241399724203, 'weight_decay': 8.115631037190981e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:06:59,268] Trial 847 finished with value: 0.00022134471219033004 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23851847095528847, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.16759155194599068, 'learning_rate': 0.0033056969348261023, 'weight_decay': 2.7094366168494793e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:08:49,289] Trial 848 finished with value: 0.0002386275416938588 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24954540782718698, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.14099829140829792, 'learning_rate': 0.0025005835179791177, 'weight_decay': 6.884680059039351e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:10:06,741] Trial 849 finished with value: 0.0023338896833593028 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.225420691691029, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15063893170641343, 'learning_rate': 0.005109060357806424, 'weight_decay': 5.67084409886882e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:11:30,148] Trial 850 finished with value: 0.0023240704962518067 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23437966365623972, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15766240781878624, 'learning_rate': 0.004389439477530394, 'weight_decay': 4.69497184205834e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:12:39,945] Trial 851 finished with value: 0.0018308716404135338 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2140618233087989, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.17136541229394042, 'learning_rate': 0.003919381523294068, 'weight_decay': 8.785247755755258e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:13:27,120] Trial 852 finished with value: 0.00022325949976220727 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24699406256400486, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14587025127286893, 'learning_rate': 0.003150862438630058, 'weight_decay': 0.00037539675949624135}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:14:23,567] Trial 853 finished with value: 0.0020299166266340763 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.20475578260645622, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17437026023351906, 'learning_rate': 0.005432316469850753, 'weight_decay': 7.297053836155029e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:15:48,225] Trial 854 finished with value: 0.0032981599739287048 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25813173805786166, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17623334123621764, 'learning_rate': 0.004653388757416454, 'weight_decay': 5.9735049952097585e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:16:55,669] Trial 855 finished with value: 0.0027968286536633967 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23426839727002888, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.38174443607693886, 'learning_rate': 0.003583806069294379, 'weight_decay': 3.967837407230105e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:18:13,576] Trial 856 finished with value: 0.0008811162289930508 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21900433375515727, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.12557764761475657, 'learning_rate': 0.00669528931834512, 'weight_decay': 5.122418679005271e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:19:39,321] Trial 857 finished with value: 0.002542800991795957 and parameters: {'hidden_size': 256, 'num_layers': 6, 'extractor_dropout': 0.24379640650164716, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15692848778334254, 'learning_rate': 0.0029087675807057097, 'weight_decay': 9.993416487856865e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:21:13,053] Trial 858 finished with value: 0.0023227068813866936 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.18961981485120896, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16530924203053057, 'learning_rate': 0.004056302441536898, 'weight_decay': 6.257714255860313e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:22:55,012] Trial 859 finished with value: 0.0003117898420896381 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22678665763565903, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.13894647700534604, 'learning_rate': 0.00039725807416016894, 'weight_decay': 7.2636471179763765e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:24:30,597] Trial 860 finished with value: 0.00019027356611331925 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23891214847202985, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.11507558797886622, 'learning_rate': 0.0046242440460623315, 'weight_decay': 8.316119271465435e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:25:28,809] Trial 861 finished with value: 0.0033262976910918953 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.20969868746227807, 'decoder_layers': 7, 'decoder_nodes': 80, 'decoder_dropout': 0.15037273808087243, 'learning_rate': 0.003303331111002457, 'weight_decay': 4.399400308864087e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:26:04,939] Trial 862 finished with value: 0.007284083729609847 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.25431483017058804, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.3051264504287713, 'learning_rate': 0.04013056943120243, 'weight_decay': 5.468477638898824e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:27:22,436] Trial 863 finished with value: 0.0004878547013504431 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2641454182239938, 'decoder_layers': 3, 'decoder_nodes': 64, 'decoder_dropout': 0.1643066512373685, 'learning_rate': 0.005359477601809501, 'weight_decay': 6.538676980782667e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:28:32,740] Trial 864 finished with value: 0.007379726090584881 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.27483128065583384, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17732485033643183, 'learning_rate': 0.014831330299068924, 'weight_decay': 4.897227062061931e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:29:31,298] Trial 865 finished with value: 0.005944572808220983 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2280796555062131, 'decoder_layers': 2, 'decoder_nodes': 176, 'decoder_dropout': 0.16844488779862887, 'learning_rate': 0.0038276468070755068, 'weight_decay': 7.854138974091087e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:30:08,029] Trial 866 finished with value: 0.02486229076894233 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1654025263864552, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.29400798377833803, 'learning_rate': 0.007908487719040312, 'weight_decay': 0.00018264711223669805}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:31:25,657] Trial 867 finished with value: 0.020889216288924217 and parameters: {'hidden_size': 256, 'num_layers': 8, 'extractor_dropout': 0.22148100308759167, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15787913168026832, 'learning_rate': 0.006093837442053488, 'weight_decay': 5.8287048055294805e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:33:04,641] Trial 868 finished with value: 0.0001998964697122574 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20057319775185603, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17728651542767176, 'learning_rate': 0.0023862663183530043, 'weight_decay': 9.392368519468507e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:34:00,807] Trial 869 finished with value: 0.03295470946468413 and parameters: {'hidden_size': 176, 'num_layers': 10, 'extractor_dropout': 0.24714385289994092, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.13330220170654064, 'learning_rate': 0.0002709359411391417, 'weight_decay': 6.792375771564576e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:34:55,424] Trial 870 finished with value: 0.004263544594869018 and parameters: {'hidden_size': 240, 'num_layers': 7, 'extractor_dropout': 0.23495350506943866, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1464762579286728, 'learning_rate': 0.004288860862243645, 'weight_decay': 0.00011804098361954367}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:36:21,773] Trial 871 finished with value: 0.0015975507514667698 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2133773475560713, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.16341846127708679, 'learning_rate': 0.0035186082929061164, 'weight_decay': 5.522213457781314e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:38:06,601] Trial 872 finished with value: 0.00021585673530353234 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2405621926030754, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.12022244278368428, 'learning_rate': 0.0027467525770465207, 'weight_decay': 4.440547420090088e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:39:30,909] Trial 873 finished with value: 0.0001912159816129133 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23027970303731238, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1737877507038423, 'learning_rate': 0.004999659708576061, 'weight_decay': 7.5378714140881085e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:40:51,132] Trial 874 finished with value: 0.0011813110002549365 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.45895470890537393, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1550633531318393, 'learning_rate': 0.004087157962992757, 'weight_decay': 6.585952650639338e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:42:11,004] Trial 875 finished with value: 0.0018197380879428238 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2545800078451317, 'decoder_layers': 5, 'decoder_nodes': 64, 'decoder_dropout': 0.13890818006100714, 'learning_rate': 0.0031588526382281754, 'weight_decay': 5.059247403929953e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:43:43,880] Trial 876 finished with value: 0.01997553672408685 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2225705159737667, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.17741695176353925, 'learning_rate': 0.005794787413090822, 'weight_decay': 3.6309663426507925e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:44:58,148] Trial 877 finished with value: 0.00019709715415956454 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24616848404052266, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1689454720206278, 'learning_rate': 0.004702060702496931, 'weight_decay': 8.63559790052428e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:46:31,576] Trial 878 finished with value: 0.0002864299589418806 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.23657881910819223, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18245487776921532, 'learning_rate': 0.003720341305786093, 'weight_decay': 6.049567799653674e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:48:16,915] Trial 879 finished with value: 0.00019261844427092 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19535925632073237, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14884932220184444, 'learning_rate': 0.0043352715433284394, 'weight_decay': 7.351333610006871e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:49:00,143] Trial 880 finished with value: 0.003839901811443269 and parameters: {'hidden_size': 256, 'num_layers': 5, 'extractor_dropout': 0.21135178143680383, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16061617753488117, 'learning_rate': 0.005273210302628285, 'weight_decay': 5.212513090707633e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:50:02,591] Trial 881 finished with value: 0.0036755307228304446 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2177758419107096, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21207407297643982, 'learning_rate': 0.006705901498704969, 'weight_decay': 6.3730800048275655e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:51:21,295] Trial 882 finished with value: 0.0007274086528923362 and parameters: {'hidden_size': 256, 'num_layers': 3, 'extractor_dropout': 0.22852407424520738, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21418101597373368, 'learning_rate': 0.002753965206279562, 'weight_decay': 4.061971065563851e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:52:54,004] Trial 883 finished with value: 0.0022933808373636565 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1833077993449848, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.18117275745313488, 'learning_rate': 0.0033010591576004165, 'weight_decay': 9.27540021295543e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:54:40,098] Trial 884 finished with value: 0.002297291469585616 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25232314306199105, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16738723562595692, 'learning_rate': 0.003869235645455875, 'weight_decay': 5.903295779724372e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:56:07,428] Trial 885 finished with value: 0.00021912547817919402 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2634076146630813, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15271159994484088, 'learning_rate': 0.004767784261477496, 'weight_decay': 4.669061710468534e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:57:31,026] Trial 886 finished with value: 0.00021323301189113408 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2410103716042856, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.17173574940134975, 'learning_rate': 0.005795574000449482, 'weight_decay': 7.706130495473057e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 10:58:54,701] Trial 887 finished with value: 0.0001970441691810265 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2049495202829439, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14361209749183412, 'learning_rate': 0.003600847461431867, 'weight_decay': 6.764473235991695e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:00:17,931] Trial 888 finished with value: 0.012068528216332197 and parameters: {'hidden_size': 240, 'num_layers': 9, 'extractor_dropout': 0.2322270331983612, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.12968554458939655, 'learning_rate': 0.004183041017777436, 'weight_decay': 5.490753739552383e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:01:53,677] Trial 889 finished with value: 0.0002445253310725093 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2485364493593464, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.2061016247556183, 'learning_rate': 0.003182295140876458, 'weight_decay': 1.0431003096490346e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:03:26,543] Trial 890 finished with value: 0.00018671630386961623 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.22435829751042058, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16183658383309957, 'learning_rate': 0.004939466165486522, 'weight_decay': 8.616870996848112e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:05:03,131] Trial 891 finished with value: 0.00020034188637509942 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2397163046952305, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1792694067121047, 'learning_rate': 0.0022813576915993545, 'weight_decay': 6.820389233737384e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:06:37,944] Trial 892 finished with value: 0.00021052735100965947 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2169444934522425, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.34123117476411335, 'learning_rate': 0.004287300199844062, 'weight_decay': 4.666762005015631e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:08:12,272] Trial 893 finished with value: 0.00020004206016892566 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23288824478019424, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.21563651233339032, 'learning_rate': 0.002918445026192795, 'weight_decay': 5.771957477535071e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:09:59,155] Trial 894 finished with value: 0.00019978484488092363 and parameters: {'hidden_size': 192, 'num_layers': 1, 'extractor_dropout': 0.2599405711539975, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19736932772506488, 'learning_rate': 0.0035923189245236006, 'weight_decay': 8.13309586535021e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:11:04,518] Trial 895 finished with value: 0.019430204258242156 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24515391426507221, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18629683627360913, 'learning_rate': 0.007423143652117907, 'weight_decay': 4.051547083994424e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:12:32,965] Trial 896 finished with value: 0.00020077800727449357 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2016780451822267, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15374924217798805, 'learning_rate': 0.005517100752905213, 'weight_decay': 3.2778832061857423e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:13:49,472] Trial 897 finished with value: 0.0002443738208967261 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2228332354533375, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.20825569389823526, 'learning_rate': 0.004541166463953277, 'weight_decay': 5.097460911192326e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:14:48,663] Trial 898 finished with value: 0.023323930185870267 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19159904578160902, 'decoder_layers': 1, 'decoder_nodes': 16, 'decoder_dropout': 0.22134173949935446, 'learning_rate': 0.0039410679461079, 'weight_decay': 6.385157809886476e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:15:26,692] Trial 899 finished with value: 0.028695680480450392 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1756136729714572, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17149815892826858, 'learning_rate': 0.0064671080681095805, 'weight_decay': 7.553996913952667e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:16:30,329] Trial 900 finished with value: 0.001256673052557744 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.252672472764498, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.13838711804909795, 'learning_rate': 0.0032793679388524654, 'weight_decay': 5.706088238675975e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:17:56,174] Trial 901 finished with value: 0.00023001576482784003 and parameters: {'hidden_size': 32, 'num_layers': 1, 'extractor_dropout': 0.2355585542452772, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.19911758648685884, 'learning_rate': 0.004969330123522957, 'weight_decay': 9.878522533252278e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:19:39,979] Trial 902 finished with value: 0.00025594134931452575 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21587529839559108, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15942303074581982, 'learning_rate': 0.0026273091701398046, 'weight_decay': 6.891874562061261e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:21:09,618] Trial 903 finished with value: 0.00020255124545656144 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24278014061965839, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1875844253597582, 'learning_rate': 0.0038162896473998395, 'weight_decay': 4.922940551300719e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:22:38,091] Trial 904 finished with value: 0.012459735918673687 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20744982211696275, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17899383448523215, 'learning_rate': 0.004442431689173095, 'weight_decay': 6.12380067668338e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:23:53,151] Trial 905 finished with value: 0.0021745436679339036 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.27094511434487184, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1472259030231758, 'learning_rate': 0.005698939398329161, 'weight_decay': 7.677563569830446e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:24:59,866] Trial 906 finished with value: 0.0027979638252872974 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22847246445657937, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20840468345031823, 'learning_rate': 0.008555107973283186, 'weight_decay': 4.35413007717099e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:26:31,584] Trial 907 finished with value: 0.00019275511294836178 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.25221084808325206, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1639906757177464, 'learning_rate': 0.003050324717105886, 'weight_decay': 5.42306723657468e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:27:49,482] Trial 908 finished with value: 0.003911753089050762 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22520719368754188, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.19673247615578543, 'learning_rate': 0.004975939921541225, 'weight_decay': 8.710697734645564e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:28:49,557] Trial 909 finished with value: 0.00026747984811663627 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.23928603400699602, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22057973058794136, 'learning_rate': 0.003511365273582874, 'weight_decay': 6.9734070529663e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:30:19,760] Trial 910 finished with value: 0.0011658911418635399 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23217677058450584, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.17306482612988505, 'learning_rate': 0.004081552985660417, 'weight_decay': 7.080337802108411e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:31:52,616] Trial 911 finished with value: 0.0002073359108180739 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21258910188379748, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.18708596473362726, 'learning_rate': 0.006079060482710526, 'weight_decay': 6.194678983643651e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:33:16,742] Trial 912 finished with value: 0.02300669895048486 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24558618986192893, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2127447669127353, 'learning_rate': 0.004565108276781791, 'weight_decay': 4.591070418726412e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:35:00,075] Trial 913 finished with value: 0.0001857471841503866 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2623444145675398, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15556536172762372, 'learning_rate': 0.0037271282939282595, 'weight_decay': 5.45548647118551e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:35:54,336] Trial 914 finished with value: 0.03927422580891289 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19559909259630204, 'decoder_layers': 2, 'decoder_nodes': 32, 'decoder_dropout': 0.20273840484410463, 'learning_rate': 0.005242115505166979, 'weight_decay': 6.835361331690371e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:37:32,085] Trial 915 finished with value: 0.00027704910316970197 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22058026094274327, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.12128867260178056, 'learning_rate': 0.0030117341806004693, 'weight_decay': 8.755263030896522e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:38:50,633] Trial 916 finished with value: 0.0023249682024470532 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23721710782812638, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16740959455441787, 'learning_rate': 0.004219510673444785, 'weight_decay': 7.690452083908917e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:39:44,830] Trial 917 finished with value: 0.0030263881038990804 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2050076631444222, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1413769717165465, 'learning_rate': 0.006901051158807237, 'weight_decay': 3.877031364881961e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:40:54,316] Trial 918 finished with value: 0.00020281299512134865 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18494992801288304, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17909411730483338, 'learning_rate': 0.0034113426547096094, 'weight_decay': 5.376735917205504e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:42:31,849] Trial 919 finished with value: 0.00022838053409941496 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24934442239488772, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.19251648341547564, 'learning_rate': 0.0024902463922018146, 'weight_decay': 6.153670138981377e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:43:55,430] Trial 920 finished with value: 0.00020605848694685847 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2268451577543833, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.2134620860836527, 'learning_rate': 0.004939875593929593, 'weight_decay': 4.995111994874658e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:45:10,744] Trial 921 finished with value: 0.013070175537723116 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2174574358929478, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15038913201303794, 'learning_rate': 0.004041744383226176, 'weight_decay': 9.775157612951316e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:46:45,088] Trial 922 finished with value: 0.00023292285040952266 and parameters: {'hidden_size': 160, 'num_layers': 1, 'extractor_dropout': 0.2422425137906297, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.12816170658405032, 'learning_rate': 0.005611948827329911, 'weight_decay': 5.70274256687515e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:47:56,373] Trial 923 finished with value: 0.006044096473488025 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.2551970803906241, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22381166424378693, 'learning_rate': 0.011109541375852528, 'weight_decay': 6.801042910256027e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:49:41,353] Trial 924 finished with value: 0.00022985460236668587 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2336156481810395, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.18300491152869133, 'learning_rate': 0.0034546974233401234, 'weight_decay': 7.866246862651608e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:51:09,145] Trial 925 finished with value: 0.00021652893628925084 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2238012071095536, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.4884803361149066, 'learning_rate': 0.004595349435712611, 'weight_decay': 4.983632544201049e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:52:50,749] Trial 926 finished with value: 0.00024106799537548795 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21244383951385812, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.16379152600503333, 'learning_rate': 0.0028379997666999296, 'weight_decay': 6.245457232958585e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:53:37,051] Trial 927 finished with value: 0.005093561415560543 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23241172291229292, 'decoder_layers': 1, 'decoder_nodes': 144, 'decoder_dropout': 0.20166953312786431, 'learning_rate': 0.003909399859296487, 'weight_decay': 4.053364251972296e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:55:02,195] Trial 928 finished with value: 0.000187058791925665 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24345666973267296, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.17399125160100032, 'learning_rate': 0.006040944137588233, 'weight_decay': 7.2174923277951655e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:56:15,291] Trial 929 finished with value: 0.004690977705467958 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2574661527225949, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.19010455232346551, 'learning_rate': 0.0043945536804903635, 'weight_decay': 5.508669175032184e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:57:29,125] Trial 930 finished with value: 0.0002263099973788485 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20035992584464057, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21922636486692995, 'learning_rate': 0.0032333348733532196, 'weight_decay': 8.701844747279262e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 11:58:49,204] Trial 931 finished with value: 0.0023327100672759114 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24751917593800396, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.15860241080604628, 'learning_rate': 0.005181229113400929, 'weight_decay': 4.464904547643003e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:00:26,369] Trial 932 finished with value: 0.0002074278221698478 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23721040742507254, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.13388104588616717, 'learning_rate': 0.002233565722424647, 'weight_decay': 1.0539926491965479e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:02:01,766] Trial 933 finished with value: 0.0006135815317975357 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2690107155556583, 'decoder_layers': 2, 'decoder_nodes': 48, 'decoder_dropout': 0.1984754118076842, 'learning_rate': 0.003683611868357066, 'weight_decay': 2.9656962911736875e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:02:49,588] Trial 934 finished with value: 0.00690796640701592 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22789306620557606, 'decoder_layers': 8, 'decoder_nodes': 224, 'decoder_dropout': 0.2066386604789911, 'learning_rate': 0.0044361252226920765, 'weight_decay': 6.274160556892323e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:03:56,910] Trial 935 finished with value: 0.002095993689727038 and parameters: {'hidden_size': 144, 'num_layers': 1, 'extractor_dropout': 0.21926387407974587, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.44901847382262583, 'learning_rate': 0.007746553864633496, 'weight_decay': 5.283969876120533e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:05:33,951] Trial 936 finished with value: 0.00020566006569424644 and parameters: {'hidden_size': 240, 'num_layers': 2, 'extractor_dropout': 0.20844798444318346, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.16741873710974925, 'learning_rate': 0.0027519614475794837, 'weight_decay': 7.815504531447037e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:06:39,261] Trial 937 finished with value: 0.022230078403663357 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2400937305609892, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.14756287808553809, 'learning_rate': 0.0038555745434504175, 'weight_decay': 6.7686954144442745e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:08:04,065] Trial 938 finished with value: 0.000492248531372752 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2503885856777152, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.18221681868253853, 'learning_rate': 0.005299333677018216, 'weight_decay': 3.463423315340398e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:08:46,858] Trial 939 finished with value: 0.004363828478381038 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2308722930079618, 'decoder_layers': 7, 'decoder_nodes': 80, 'decoder_dropout': 0.20924449643125137, 'learning_rate': 0.0033224757297078992, 'weight_decay': 5.734628120285001e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:10:27,370] Trial 940 finished with value: 0.00019792567618424073 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18783002713474303, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.189949472946874, 'learning_rate': 0.004695980222453421, 'weight_decay': 4.730949209561963e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:11:32,281] Trial 941 finished with value: 0.002575370568956714 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22113224636478465, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.22588342143383572, 'learning_rate': 0.006197949916756524, 'weight_decay': 8.177948859847605e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:12:34,687] Trial 942 finished with value: 0.013939468993339688 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.257388085239963, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1734134735925859, 'learning_rate': 0.003958158493295282, 'weight_decay': 6.871581414037062e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:14:13,608] Trial 943 finished with value: 0.00020989170880056918 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2786319890523945, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1957562795900796, 'learning_rate': 0.0030933049032165075, 'weight_decay': 9.340315580384e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:15:19,342] Trial 944 finished with value: 0.00528818404127378 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.19471183705213288, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15661428920550616, 'learning_rate': 0.0049951053626135725, 'weight_decay': 6.096895733477919e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:16:36,682] Trial 945 finished with value: 0.0025530793966026975 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.23634702818689055, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.1821914932012457, 'learning_rate': 0.006788651067336628, 'weight_decay': 5.125286190967218e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:18:12,717] Trial 946 finished with value: 0.00021463036828208714 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.21300584036362605, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21264676709473046, 'learning_rate': 0.0041505084082090905, 'weight_decay': 7.264056563385536e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:19:47,691] Trial 947 finished with value: 0.00023268711229320615 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24440080994745245, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.21764790616970772, 'learning_rate': 0.00347740140385211, 'weight_decay': 4.284870598088523e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:21:20,612] Trial 948 finished with value: 0.00024600365723017605 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.17832185336071832, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.35969883413677867, 'learning_rate': 0.00543372281026645, 'weight_decay': 6.171474549068844e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:22:51,076] Trial 949 finished with value: 0.0001768592046573758 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2271948568008967, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1413692501182891, 'learning_rate': 0.009698410542814978, 'weight_decay': 5.551195005373711e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:23:25,348] Trial 950 finished with value: 0.0059292148653184995 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.22168448353275705, 'decoder_layers': 2, 'decoder_nodes': 96, 'decoder_dropout': 0.1383155941503524, 'learning_rate': 0.011802020040700245, 'weight_decay': 3.997375896172989e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:23:57,110] Trial 951 finished with value: 0.0027466942090541126 and parameters: {'hidden_size': 256, 'num_layers': 3, 'extractor_dropout': 0.22661751216274567, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.12439818218357429, 'learning_rate': 0.009372994119204723, 'weight_decay': 4.959818605163705e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:25:15,678] Trial 952 finished with value: 0.005242834442469757 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.47669321419177557, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.130013318943286, 'learning_rate': 0.008260421546207099, 'weight_decay': 3.703469443945919e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:26:15,513] Trial 953 finished with value: 0.008360123820602893 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2131672468760675, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14229276392790668, 'learning_rate': 0.010175447952521535, 'weight_decay': 5.655748731801782e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:27:25,505] Trial 954 finished with value: 0.007374468208581675 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20673421903990755, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13379043302371577, 'learning_rate': 0.009732267797347177, 'weight_decay': 4.356671495820235e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:28:34,041] Trial 955 finished with value: 0.0028340999648207798 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21996059902282228, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.13685178152232305, 'learning_rate': 0.007874417519126846, 'weight_decay': 4.767351482424479e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:29:29,903] Trial 956 finished with value: 0.006769936914497521 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23052939783958246, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.14645918370742175, 'learning_rate': 0.011086286016372581, 'weight_decay': 5.468718612346127e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:30:25,632] Trial 957 finished with value: 0.006812954694032669 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22495443521684158, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.14930734284027425, 'learning_rate': 0.012327982424287199, 'weight_decay': 4.65448847767217e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:31:19,445] Trial 958 finished with value: 0.029577760305255652 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2023941321825864, 'decoder_layers': 4, 'decoder_nodes': 64, 'decoder_dropout': 0.4054838487835191, 'learning_rate': 0.009124567624493117, 'weight_decay': 5.414190020152786e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:32:42,902] Trial 959 finished with value: 0.0002045043249381706 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21387885904352652, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.10895650622804323, 'learning_rate': 0.00714299738155837, 'weight_decay': 7.4281231363822365e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:33:48,738] Trial 960 finished with value: 0.00624486040615011 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2303986659350522, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.14082399611466637, 'learning_rate': 0.010375134654318692, 'weight_decay': 6.757195135714217e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:34:47,338] Trial 961 finished with value: 0.0033310797036392613 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21864638623747135, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.12166681353695634, 'learning_rate': 0.014423290647820672, 'weight_decay': 5.925976363253386e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:35:43,500] Trial 962 finished with value: 0.0027785057493019847 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.44791453285920796, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.150173731521353, 'learning_rate': 0.01106840298976522, 'weight_decay': 8.879812391232086e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:36:39,597] Trial 963 finished with value: 0.005265738847083412 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2346937686615027, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15059906742429224, 'learning_rate': 0.009583770901581808, 'weight_decay': 5.234092699014961e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:37:38,111] Trial 964 finished with value: 0.004804619122296572 and parameters: {'hidden_size': 256, 'num_layers': 4, 'extractor_dropout': 0.22579555941648877, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.3322100547050519, 'learning_rate': 0.007695880782694487, 'weight_decay': 7.888239081491122e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:38:44,395] Trial 965 finished with value: 0.008357154577970505 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.20475750906210294, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.13627330125497406, 'learning_rate': 0.00863658313018064, 'weight_decay': 6.4272191058113155e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:40:20,513] Trial 966 finished with value: 0.00022521692008012906 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23714576351383126, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.15792158780076324, 'learning_rate': 0.0028787352406407546, 'weight_decay': 4.458833233802726e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:41:54,316] Trial 967 finished with value: 0.00021749541483586654 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.2150046064590208, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15518843694530926, 'learning_rate': 0.0022873965585556194, 'weight_decay': 1.0346404567506953e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:43:36,303] Trial 968 finished with value: 0.00023866881674621253 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.1939737604389335, 'decoder_layers': 3, 'decoder_nodes': 80, 'decoder_dropout': 0.1413284909650494, 'learning_rate': 0.002550950689594317, 'weight_decay': 5.873300627249582e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:45:05,393] Trial 969 finished with value: 0.00020527233136817812 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.22630118306291183, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.12730740211253014, 'learning_rate': 0.0030997926088111257, 'weight_decay': 3.649896736915272e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:46:05,523] Trial 970 finished with value: 0.006255017127841711 and parameters: {'hidden_size': 256, 'num_layers': 7, 'extractor_dropout': 0.1700612314290692, 'decoder_layers': 1, 'decoder_nodes': 160, 'decoder_dropout': 0.2258924118999323, 'learning_rate': 0.0036085283859847977, 'weight_decay': 7.1908634185963215e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:47:27,146] Trial 971 finished with value: 0.00023450946609955282 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23172398866010818, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.16029941715533805, 'learning_rate': 0.00611351804967073, 'weight_decay': 4.97671843132191e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:48:19,992] Trial 972 finished with value: 0.04521574694517767 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21865072403649186, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.1413127381768278, 'learning_rate': 0.008602935474932618, 'weight_decay': 8.277023046205934e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:49:50,613] Trial 973 finished with value: 0.0017743271906510926 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.208143621907974, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21941028183181996, 'learning_rate': 0.006860046862229941, 'weight_decay': 6.5627383841035415e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:51:35,755] Trial 974 finished with value: 0.0001843008940340951 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24027338381756175, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.1636349694522885, 'learning_rate': 0.004052321264721286, 'weight_decay': 4.100409164277854e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:52:45,630] Trial 975 finished with value: 0.0011882636026712134 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2239785989270346, 'decoder_layers': 2, 'decoder_nodes': 64, 'decoder_dropout': 0.14737600812254975, 'learning_rate': 0.0046806637489006705, 'weight_decay': 5.529539380582169e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:53:39,881] Trial 976 finished with value: 0.007384558548801578 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23441748756506536, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20662837048264732, 'learning_rate': 0.013760265900403197, 'weight_decay': 2.2623969493198417e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:55:22,522] Trial 977 finished with value: 0.00024607437808299437 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.23971531471105748, 'decoder_layers': 1, 'decoder_nodes': 32, 'decoder_dropout': 0.11607189619219194, 'learning_rate': 0.0033382642208435215, 'weight_decay': 9.555343460446923e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:56:21,893] Trial 978 finished with value: 0.0022413686063373463 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.19828027281201863, 'decoder_layers': 1, 'decoder_nodes': 96, 'decoder_dropout': 0.1330661956121438, 'learning_rate': 0.005834103888161622, 'weight_decay': 6.0656017004025785e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:57:56,213] Trial 979 finished with value: 0.00021376865624915807 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.2174074320612567, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.215981417590866, 'learning_rate': 0.003770751803392696, 'weight_decay': 4.7993807211806814e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 12:59:30,535] Trial 980 finished with value: 0.0001934809668455273 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2294864026772293, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.15324881975649554, 'learning_rate': 0.002947166111620326, 'weight_decay': 7.341352602198981e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:00:35,520] Trial 981 finished with value: 0.003643817601550836 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.18905745226772944, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.22664600763304887, 'learning_rate': 0.004915371385941573, 'weight_decay': 3.1654098652519062e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:02:03,357] Trial 982 finished with value: 0.0001873358094599098 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.20781608713269942, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.16532692848336505, 'learning_rate': 0.0026464870206471666, 'weight_decay': 8.26224767651684e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:03:26,046] Trial 983 finished with value: 0.0016012757871067152 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.24404941134416902, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.20898239615761194, 'learning_rate': 0.004243178343132218, 'weight_decay': 5.372252733425932e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:04:40,117] Trial 984 finished with value: 0.00043905973725486545 and parameters: {'hidden_size': 256, 'num_layers': 2, 'extractor_dropout': 0.22500332363705663, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.14459749930090404, 'learning_rate': 0.005457681834521022, 'weight_decay': 6.4286835604064975e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:06:24,200] Trial 985 finished with value: 0.00019544566748663783 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.2325423111595048, 'decoder_layers': 1, 'decoder_nodes': 80, 'decoder_dropout': 0.20383470359705194, 'learning_rate': 0.003477877717936055, 'weight_decay': 4.330533125142823e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:07:43,336] Trial 986 finished with value: 0.005442624181159772 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.24667441891739667, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.15563859243256264, 'learning_rate': 0.00653248917335523, 'weight_decay': 1.2599918529613003e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:09:08,510] Trial 987 finished with value: 0.0011861311737447976 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.21886643753033241, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.1724819990119845, 'learning_rate': 0.004378363236578962, 'weight_decay': 7.168743888524355e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:10:31,508] Trial 988 finished with value: 0.00021294520556693896 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.1816975440988457, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.21424710652358714, 'learning_rate': 0.0037408138570117168, 'weight_decay': 5.918457503260855e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:12:16,216] Trial 989 finished with value: 0.0001904387623653747 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.23816112605285905, 'decoder_layers': 1, 'decoder_nodes': 48, 'decoder_dropout': 0.222263536519598, 'learning_rate': 0.005011420956006121, 'weight_decay': 4.9445114645565895e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:13:55,623] Trial 990 finished with value: 0.00018512014648877084 and parameters: {'hidden_size': 240, 'num_layers': 1, 'extractor_dropout': 0.22928412650097307, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.1625090612615025, 'learning_rate': 0.0030444592830505615, 'weight_decay': 9.000259527193952e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:14:37,293] Trial 991 finished with value: 0.00836481861770153 and parameters: {'hidden_size': 256, 'num_layers': 1, 'extractor_dropout': 0.21010225430878035, 'decoder_layers': 2, 'decoder_nodes': 80, 'decoder_dropout': 0.1955652687022152, 'learning_rate': 0.016249437786356156, 'weight_decay': 6.812757068853501e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:16:15,799] Trial 992 finished with value: 0.00017930158210219816 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2516276357832009, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.13182315380558832, 'learning_rate': 0.0041547130037703495, 'weight_decay': 5.554396541783695e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:17:54,463] Trial 993 finished with value: 0.00017875331395771353 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2599461269212159, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.10601281249535831, 'learning_rate': 0.0034731392377055723, 'weight_decay': 8.196999304113592e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:19:21,419] Trial 994 finished with value: 0.000702071595878806 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.2687650792450066, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.10349139001705403, 'learning_rate': 0.0035310052351477544, 'weight_decay': 9.47882489660706e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:20:36,935] Trial 995 finished with value: 0.0006862596346763894 and parameters: {'hidden_size': 192, 'num_layers': 2, 'extractor_dropout': 0.27675773406504245, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.10270795787935524, 'learning_rate': 0.004040700819553818, 'weight_decay': 1.1320055904967972e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:22:04,941] Trial 996 finished with value: 0.0001976973609998822 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.26464366905707953, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.12609709087024235, 'learning_rate': 0.003906452609900076, 'weight_decay': 1.0881497297633514e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:23:30,565] Trial 997 finished with value: 0.00019664690626086667 and parameters: {'hidden_size': 224, 'num_layers': 1, 'extractor_dropout': 0.270495070768731, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.11103001281454725, 'learning_rate': 0.00345761704728448, 'weight_decay': 8.503957511570228e-06}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:24:56,366] Trial 998 finished with value: 0.00020479593513300642 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.2572182822610629, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.11238241382107148, 'learning_rate': 0.004385161011263, 'weight_decay': 1.0482424556456642e-05}. Best is trial 663 with value: 0.00017342455830657855.\n",
      "[I 2025-08-07 13:26:30,371] Trial 999 finished with value: 0.00020055474160471932 and parameters: {'hidden_size': 208, 'num_layers': 1, 'extractor_dropout': 0.26204422984143033, 'decoder_layers': 1, 'decoder_nodes': 64, 'decoder_dropout': 0.12572808909326189, 'learning_rate': 0.003925436933787695, 'weight_decay': 7.752755258931372e-06}. Best is trial 663 with value: 0.00017342455830657855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "최적화 완료!\n",
      "==================================================\n",
      "최적의 하이퍼파라미터:\n",
      "  hidden_size: 256\n",
      "  num_layers: 1\n",
      "  extractor_dropout: 0.21824408405832693\n",
      "  decoder_layers: 1\n",
      "  decoder_nodes: 48\n",
      "  decoder_dropout: 0.17364019436412279\n",
      "  learning_rate: 0.005021381083170737\n",
      "  weight_decay: 5.028817220893871e-06\n",
      "\n",
      "최적의 검증 손실: 0.000173\n",
      "완료된 trial 수: 1000\n",
      "성공한 trial 수: 1000\n",
      "실패한 trial 수: 0\n",
      "\n",
      "결과 저장 완료:\n",
      "  - 데이터베이스: bmed_optuna_study.db\n",
      "  - JSON 파일: bmed_autoregressive_optimization_results.json\n"
     ]
    }
   ],
   "source": [
    "# BMED 자기회귀 모델 하이퍼파라미터 최적화 실행\n",
    "print(\"BMED 하이퍼파라미터 최적화 준비 중...\")\n",
    "\n",
    "# SQLite 데이터베이스에 study 결과 저장\n",
    "study_name = \"bmed_autoregressive_optimization\"\n",
    "storage_name = \"sqlite:///bmed_optuna_study.db\"\n",
    "\n",
    "# Optuna study 생성 - K-fold CV 기반\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction='minimize',  # 손실을 최소화\n",
    "    pruner=optuna.pruners.NopPruner(),  # K-fold CV와 호환을 위해 pruning 비활성화\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    load_if_exists=True  # 기존 study가 있으면 이어서 실행\n",
    ")\n",
    "\n",
    "print(\"BMED 자기회귀 모델 하이퍼파라미터 최적화 시작...\")\n",
    "print(f\"Study 이름: {study_name}\")\n",
    "print(f\"저장 위치: {storage_name}\")\n",
    "print(\"최적화 방식: K-fold Cross Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 최적화 실행 - 품질 중심\n",
    "study.optimize(\n",
    "    lambda trial: optimize_bmed_hyperparameters(trial, dataloaders), \n",
    "    n_trials=1000,  # 품질 중심의 최적화\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"최적화 완료!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n최적의 검증 손실: {study.best_value:.6f}\")\n",
    "print(f\"완료된 trial 수: {len(study.trials)}\")\n",
    "print(f\"성공한 trial 수: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"실패한 trial 수: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "\n",
    "# 결과를 JSON 파일로도 저장\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "results_dict = {\n",
    "    'study_name': study_name,\n",
    "    'model_type': 'BMED_Autoregressive',\n",
    "    'optimization_method': 'K-fold_Cross_Validation',\n",
    "    'best_params': study.best_params,\n",
    "    'best_value': study.best_value,\n",
    "    'n_trials': len(study.trials),\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'trials': [\n",
    "        {\n",
    "            'number': trial.number,\n",
    "            'value': trial.value,\n",
    "            'params': trial.params,\n",
    "            'state': trial.state.name\n",
    "        }\n",
    "        for trial in study.trials\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('bmed_autoregressive_optimization_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n결과 저장 완료:\")\n",
    "print(f\"  - 데이터베이스: bmed_optuna_study.db\")\n",
    "print(f\"  - JSON 파일: bmed_autoregressive_optimization_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1oezb5wqsgv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼파라미터로 최종 모델 학습...\n",
      "Using device: cuda\n",
      "GPU: NVIDIA RTX A4000\n",
      "\n",
      "=== Final Training Fold 1 ===\n",
      "Epoch  20: Train Loss = 0.560700, Val Loss = 0.538568, Best_val_loss = 0.226450\n",
      "Epoch  40: Train Loss = 0.566254, Val Loss = 0.545490, Best_val_loss = 0.226450\n",
      "Epoch  60: Train Loss = 0.570157, Val Loss = 0.544910, Best_val_loss = 0.226450\n",
      "Epoch  80: Train Loss = 0.576220, Val Loss = 0.560721, Best_val_loss = 0.226450\n",
      "Epoch 100: Train Loss = 0.578559, Val Loss = 0.566485, Best_val_loss = 0.226450\n",
      "Early stopping at epoch 109\n",
      "\n",
      "=== Final Training Fold 2 ===\n",
      "Epoch  20: Train Loss = 3062576316416.000000, Val Loss = 2094986821632.000000, Best_val_loss = 0.069813\n",
      "Epoch  40: Train Loss = 2186937892864.000000, Val Loss = 2094986821632.000000, Best_val_loss = 0.069813\n",
      "Epoch  60: Train Loss = 2577539399680.000000, Val Loss = 2094986821632.000000, Best_val_loss = 0.069813\n",
      "Epoch  80: Train Loss = 5054940381184.000000, Val Loss = 2094986821632.000000, Best_val_loss = 0.005789\n",
      "Epoch 100: Train Loss = 4195148922880.000000, Val Loss = 0.015572, Best_val_loss = 0.005789\n",
      "Epoch 120: Train Loss = 50363537293312.000000, Val Loss = 61913899728896.000000, Best_val_loss = 0.005789\n",
      "Epoch 140: Train Loss = 13998131970048.000000, Val Loss = 6354381045760.000000, Best_val_loss = 0.005789\n",
      "Epoch 160: Train Loss = 12726015229952.000000, Val Loss = 6354381045760.000000, Best_val_loss = 0.005789\n",
      "Early stopping at epoch 167\n",
      "\n",
      "=== Final Training Fold 3 ===\n",
      "Epoch  20: Train Loss = 1064717123584.000000, Val Loss = 7833855488.000000, Best_val_loss = 0.007141\n",
      "Epoch  40: Train Loss = 2787951968256.000000, Val Loss = 0.012452, Best_val_loss = 0.006917\n",
      "Epoch  60: Train Loss = 10555065368576.000000, Val Loss = 1216433356800.000000, Best_val_loss = 0.006917\n",
      "Epoch  80: Train Loss = 891474411520.000000, Val Loss = 51481276416.000000, Best_val_loss = 0.005520\n",
      "Epoch 100: Train Loss = 1574093258752.000000, Val Loss = 0.004742, Best_val_loss = 0.004742\n",
      "Epoch 120: Train Loss = 7071620464640.000000, Val Loss = 9838512832512.000000, Best_val_loss = 0.004742\n",
      "Epoch 140: Train Loss = 6476170461184.000000, Val Loss = 9838512832512.000000, Best_val_loss = 0.004742\n",
      "Epoch 160: Train Loss = 6060402147328.000000, Val Loss = 8835942055936.000000, Best_val_loss = 0.004742\n",
      "Epoch 180: Train Loss = 32274261475328.000000, Val Loss = 70002858262528.000000, Best_val_loss = 0.004742\n",
      "Epoch 200: Train Loss = 68672506822656.000000, Val Loss = 70002858262528.000000, Best_val_loss = 0.004742\n",
      "Early stopping at epoch 200\n",
      "\n",
      "=== Final Training Fold 4 ===\n",
      "Epoch  20: Train Loss = 0.478167, Val Loss = 0.474794, Best_val_loss = 0.361289\n",
      "Epoch  40: Train Loss = 0.566098, Val Loss = 0.569594, Best_val_loss = 0.361289\n",
      "Epoch  60: Train Loss = 0.557159, Val Loss = 0.551390, Best_val_loss = 0.361289\n",
      "Epoch  80: Train Loss = 0.523356, Val Loss = 0.516964, Best_val_loss = 0.361289\n",
      "Epoch 100: Train Loss = 0.501600, Val Loss = 0.495098, Best_val_loss = 0.361289\n",
      "Early stopping at epoch 101\n",
      "\n",
      "=== Final Training Fold 5 ===\n",
      "Epoch  20: Train Loss = 4457637150720.000000, Val Loss = 4671430721536.000000, Best_val_loss = 38028076.000000\n",
      "Epoch  40: Train Loss = 37910702981120.000000, Val Loss = 14672664199168.000000, Best_val_loss = 38028076.000000\n",
      "Epoch  60: Train Loss = 2356889485312.000000, Val Loss = 2202596016128.000000, Best_val_loss = 38028076.000000\n",
      "Epoch  80: Train Loss = 2245034442752.000000, Val Loss = 2202596016128.000000, Best_val_loss = 38028076.000000\n",
      "Epoch 100: Train Loss = 28205741331.500000, Val Loss = 0.941905, Best_val_loss = 0.646252\n",
      "Epoch 120: Train Loss = 23179895744.000000, Val Loss = 0.873001, Best_val_loss = 0.646252\n",
      "Epoch 140: Train Loss = 9206788576.000000, Val Loss = 0.934855, Best_val_loss = 0.646252\n",
      "Epoch 160: Train Loss = 51235119296.000000, Val Loss = 0.653299, Best_val_loss = 0.646252\n",
      "Epoch 180: Train Loss = 13309537792.210798, Val Loss = 0.810610, Best_val_loss = 0.646252\n",
      "Early stopping at epoch 192\n",
      "\n",
      "============================================================\n",
      "최종 결과 (BMED 자기회귀 모델)\n",
      "============================================================\n",
      "평균 검증 손실: 0.248904 ± 0.240724\n",
      "최고 성능 Fold: 3\n",
      "최고 검증 손실: 0.004742\n",
      "Fold 1: 0.226450\n",
      "Fold 2: 0.005789\n",
      "Fold 3: 0.004742\n",
      "Fold 4: 0.361289\n",
      "Fold 5: 0.646252\n",
      "\n",
      "최고 성능 모델 저장: best_bmed_autoregressive_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 최종 BMED 자기회귀 모델 학습\n",
    "print(\"최적의 하이퍼파라미터로 최종 모델 학습...\")\n",
    "\n",
    "# 최적 파라미터로 모델 설정\n",
    "best_params = study.best_params\n",
    "final_model_params = {\n",
    "    'state_extractor': {\n",
    "        'input_size': 12,\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['extractor_dropout']\n",
    "    },\n",
    "    'decoder': {\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'output_size': 7,\n",
    "        'num_layers': best_params['decoder_layers'],\n",
    "        'num_nodes': best_params['decoder_nodes'],\n",
    "        'dropout': best_params['decoder_dropout']\n",
    "    }\n",
    "}\n",
    "\n",
    "final_train_params = {\n",
    "    'epochs': 1000,  # 최종 학습에서는 더 많은 에포크\n",
    "    'patience': 100,\n",
    "    'optimizer': {\n",
    "        'lr': best_params['learning_rate'],\n",
    "        'weight_decay': best_params['weight_decay']\n",
    "    }\n",
    "}\n",
    "\n",
    "# K-fold로 최종 평가\n",
    "device = set_device()\n",
    "final_results = []\n",
    "\n",
    "for fold, (train_loader, val_loader) in enumerate(dataloaders):\n",
    "    print(f\"\\n=== Final Training Fold {fold + 1} ===\")\n",
    "    \n",
    "    # 모델 초기화\n",
    "    model = BMEDAutoregressiveModel(final_model_params['state_extractor'], final_model_params['decoder']).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), **final_train_params['optimizer'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(final_train_params['epochs']):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss = validate_epoch(model, val_loader, device)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}, Best_val_loss = {best_val_loss:.6f}\")\n",
    "            \n",
    "        if patience_counter >= final_train_params['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    final_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'model_state': best_model_state\n",
    "    })\n",
    "\n",
    "# 최종 결과 요약\n",
    "final_val_losses = [result['best_val_loss'] for result in final_results]\n",
    "final_mean_loss = sum(final_val_losses) / len(final_val_losses)\n",
    "final_std_loss = (sum([(x - final_mean_loss)**2 for x in final_val_losses]) / len(final_val_losses))**0.5\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"최종 결과 (BMED 자기회귀 모델)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"평균 검증 손실: {final_mean_loss:.6f} ± {final_std_loss:.6f}\")\n",
    "print(f\"최고 성능 Fold: {min(enumerate(final_val_losses), key=lambda x: x[1])[0] + 1}\")\n",
    "print(f\"최고 검증 손실: {min(final_val_losses):.6f}\")\n",
    "\n",
    "for i, result in enumerate(final_results):\n",
    "    print(f\"Fold {i+1}: {result['best_val_loss']:.6f}\")\n",
    "\n",
    "# 최고 성능 모델 저장\n",
    "best_fold_idx = min(enumerate(final_val_losses), key=lambda x: x[1])[0]\n",
    "best_model_path = 'best_bmed_autoregressive_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': final_results[best_fold_idx]['model_state'],\n",
    "    'model_params': final_model_params,\n",
    "    'best_params': best_params,\n",
    "    'val_loss': min(final_val_losses),\n",
    "    'fold': best_fold_idx + 1,\n",
    "    'model_type': 'BMED_Autoregressive'\n",
    "}, best_model_path)\n",
    "\n",
    "print(f\"\\n최고 성능 모델 저장: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733vckgi2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "하이퍼파라미터 최적화 요약\n",
      "==================================================\n",
      "총 실행된 trial 수: 1000\n",
      "성공한 trial 수: 1000\n",
      "Pruned trial 수: 0\n",
      "실패한 trial 수: 0\n",
      "\n",
      "최적의 검증 손실: 0.000173\n",
      "\n",
      "최적 하이퍼파라미터:\n",
      "  hidden_size: 256\n",
      "  num_layers: 1\n",
      "  extractor_dropout: 0.21824408405832693\n",
      "  decoder_layers: 1\n",
      "  decoder_nodes: 48\n",
      "  decoder_dropout: 0.17364019436412279\n",
      "  learning_rate: 0.005021381083170737\n",
      "  weight_decay: 5.028817220893871e-06\n",
      "\n",
      "상위 5개 trial:\n",
      "  1. Trial 663: Loss = 0.000173\n",
      "  2. Trial 661: Loss = 0.000174\n",
      "  3. Trial 552: Loss = 0.000176\n",
      "  4. Trial 949: Loss = 0.000177\n",
      "  5. Trial 479: Loss = 0.000178\n"
     ]
    }
   ],
   "source": [
    "# Optuna 최적화 결과 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 최적화 과정 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1-1. Optimization History\n",
    "trials = study.trials\n",
    "trial_values = [t.value for t in trials if t.value is not None]\n",
    "trial_numbers = [t.number for t in trials if t.value is not None]\n",
    "\n",
    "axes[0, 0].plot(trial_numbers, trial_values, 'b-', alpha=0.6)\n",
    "axes[0, 0].scatter(trial_numbers, trial_values, c='blue', alpha=0.6, s=20)\n",
    "axes[0, 0].axhline(y=study.best_value, color='red', linestyle='--', \n",
    "                   label=f'Best: {study.best_value:.6f}')\n",
    "axes[0, 0].set_xlabel('Trial Number')\n",
    "axes[0, 0].set_ylabel('Validation Loss')\n",
    "axes[0, 0].set_title('Optimization History')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 1-2. Parameter Importance\n",
    "try:\n",
    "    importance = optuna.importance.get_param_importances(study)\n",
    "    params = list(importance.keys())\n",
    "    values = list(importance.values())\n",
    "    \n",
    "    axes[0, 1].barh(params, values)\n",
    "    axes[0, 1].set_xlabel('Importance')\n",
    "    axes[0, 1].set_title('Parameter Importance')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "except:\n",
    "    axes[0, 1].text(0.5, 0.5, 'Parameter importance\\nnot available', \n",
    "                    ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('Parameter Importance')\n",
    "\n",
    "# 1-3. Best Parameters Visualization\n",
    "best_params = study.best_params\n",
    "param_names = list(best_params.keys())\n",
    "param_values = list(best_params.values())\n",
    "\n",
    "# 숫자형 파라미터만 시각화\n",
    "numeric_params = [(name, val) for name, val in best_params.items() if isinstance(val, (int, float))]\n",
    "if numeric_params:\n",
    "    names, vals = zip(*numeric_params)\n",
    "    axes[1, 0].bar(range(len(names)), vals)\n",
    "    axes[1, 0].set_xticks(range(len(names)))\n",
    "    axes[1, 0].set_xticklabels(names, rotation=45, ha='right')\n",
    "    axes[1, 0].set_ylabel('Parameter Value')\n",
    "    axes[1, 0].set_title('Best Parameters')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 1-4. Trial States Distribution\n",
    "states = [t.state.name for t in study.trials]\n",
    "unique_states, counts = np.unique(states, return_counts=True)\n",
    "\n",
    "axes[1, 1].pie(counts, labels=unique_states, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 1].set_title('Trial States Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 최적화 전후 비교 (만약 이전 결과가 있다면)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"하이퍼파라미터 최적화 요약\")\n",
    "print(\"=\"*50)\n",
    "print(f\"총 실행된 trial 수: {len(study.trials)}\")\n",
    "print(f\"성공한 trial 수: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"Pruned trial 수: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "print(f\"실패한 trial 수: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "print(f\"\\n최적의 검증 손실: {study.best_value:.6f}\")\n",
    "print(\"\\n최적 하이퍼파라미터:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 3. 상위 5개 trial 정보\n",
    "print(f\"\\n상위 5개 trial:\")\n",
    "best_trials = sorted([t for t in study.trials if t.value is not None], \n",
    "                    key=lambda x: x.value)[:5]\n",
    "for i, trial in enumerate(best_trials, 1):\n",
    "    print(f\"  {i}. Trial {trial.number}: Loss = {trial.value:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
