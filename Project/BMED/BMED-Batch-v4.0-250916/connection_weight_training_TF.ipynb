{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993e6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "import math\n",
    "import optuna\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42dc2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a49cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "\n",
    "    # Get the unique experiment numbers in order\n",
    "    exp_num_list = sorted(ndf['exp'].unique())\n",
    "    return ndf, exp_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d900108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data(ndf):\n",
    "    seq = []\n",
    "    # CBLA, CAK만 제거: 학습 불안정성 때문에\n",
    "    # 전류(I)는 포함: ground truth로 사용하여 예측 성능 비교\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        seq.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2021b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    max_len = max([len(seq) for seq in seq])\n",
    "    seq_len = [len(seq) for seq in seq]\n",
    "    pad_seq = pad_sequence([torch.tensor(seq) for seq in seq], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return pad_seq, seq_len, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ddc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67ed67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(dataset, exp_num_list, batch_size=4):\n",
    "    \"\"\"\n",
    "    Split the dataset into train/val/test with 8:1:1 ratio\n",
    "    \n",
    "    Args:\n",
    "        dataset: TensorDataset\n",
    "        exp_num_list: list of experiment numbers\n",
    "        batch_size: batch size\n",
    "        random_state: random seed\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # required train experiment numbers\n",
    "    required_train_exps = [0, 5, 8, 10, 15, 17, 20, 21, 22, 23, 30]\n",
    "    \n",
    "    # all experiment numbers\n",
    "    all_exps = exp_num_list\n",
    "    total_exps = len(all_exps)\n",
    "    \n",
    "    # batch_size\n",
    "    batch_size = math.ceil(len(dataset)/10)\n",
    "\n",
    "    # 8:1:1 ratio\n",
    "    train_count = int(total_exps * 0.8)\n",
    "    val_count = math.ceil(total_exps * 0.1)\n",
    "    \n",
    "    # remaining experiments\n",
    "    remaining_exps = [exp for exp in all_exps if exp not in required_train_exps]\n",
    "    \n",
    "    # number of experiments to add to train\n",
    "    additional_train_needed = train_count - len(required_train_exps)\n",
    "    \n",
    "    if additional_train_needed < 0:\n",
    "        raise ValueError(\"The number of required train experiments is greater than the total train set. Please adjust required_train_exps.\")\n",
    "    \n",
    "    # shuffle remaining experiments\n",
    "    np.random.shuffle(remaining_exps)\n",
    "    \n",
    "    # split remaining experiments into train, val, test\n",
    "    train_exps = required_train_exps + remaining_exps[:additional_train_needed]\n",
    "    val_exps = remaining_exps[additional_train_needed:additional_train_needed + val_count]\n",
    "    test_exps = remaining_exps[additional_train_needed + val_count:]\n",
    "    \n",
    "    print(f\"Actual split:\")\n",
    "    print(f\"  Train: {sorted(train_exps)} ({len(train_exps)} experiments)\")\n",
    "    print(f\"  Val: {sorted(val_exps)} ({len(val_exps)} experiments)\")  \n",
    "    print(f\"  Test: {sorted(test_exps)} ({len(test_exps)} experiments)\")\n",
    "    \n",
    "    # find indices of each experiment (exp_num_list and dataset have the same order)\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    for idx, exp in enumerate(all_exps):\n",
    "        if exp in train_exps:\n",
    "            train_indices.append(idx)\n",
    "        elif exp in val_exps:\n",
    "            val_indices.append(idx)\n",
    "        elif exp in test_exps:\n",
    "            test_indices.append(idx)\n",
    "    \n",
    "    # split dataset into train, val, test\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "    \n",
    "    # create DataLoader\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nCompleted DataLoader creation:\")\n",
    "    print(f\"  Train: {len(train_subset) if train_subset else 0} sequences\")\n",
    "    print(f\"  Val: {len(val_subset) if val_subset else 0} sequences\")\n",
    "    print(f\"  Test: {len(test_subset) if test_subset else 0} sequences\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d07f3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormLSTMCell(nn.Module):\n",
    "    \"\"\"LSTM Cell with Layer Normalization applied to gates\"\"\"\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "        \n",
    "        # Input-to-hidden and hidden-to-hidden transformations\n",
    "        self.weight_ih = nn.Linear(input_node, 4 * hidden_node, bias=False)\n",
    "        self.weight_hh = nn.Linear(hidden_node, 4 * hidden_node, bias=False)\n",
    "        \n",
    "        # Layer normalization for each gate\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)  # Input gate\n",
    "        self.ln_f = nn.LayerNorm(hidden_node)  # Forget gate  \n",
    "        self.ln_g = nn.LayerNorm(hidden_node)  # Cell gate\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)  # Output gate\n",
    "        \n",
    "        # Cell state layer norm\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        \n",
    "        # Input-to-hidden and hidden-to-hidden transformations\n",
    "        gi = self.weight_ih(input)    # [batch, 4*hidden_size] - 입력에 대한 4개 게이트 계산\n",
    "        gh = self.weight_hh(h_prev)   # [batch, 4*hidden_size] - 이전 히든 상태에 대한 4개 게이트 계산\n",
    "        i_i, i_f, i_g, i_o = gi.chunk(4, 1)\n",
    "        h_i, h_f, h_g, h_o = gh.chunk(4, 1)\n",
    "        \n",
    "        # Apply layer normalization to each gate\n",
    "        i_gate = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_gate = torch.sigmoid(self.ln_f(i_f + h_f))  \n",
    "        g_gate = torch.tanh(self.ln_g(i_g + h_g))\n",
    "        o_gate = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "        \n",
    "        # Update cell state with layer norm\n",
    "        c_new = f_gate * c_prev + i_gate * g_gate\n",
    "        c_new = self.ln_c(c_new)\n",
    "        \n",
    "        # Update hidden state\n",
    "        h_new = o_gate * torch.tanh(c_new)\n",
    "        \n",
    "        return h_new, c_new\n",
    "\n",
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, nlayer, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.nlayer = nlayer\n",
    "        self.input_size = input_node\n",
    "        \n",
    "        # Create LayerNorm LSTM layers\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        \n",
    "        # First layer: input_size -> hidden_size\n",
    "        self.lstm_cells.append(LayerNormLSTMCell(input_node, hidden_node))\n",
    "        \n",
    "        # Additional layers: hidden_size -> hidden_size\n",
    "        for _ in range(nlayer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTMCell(hidden_node, hidden_node))\n",
    "        \n",
    "        # Dropout between layers (only applied if nlayer > 1)\n",
    "        self.dropout = nn.Dropout(dropout) if nlayer > 1 else nn.Identity()\n",
    "        \n",
    "        # Final layer norm and dropout\n",
    "        self.final_layer_norm = nn.LayerNorm(hidden_node)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        시계열 상태 시퀀스를 처리하여 각 시점의 hidden state 추출\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size] - BMED 시스템 상태 시퀀스\n",
    "            seq_len: [batch_size] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 각 시점의 누적된 hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        # 입력 검증\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        batch_size, max_len, input_node = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # 초기 hidden/cell states 초기화\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "        for _ in range(self.nlayer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "        \n",
    "        # 각 시점별 출력 저장\n",
    "        outputs = []\n",
    "        \n",
    "        # 시점별로 순차 처리\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]  # [batch_size, input_node]\n",
    "            \n",
    "            # 각 LSTM layer 순차 처리\n",
    "            layer_input = x_t\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                \n",
    "                # 상태 업데이트\n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "                \n",
    "                # 다음 레이어 입력 준비 (dropout 적용)\n",
    "                if layer_idx < len(self.lstm_cells) - 1:  # 마지막 레이어가 아닌 경우\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "            \n",
    "            outputs.append(layer_input)\n",
    "        \n",
    "        # [batch_size, seq_len, hidden_size] 형태로 변환\n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        \n",
    "        # 시퀀스 길이에 따른 마스킹 (패딩 부분 0으로 설정)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        \n",
    "        # 시퀀스 길이 유효성 검사\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "        \n",
    "        # 마스크 생성 및 적용\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)  # [batch, seq_len, 1]\n",
    "        \n",
    "        # 마스킹 적용\n",
    "        masked_output = output_tensor * mask\n",
    "        \n",
    "        # Final normalization and dropout\n",
    "        normalized = self.final_layer_norm(masked_output)\n",
    "        return self.final_dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be1c313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden state로부터 BMED 시스템의 물리적 변화량과 새로운 전류값을 디코딩하는 MLP\n",
    "    출력: [dVA, dVB, dNALA, dNBK, nI] - 5개 물리적 변화량 (CBLA, CAK 제거로 dNBLA, dNAK 불필요)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # 첫 번째 레이어: hidden_size → num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 중간 은닉층들: num_nodes → num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 마지막 출력층: num_nodes → output_size (5개 물리적 변화량)\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Hidden state를 물리적 변화량으로 디코딩\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 시점별 hidden state\n",
    "            \n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, 5] - 물리적 변화량\n",
    "                [dVA, dVB, dNALA, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0213a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    물리적 변화량을 실제 시스템 상태로 변환하면서 물리적 제약 조건을 적용\n",
    "    Bipolar membrane electrodialysis 시스템의 물리 법칙 기반 상태 업데이트\n",
    "    CBLA, CAK는 완전히 제거되어 더 이상 존재하지 않음\n",
    "    전류는 dependent variable이므로 input에 포함하지 않고 output으로만 예측\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-1):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # division by zero 방지\n",
    "        \n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        물리적 변화량을 현재 상태에 적용하여 다음 상태 계산\n",
    "        \n",
    "        Args:\n",
    "            physical_changes: [batch, seq, 5] - [dVA, dVB, dNALA, dNBK, nI]\n",
    "            current_state: [batch, seq, 9] - 현재 BMED 시스템 상태 (전류 제외)\n",
    "                V, E, VF, VA, VB, CFLA, CALA, CFK, CBK\n",
    "                \n",
    "        Returns:\n",
    "            next_state: [batch, seq, 10] - 물리 제약이 적용된 다음 상태\n",
    "                V, E, VF, VA, VB, CFLA, CALA, CFK, CBK, I\n",
    "        \"\"\"\n",
    "        # 입력 차원 검증\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 9:\n",
    "            raise ValueError(f\"Expected 9 state features, got {current_state.size(-1)}\")\n",
    "            \n",
    "        if physical_changes.size(-1) != 5:\n",
    "            raise ValueError(f\"Expected 5 physical changes, got {physical_changes.size(-1)}\")\n",
    "        \n",
    "        # 현재 상태 변수 추출 (9개)\n",
    "        V = current_state[..., 0:1]     # 전압 (고정값)\n",
    "        E = current_state[..., 1:2]     # 외부 전해질 농도 (고정값)\n",
    "        VF = current_state[..., 2:3]    # Feed 부피\n",
    "        VA = current_state[..., 3:4]    # Acid 부피\n",
    "        VB = current_state[..., 4:5]    # Base 부피\n",
    "        CFLA = current_state[..., 5:6]  # Feed LA 농도\n",
    "        CALA = current_state[..., 6:7]  # Acid LA 농도\n",
    "        CFK = current_state[..., 7:8]   # Feed K 농도\n",
    "        CBK = current_state[..., 8:9]   # Base K 농도\n",
    "\n",
    "        # 물질량 계산 (농도 × 부피) - CBLA, CAK 관련은 완전 제거\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA  \n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        # 물리적 변화량 추출 (5개)\n",
    "        dVA = physical_changes[..., 0:1]    # Acid 부피 변화량\n",
    "        dVB = physical_changes[..., 1:2]    # Base 부피 변화량\n",
    "        dNALA = physical_changes[..., 2:3]  # Acid LA 물질량 변화량 (F→A)\n",
    "        dNBK = physical_changes[..., 3:4]   # Base K 물질량 변화량 (F→B)\n",
    "        nI = physical_changes[..., 4:5]     # 새로운 전류값 (모델이 예측)\n",
    "\n",
    "        # 새로운 부피 계산\n",
    "        nVF = VF - dVA - dVB\n",
    "        nVA = VA + dVA        \n",
    "        nVB = VB + dVB        \n",
    "        \n",
    "        # 물질 이동량을 일방향으로 제한\n",
    "        dNALA_clipped = torch.clamp(dNALA, min=0)  # F→A 이동만\n",
    "        dNBK_clipped = torch.clamp(dNBK, min=0)    # F→B 이동만\n",
    "        \n",
    "        # 새로운 물질량 계산 (CBLA, CAK 관련 제거)\n",
    "        nNFLA = NFLA - dNALA_clipped  # Feed에서 LA 유출\n",
    "        nNALA = NALA + dNALA_clipped  # Acid로 LA 유입\n",
    "        nNFK = NFK - dNBK_clipped     # Feed에서 K 유출  \n",
    "        nNBK = NBK + dNBK_clipped     # Base로 K 유입\n",
    "        \n",
    "        # 물리적 제약 조건 적용 (양수 유지)\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        \n",
    "        # 물질량 음수 방지\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        \n",
    "        # 새로운 농도 계산\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCFK = nNFK / nVF\n",
    "        nCBK = nNBK / nVB\n",
    "        \n",
    "        # 전류는 양수 제약\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # 새로운 상태 조립 (10개 변수, CBLA, CAK 완전 제거, 전류는 예측 결과로 추가)\n",
    "        next_state = torch.cat([\n",
    "            V, E,  # 고정값: 전압, 외부 전해질 농도\n",
    "            nVF, nVA, nVB,  # 새로운 부피\n",
    "            nCFLA, nCALA,   # 새로운 LA 농도 (CBLA 제거)\n",
    "            nCFK, nCBK,     # 새로운 K 농도 (CAK 제거)\n",
    "            nI  # 새로운 전류 (모델이 예측한 dependent variable)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c20aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED 시스템의 시계열 상태 예측을 위한 자기회귀 모델\n",
    "    \n",
    "    구조:\n",
    "    1. StateExtr: LSTM으로 시계열 패턴의 hidden state 추출\n",
    "    2. PhysicalChangeDecoder: Hidden state를 물리적 변화량으로 디코딩  \n",
    "    3. PhysicsConstraintLayer: 물리 법칙 적용하여 다음 상태 계산\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = StateExtr(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_states, seq_lengths):\n",
    "        \"\"\"\n",
    "        현재 시점까지의 상태들로부터 다음 상태들 예측\n",
    "        \n",
    "        Args:\n",
    "            current_states: [batch, seq_len, 9] - 현재까지의 전류를 제외한한 BMED 시스템 상태들\n",
    "            seq_lengths: [batch] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            next_states: [batch, seq_len, 10] - 예측된 다음 시점 상태들 (전류 포함)\n",
    "        \"\"\"\n",
    "        # 1. LSTM으로 각 시점의 hidden state 추출 (과거 정보 누적)\n",
    "        hidden_states = self.state_extractor(current_states, seq_lengths)\n",
    "        \n",
    "        # 2. Hidden state를 물리적 변화량으로 디코딩\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        \n",
    "        # 3. 물리적 제약 조건을 적용하여 다음 상태 계산\n",
    "        next_states = self.physics_constraint(physical_changes, current_states)\n",
    "        \n",
    "        return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b58e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(predictions, targets, seq_lengths):\n",
    "    \"\"\"\n",
    "    개선된 마스킹된 MSE 손실 함수 - device 호환성, 안정성 강화\n",
    "    물리적 의미가 개선되어 feature별 가중치 불필요\n",
    "    \n",
    "    Args:\n",
    "        predictions: 모델 예측값 [batch_size, seq_len, features]\n",
    "        targets: 실제 타겟값 [batch_size, seq_len, features]  \n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        masked_loss: 패딩 부분을 제외한 평균 MSE 손실\n",
    "    \"\"\"\n",
    "    # 입력 검증\n",
    "    if predictions.shape != targets.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {predictions.shape} vs targets {targets.shape}\")\n",
    "    \n",
    "    if predictions.size(0) != seq_lengths.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {predictions.size(0)} vs seq_lengths {seq_lengths.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = predictions.shape\n",
    "    \n",
    "    # seq_lengths를 CPU로 이동하여 arange와 호환되도록 처리\n",
    "    seq_lengths_cpu = seq_lengths.detach().cpu().long()\n",
    "    \n",
    "    # 시퀀스 길이 유효성 검사\n",
    "    if (seq_lengths_cpu <= 0).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu <= 0]\n",
    "        raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "    \n",
    "    # 최대 길이 초과 검사\n",
    "    if (seq_lengths_cpu > max_len).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu > max_len]\n",
    "        raise ValueError(f\"Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}\")\n",
    "    \n",
    "    # 마스크 생성: 실제 시퀀스 길이만큼만 True\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_lengths_cpu[:, None]\n",
    "    mask = mask.float().to(predictions.device)\n",
    "    \n",
    "    # 각 요소별 MSE 계산 (reduction='none')\n",
    "    loss = F.mse_loss(predictions, targets, reduction='none')  # [batch, seq_len, features]\n",
    "    \n",
    "    # 마스크 적용하여 패딩 부분 제거\n",
    "    masked_loss = loss * mask.unsqueeze(-1)  # [batch, seq_len, features]\n",
    "    \n",
    "    # 전체 손실 합계와 전체 valid elements 계산\n",
    "    total_loss = masked_loss.sum()\n",
    "    total_elements = mask.sum() * features\n",
    "    \n",
    "    # 0으로 나누기 방지\n",
    "    if total_elements == 0:\n",
    "        raise ValueError(\"No valid elements found after masking. Check sequence lengths and data.\")\n",
    "    \n",
    "    masked_loss = total_loss / total_elements\n",
    "    \n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf439fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_teacher_forcing_data(input_sequences, seq_lengths):\n",
    "    \"\"\"\n",
    "    Teacher Forcing을 위한 입력-타겟 데이터 준비\n",
    "    전류는 dependent variable이므로 input에서 제외하고 output에만 포함\n",
    "    \n",
    "    Args:\n",
    "        input_sequences: 전체 시퀀스 [batch_size, seq_len, 10] (CBLA, CAK 제거된 상태)\n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        inputs: [t0, t1, ..., t_{n-1}] 현재 상태들 [batch_size, seq_len-1, 9] (전류 제외)\n",
    "        targets: [t1, t2, ..., t_n] 다음 상태들 [batch_size, seq_len-1, 10] (전류 포함)\n",
    "        target_seq_lengths: 타겟 시퀀스 길이 (1씩 감소)\n",
    "    \"\"\"\n",
    "    # 입력: 마지막 시점 제외 [:-1] 및 전류 제외 [:-1]\n",
    "    inputs = input_sequences[:, :-1, :-1]  # 전류 제외하여 9개 features\n",
    "    \n",
    "    # 타겟: 첫 번째 시점 제외 [1:], 전류 포함하여 10개 features\n",
    "    targets = input_sequences[:, 1:, :]\n",
    "    \n",
    "    # 타겟 시퀀스 길이는 1씩 감소 (마지막 시점 예측 불가)\n",
    "    if (seq_lengths - 1 < 1).any():\n",
    "        invalid_lengths = seq_lengths[seq_lengths - 1 < 1]\n",
    "        raise ValueError(f\"타겟 시퀀스 길이가 0보다 작아질 수 없습니다. 잘못된 seq_lengths: {invalid_lengths.tolist()}\")\n",
    "    target_seq_lengths = seq_lengths - 1\n",
    "    \n",
    "    return inputs, targets, target_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c8fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Dataset created with 24 experiments\n",
      "Max sequence length: 33\n",
      "Experiment numbers: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23)]\n",
      "Actual split:\n",
      "  Train: [0, np.int64(1), np.int64(2), 5, np.int64(6), np.int64(7), 8, 10, np.int64(11), np.int64(12), 15, np.int64(16), 17, np.int64(19), 20, 21, 22, 23, 30] (19 experiments)\n",
      "  Val: [np.int64(3), np.int64(13), np.int64(18)] (3 experiments)\n",
      "  Test: [np.int64(4), np.int64(9), np.int64(14)] (3 experiments)\n",
      "\n",
      "Completed DataLoader creation:\n",
      "  Train: 18 sequences\n",
      "  Val: 3 sequences\n",
      "  Test: 3 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load data and create dataloaders\n",
    "print(\"Loading and preprocessing data...\")\n",
    "ndf, exp_num_list = norm_data('BMED_DATA_AG.csv')\n",
    "sequences = seq_data(ndf)\n",
    "padded_seq, seq_len, max_seq_len = pad_seq(sequences)\n",
    "dataset = gen_dataset(padded_seq, seq_len)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} experiments\")\n",
    "print(f\"Max sequence length: {max_seq_len}\")\n",
    "print(f\"Experiment numbers: {sorted(exp_num_list)}\")\n",
    "\n",
    "# Create train/val/test dataloaders with stratified split\n",
    "train_loader, val_loader, test_loader = dataloaders(dataset, exp_num_list, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95396be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "  Input features: 9 (without current)\n",
      "  Hidden size: 256\n",
      "  LSTM layers: 5\n",
      "  Output features: 5 (physical changes)\n",
      "  Model parameters: 2,714,629\n",
      "\n",
      "Training configuration:\n",
      "  Total epochs: 10,000\n",
      "  Warmup epochs: 1,000 (5%)\n",
      "  Min epochs: 2,000\n",
      "  Patience: 1,000\n",
      "  Peak learning rate: 9.88e-04\n"
     ]
    }
   ],
   "source": [
    "class NoamScheduler:\n",
    "    \"\"\"\n",
    "    Transformer에서 사용하는 Noam 학습률 스케줄러\n",
    "    LSTM에 맞게 epoch 기반으로 수정\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, model_size, warmup_epochs, factor=1.0):\n",
    "        self.optimizer = optimizer\n",
    "        self.model_size = model_size\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.factor = factor\n",
    "        self.epoch_num = 0\n",
    "        \n",
    "    def step_epoch(self):\n",
    "        \"\"\"에포크마다 학습률 업데이트\"\"\"\n",
    "        self.epoch_num += 1\n",
    "        lr = self.factor * (\n",
    "            self.model_size ** (-0.5) *\n",
    "            min(self.epoch_num ** (-0.5), self.epoch_num * self.warmup_epochs ** (-1.5))\n",
    "        )\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        return lr\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "# Model parameters - 입력 차원 수정\n",
    "state_extr_params = {\n",
    "    'input_node': 9,   # 수정: 10 -> 9 (전류 제외한 입력)\n",
    "    'hidden_node': 256,\n",
    "    'nlayer': 5,\n",
    "    'dropout': 0.3\n",
    "}\n",
    "\n",
    "decoder_params = {\n",
    "    'hidden_size': 256,\n",
    "    'output_size': 5,  # [dVA, dVB, dNALA, dNBK, nI]\n",
    "    'num_layers': 5,\n",
    "    'num_nodes': 256,\n",
    "    'dropout': 0.3\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = BMEDAutoregressiveModel(state_extr_params, decoder_params)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(f\"  Input features: {state_extr_params['input_node']} (without current)\")\n",
    "print(f\"  Hidden size: {state_extr_params['hidden_node']}\")\n",
    "print(f\"  LSTM layers: {state_extr_params['nlayer']}\")\n",
    "print(f\"  Output features: {decoder_params['output_size']} (physical changes)\")\n",
    "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Training setup with Noam scheduler (epoch-based)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1.0)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10000\n",
    "\n",
    "\n",
    "# Noam 스케줄러 설정 (epoch 기반)\n",
    "warmup_epochs = int(num_epochs * 0.1)  # 전체 epoch의 5%\n",
    "scheduler = NoamScheduler(\n",
    "    optimizer, \n",
    "    model_size=256,  # hidden_size와 동일\n",
    "    warmup_epochs=warmup_epochs,  # 500 epochs\n",
    "    factor=1  # 학습률 스케일링 팩터\n",
    ")\n",
    "\n",
    "min_epochs = warmup_epochs + 1000\n",
    "patience = 1000\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Total epochs: {num_epochs:,}\")\n",
    "print(f\"  Warmup epochs: {warmup_epochs:,} (5%)\")\n",
    "print(f\"  Min epochs: {min_epochs:,}\")\n",
    "print(f\"  Patience: {patience:,}\")\n",
    "peak_lr = 0.5 * (256 ** (-0.5)) * (warmup_epochs ** (-0.5))\n",
    "print(f\"  Peak learning rate: {peak_lr:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thtkmdiuz0l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with Noam scheduler (epoch-based)...\n",
      "데이터 분포 - Train: 18(0.857), Val: 3(0.143)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: Train: 2.631874, Val: 0.532642, Total: 2.331984, LR: 1.98e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 2.631874, Val: 0.532642, Total: 2.331984 (Epoch 1)\n",
      "Epoch    2: Train: 2.664341, Val: 0.455765, Total: 2.348830, LR: 3.95e-06 [WARMUP]\n",
      "          Best: Train: 2.631874, Val: 0.532642, Total: 2.331984 (Epoch 1)\n",
      "Epoch    3: Train: 2.042231, Val: 0.372538, Total: 1.803704, LR: 5.93e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 2.042231, Val: 0.372538, Total: 1.803704 (Epoch 3)\n",
      "Epoch    4: Train: 1.830030, Val: 0.374966, Total: 1.622164, LR: 7.91e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 1.830030, Val: 0.374966, Total: 1.622164 (Epoch 4)\n",
      "Epoch    5: Train: 1.266364, Val: 0.461620, Total: 1.151400, LR: 9.88e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 1.266364, Val: 0.461620, Total: 1.151400 (Epoch 5)\n",
      "Epoch    6: Train: 1.055035, Val: 0.627699, Total: 0.993987, LR: 1.19e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 1.055035, Val: 0.627699, Total: 0.993987 (Epoch 6)\n",
      "Epoch    7: Train: 0.914346, Val: 0.756069, Total: 0.891735, LR: 1.38e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.914346, Val: 0.756069, Total: 0.891735 (Epoch 7)\n",
      "Epoch    8: Train: 0.791347, Val: 0.820268, Total: 0.795479, LR: 1.58e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.791347, Val: 0.820268, Total: 0.795479 (Epoch 8)\n",
      "Epoch    9: Train: 0.623781, Val: 0.905997, Total: 0.664098, LR: 1.78e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.623781, Val: 0.905997, Total: 0.664098 (Epoch 9)\n",
      "Epoch   10: Train: 0.543056, Val: 0.945088, Total: 0.600489, LR: 1.98e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.543056, Val: 0.945088, Total: 0.600489 (Epoch 10)\n",
      "Epoch   11: Train: 0.475574, Val: 0.989457, Total: 0.548986, LR: 2.17e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.475574, Val: 0.989457, Total: 0.548986 (Epoch 11)\n",
      "Epoch   12: Train: 0.367806, Val: 1.040843, Total: 0.463954, LR: 2.37e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.367806, Val: 1.040843, Total: 0.463954 (Epoch 12)\n",
      "Epoch   13: Train: 0.366740, Val: 0.984917, Total: 0.455051, LR: 2.57e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.366740, Val: 0.984917, Total: 0.455051 (Epoch 13)\n",
      "Epoch   14: Train: 0.301975, Val: 0.912005, Total: 0.389122, LR: 2.77e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.301975, Val: 0.912005, Total: 0.389122 (Epoch 14)\n",
      "Epoch   15: Train: 0.337799, Val: 0.825509, Total: 0.407471, LR: 2.96e-05 [WARMUP]\n",
      "          Best: Train: 0.301975, Val: 0.912005, Total: 0.389122 (Epoch 14)\n",
      "Epoch   16: Train: 0.275012, Val: 0.591183, Total: 0.320179, LR: 3.16e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.275012, Val: 0.591183, Total: 0.320179 (Epoch 16)\n",
      "Epoch   17: Train: 0.226286, Val: 0.386209, Total: 0.249132, LR: 3.36e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.226286, Val: 0.386209, Total: 0.249132 (Epoch 17)\n",
      "Epoch   18: Train: 0.218156, Val: 0.185857, Total: 0.213542, LR: 3.56e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.218156, Val: 0.185857, Total: 0.213542 (Epoch 18)\n",
      "Epoch   19: Train: 0.217794, Val: 0.169536, Total: 0.210900, LR: 3.76e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.217794, Val: 0.169536, Total: 0.210900 (Epoch 19)\n",
      "Epoch   20: Train: 0.161071, Val: 0.070338, Total: 0.148109, LR: 3.95e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.161071, Val: 0.070338, Total: 0.148109 (Epoch 20)\n",
      "Epoch   21: Train: 0.150506, Val: 0.063290, Total: 0.138047, LR: 4.15e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.150506, Val: 0.063290, Total: 0.138047 (Epoch 21)\n",
      "Epoch   22: Train: 0.152300, Val: 0.053496, Total: 0.138186, LR: 4.35e-05 [WARMUP]\n",
      "          Best: Train: 0.150506, Val: 0.063290, Total: 0.138047 (Epoch 21)\n",
      "Epoch   23: Train: 0.146012, Val: 0.054228, Total: 0.132900, LR: 4.55e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.146012, Val: 0.054228, Total: 0.132900 (Epoch 23)\n",
      "Epoch   24: Train: 0.117050, Val: 0.042344, Total: 0.106378, LR: 4.74e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   25: Train: 0.123567, Val: 0.043623, Total: 0.112146, LR: 4.94e-05 [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   26: Train: 0.155329, Val: 0.056208, Total: 0.141169, LR: 5.14e-05 [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   27: Train: 0.128464, Val: 0.050163, Total: 0.117278, LR: 5.34e-05 [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   28: Train: 0.127395, Val: 0.042802, Total: 0.115311, LR: 5.53e-05 [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   29: Train: 0.122523, Val: 0.034274, Total: 0.109916, LR: 5.73e-05 [WARMUP]\n",
      "          Best: Train: 0.117050, Val: 0.042344, Total: 0.106378 (Epoch 24)\n",
      "Epoch   30: Train: 0.102638, Val: 0.025957, Total: 0.091683, LR: 5.93e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.102638, Val: 0.025957, Total: 0.091683 (Epoch 30)\n",
      "Epoch   31: Train: 0.110384, Val: 0.020703, Total: 0.097572, LR: 6.13e-05 [WARMUP]\n",
      "          Best: Train: 0.102638, Val: 0.025957, Total: 0.091683 (Epoch 30)\n",
      "Epoch   32: Train: 0.119924, Val: 0.020021, Total: 0.105652, LR: 6.32e-05 [WARMUP]\n",
      "          Best: Train: 0.102638, Val: 0.025957, Total: 0.091683 (Epoch 30)\n",
      "Epoch   33: Train: 0.094925, Val: 0.036238, Total: 0.086541, LR: 6.52e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.094925, Val: 0.036238, Total: 0.086541 (Epoch 33)\n",
      "Epoch   34: Train: 0.089991, Val: 0.024176, Total: 0.080589, LR: 6.72e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.089991, Val: 0.024176, Total: 0.080589 (Epoch 34)\n",
      "Epoch   35: Train: 0.076037, Val: 0.022375, Total: 0.068371, LR: 6.92e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.076037, Val: 0.022375, Total: 0.068371 (Epoch 35)\n",
      "Epoch   36: Train: 0.082425, Val: 0.027042, Total: 0.074513, LR: 7.12e-05 [WARMUP]\n",
      "          Best: Train: 0.076037, Val: 0.022375, Total: 0.068371 (Epoch 35)\n",
      "Epoch   37: Train: 0.079053, Val: 0.029985, Total: 0.072043, LR: 7.31e-05 [WARMUP]\n",
      "          Best: Train: 0.076037, Val: 0.022375, Total: 0.068371 (Epoch 35)\n",
      "Epoch   38: Train: 0.061111, Val: 0.022557, Total: 0.055603, LR: 7.51e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.061111, Val: 0.022557, Total: 0.055603 (Epoch 38)\n",
      "Epoch   39: Train: 0.079803, Val: 0.018448, Total: 0.071038, LR: 7.71e-05 [WARMUP]\n",
      "          Best: Train: 0.061111, Val: 0.022557, Total: 0.055603 (Epoch 38)\n",
      "Epoch   40: Train: 0.077012, Val: 0.028736, Total: 0.070115, LR: 7.91e-05 [WARMUP]\n",
      "          Best: Train: 0.061111, Val: 0.022557, Total: 0.055603 (Epoch 38)\n",
      "Epoch   41: Train: 0.067240, Val: 0.015068, Total: 0.059787, LR: 8.10e-05 [WARMUP]\n",
      "          Best: Train: 0.061111, Val: 0.022557, Total: 0.055603 (Epoch 38)\n",
      "Epoch   42: Train: 0.060800, Val: 0.012065, Total: 0.053838, LR: 8.30e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.060800, Val: 0.012065, Total: 0.053838 (Epoch 42)\n",
      "Epoch   43: Train: 0.055483, Val: 0.018259, Total: 0.050165, LR: 8.50e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.055483, Val: 0.018259, Total: 0.050165 (Epoch 43)\n",
      "Epoch   44: Train: 0.047406, Val: 0.015098, Total: 0.042791, LR: 8.70e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.047406, Val: 0.015098, Total: 0.042791 (Epoch 44)\n",
      "Epoch   45: Train: 0.051232, Val: 0.011769, Total: 0.045595, LR: 8.89e-05 [WARMUP]\n",
      "          Best: Train: 0.047406, Val: 0.015098, Total: 0.042791 (Epoch 44)\n",
      "Epoch   46: Train: 0.050008, Val: 0.012351, Total: 0.044629, LR: 9.09e-05 [WARMUP]\n",
      "          Best: Train: 0.047406, Val: 0.015098, Total: 0.042791 (Epoch 44)\n",
      "Epoch   47: Train: 0.050891, Val: 0.016564, Total: 0.045987, LR: 9.29e-05 [WARMUP]\n",
      "          Best: Train: 0.047406, Val: 0.015098, Total: 0.042791 (Epoch 44)\n",
      "Epoch   48: Train: 0.045391, Val: 0.015562, Total: 0.041130, LR: 9.49e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.045391, Val: 0.015562, Total: 0.041130 (Epoch 48)\n",
      "Epoch   49: Train: 0.043751, Val: 0.013459, Total: 0.039424, LR: 9.68e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.043751, Val: 0.013459, Total: 0.039424 (Epoch 49)\n",
      "Epoch   50: Train: 0.042899, Val: 0.013092, Total: 0.038641, LR: 9.88e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.042899, Val: 0.013092, Total: 0.038641 (Epoch 50)\n",
      "Epoch   51: Train: 0.034279, Val: 0.009215, Total: 0.030699, LR: 1.01e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.034279, Val: 0.009215, Total: 0.030699 (Epoch 51)\n",
      "Epoch   52: Train: 0.036296, Val: 0.009305, Total: 0.032440, LR: 1.03e-04 [WARMUP]\n",
      "          Best: Train: 0.034279, Val: 0.009215, Total: 0.030699 (Epoch 51)\n",
      "Epoch   53: Train: 0.037037, Val: 0.006967, Total: 0.032741, LR: 1.05e-04 [WARMUP]\n",
      "          Best: Train: 0.034279, Val: 0.009215, Total: 0.030699 (Epoch 51)\n",
      "Epoch   54: Train: 0.036669, Val: 0.007480, Total: 0.032499, LR: 1.07e-04 [WARMUP]\n",
      "          Best: Train: 0.034279, Val: 0.009215, Total: 0.030699 (Epoch 51)\n",
      "Epoch   55: Train: 0.028856, Val: 0.009763, Total: 0.026129, LR: 1.09e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.028856, Val: 0.009763, Total: 0.026129 (Epoch 55)\n",
      "Epoch   56: Train: 0.028505, Val: 0.009280, Total: 0.025759, LR: 1.11e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.028505, Val: 0.009280, Total: 0.025759 (Epoch 56)\n",
      "Epoch   57: Train: 0.027301, Val: 0.005976, Total: 0.024254, LR: 1.13e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.027301, Val: 0.005976, Total: 0.024254 (Epoch 57)\n",
      "Epoch   58: Train: 0.025184, Val: 0.004278, Total: 0.022197, LR: 1.15e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.025184, Val: 0.004278, Total: 0.022197 (Epoch 58)\n",
      "Epoch   59: Train: 0.022745, Val: 0.003910, Total: 0.020054, LR: 1.17e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.022745, Val: 0.003910, Total: 0.020054 (Epoch 59)\n",
      "Epoch   60: Train: 0.023795, Val: 0.003895, Total: 0.020952, LR: 1.19e-04 [WARMUP]\n",
      "          Best: Train: 0.022745, Val: 0.003910, Total: 0.020054 (Epoch 59)\n",
      "Epoch   61: Train: 0.022422, Val: 0.003852, Total: 0.019769, LR: 1.21e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.022422, Val: 0.003852, Total: 0.019769 (Epoch 61)\n",
      "Epoch   62: Train: 0.020469, Val: 0.003602, Total: 0.018060, LR: 1.23e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.020469, Val: 0.003602, Total: 0.018060 (Epoch 62)\n",
      "Epoch   63: Train: 0.019465, Val: 0.004033, Total: 0.017260, LR: 1.25e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.019465, Val: 0.004033, Total: 0.017260 (Epoch 63)\n",
      "Epoch   64: Train: 0.020302, Val: 0.004461, Total: 0.018039, LR: 1.26e-04 [WARMUP]\n",
      "          Best: Train: 0.019465, Val: 0.004033, Total: 0.017260 (Epoch 63)\n",
      "Epoch   65: Train: 0.018241, Val: 0.003316, Total: 0.016109, LR: 1.28e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.018241, Val: 0.003316, Total: 0.016109 (Epoch 65)\n",
      "Epoch   66: Train: 0.017820, Val: 0.003352, Total: 0.015753, LR: 1.30e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.017820, Val: 0.003352, Total: 0.015753 (Epoch 66)\n",
      "Epoch   67: Train: 0.017522, Val: 0.004241, Total: 0.015625, LR: 1.32e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.017522, Val: 0.004241, Total: 0.015625 (Epoch 67)\n",
      "Epoch   68: Train: 0.016819, Val: 0.003661, Total: 0.014940, LR: 1.34e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.016819, Val: 0.003661, Total: 0.014940 (Epoch 68)\n",
      "Epoch   69: Train: 0.017236, Val: 0.003938, Total: 0.015337, LR: 1.36e-04 [WARMUP]\n",
      "          Best: Train: 0.016819, Val: 0.003661, Total: 0.014940 (Epoch 68)\n",
      "Epoch   70: Train: 0.018471, Val: 0.003754, Total: 0.016369, LR: 1.38e-04 [WARMUP]\n",
      "          Best: Train: 0.016819, Val: 0.003661, Total: 0.014940 (Epoch 68)\n",
      "Epoch   71: Train: 0.015984, Val: 0.003518, Total: 0.014203, LR: 1.40e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.015984, Val: 0.003518, Total: 0.014203 (Epoch 71)\n",
      "Epoch   72: Train: 0.016784, Val: 0.003782, Total: 0.014927, LR: 1.42e-04 [WARMUP]\n",
      "          Best: Train: 0.015984, Val: 0.003518, Total: 0.014203 (Epoch 71)\n",
      "Epoch   73: Train: 0.015976, Val: 0.003453, Total: 0.014187, LR: 1.44e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.015976, Val: 0.003453, Total: 0.014187 (Epoch 73)\n",
      "Epoch   74: Train: 0.015893, Val: 0.003450, Total: 0.014115, LR: 1.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.015893, Val: 0.003450, Total: 0.014115 (Epoch 74)\n",
      "Epoch   75: Train: 0.014709, Val: 0.003172, Total: 0.013061, LR: 1.48e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.014709, Val: 0.003172, Total: 0.013061 (Epoch 75)\n",
      "Epoch   76: Train: 0.014330, Val: 0.002888, Total: 0.012696, LR: 1.50e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.014330, Val: 0.002888, Total: 0.012696 (Epoch 76)\n",
      "Epoch   77: Train: 0.013095, Val: 0.002790, Total: 0.011623, LR: 1.52e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.013095, Val: 0.002790, Total: 0.011623 (Epoch 77)\n",
      "Epoch   78: Train: 0.013364, Val: 0.002782, Total: 0.011852, LR: 1.54e-04 [WARMUP]\n",
      "          Best: Train: 0.013095, Val: 0.002790, Total: 0.011623 (Epoch 77)\n",
      "Epoch   79: Train: 0.015039, Val: 0.003399, Total: 0.013376, LR: 1.56e-04 [WARMUP]\n",
      "          Best: Train: 0.013095, Val: 0.002790, Total: 0.011623 (Epoch 77)\n",
      "Epoch   80: Train: 0.013532, Val: 0.002723, Total: 0.011988, LR: 1.58e-04 [WARMUP]\n",
      "          Best: Train: 0.013095, Val: 0.002790, Total: 0.011623 (Epoch 77)\n",
      "Epoch   81: Train: 0.012585, Val: 0.002915, Total: 0.011203, LR: 1.60e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.012585, Val: 0.002915, Total: 0.011203 (Epoch 81)\n",
      "Epoch   82: Train: 0.012219, Val: 0.003255, Total: 0.010938, LR: 1.62e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.012219, Val: 0.003255, Total: 0.010938 (Epoch 82)\n",
      "Epoch   83: Train: 0.012069, Val: 0.003214, Total: 0.010804, LR: 1.64e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.012069, Val: 0.003214, Total: 0.010804 (Epoch 83)\n",
      "Epoch   84: Train: 0.010786, Val: 0.003467, Total: 0.009740, LR: 1.66e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010786, Val: 0.003467, Total: 0.009740 (Epoch 84)\n",
      "Epoch   85: Train: 0.011796, Val: 0.003916, Total: 0.010671, LR: 1.68e-04 [WARMUP]\n",
      "          Best: Train: 0.010786, Val: 0.003467, Total: 0.009740 (Epoch 84)\n",
      "Epoch   86: Train: 0.010814, Val: 0.003238, Total: 0.009732, LR: 1.70e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010814, Val: 0.003238, Total: 0.009732 (Epoch 86)\n",
      "Epoch   87: Train: 0.012306, Val: 0.003236, Total: 0.011010, LR: 1.72e-04 [WARMUP]\n",
      "          Best: Train: 0.010814, Val: 0.003238, Total: 0.009732 (Epoch 86)\n",
      "Epoch   88: Train: 0.010015, Val: 0.003170, Total: 0.009037, LR: 1.74e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010015, Val: 0.003170, Total: 0.009037 (Epoch 88)\n",
      "Epoch   89: Train: 0.009507, Val: 0.003368, Total: 0.008630, LR: 1.76e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.009507, Val: 0.003368, Total: 0.008630 (Epoch 89)\n",
      "Epoch   90: Train: 0.009753, Val: 0.003466, Total: 0.008855, LR: 1.78e-04 [WARMUP]\n",
      "          Best: Train: 0.009507, Val: 0.003368, Total: 0.008630 (Epoch 89)\n",
      "Epoch   91: Train: 0.009326, Val: 0.003842, Total: 0.008543, LR: 1.80e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.009326, Val: 0.003842, Total: 0.008543 (Epoch 91)\n",
      "Epoch   92: Train: 0.009848, Val: 0.003820, Total: 0.008987, LR: 1.82e-04 [WARMUP]\n",
      "          Best: Train: 0.009326, Val: 0.003842, Total: 0.008543 (Epoch 91)\n",
      "Epoch   93: Train: 0.008002, Val: 0.004398, Total: 0.007487, LR: 1.84e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008002, Val: 0.004398, Total: 0.007487 (Epoch 93)\n",
      "Epoch   94: Train: 0.008686, Val: 0.004883, Total: 0.008143, LR: 1.86e-04 [WARMUP]\n",
      "          Best: Train: 0.008002, Val: 0.004398, Total: 0.007487 (Epoch 93)\n",
      "Epoch   95: Train: 0.009275, Val: 0.005069, Total: 0.008674, LR: 1.88e-04 [WARMUP]\n",
      "          Best: Train: 0.008002, Val: 0.004398, Total: 0.007487 (Epoch 93)\n",
      "Epoch   96: Train: 0.008425, Val: 0.005966, Total: 0.008074, LR: 1.90e-04 [WARMUP]\n",
      "          Best: Train: 0.008002, Val: 0.004398, Total: 0.007487 (Epoch 93)\n",
      "Epoch   97: Train: 0.007969, Val: 0.006326, Total: 0.007734, LR: 1.92e-04 [WARMUP]\n",
      "          Best: Train: 0.008002, Val: 0.004398, Total: 0.007487 (Epoch 93)\n",
      "Epoch   98: Train: 0.007117, Val: 0.006725, Total: 0.007061, LR: 1.94e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.007117, Val: 0.006725, Total: 0.007061 (Epoch 98)\n",
      "Epoch   99: Train: 0.007035, Val: 0.007004, Total: 0.007030, LR: 1.96e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.007035, Val: 0.007004, Total: 0.007030 (Epoch 99)\n",
      "Epoch  100: Train: 0.008015, Val: 0.007712, Total: 0.007972, LR: 1.98e-04 [WARMUP]\n",
      "          Best: Train: 0.007035, Val: 0.007004, Total: 0.007030 (Epoch 99)\n",
      "Epoch  101: Train: 0.007624, Val: 0.007696, Total: 0.007635, LR: 2.00e-04 [WARMUP]\n",
      "          Best: Train: 0.007035, Val: 0.007004, Total: 0.007030 (Epoch 99)\n",
      "Epoch  102: Train: 0.006871, Val: 0.007688, Total: 0.006988, LR: 2.02e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006871, Val: 0.007688, Total: 0.006988 (Epoch 102)\n",
      "Epoch  103: Train: 0.007319, Val: 0.006979, Total: 0.007270, LR: 2.04e-04 [WARMUP]\n",
      "          Best: Train: 0.006871, Val: 0.007688, Total: 0.006988 (Epoch 102)\n",
      "Epoch  104: Train: 0.006813, Val: 0.006806, Total: 0.006812, LR: 2.06e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006813, Val: 0.006806, Total: 0.006812 (Epoch 104)\n",
      "Epoch  105: Train: 0.006652, Val: 0.007224, Total: 0.006734, LR: 2.08e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006652, Val: 0.007224, Total: 0.006734 (Epoch 105)\n",
      "Epoch  106: Train: 0.006413, Val: 0.008522, Total: 0.006714, LR: 2.10e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006413, Val: 0.008522, Total: 0.006714 (Epoch 106)\n",
      "Epoch  107: Train: 0.006899, Val: 0.007302, Total: 0.006956, LR: 2.11e-04 [WARMUP]\n",
      "          Best: Train: 0.006413, Val: 0.008522, Total: 0.006714 (Epoch 106)\n",
      "Epoch  108: Train: 0.007024, Val: 0.007114, Total: 0.007037, LR: 2.13e-04 [WARMUP]\n",
      "          Best: Train: 0.006413, Val: 0.008522, Total: 0.006714 (Epoch 106)\n",
      "Epoch  109: Train: 0.006843, Val: 0.008313, Total: 0.007053, LR: 2.15e-04 [WARMUP]\n",
      "          Best: Train: 0.006413, Val: 0.008522, Total: 0.006714 (Epoch 106)\n",
      "Epoch  110: Train: 0.005964, Val: 0.007103, Total: 0.006127, LR: 2.17e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005964, Val: 0.007103, Total: 0.006127 (Epoch 110)\n",
      "Epoch  111: Train: 0.005614, Val: 0.006505, Total: 0.005741, LR: 2.19e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005614, Val: 0.006505, Total: 0.005741 (Epoch 111)\n",
      "Epoch  112: Train: 0.005817, Val: 0.006680, Total: 0.005940, LR: 2.21e-04 [WARMUP]\n",
      "          Best: Train: 0.005614, Val: 0.006505, Total: 0.005741 (Epoch 111)\n",
      "Epoch  113: Train: 0.006202, Val: 0.006423, Total: 0.006233, LR: 2.23e-04 [WARMUP]\n",
      "          Best: Train: 0.005614, Val: 0.006505, Total: 0.005741 (Epoch 111)\n",
      "Epoch  114: Train: 0.005091, Val: 0.006906, Total: 0.005351, LR: 2.25e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005091, Val: 0.006906, Total: 0.005351 (Epoch 114)\n",
      "Epoch  115: Train: 0.004762, Val: 0.007013, Total: 0.005084, LR: 2.27e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004762, Val: 0.007013, Total: 0.005084 (Epoch 115)\n",
      "Epoch  116: Train: 0.005379, Val: 0.007209, Total: 0.005640, LR: 2.29e-04 [WARMUP]\n",
      "          Best: Train: 0.004762, Val: 0.007013, Total: 0.005084 (Epoch 115)\n",
      "Epoch  117: Train: 0.004846, Val: 0.007654, Total: 0.005247, LR: 2.31e-04 [WARMUP]\n",
      "          Best: Train: 0.004762, Val: 0.007013, Total: 0.005084 (Epoch 115)\n",
      "Epoch  118: Train: 0.005208, Val: 0.007858, Total: 0.005587, LR: 2.33e-04 [WARMUP]\n",
      "          Best: Train: 0.004762, Val: 0.007013, Total: 0.005084 (Epoch 115)\n",
      "Epoch  119: Train: 0.004679, Val: 0.008149, Total: 0.005175, LR: 2.35e-04 [WARMUP]\n",
      "          Best: Train: 0.004762, Val: 0.007013, Total: 0.005084 (Epoch 115)\n",
      "Epoch  120: Train: 0.004581, Val: 0.007373, Total: 0.004980, LR: 2.37e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004581, Val: 0.007373, Total: 0.004980 (Epoch 120)\n",
      "Epoch  121: Train: 0.004846, Val: 0.007064, Total: 0.005163, LR: 2.39e-04 [WARMUP]\n",
      "          Best: Train: 0.004581, Val: 0.007373, Total: 0.004980 (Epoch 120)\n",
      "Epoch  122: Train: 0.004303, Val: 0.006846, Total: 0.004666, LR: 2.41e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004303, Val: 0.006846, Total: 0.004666 (Epoch 122)\n",
      "Epoch  123: Train: 0.004311, Val: 0.006771, Total: 0.004663, LR: 2.43e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004311, Val: 0.006771, Total: 0.004663 (Epoch 123)\n",
      "Epoch  124: Train: 0.004361, Val: 0.006871, Total: 0.004719, LR: 2.45e-04 [WARMUP]\n",
      "          Best: Train: 0.004311, Val: 0.006771, Total: 0.004663 (Epoch 123)\n",
      "Epoch  125: Train: 0.004571, Val: 0.006556, Total: 0.004855, LR: 2.47e-04 [WARMUP]\n",
      "          Best: Train: 0.004311, Val: 0.006771, Total: 0.004663 (Epoch 123)\n",
      "Epoch  126: Train: 0.004588, Val: 0.006556, Total: 0.004869, LR: 2.49e-04 [WARMUP]\n",
      "          Best: Train: 0.004311, Val: 0.006771, Total: 0.004663 (Epoch 123)\n",
      "Epoch  127: Train: 0.003725, Val: 0.006948, Total: 0.004186, LR: 2.51e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003725, Val: 0.006948, Total: 0.004186 (Epoch 127)\n",
      "Epoch  128: Train: 0.004121, Val: 0.006605, Total: 0.004475, LR: 2.53e-04 [WARMUP]\n",
      "          Best: Train: 0.003725, Val: 0.006948, Total: 0.004186 (Epoch 127)\n",
      "Epoch  129: Train: 0.004307, Val: 0.006234, Total: 0.004583, LR: 2.55e-04 [WARMUP]\n",
      "          Best: Train: 0.003725, Val: 0.006948, Total: 0.004186 (Epoch 127)\n",
      "Epoch  130: Train: 0.003749, Val: 0.006140, Total: 0.004091, LR: 2.57e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003749, Val: 0.006140, Total: 0.004091 (Epoch 130)\n",
      "Epoch  131: Train: 0.004156, Val: 0.006393, Total: 0.004475, LR: 2.59e-04 [WARMUP]\n",
      "          Best: Train: 0.003749, Val: 0.006140, Total: 0.004091 (Epoch 130)\n",
      "Epoch  132: Train: 0.003822, Val: 0.006768, Total: 0.004243, LR: 2.61e-04 [WARMUP]\n",
      "          Best: Train: 0.003749, Val: 0.006140, Total: 0.004091 (Epoch 130)\n",
      "Epoch  133: Train: 0.003924, Val: 0.006572, Total: 0.004302, LR: 2.63e-04 [WARMUP]\n",
      "          Best: Train: 0.003749, Val: 0.006140, Total: 0.004091 (Epoch 130)\n",
      "Epoch  134: Train: 0.004100, Val: 0.006430, Total: 0.004433, LR: 2.65e-04 [WARMUP]\n",
      "          Best: Train: 0.003749, Val: 0.006140, Total: 0.004091 (Epoch 130)\n",
      "Epoch  135: Train: 0.003606, Val: 0.006886, Total: 0.004075, LR: 2.67e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003606, Val: 0.006886, Total: 0.004075 (Epoch 135)\n",
      "Epoch  136: Train: 0.003973, Val: 0.006653, Total: 0.004356, LR: 2.69e-04 [WARMUP]\n",
      "          Best: Train: 0.003606, Val: 0.006886, Total: 0.004075 (Epoch 135)\n",
      "Epoch  137: Train: 0.003775, Val: 0.006457, Total: 0.004158, LR: 2.71e-04 [WARMUP]\n",
      "          Best: Train: 0.003606, Val: 0.006886, Total: 0.004075 (Epoch 135)\n",
      "Epoch  138: Train: 0.003779, Val: 0.006065, Total: 0.004106, LR: 2.73e-04 [WARMUP]\n",
      "          Best: Train: 0.003606, Val: 0.006886, Total: 0.004075 (Epoch 135)\n",
      "Epoch  139: Train: 0.004028, Val: 0.005994, Total: 0.004309, LR: 2.75e-04 [WARMUP]\n",
      "          Best: Train: 0.003606, Val: 0.006886, Total: 0.004075 (Epoch 135)\n",
      "Epoch  140: Train: 0.003662, Val: 0.006316, Total: 0.004041, LR: 2.77e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003662, Val: 0.006316, Total: 0.004041 (Epoch 140)\n",
      "Epoch  141: Train: 0.003960, Val: 0.006726, Total: 0.004355, LR: 2.79e-04 [WARMUP]\n",
      "          Best: Train: 0.003662, Val: 0.006316, Total: 0.004041 (Epoch 140)\n",
      "Epoch  142: Train: 0.003449, Val: 0.006760, Total: 0.003922, LR: 2.81e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003449, Val: 0.006760, Total: 0.003922 (Epoch 142)\n",
      "Epoch  143: Train: 0.003498, Val: 0.005997, Total: 0.003855, LR: 2.83e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003498, Val: 0.005997, Total: 0.003855 (Epoch 143)\n",
      "Epoch  144: Train: 0.003205, Val: 0.005981, Total: 0.003602, LR: 2.85e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003205, Val: 0.005981, Total: 0.003602 (Epoch 144)\n",
      "Epoch  145: Train: 0.003432, Val: 0.006407, Total: 0.003857, LR: 2.87e-04 [WARMUP]\n",
      "          Best: Train: 0.003205, Val: 0.005981, Total: 0.003602 (Epoch 144)\n",
      "Epoch  146: Train: 0.003213, Val: 0.006360, Total: 0.003662, LR: 2.89e-04 [WARMUP]\n",
      "          Best: Train: 0.003205, Val: 0.005981, Total: 0.003602 (Epoch 144)\n",
      "Epoch  147: Train: 0.002987, Val: 0.006346, Total: 0.003467, LR: 2.91e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002987, Val: 0.006346, Total: 0.003467 (Epoch 147)\n",
      "Epoch  148: Train: 0.002967, Val: 0.006433, Total: 0.003462, LR: 2.93e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002967, Val: 0.006433, Total: 0.003462 (Epoch 148)\n",
      "Epoch  149: Train: 0.003357, Val: 0.006379, Total: 0.003789, LR: 2.94e-04 [WARMUP]\n",
      "          Best: Train: 0.002967, Val: 0.006433, Total: 0.003462 (Epoch 148)\n",
      "Epoch  150: Train: 0.003186, Val: 0.005368, Total: 0.003498, LR: 2.96e-04 [WARMUP]\n",
      "          Best: Train: 0.002967, Val: 0.006433, Total: 0.003462 (Epoch 148)\n",
      "Epoch  151: Train: 0.003288, Val: 0.005305, Total: 0.003576, LR: 2.98e-04 [WARMUP]\n",
      "          Best: Train: 0.002967, Val: 0.006433, Total: 0.003462 (Epoch 148)\n",
      "Epoch  152: Train: 0.003057, Val: 0.006024, Total: 0.003481, LR: 3.00e-04 [WARMUP]\n",
      "          Best: Train: 0.002967, Val: 0.006433, Total: 0.003462 (Epoch 148)\n",
      "Epoch  153: Train: 0.002840, Val: 0.005911, Total: 0.003279, LR: 3.02e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002840, Val: 0.005911, Total: 0.003279 (Epoch 153)\n",
      "Epoch  154: Train: 0.002889, Val: 0.005959, Total: 0.003328, LR: 3.04e-04 [WARMUP]\n",
      "          Best: Train: 0.002840, Val: 0.005911, Total: 0.003279 (Epoch 153)\n",
      "Epoch  155: Train: 0.003039, Val: 0.006431, Total: 0.003523, LR: 3.06e-04 [WARMUP]\n",
      "          Best: Train: 0.002840, Val: 0.005911, Total: 0.003279 (Epoch 153)\n",
      "Epoch  156: Train: 0.002868, Val: 0.005820, Total: 0.003290, LR: 3.08e-04 [WARMUP]\n",
      "          Best: Train: 0.002840, Val: 0.005911, Total: 0.003279 (Epoch 153)\n",
      "Epoch  157: Train: 0.003019, Val: 0.005006, Total: 0.003303, LR: 3.10e-04 [WARMUP]\n",
      "          Best: Train: 0.002840, Val: 0.005911, Total: 0.003279 (Epoch 153)\n",
      "Epoch  158: Train: 0.002849, Val: 0.004883, Total: 0.003140, LR: 3.12e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002849, Val: 0.004883, Total: 0.003140 (Epoch 158)\n",
      "Epoch  159: Train: 0.002894, Val: 0.005403, Total: 0.003252, LR: 3.14e-04 [WARMUP]\n",
      "          Best: Train: 0.002849, Val: 0.004883, Total: 0.003140 (Epoch 158)\n",
      "Epoch  160: Train: 0.003020, Val: 0.005786, Total: 0.003415, LR: 3.16e-04 [WARMUP]\n",
      "          Best: Train: 0.002849, Val: 0.004883, Total: 0.003140 (Epoch 158)\n",
      "Epoch  161: Train: 0.002847, Val: 0.006491, Total: 0.003368, LR: 3.18e-04 [WARMUP]\n",
      "          Best: Train: 0.002849, Val: 0.004883, Total: 0.003140 (Epoch 158)\n",
      "Epoch  162: Train: 0.002916, Val: 0.006521, Total: 0.003431, LR: 3.20e-04 [WARMUP]\n",
      "          Best: Train: 0.002849, Val: 0.004883, Total: 0.003140 (Epoch 158)\n",
      "Epoch  163: Train: 0.002689, Val: 0.005730, Total: 0.003124, LR: 3.22e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002689, Val: 0.005730, Total: 0.003124 (Epoch 163)\n",
      "Epoch  164: Train: 0.002647, Val: 0.004921, Total: 0.002972, LR: 3.24e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002647, Val: 0.004921, Total: 0.002972 (Epoch 164)\n",
      "Epoch  165: Train: 0.002570, Val: 0.004809, Total: 0.002890, LR: 3.26e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002570, Val: 0.004809, Total: 0.002890 (Epoch 165)\n",
      "Epoch  166: Train: 0.002506, Val: 0.005375, Total: 0.002916, LR: 3.28e-04 [WARMUP]\n",
      "          Best: Train: 0.002570, Val: 0.004809, Total: 0.002890 (Epoch 165)\n",
      "Epoch  167: Train: 0.002566, Val: 0.005664, Total: 0.003008, LR: 3.30e-04 [WARMUP]\n",
      "          Best: Train: 0.002570, Val: 0.004809, Total: 0.002890 (Epoch 165)\n",
      "Epoch  168: Train: 0.002588, Val: 0.005259, Total: 0.002969, LR: 3.32e-04 [WARMUP]\n",
      "          Best: Train: 0.002570, Val: 0.004809, Total: 0.002890 (Epoch 165)\n",
      "Epoch  169: Train: 0.002486, Val: 0.005053, Total: 0.002852, LR: 3.34e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002486, Val: 0.005053, Total: 0.002852 (Epoch 169)\n",
      "Epoch  170: Train: 0.002460, Val: 0.005056, Total: 0.002831, LR: 3.36e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002460, Val: 0.005056, Total: 0.002831 (Epoch 170)\n",
      "Epoch  171: Train: 0.002571, Val: 0.005150, Total: 0.002939, LR: 3.38e-04 [WARMUP]\n",
      "          Best: Train: 0.002460, Val: 0.005056, Total: 0.002831 (Epoch 170)\n",
      "Epoch  172: Train: 0.002367, Val: 0.004991, Total: 0.002742, LR: 3.40e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002367, Val: 0.004991, Total: 0.002742 (Epoch 172)\n",
      "Epoch  173: Train: 0.002357, Val: 0.004786, Total: 0.002704, LR: 3.42e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002357, Val: 0.004786, Total: 0.002704 (Epoch 173)\n",
      "Epoch  174: Train: 0.002447, Val: 0.004864, Total: 0.002792, LR: 3.44e-04 [WARMUP]\n",
      "          Best: Train: 0.002357, Val: 0.004786, Total: 0.002704 (Epoch 173)\n",
      "Epoch  175: Train: 0.002325, Val: 0.004513, Total: 0.002638, LR: 3.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002325, Val: 0.004513, Total: 0.002638 (Epoch 175)\n",
      "Epoch  176: Train: 0.002461, Val: 0.004867, Total: 0.002804, LR: 3.48e-04 [WARMUP]\n",
      "          Best: Train: 0.002325, Val: 0.004513, Total: 0.002638 (Epoch 175)\n",
      "Epoch  177: Train: 0.002261, Val: 0.004600, Total: 0.002595, LR: 3.50e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002261, Val: 0.004600, Total: 0.002595 (Epoch 177)\n",
      "Epoch  178: Train: 0.002404, Val: 0.004940, Total: 0.002766, LR: 3.52e-04 [WARMUP]\n",
      "          Best: Train: 0.002261, Val: 0.004600, Total: 0.002595 (Epoch 177)\n",
      "Epoch  179: Train: 0.002091, Val: 0.004563, Total: 0.002444, LR: 3.54e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  180: Train: 0.002223, Val: 0.004976, Total: 0.002617, LR: 3.56e-04 [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  181: Train: 0.002260, Val: 0.004885, Total: 0.002635, LR: 3.58e-04 [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  182: Train: 0.002282, Val: 0.004600, Total: 0.002613, LR: 3.60e-04 [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  183: Train: 0.002383, Val: 0.004991, Total: 0.002756, LR: 3.62e-04 [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  184: Train: 0.002280, Val: 0.004008, Total: 0.002527, LR: 3.64e-04 [WARMUP]\n",
      "          Best: Train: 0.002091, Val: 0.004563, Total: 0.002444 (Epoch 179)\n",
      "Epoch  185: Train: 0.002170, Val: 0.003971, Total: 0.002427, LR: 3.66e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002170, Val: 0.003971, Total: 0.002427 (Epoch 185)\n",
      "Epoch  186: Train: 0.001901, Val: 0.004243, Total: 0.002236, LR: 3.68e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  187: Train: 0.002083, Val: 0.004316, Total: 0.002402, LR: 3.70e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  188: Train: 0.002165, Val: 0.003963, Total: 0.002421, LR: 3.72e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  189: Train: 0.002161, Val: 0.004965, Total: 0.002561, LR: 3.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  190: Train: 0.002020, Val: 0.004544, Total: 0.002380, LR: 3.76e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  191: Train: 0.002068, Val: 0.003825, Total: 0.002319, LR: 3.77e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  192: Train: 0.002138, Val: 0.004682, Total: 0.002501, LR: 3.79e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  193: Train: 0.002041, Val: 0.004682, Total: 0.002418, LR: 3.81e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  194: Train: 0.002120, Val: 0.004742, Total: 0.002495, LR: 3.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  195: Train: 0.002074, Val: 0.004548, Total: 0.002428, LR: 3.85e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  196: Train: 0.002055, Val: 0.003904, Total: 0.002319, LR: 3.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  197: Train: 0.002020, Val: 0.003573, Total: 0.002242, LR: 3.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  198: Train: 0.001993, Val: 0.004572, Total: 0.002362, LR: 3.91e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  199: Train: 0.002090, Val: 0.004211, Total: 0.002393, LR: 3.93e-04 [WARMUP]\n",
      "          Best: Train: 0.001901, Val: 0.004243, Total: 0.002236 (Epoch 186)\n",
      "Epoch  200: Train: 0.001906, Val: 0.003537, Total: 0.002139, LR: 3.95e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001906, Val: 0.003537, Total: 0.002139 (Epoch 200)\n",
      "Epoch  201: Train: 0.001803, Val: 0.003682, Total: 0.002071, LR: 3.97e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001803, Val: 0.003682, Total: 0.002071 (Epoch 201)\n",
      "Epoch  202: Train: 0.001955, Val: 0.004060, Total: 0.002256, LR: 3.99e-04 [WARMUP]\n",
      "          Best: Train: 0.001803, Val: 0.003682, Total: 0.002071 (Epoch 201)\n",
      "Epoch  203: Train: 0.001909, Val: 0.003699, Total: 0.002165, LR: 4.01e-04 [WARMUP]\n",
      "          Best: Train: 0.001803, Val: 0.003682, Total: 0.002071 (Epoch 201)\n",
      "Epoch  204: Train: 0.001823, Val: 0.003953, Total: 0.002127, LR: 4.03e-04 [WARMUP]\n",
      "          Best: Train: 0.001803, Val: 0.003682, Total: 0.002071 (Epoch 201)\n",
      "Epoch  205: Train: 0.001927, Val: 0.003513, Total: 0.002154, LR: 4.05e-04 [WARMUP]\n",
      "          Best: Train: 0.001803, Val: 0.003682, Total: 0.002071 (Epoch 201)\n",
      "Epoch  206: Train: 0.001839, Val: 0.003421, Total: 0.002065, LR: 4.07e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001839, Val: 0.003421, Total: 0.002065 (Epoch 206)\n",
      "Epoch  207: Train: 0.001794, Val: 0.003751, Total: 0.002073, LR: 4.09e-04 [WARMUP]\n",
      "          Best: Train: 0.001839, Val: 0.003421, Total: 0.002065 (Epoch 206)\n",
      "Epoch  208: Train: 0.001762, Val: 0.004290, Total: 0.002123, LR: 4.11e-04 [WARMUP]\n",
      "          Best: Train: 0.001839, Val: 0.003421, Total: 0.002065 (Epoch 206)\n",
      "Epoch  209: Train: 0.001767, Val: 0.003526, Total: 0.002019, LR: 4.13e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001767, Val: 0.003526, Total: 0.002019 (Epoch 209)\n",
      "Epoch  210: Train: 0.001821, Val: 0.004400, Total: 0.002190, LR: 4.15e-04 [WARMUP]\n",
      "          Best: Train: 0.001767, Val: 0.003526, Total: 0.002019 (Epoch 209)\n",
      "Epoch  211: Train: 0.001822, Val: 0.003959, Total: 0.002128, LR: 4.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001767, Val: 0.003526, Total: 0.002019 (Epoch 209)\n",
      "Epoch  212: Train: 0.001657, Val: 0.003317, Total: 0.001894, LR: 4.19e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  213: Train: 0.001782, Val: 0.003429, Total: 0.002017, LR: 4.21e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  214: Train: 0.001625, Val: 0.004211, Total: 0.001994, LR: 4.23e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  215: Train: 0.001716, Val: 0.004334, Total: 0.002090, LR: 4.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  216: Train: 0.001613, Val: 0.004007, Total: 0.001955, LR: 4.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  217: Train: 0.001847, Val: 0.003681, Total: 0.002109, LR: 4.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  218: Train: 0.001586, Val: 0.003980, Total: 0.001928, LR: 4.31e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  219: Train: 0.001795, Val: 0.003656, Total: 0.002061, LR: 4.33e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  220: Train: 0.001647, Val: 0.003580, Total: 0.001923, LR: 4.35e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  221: Train: 0.001698, Val: 0.003738, Total: 0.001990, LR: 4.37e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  222: Train: 0.001743, Val: 0.003959, Total: 0.002060, LR: 4.39e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  223: Train: 0.001717, Val: 0.003325, Total: 0.001947, LR: 4.41e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  224: Train: 0.001763, Val: 0.003558, Total: 0.002020, LR: 4.43e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  225: Train: 0.001755, Val: 0.003523, Total: 0.002008, LR: 4.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  226: Train: 0.001649, Val: 0.003609, Total: 0.001929, LR: 4.47e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  227: Train: 0.001655, Val: 0.004018, Total: 0.001992, LR: 4.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  228: Train: 0.001586, Val: 0.003810, Total: 0.001904, LR: 4.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  229: Train: 0.001685, Val: 0.003668, Total: 0.001968, LR: 4.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001657, Val: 0.003317, Total: 0.001894 (Epoch 212)\n",
      "Epoch  230: Train: 0.001509, Val: 0.004046, Total: 0.001872, LR: 4.55e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001509, Val: 0.004046, Total: 0.001872 (Epoch 230)\n",
      "Epoch  231: Train: 0.001525, Val: 0.003514, Total: 0.001809, LR: 4.57e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  232: Train: 0.001602, Val: 0.003754, Total: 0.001910, LR: 4.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  233: Train: 0.001564, Val: 0.003562, Total: 0.001850, LR: 4.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  234: Train: 0.001637, Val: 0.003527, Total: 0.001907, LR: 4.62e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  235: Train: 0.001697, Val: 0.003931, Total: 0.002016, LR: 4.64e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  236: Train: 0.001532, Val: 0.003910, Total: 0.001872, LR: 4.66e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  237: Train: 0.001680, Val: 0.003879, Total: 0.001994, LR: 4.68e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  238: Train: 0.001522, Val: 0.003872, Total: 0.001857, LR: 4.70e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  239: Train: 0.001559, Val: 0.004123, Total: 0.001925, LR: 4.72e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  240: Train: 0.001552, Val: 0.003456, Total: 0.001824, LR: 4.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  241: Train: 0.001621, Val: 0.003434, Total: 0.001880, LR: 4.76e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  242: Train: 0.001504, Val: 0.003980, Total: 0.001858, LR: 4.78e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  243: Train: 0.001693, Val: 0.003506, Total: 0.001952, LR: 4.80e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  244: Train: 0.001614, Val: 0.003271, Total: 0.001850, LR: 4.82e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  245: Train: 0.001831, Val: 0.003626, Total: 0.002088, LR: 4.84e-04 [WARMUP]\n",
      "          Best: Train: 0.001525, Val: 0.003514, Total: 0.001809 (Epoch 231)\n",
      "Epoch  246: Train: 0.001513, Val: 0.003511, Total: 0.001799, LR: 4.86e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001513, Val: 0.003511, Total: 0.001799 (Epoch 246)\n",
      "Epoch  247: Train: 0.001591, Val: 0.004018, Total: 0.001938, LR: 4.88e-04 [WARMUP]\n",
      "          Best: Train: 0.001513, Val: 0.003511, Total: 0.001799 (Epoch 246)\n",
      "Epoch  248: Train: 0.001496, Val: 0.003944, Total: 0.001846, LR: 4.90e-04 [WARMUP]\n",
      "          Best: Train: 0.001513, Val: 0.003511, Total: 0.001799 (Epoch 246)\n",
      "Epoch  249: Train: 0.001496, Val: 0.003750, Total: 0.001818, LR: 4.92e-04 [WARMUP]\n",
      "          Best: Train: 0.001513, Val: 0.003511, Total: 0.001799 (Epoch 246)\n",
      "Epoch  250: Train: 0.001602, Val: 0.003264, Total: 0.001839, LR: 4.94e-04 [WARMUP]\n",
      "          Best: Train: 0.001513, Val: 0.003511, Total: 0.001799 (Epoch 246)\n",
      "Epoch  251: Train: 0.001490, Val: 0.003405, Total: 0.001764, LR: 4.96e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.003405, Total: 0.001764 (Epoch 251)\n",
      "Epoch  252: Train: 0.001590, Val: 0.003534, Total: 0.001868, LR: 4.98e-04 [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.003405, Total: 0.001764 (Epoch 251)\n",
      "Epoch  253: Train: 0.001505, Val: 0.003283, Total: 0.001759, LR: 5.00e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  254: Train: 0.001506, Val: 0.003769, Total: 0.001830, LR: 5.02e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  255: Train: 0.001470, Val: 0.003611, Total: 0.001776, LR: 5.04e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  256: Train: 0.001495, Val: 0.003823, Total: 0.001828, LR: 5.06e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  257: Train: 0.001628, Val: 0.003413, Total: 0.001883, LR: 5.08e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  258: Train: 0.001489, Val: 0.003781, Total: 0.001816, LR: 5.10e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  259: Train: 0.001424, Val: 0.003973, Total: 0.001788, LR: 5.12e-04 [WARMUP]\n",
      "          Best: Train: 0.001505, Val: 0.003283, Total: 0.001759 (Epoch 253)\n",
      "Epoch  260: Train: 0.001369, Val: 0.003331, Total: 0.001650, LR: 5.14e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  261: Train: 0.001423, Val: 0.003369, Total: 0.001701, LR: 5.16e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  262: Train: 0.001453, Val: 0.003943, Total: 0.001808, LR: 5.18e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  263: Train: 0.001527, Val: 0.003770, Total: 0.001847, LR: 5.20e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  264: Train: 0.001462, Val: 0.003648, Total: 0.001775, LR: 5.22e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  265: Train: 0.001480, Val: 0.003806, Total: 0.001812, LR: 5.24e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  266: Train: 0.001472, Val: 0.003703, Total: 0.001791, LR: 5.26e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  267: Train: 0.001442, Val: 0.003874, Total: 0.001789, LR: 5.28e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  268: Train: 0.001419, Val: 0.003847, Total: 0.001766, LR: 5.30e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  269: Train: 0.001384, Val: 0.003393, Total: 0.001671, LR: 5.32e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  270: Train: 0.001519, Val: 0.003837, Total: 0.001850, LR: 5.34e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  271: Train: 0.001420, Val: 0.003789, Total: 0.001758, LR: 5.36e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  272: Train: 0.001445, Val: 0.003765, Total: 0.001776, LR: 5.38e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  273: Train: 0.001368, Val: 0.004760, Total: 0.001852, LR: 5.40e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  274: Train: 0.001484, Val: 0.003472, Total: 0.001768, LR: 5.42e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  275: Train: 0.001352, Val: 0.003498, Total: 0.001659, LR: 5.44e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  276: Train: 0.001312, Val: 0.004097, Total: 0.001710, LR: 5.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  277: Train: 0.001482, Val: 0.003858, Total: 0.001821, LR: 5.47e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  278: Train: 0.001569, Val: 0.002987, Total: 0.001771, LR: 5.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  279: Train: 0.001632, Val: 0.003740, Total: 0.001933, LR: 5.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  280: Train: 0.001468, Val: 0.004256, Total: 0.001866, LR: 5.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001369, Val: 0.003331, Total: 0.001650 (Epoch 260)\n",
      "Epoch  281: Train: 0.001341, Val: 0.003377, Total: 0.001632, LR: 5.55e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001341, Val: 0.003377, Total: 0.001632 (Epoch 281)\n",
      "Epoch  282: Train: 0.001558, Val: 0.003264, Total: 0.001801, LR: 5.57e-04 [WARMUP]\n",
      "          Best: Train: 0.001341, Val: 0.003377, Total: 0.001632 (Epoch 281)\n",
      "Epoch  283: Train: 0.001529, Val: 0.003176, Total: 0.001764, LR: 5.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001341, Val: 0.003377, Total: 0.001632 (Epoch 281)\n",
      "Epoch  284: Train: 0.001322, Val: 0.004349, Total: 0.001755, LR: 5.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001341, Val: 0.003377, Total: 0.001632 (Epoch 281)\n",
      "Epoch  285: Train: 0.001341, Val: 0.003759, Total: 0.001687, LR: 5.63e-04 [WARMUP]\n",
      "          Best: Train: 0.001341, Val: 0.003377, Total: 0.001632 (Epoch 281)\n",
      "Epoch  286: Train: 0.001216, Val: 0.003286, Total: 0.001512, LR: 5.65e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  287: Train: 0.001334, Val: 0.003253, Total: 0.001608, LR: 5.67e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  288: Train: 0.001423, Val: 0.003931, Total: 0.001781, LR: 5.69e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  289: Train: 0.001319, Val: 0.003704, Total: 0.001660, LR: 5.71e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  290: Train: 0.001366, Val: 0.003747, Total: 0.001706, LR: 5.73e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  291: Train: 0.001319, Val: 0.003947, Total: 0.001695, LR: 5.75e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  292: Train: 0.001242, Val: 0.003358, Total: 0.001544, LR: 5.77e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  293: Train: 0.001289, Val: 0.003236, Total: 0.001567, LR: 5.79e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  294: Train: 0.001285, Val: 0.003429, Total: 0.001591, LR: 5.81e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  295: Train: 0.001423, Val: 0.003066, Total: 0.001658, LR: 5.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001216, Val: 0.003286, Total: 0.001512 (Epoch 286)\n",
      "Epoch  296: Train: 0.001160, Val: 0.003587, Total: 0.001507, LR: 5.85e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  297: Train: 0.001221, Val: 0.003594, Total: 0.001560, LR: 5.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  298: Train: 0.001206, Val: 0.003503, Total: 0.001534, LR: 5.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  299: Train: 0.001274, Val: 0.003403, Total: 0.001578, LR: 5.91e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  300: Train: 0.001200, Val: 0.003450, Total: 0.001522, LR: 5.93e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  301: Train: 0.001431, Val: 0.003213, Total: 0.001685, LR: 5.95e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  302: Train: 0.001406, Val: 0.003303, Total: 0.001677, LR: 5.97e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  303: Train: 0.001280, Val: 0.003734, Total: 0.001631, LR: 5.99e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  304: Train: 0.001361, Val: 0.003353, Total: 0.001646, LR: 6.01e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  305: Train: 0.001328, Val: 0.003002, Total: 0.001567, LR: 6.03e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  306: Train: 0.001230, Val: 0.003684, Total: 0.001581, LR: 6.05e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  307: Train: 0.001221, Val: 0.003513, Total: 0.001548, LR: 6.07e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  308: Train: 0.001382, Val: 0.003461, Total: 0.001679, LR: 6.09e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  309: Train: 0.001504, Val: 0.003012, Total: 0.001719, LR: 6.11e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  310: Train: 0.001386, Val: 0.003454, Total: 0.001681, LR: 6.13e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  311: Train: 0.001323, Val: 0.004464, Total: 0.001772, LR: 6.15e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  312: Train: 0.001481, Val: 0.003622, Total: 0.001787, LR: 6.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  313: Train: 0.001211, Val: 0.003748, Total: 0.001574, LR: 6.19e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  314: Train: 0.001262, Val: 0.003087, Total: 0.001523, LR: 6.21e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  315: Train: 0.001322, Val: 0.003351, Total: 0.001612, LR: 6.23e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  316: Train: 0.001258, Val: 0.003663, Total: 0.001601, LR: 6.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  317: Train: 0.001414, Val: 0.003515, Total: 0.001714, LR: 6.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  318: Train: 0.001248, Val: 0.003765, Total: 0.001607, LR: 6.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  319: Train: 0.001283, Val: 0.003156, Total: 0.001551, LR: 6.30e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  320: Train: 0.001390, Val: 0.003199, Total: 0.001648, LR: 6.32e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  321: Train: 0.001313, Val: 0.003595, Total: 0.001639, LR: 6.34e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  322: Train: 0.001220, Val: 0.003293, Total: 0.001516, LR: 6.36e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  323: Train: 0.001127, Val: 0.004039, Total: 0.001543, LR: 6.38e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  324: Train: 0.001319, Val: 0.003066, Total: 0.001568, LR: 6.40e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.003587, Total: 0.001507 (Epoch 296)\n",
      "Epoch  325: Train: 0.001177, Val: 0.003418, Total: 0.001497, LR: 6.42e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001177, Val: 0.003418, Total: 0.001497 (Epoch 325)\n",
      "Epoch  326: Train: 0.001273, Val: 0.003216, Total: 0.001550, LR: 6.44e-04 [WARMUP]\n",
      "          Best: Train: 0.001177, Val: 0.003418, Total: 0.001497 (Epoch 325)\n",
      "Epoch  327: Train: 0.001190, Val: 0.003273, Total: 0.001487, LR: 6.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001190, Val: 0.003273, Total: 0.001487 (Epoch 327)\n",
      "Epoch  328: Train: 0.001173, Val: 0.003122, Total: 0.001451, LR: 6.48e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  329: Train: 0.001213, Val: 0.003357, Total: 0.001520, LR: 6.50e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  330: Train: 0.001150, Val: 0.003447, Total: 0.001478, LR: 6.52e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  331: Train: 0.001169, Val: 0.003844, Total: 0.001551, LR: 6.54e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  332: Train: 0.001174, Val: 0.003660, Total: 0.001529, LR: 6.56e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  333: Train: 0.001087, Val: 0.004099, Total: 0.001517, LR: 6.58e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  334: Train: 0.001158, Val: 0.003661, Total: 0.001515, LR: 6.60e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  335: Train: 0.001161, Val: 0.003409, Total: 0.001482, LR: 6.62e-04 [WARMUP]\n",
      "          Best: Train: 0.001173, Val: 0.003122, Total: 0.001451 (Epoch 328)\n",
      "Epoch  336: Train: 0.001080, Val: 0.003155, Total: 0.001377, LR: 6.64e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  337: Train: 0.001274, Val: 0.003442, Total: 0.001584, LR: 6.66e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  338: Train: 0.001302, Val: 0.003585, Total: 0.001628, LR: 6.68e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  339: Train: 0.001199, Val: 0.004078, Total: 0.001610, LR: 6.70e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  340: Train: 0.001231, Val: 0.003842, Total: 0.001604, LR: 6.72e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  341: Train: 0.001278, Val: 0.003712, Total: 0.001626, LR: 6.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  342: Train: 0.001279, Val: 0.003149, Total: 0.001546, LR: 6.76e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  343: Train: 0.001153, Val: 0.003295, Total: 0.001459, LR: 6.78e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  344: Train: 0.001209, Val: 0.003931, Total: 0.001598, LR: 6.80e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  345: Train: 0.001345, Val: 0.003313, Total: 0.001626, LR: 6.82e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  346: Train: 0.001300, Val: 0.003210, Total: 0.001573, LR: 6.84e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  347: Train: 0.001215, Val: 0.003361, Total: 0.001522, LR: 6.86e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  348: Train: 0.001177, Val: 0.003625, Total: 0.001527, LR: 6.88e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  349: Train: 0.001200, Val: 0.003306, Total: 0.001501, LR: 6.90e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  350: Train: 0.001205, Val: 0.003555, Total: 0.001541, LR: 6.92e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  351: Train: 0.001057, Val: 0.003651, Total: 0.001428, LR: 6.94e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  352: Train: 0.001175, Val: 0.003388, Total: 0.001491, LR: 6.96e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  353: Train: 0.001223, Val: 0.003559, Total: 0.001557, LR: 6.98e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  354: Train: 0.001312, Val: 0.003540, Total: 0.001630, LR: 7.00e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  355: Train: 0.001268, Val: 0.003376, Total: 0.001569, LR: 7.02e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  356: Train: 0.001093, Val: 0.003863, Total: 0.001488, LR: 7.04e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  357: Train: 0.001082, Val: 0.003268, Total: 0.001395, LR: 7.06e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  358: Train: 0.001177, Val: 0.004340, Total: 0.001629, LR: 7.08e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  359: Train: 0.001119, Val: 0.003125, Total: 0.001406, LR: 7.10e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  360: Train: 0.001196, Val: 0.003669, Total: 0.001550, LR: 7.12e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  361: Train: 0.001112, Val: 0.003430, Total: 0.001443, LR: 7.13e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  362: Train: 0.001095, Val: 0.003448, Total: 0.001431, LR: 7.15e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  363: Train: 0.001110, Val: 0.004063, Total: 0.001532, LR: 7.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  364: Train: 0.001129, Val: 0.004189, Total: 0.001566, LR: 7.19e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  365: Train: 0.001227, Val: 0.003499, Total: 0.001551, LR: 7.21e-04 [WARMUP]\n",
      "          Best: Train: 0.001080, Val: 0.003155, Total: 0.001377 (Epoch 336)\n",
      "Epoch  366: Train: 0.001051, Val: 0.003293, Total: 0.001371, LR: 7.23e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  367: Train: 0.001176, Val: 0.003598, Total: 0.001522, LR: 7.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  368: Train: 0.001313, Val: 0.004148, Total: 0.001718, LR: 7.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  369: Train: 0.001230, Val: 0.003715, Total: 0.001585, LR: 7.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  370: Train: 0.001074, Val: 0.003509, Total: 0.001422, LR: 7.31e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  371: Train: 0.001063, Val: 0.003920, Total: 0.001471, LR: 7.33e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  372: Train: 0.001155, Val: 0.004374, Total: 0.001615, LR: 7.35e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  373: Train: 0.001137, Val: 0.003433, Total: 0.001465, LR: 7.37e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  374: Train: 0.001170, Val: 0.003068, Total: 0.001441, LR: 7.39e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  375: Train: 0.001181, Val: 0.003750, Total: 0.001548, LR: 7.41e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  376: Train: 0.001257, Val: 0.003209, Total: 0.001536, LR: 7.43e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  377: Train: 0.001565, Val: 0.003642, Total: 0.001862, LR: 7.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  378: Train: 0.001333, Val: 0.005407, Total: 0.001915, LR: 7.47e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  379: Train: 0.001270, Val: 0.004507, Total: 0.001732, LR: 7.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  380: Train: 0.001137, Val: 0.004414, Total: 0.001605, LR: 7.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  381: Train: 0.001154, Val: 0.003806, Total: 0.001533, LR: 7.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  382: Train: 0.001223, Val: 0.004364, Total: 0.001672, LR: 7.55e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  383: Train: 0.001142, Val: 0.003947, Total: 0.001543, LR: 7.57e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  384: Train: 0.001189, Val: 0.003254, Total: 0.001484, LR: 7.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  385: Train: 0.001098, Val: 0.004119, Total: 0.001529, LR: 7.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  386: Train: 0.001059, Val: 0.003891, Total: 0.001464, LR: 7.63e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  387: Train: 0.001039, Val: 0.003702, Total: 0.001419, LR: 7.65e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  388: Train: 0.001000, Val: 0.003938, Total: 0.001420, LR: 7.67e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  389: Train: 0.001081, Val: 0.004189, Total: 0.001525, LR: 7.69e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  390: Train: 0.001048, Val: 0.003991, Total: 0.001469, LR: 7.71e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  391: Train: 0.001099, Val: 0.004203, Total: 0.001543, LR: 7.73e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  392: Train: 0.001061, Val: 0.003620, Total: 0.001426, LR: 7.75e-04 [WARMUP]\n",
      "          Best: Train: 0.001051, Val: 0.003293, Total: 0.001371 (Epoch 366)\n",
      "Epoch  393: Train: 0.001071, Val: 0.003133, Total: 0.001366, LR: 7.77e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001071, Val: 0.003133, Total: 0.001366 (Epoch 393)\n",
      "Epoch  394: Train: 0.001039, Val: 0.003204, Total: 0.001348, LR: 7.79e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  395: Train: 0.001192, Val: 0.003445, Total: 0.001514, LR: 7.81e-04 [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  396: Train: 0.001159, Val: 0.003607, Total: 0.001508, LR: 7.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  397: Train: 0.001214, Val: 0.003303, Total: 0.001513, LR: 7.85e-04 [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  398: Train: 0.001186, Val: 0.003426, Total: 0.001506, LR: 7.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  399: Train: 0.001069, Val: 0.003591, Total: 0.001429, LR: 7.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001039, Val: 0.003204, Total: 0.001348 (Epoch 394)\n",
      "Epoch  400: Train: 0.000970, Val: 0.003432, Total: 0.001322, LR: 7.91e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  401: Train: 0.001070, Val: 0.003396, Total: 0.001402, LR: 7.93e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  402: Train: 0.001025, Val: 0.003377, Total: 0.001361, LR: 7.95e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  403: Train: 0.001011, Val: 0.003613, Total: 0.001383, LR: 7.96e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  404: Train: 0.001077, Val: 0.003679, Total: 0.001449, LR: 7.98e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  405: Train: 0.001097, Val: 0.003962, Total: 0.001506, LR: 8.00e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  406: Train: 0.001182, Val: 0.003310, Total: 0.001486, LR: 8.02e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  407: Train: 0.001124, Val: 0.004017, Total: 0.001538, LR: 8.04e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  408: Train: 0.000965, Val: 0.004208, Total: 0.001428, LR: 8.06e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  409: Train: 0.001212, Val: 0.003935, Total: 0.001601, LR: 8.08e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  410: Train: 0.001135, Val: 0.003756, Total: 0.001510, LR: 8.10e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  411: Train: 0.001314, Val: 0.003780, Total: 0.001666, LR: 8.12e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  412: Train: 0.001188, Val: 0.003038, Total: 0.001452, LR: 8.14e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  413: Train: 0.001130, Val: 0.003280, Total: 0.001437, LR: 8.16e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  414: Train: 0.001178, Val: 0.004114, Total: 0.001597, LR: 8.18e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  415: Train: 0.001098, Val: 0.003063, Total: 0.001379, LR: 8.20e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  416: Train: 0.001091, Val: 0.003053, Total: 0.001371, LR: 8.22e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  417: Train: 0.001052, Val: 0.003913, Total: 0.001460, LR: 8.24e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  418: Train: 0.001062, Val: 0.004097, Total: 0.001496, LR: 8.26e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  419: Train: 0.001108, Val: 0.003143, Total: 0.001399, LR: 8.28e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  420: Train: 0.001024, Val: 0.003531, Total: 0.001382, LR: 8.30e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  421: Train: 0.001205, Val: 0.003267, Total: 0.001500, LR: 8.32e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  422: Train: 0.001039, Val: 0.003416, Total: 0.001379, LR: 8.34e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  423: Train: 0.001141, Val: 0.003435, Total: 0.001468, LR: 8.36e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  424: Train: 0.001131, Val: 0.004145, Total: 0.001562, LR: 8.38e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  425: Train: 0.001084, Val: 0.003114, Total: 0.001374, LR: 8.40e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  426: Train: 0.001115, Val: 0.003427, Total: 0.001445, LR: 8.42e-04 [WARMUP]\n",
      "          Best: Train: 0.000970, Val: 0.003432, Total: 0.001322 (Epoch 400)\n",
      "Epoch  427: Train: 0.000969, Val: 0.003398, Total: 0.001316, LR: 8.44e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000969, Val: 0.003398, Total: 0.001316 (Epoch 427)\n",
      "Epoch  428: Train: 0.000908, Val: 0.003630, Total: 0.001297, LR: 8.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  429: Train: 0.001060, Val: 0.002989, Total: 0.001335, LR: 8.48e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  430: Train: 0.001139, Val: 0.003888, Total: 0.001531, LR: 8.50e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  431: Train: 0.001231, Val: 0.003231, Total: 0.001516, LR: 8.52e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  432: Train: 0.001307, Val: 0.003028, Total: 0.001553, LR: 8.54e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  433: Train: 0.000948, Val: 0.003697, Total: 0.001340, LR: 8.56e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  434: Train: 0.001171, Val: 0.003351, Total: 0.001482, LR: 8.58e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  435: Train: 0.001046, Val: 0.003195, Total: 0.001353, LR: 8.60e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  436: Train: 0.001072, Val: 0.003398, Total: 0.001404, LR: 8.62e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  437: Train: 0.001020, Val: 0.003146, Total: 0.001324, LR: 8.64e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  438: Train: 0.001066, Val: 0.003746, Total: 0.001449, LR: 8.66e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  439: Train: 0.001012, Val: 0.003682, Total: 0.001394, LR: 8.68e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  440: Train: 0.001267, Val: 0.003370, Total: 0.001567, LR: 8.70e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  441: Train: 0.001399, Val: 0.002997, Total: 0.001627, LR: 8.72e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  442: Train: 0.001124, Val: 0.003305, Total: 0.001435, LR: 8.74e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  443: Train: 0.001114, Val: 0.003974, Total: 0.001523, LR: 8.76e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  444: Train: 0.001053, Val: 0.003194, Total: 0.001359, LR: 8.78e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  445: Train: 0.001102, Val: 0.003391, Total: 0.001429, LR: 8.80e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  446: Train: 0.001012, Val: 0.003611, Total: 0.001383, LR: 8.81e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  447: Train: 0.000998, Val: 0.003557, Total: 0.001364, LR: 8.83e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  448: Train: 0.000983, Val: 0.003655, Total: 0.001365, LR: 8.85e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  449: Train: 0.001063, Val: 0.003484, Total: 0.001409, LR: 8.87e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  450: Train: 0.001078, Val: 0.003457, Total: 0.001418, LR: 8.89e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  451: Train: 0.001163, Val: 0.003140, Total: 0.001446, LR: 8.91e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  452: Train: 0.000983, Val: 0.003640, Total: 0.001363, LR: 8.93e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  453: Train: 0.001022, Val: 0.003203, Total: 0.001333, LR: 8.95e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  454: Train: 0.000997, Val: 0.003698, Total: 0.001383, LR: 8.97e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  455: Train: 0.001000, Val: 0.003419, Total: 0.001346, LR: 8.99e-04 [WARMUP]\n",
      "          Best: Train: 0.000908, Val: 0.003630, Total: 0.001297 (Epoch 428)\n",
      "Epoch  456: Train: 0.000924, Val: 0.003502, Total: 0.001293, LR: 9.01e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000924, Val: 0.003502, Total: 0.001293 (Epoch 456)\n",
      "Epoch  457: Train: 0.000990, Val: 0.003134, Total: 0.001297, LR: 9.03e-04 [WARMUP]\n",
      "          Best: Train: 0.000924, Val: 0.003502, Total: 0.001293 (Epoch 456)\n",
      "Epoch  458: Train: 0.001003, Val: 0.003474, Total: 0.001356, LR: 9.05e-04 [WARMUP]\n",
      "          Best: Train: 0.000924, Val: 0.003502, Total: 0.001293 (Epoch 456)\n",
      "Epoch  459: Train: 0.001055, Val: 0.003347, Total: 0.001382, LR: 9.07e-04 [WARMUP]\n",
      "          Best: Train: 0.000924, Val: 0.003502, Total: 0.001293 (Epoch 456)\n",
      "Epoch  460: Train: 0.000940, Val: 0.003272, Total: 0.001273, LR: 9.09e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  461: Train: 0.001123, Val: 0.003125, Total: 0.001409, LR: 9.11e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  462: Train: 0.001224, Val: 0.003826, Total: 0.001595, LR: 9.13e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  463: Train: 0.001211, Val: 0.002964, Total: 0.001462, LR: 9.15e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  464: Train: 0.001041, Val: 0.003688, Total: 0.001419, LR: 9.17e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  465: Train: 0.001113, Val: 0.003346, Total: 0.001432, LR: 9.19e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  466: Train: 0.001197, Val: 0.003225, Total: 0.001486, LR: 9.21e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  467: Train: 0.001232, Val: 0.003855, Total: 0.001607, LR: 9.23e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  468: Train: 0.001146, Val: 0.003390, Total: 0.001467, LR: 9.25e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  469: Train: 0.001014, Val: 0.003308, Total: 0.001342, LR: 9.27e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  470: Train: 0.001042, Val: 0.003372, Total: 0.001375, LR: 9.29e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  471: Train: 0.000995, Val: 0.003318, Total: 0.001327, LR: 9.31e-04 [WARMUP]\n",
      "          Best: Train: 0.000940, Val: 0.003272, Total: 0.001273 (Epoch 460)\n",
      "Epoch  472: Train: 0.000936, Val: 0.003156, Total: 0.001253, LR: 9.33e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  473: Train: 0.000968, Val: 0.003474, Total: 0.001326, LR: 9.35e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  474: Train: 0.000929, Val: 0.003227, Total: 0.001258, LR: 9.37e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  475: Train: 0.001039, Val: 0.003613, Total: 0.001407, LR: 9.39e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  476: Train: 0.001060, Val: 0.003441, Total: 0.001400, LR: 9.41e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  477: Train: 0.001047, Val: 0.004029, Total: 0.001473, LR: 9.43e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  478: Train: 0.000953, Val: 0.004063, Total: 0.001397, LR: 9.45e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  479: Train: 0.000995, Val: 0.004024, Total: 0.001428, LR: 9.47e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  480: Train: 0.001004, Val: 0.004257, Total: 0.001469, LR: 9.49e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  481: Train: 0.000984, Val: 0.003280, Total: 0.001312, LR: 9.51e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  482: Train: 0.001016, Val: 0.003465, Total: 0.001366, LR: 9.53e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  483: Train: 0.000961, Val: 0.003575, Total: 0.001334, LR: 9.55e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  484: Train: 0.000972, Val: 0.003692, Total: 0.001361, LR: 9.57e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  485: Train: 0.001026, Val: 0.003842, Total: 0.001428, LR: 9.59e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  486: Train: 0.001080, Val: 0.004133, Total: 0.001516, LR: 9.61e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  487: Train: 0.001023, Val: 0.003132, Total: 0.001325, LR: 9.63e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  488: Train: 0.001073, Val: 0.003607, Total: 0.001435, LR: 9.64e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  489: Train: 0.000940, Val: 0.003285, Total: 0.001275, LR: 9.66e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  490: Train: 0.000917, Val: 0.003685, Total: 0.001313, LR: 9.68e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  491: Train: 0.000954, Val: 0.003326, Total: 0.001293, LR: 9.70e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  492: Train: 0.000892, Val: 0.003457, Total: 0.001258, LR: 9.72e-04 [WARMUP]\n",
      "          Best: Train: 0.000936, Val: 0.003156, Total: 0.001253 (Epoch 472)\n",
      "Epoch  493: Train: 0.000858, Val: 0.003436, Total: 0.001226, LR: 9.74e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000858, Val: 0.003436, Total: 0.001226 (Epoch 493)\n",
      "Epoch  494: Train: 0.000885, Val: 0.003594, Total: 0.001272, LR: 9.76e-04 [WARMUP]\n",
      "          Best: Train: 0.000858, Val: 0.003436, Total: 0.001226 (Epoch 493)\n",
      "Epoch  495: Train: 0.000875, Val: 0.003170, Total: 0.001203, LR: 9.78e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  496: Train: 0.000888, Val: 0.003605, Total: 0.001276, LR: 9.80e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  497: Train: 0.000880, Val: 0.003342, Total: 0.001231, LR: 9.82e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  498: Train: 0.000966, Val: 0.003651, Total: 0.001350, LR: 9.84e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  499: Train: 0.000944, Val: 0.003069, Total: 0.001248, LR: 9.86e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  500: Train: 0.000891, Val: 0.003271, Total: 0.001231, LR: 9.88e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  501: Train: 0.000926, Val: 0.003512, Total: 0.001295, LR: 9.90e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  502: Train: 0.000892, Val: 0.003297, Total: 0.001235, LR: 9.92e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  503: Train: 0.000913, Val: 0.003299, Total: 0.001254, LR: 9.94e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  504: Train: 0.000909, Val: 0.003015, Total: 0.001210, LR: 9.96e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  505: Train: 0.000893, Val: 0.003220, Total: 0.001225, LR: 9.98e-04 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  506: Train: 0.000954, Val: 0.003206, Total: 0.001276, LR: 1.00e-03 [WARMUP]\n",
      "          Best: Train: 0.000875, Val: 0.003170, Total: 0.001203 (Epoch 495)\n",
      "Epoch  507: Train: 0.000889, Val: 0.002982, Total: 0.001188, LR: 1.00e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  508: Train: 0.000987, Val: 0.003453, Total: 0.001339, LR: 1.00e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  509: Train: 0.001134, Val: 0.003455, Total: 0.001466, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  510: Train: 0.001320, Val: 0.003712, Total: 0.001662, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  511: Train: 0.001218, Val: 0.004264, Total: 0.001653, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  512: Train: 0.001195, Val: 0.003195, Total: 0.001481, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  513: Train: 0.001213, Val: 0.003709, Total: 0.001570, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  514: Train: 0.001146, Val: 0.003464, Total: 0.001477, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  515: Train: 0.001292, Val: 0.004113, Total: 0.001695, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  516: Train: 0.001319, Val: 0.003265, Total: 0.001597, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  517: Train: 0.001264, Val: 0.003100, Total: 0.001527, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  518: Train: 0.001109, Val: 0.003638, Total: 0.001470, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  519: Train: 0.001220, Val: 0.002870, Total: 0.001456, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  520: Train: 0.001204, Val: 0.003543, Total: 0.001538, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  521: Train: 0.001089, Val: 0.003308, Total: 0.001406, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  522: Train: 0.001079, Val: 0.004117, Total: 0.001513, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  523: Train: 0.001029, Val: 0.003059, Total: 0.001319, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  524: Train: 0.001087, Val: 0.003216, Total: 0.001391, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  525: Train: 0.001118, Val: 0.003262, Total: 0.001425, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  526: Train: 0.001047, Val: 0.003824, Total: 0.001444, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  527: Train: 0.001105, Val: 0.003161, Total: 0.001399, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  528: Train: 0.001029, Val: 0.003055, Total: 0.001318, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  529: Train: 0.001114, Val: 0.003592, Total: 0.001468, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  530: Train: 0.001052, Val: 0.003084, Total: 0.001342, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  531: Train: 0.001297, Val: 0.004175, Total: 0.001708, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  532: Train: 0.001188, Val: 0.002965, Total: 0.001441, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  533: Train: 0.001138, Val: 0.003422, Total: 0.001464, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  534: Train: 0.001190, Val: 0.003084, Total: 0.001461, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  535: Train: 0.001036, Val: 0.003756, Total: 0.001425, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  536: Train: 0.001112, Val: 0.003749, Total: 0.001489, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  537: Train: 0.001176, Val: 0.003100, Total: 0.001451, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  538: Train: 0.001046, Val: 0.003179, Total: 0.001350, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  539: Train: 0.000910, Val: 0.003954, Total: 0.001345, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  540: Train: 0.001065, Val: 0.003728, Total: 0.001446, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  541: Train: 0.001051, Val: 0.003542, Total: 0.001407, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  542: Train: 0.001267, Val: 0.003958, Total: 0.001651, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  543: Train: 0.001224, Val: 0.004260, Total: 0.001658, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  544: Train: 0.001169, Val: 0.002915, Total: 0.001419, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  545: Train: 0.001120, Val: 0.003408, Total: 0.001447, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  546: Train: 0.001115, Val: 0.003212, Total: 0.001414, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  547: Train: 0.001009, Val: 0.003654, Total: 0.001386, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  548: Train: 0.001195, Val: 0.003315, Total: 0.001498, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  549: Train: 0.001136, Val: 0.003554, Total: 0.001482, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  550: Train: 0.001052, Val: 0.003323, Total: 0.001376, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  551: Train: 0.001138, Val: 0.003936, Total: 0.001538, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  552: Train: 0.001112, Val: 0.003039, Total: 0.001387, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  553: Train: 0.001016, Val: 0.003499, Total: 0.001371, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  554: Train: 0.000963, Val: 0.003333, Total: 0.001301, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  555: Train: 0.000967, Val: 0.003181, Total: 0.001283, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  556: Train: 0.000981, Val: 0.003387, Total: 0.001325, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  557: Train: 0.001046, Val: 0.003155, Total: 0.001348, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  558: Train: 0.001310, Val: 0.003484, Total: 0.001621, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  559: Train: 0.001468, Val: 0.004107, Total: 0.001845, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  560: Train: 0.001481, Val: 0.003501, Total: 0.001770, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  561: Train: 0.001286, Val: 0.003458, Total: 0.001596, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  562: Train: 0.001844, Val: 0.003389, Total: 0.002064, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  563: Train: 0.001435, Val: 0.004071, Total: 0.001811, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  564: Train: 0.001386, Val: 0.003072, Total: 0.001627, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  565: Train: 0.001336, Val: 0.003088, Total: 0.001586, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  566: Train: 0.001089, Val: 0.003078, Total: 0.001373, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  567: Train: 0.000941, Val: 0.003033, Total: 0.001240, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  568: Train: 0.000987, Val: 0.003102, Total: 0.001289, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  569: Train: 0.001124, Val: 0.002981, Total: 0.001389, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  570: Train: 0.000936, Val: 0.003392, Total: 0.001287, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  571: Train: 0.000930, Val: 0.002963, Total: 0.001220, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  572: Train: 0.000912, Val: 0.003426, Total: 0.001271, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  573: Train: 0.000917, Val: 0.003283, Total: 0.001255, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  574: Train: 0.000998, Val: 0.003614, Total: 0.001372, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  575: Train: 0.000957, Val: 0.002951, Total: 0.001242, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  576: Train: 0.000912, Val: 0.003281, Total: 0.001250, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  577: Train: 0.000909, Val: 0.003066, Total: 0.001217, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  578: Train: 0.000871, Val: 0.003254, Total: 0.001212, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000889, Val: 0.002982, Total: 0.001188 (Epoch 507)\n",
      "Epoch  579: Train: 0.000825, Val: 0.002855, Total: 0.001115, LR: 1.14e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  580: Train: 0.000881, Val: 0.003227, Total: 0.001216, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  581: Train: 0.000894, Val: 0.003168, Total: 0.001219, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  582: Train: 0.000857, Val: 0.003168, Total: 0.001187, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  583: Train: 0.000839, Val: 0.003221, Total: 0.001179, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  584: Train: 0.000868, Val: 0.003217, Total: 0.001203, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  585: Train: 0.000863, Val: 0.003188, Total: 0.001195, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  586: Train: 0.000767, Val: 0.003276, Total: 0.001125, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  587: Train: 0.000882, Val: 0.003457, Total: 0.001250, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  588: Train: 0.000856, Val: 0.003018, Total: 0.001165, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  589: Train: 0.000809, Val: 0.002947, Total: 0.001115, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  590: Train: 0.000852, Val: 0.003200, Total: 0.001187, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  591: Train: 0.000850, Val: 0.003198, Total: 0.001185, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  592: Train: 0.000814, Val: 0.003345, Total: 0.001176, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  593: Train: 0.000816, Val: 0.003181, Total: 0.001154, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  594: Train: 0.000989, Val: 0.003335, Total: 0.001324, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  595: Train: 0.000967, Val: 0.003124, Total: 0.001275, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  596: Train: 0.000841, Val: 0.003463, Total: 0.001216, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  597: Train: 0.000865, Val: 0.002965, Total: 0.001165, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  598: Train: 0.000828, Val: 0.003366, Total: 0.001190, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  599: Train: 0.000848, Val: 0.002997, Total: 0.001155, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  600: Train: 0.000784, Val: 0.003407, Total: 0.001159, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  601: Train: 0.000816, Val: 0.003161, Total: 0.001151, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  602: Train: 0.000841, Val: 0.003133, Total: 0.001168, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  603: Train: 0.000823, Val: 0.003386, Total: 0.001189, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  604: Train: 0.000849, Val: 0.003229, Total: 0.001189, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  605: Train: 0.000929, Val: 0.003230, Total: 0.001258, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  606: Train: 0.000939, Val: 0.003399, Total: 0.001291, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  607: Train: 0.001049, Val: 0.004310, Total: 0.001515, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  608: Train: 0.001203, Val: 0.003808, Total: 0.001575, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  609: Train: 0.001290, Val: 0.003492, Total: 0.001604, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  610: Train: 0.001570, Val: 0.004042, Total: 0.001923, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  611: Train: 0.001295, Val: 0.003452, Total: 0.001603, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  612: Train: 0.001298, Val: 0.003272, Total: 0.001580, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  613: Train: 0.001216, Val: 0.003549, Total: 0.001550, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  614: Train: 0.001672, Val: 0.004278, Total: 0.002044, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  615: Train: 0.001511, Val: 0.004113, Total: 0.001883, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  616: Train: 0.001510, Val: 0.003218, Total: 0.001754, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  617: Train: 0.001257, Val: 0.004165, Total: 0.001672, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  618: Train: 0.001331, Val: 0.003430, Total: 0.001631, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  619: Train: 0.001308, Val: 0.003138, Total: 0.001569, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  620: Train: 0.001150, Val: 0.003756, Total: 0.001522, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  621: Train: 0.001200, Val: 0.003486, Total: 0.001526, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  622: Train: 0.001144, Val: 0.003370, Total: 0.001462, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  623: Train: 0.000987, Val: 0.003441, Total: 0.001337, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  624: Train: 0.001190, Val: 0.003509, Total: 0.001521, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  625: Train: 0.001057, Val: 0.003238, Total: 0.001368, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  626: Train: 0.000974, Val: 0.003434, Total: 0.001325, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  627: Train: 0.001040, Val: 0.003314, Total: 0.001365, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  628: Train: 0.000982, Val: 0.003392, Total: 0.001326, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  629: Train: 0.000966, Val: 0.003588, Total: 0.001340, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  630: Train: 0.000935, Val: 0.003256, Total: 0.001266, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  631: Train: 0.000888, Val: 0.003260, Total: 0.001227, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  632: Train: 0.000918, Val: 0.003559, Total: 0.001295, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  633: Train: 0.000981, Val: 0.002966, Total: 0.001264, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  634: Train: 0.000949, Val: 0.003505, Total: 0.001314, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  635: Train: 0.000904, Val: 0.003165, Total: 0.001227, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  636: Train: 0.000932, Val: 0.003453, Total: 0.001292, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  637: Train: 0.000908, Val: 0.003029, Total: 0.001211, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  638: Train: 0.000853, Val: 0.003464, Total: 0.001226, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  639: Train: 0.000830, Val: 0.003351, Total: 0.001190, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  640: Train: 0.000820, Val: 0.002886, Total: 0.001115, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  641: Train: 0.000850, Val: 0.003485, Total: 0.001227, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  642: Train: 0.000868, Val: 0.003011, Total: 0.001174, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  643: Train: 0.000844, Val: 0.003309, Total: 0.001197, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  644: Train: 0.000866, Val: 0.002970, Total: 0.001167, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  645: Train: 0.000965, Val: 0.002919, Total: 0.001244, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  646: Train: 0.000899, Val: 0.003932, Total: 0.001332, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  647: Train: 0.000922, Val: 0.002814, Total: 0.001192, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  648: Train: 0.000884, Val: 0.003427, Total: 0.001248, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  649: Train: 0.000915, Val: 0.003352, Total: 0.001263, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  650: Train: 0.000848, Val: 0.003213, Total: 0.001185, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  651: Train: 0.000837, Val: 0.003543, Total: 0.001223, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  652: Train: 0.000841, Val: 0.003246, Total: 0.001184, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  653: Train: 0.000905, Val: 0.003193, Total: 0.001232, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  654: Train: 0.000965, Val: 0.003434, Total: 0.001318, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  655: Train: 0.000917, Val: 0.003226, Total: 0.001246, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  656: Train: 0.000907, Val: 0.003518, Total: 0.001280, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  657: Train: 0.000891, Val: 0.003018, Total: 0.001195, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  658: Train: 0.000861, Val: 0.003150, Total: 0.001188, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  659: Train: 0.000814, Val: 0.003362, Total: 0.001178, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  660: Train: 0.000855, Val: 0.003309, Total: 0.001205, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  661: Train: 0.000814, Val: 0.003325, Total: 0.001173, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  662: Train: 0.000786, Val: 0.003254, Total: 0.001138, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  663: Train: 0.000842, Val: 0.003249, Total: 0.001186, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  664: Train: 0.000822, Val: 0.003221, Total: 0.001165, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  665: Train: 0.000874, Val: 0.003385, Total: 0.001232, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  666: Train: 0.000905, Val: 0.003395, Total: 0.001261, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  667: Train: 0.000971, Val: 0.003014, Total: 0.001263, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  668: Train: 0.000928, Val: 0.003259, Total: 0.001261, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  669: Train: 0.000972, Val: 0.003463, Total: 0.001327, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  670: Train: 0.000847, Val: 0.003208, Total: 0.001184, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  671: Train: 0.000810, Val: 0.003158, Total: 0.001146, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  672: Train: 0.000915, Val: 0.003094, Total: 0.001226, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  673: Train: 0.000846, Val: 0.003340, Total: 0.001202, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  674: Train: 0.000836, Val: 0.003009, Total: 0.001147, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  675: Train: 0.000840, Val: 0.003774, Total: 0.001259, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  676: Train: 0.000848, Val: 0.003085, Total: 0.001168, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  677: Train: 0.000816, Val: 0.003719, Total: 0.001230, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  678: Train: 0.000933, Val: 0.003172, Total: 0.001253, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  679: Train: 0.000848, Val: 0.003284, Total: 0.001196, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  680: Train: 0.000828, Val: 0.003125, Total: 0.001156, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  681: Train: 0.000902, Val: 0.003524, Total: 0.001277, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  682: Train: 0.000907, Val: 0.003240, Total: 0.001240, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  683: Train: 0.000814, Val: 0.003520, Total: 0.001201, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  684: Train: 0.000955, Val: 0.003247, Total: 0.001282, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  685: Train: 0.000797, Val: 0.003233, Total: 0.001145, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  686: Train: 0.000902, Val: 0.003575, Total: 0.001284, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  687: Train: 0.000867, Val: 0.003264, Total: 0.001209, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  688: Train: 0.000962, Val: 0.003447, Total: 0.001317, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  689: Train: 0.001116, Val: 0.003384, Total: 0.001440, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  690: Train: 0.001212, Val: 0.004041, Total: 0.001616, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  691: Train: 0.001600, Val: 0.003977, Total: 0.001939, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  692: Train: 0.001294, Val: 0.003420, Total: 0.001598, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  693: Train: 0.001066, Val: 0.003010, Total: 0.001344, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  694: Train: 0.000879, Val: 0.003123, Total: 0.001200, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  695: Train: 0.000913, Val: 0.003390, Total: 0.001267, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  696: Train: 0.000904, Val: 0.002958, Total: 0.001197, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  697: Train: 0.000912, Val: 0.003196, Total: 0.001239, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  698: Train: 0.000854, Val: 0.003165, Total: 0.001184, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000825, Val: 0.002855, Total: 0.001115 (Epoch 579)\n",
      "Epoch  699: Train: 0.000754, Val: 0.003140, Total: 0.001095, LR: 1.38e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  700: Train: 0.000806, Val: 0.003086, Total: 0.001132, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  701: Train: 0.000821, Val: 0.003262, Total: 0.001170, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  702: Train: 0.000806, Val: 0.002942, Total: 0.001111, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  703: Train: 0.000817, Val: 0.003301, Total: 0.001172, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  704: Train: 0.000800, Val: 0.002891, Total: 0.001098, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  705: Train: 0.000777, Val: 0.003210, Total: 0.001124, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  706: Train: 0.000815, Val: 0.002960, Total: 0.001122, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  707: Train: 0.000789, Val: 0.003541, Total: 0.001182, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  708: Train: 0.000768, Val: 0.003334, Total: 0.001135, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000754, Val: 0.003140, Total: 0.001095 (Epoch 699)\n",
      "Epoch  709: Train: 0.000736, Val: 0.003033, Total: 0.001064, LR: 1.40e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  710: Train: 0.000775, Val: 0.003444, Total: 0.001156, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  711: Train: 0.000810, Val: 0.002976, Total: 0.001120, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  712: Train: 0.000774, Val: 0.003214, Total: 0.001123, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  713: Train: 0.000837, Val: 0.003226, Total: 0.001179, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  714: Train: 0.000837, Val: 0.003094, Total: 0.001159, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  715: Train: 0.000849, Val: 0.003313, Total: 0.001201, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  716: Train: 0.000774, Val: 0.003104, Total: 0.001107, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  717: Train: 0.000819, Val: 0.003461, Total: 0.001196, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  718: Train: 0.000774, Val: 0.003096, Total: 0.001106, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  719: Train: 0.000798, Val: 0.003139, Total: 0.001133, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  720: Train: 0.000755, Val: 0.003136, Total: 0.001096, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  721: Train: 0.000771, Val: 0.003199, Total: 0.001118, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  722: Train: 0.000795, Val: 0.003096, Total: 0.001124, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  723: Train: 0.000783, Val: 0.003282, Total: 0.001140, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  724: Train: 0.000791, Val: 0.003372, Total: 0.001159, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  725: Train: 0.000726, Val: 0.003239, Total: 0.001085, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  726: Train: 0.000802, Val: 0.003520, Total: 0.001190, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  727: Train: 0.000803, Val: 0.003145, Total: 0.001137, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  728: Train: 0.000769, Val: 0.003306, Total: 0.001131, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  729: Train: 0.000749, Val: 0.003073, Total: 0.001081, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  730: Train: 0.000765, Val: 0.003209, Total: 0.001114, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000736, Val: 0.003033, Total: 0.001064 (Epoch 709)\n",
      "Epoch  731: Train: 0.000729, Val: 0.003014, Total: 0.001055, LR: 1.44e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  732: Train: 0.000757, Val: 0.003400, Total: 0.001135, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  733: Train: 0.000793, Val: 0.003232, Total: 0.001141, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  734: Train: 0.000722, Val: 0.003620, Total: 0.001136, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  735: Train: 0.000759, Val: 0.003227, Total: 0.001112, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  736: Train: 0.000717, Val: 0.003469, Total: 0.001110, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  737: Train: 0.000810, Val: 0.003193, Total: 0.001151, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  738: Train: 0.000772, Val: 0.003367, Total: 0.001143, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  739: Train: 0.000880, Val: 0.003117, Total: 0.001200, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  740: Train: 0.000804, Val: 0.003188, Total: 0.001145, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  741: Train: 0.000757, Val: 0.003052, Total: 0.001085, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  742: Train: 0.000812, Val: 0.002986, Total: 0.001122, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  743: Train: 0.000820, Val: 0.003056, Total: 0.001140, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  744: Train: 0.000762, Val: 0.003493, Total: 0.001152, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  745: Train: 0.000774, Val: 0.002961, Total: 0.001086, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  746: Train: 0.000798, Val: 0.003597, Total: 0.001198, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  747: Train: 0.000745, Val: 0.003343, Total: 0.001116, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  748: Train: 0.000767, Val: 0.003114, Total: 0.001102, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  749: Train: 0.000746, Val: 0.003210, Total: 0.001098, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  750: Train: 0.000737, Val: 0.003178, Total: 0.001085, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  751: Train: 0.000799, Val: 0.003218, Total: 0.001144, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  752: Train: 0.000756, Val: 0.003171, Total: 0.001101, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  753: Train: 0.000825, Val: 0.003109, Total: 0.001151, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  754: Train: 0.000776, Val: 0.003164, Total: 0.001117, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  755: Train: 0.000791, Val: 0.003280, Total: 0.001146, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  756: Train: 0.000794, Val: 0.003400, Total: 0.001166, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  757: Train: 0.000747, Val: 0.003103, Total: 0.001084, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  758: Train: 0.000809, Val: 0.003354, Total: 0.001172, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  759: Train: 0.000752, Val: 0.003261, Total: 0.001111, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  760: Train: 0.000789, Val: 0.003609, Total: 0.001192, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  761: Train: 0.000735, Val: 0.003086, Total: 0.001071, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  762: Train: 0.000750, Val: 0.003315, Total: 0.001116, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  763: Train: 0.000774, Val: 0.003270, Total: 0.001130, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  764: Train: 0.000720, Val: 0.003473, Total: 0.001114, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  765: Train: 0.000823, Val: 0.003346, Total: 0.001184, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  766: Train: 0.000762, Val: 0.003194, Total: 0.001109, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  767: Train: 0.000803, Val: 0.003727, Total: 0.001221, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  768: Train: 0.000728, Val: 0.003068, Total: 0.001063, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  769: Train: 0.000812, Val: 0.003303, Total: 0.001168, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  770: Train: 0.000831, Val: 0.003265, Total: 0.001179, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  771: Train: 0.000776, Val: 0.003580, Total: 0.001177, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  772: Train: 0.000770, Val: 0.003014, Total: 0.001091, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  773: Train: 0.000774, Val: 0.003606, Total: 0.001179, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  774: Train: 0.000797, Val: 0.003073, Total: 0.001122, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  775: Train: 0.000840, Val: 0.003383, Total: 0.001204, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  776: Train: 0.000790, Val: 0.002754, Total: 0.001071, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  777: Train: 0.000727, Val: 0.003491, Total: 0.001122, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000729, Val: 0.003014, Total: 0.001055 (Epoch 731)\n",
      "Epoch  778: Train: 0.000722, Val: 0.002804, Total: 0.001020, LR: 1.54e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  779: Train: 0.000731, Val: 0.003137, Total: 0.001074, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  780: Train: 0.000738, Val: 0.002862, Total: 0.001042, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  781: Train: 0.000737, Val: 0.003257, Total: 0.001097, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  782: Train: 0.000756, Val: 0.002918, Total: 0.001065, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  783: Train: 0.000762, Val: 0.003369, Total: 0.001135, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  784: Train: 0.000783, Val: 0.003151, Total: 0.001121, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  785: Train: 0.001101, Val: 0.003675, Total: 0.001468, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  786: Train: 0.001095, Val: 0.003948, Total: 0.001502, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  787: Train: 0.001265, Val: 0.003144, Total: 0.001533, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  788: Train: 0.001494, Val: 0.003258, Total: 0.001746, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  789: Train: 0.001574, Val: 0.003201, Total: 0.001806, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  790: Train: 0.001142, Val: 0.003690, Total: 0.001506, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  791: Train: 0.001037, Val: 0.002949, Total: 0.001310, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  792: Train: 0.001102, Val: 0.002934, Total: 0.001364, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  793: Train: 0.001070, Val: 0.003492, Total: 0.001416, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  794: Train: 0.001061, Val: 0.003194, Total: 0.001366, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  795: Train: 0.001047, Val: 0.003217, Total: 0.001357, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  796: Train: 0.001077, Val: 0.003264, Total: 0.001390, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  797: Train: 0.001049, Val: 0.002830, Total: 0.001303, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  798: Train: 0.001602, Val: 0.005080, Total: 0.002099, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  799: Train: 0.001075, Val: 0.004386, Total: 0.001548, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  800: Train: 0.001408, Val: 0.003776, Total: 0.001746, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  801: Train: 0.001290, Val: 0.003774, Total: 0.001645, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  802: Train: 0.001901, Val: 0.002800, Total: 0.002030, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  803: Train: 0.001563, Val: 0.002768, Total: 0.001735, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  804: Train: 0.001557, Val: 0.005445, Total: 0.002112, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  805: Train: 0.002011, Val: 0.005744, Total: 0.002544, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  806: Train: 0.003445, Val: 0.002721, Total: 0.003342, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  807: Train: 0.002989, Val: 0.005217, Total: 0.003308, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  808: Train: 0.003692, Val: 0.002827, Total: 0.003569, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  809: Train: 0.004875, Val: 0.003535, Total: 0.004684, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  810: Train: 0.003506, Val: 0.005346, Total: 0.003769, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  811: Train: 0.002562, Val: 0.007207, Total: 0.003225, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  812: Train: 0.002498, Val: 0.003991, Total: 0.002711, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  813: Train: 0.002068, Val: 0.004332, Total: 0.002391, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  814: Train: 0.001738, Val: 0.004945, Total: 0.002196, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  815: Train: 0.001633, Val: 0.005835, Total: 0.002233, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  816: Train: 0.001688, Val: 0.004330, Total: 0.002065, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  817: Train: 0.001664, Val: 0.005205, Total: 0.002170, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  818: Train: 0.001656, Val: 0.004157, Total: 0.002013, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  819: Train: 0.001597, Val: 0.005036, Total: 0.002088, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  820: Train: 0.001461, Val: 0.004556, Total: 0.001903, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  821: Train: 0.001498, Val: 0.004195, Total: 0.001884, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  822: Train: 0.001449, Val: 0.004267, Total: 0.001852, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  823: Train: 0.001220, Val: 0.002895, Total: 0.001460, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  824: Train: 0.001288, Val: 0.004771, Total: 0.001786, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  825: Train: 0.001250, Val: 0.002694, Total: 0.001457, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  826: Train: 0.001618, Val: 0.005263, Total: 0.002138, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  827: Train: 0.001555, Val: 0.004073, Total: 0.001915, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  828: Train: 0.001654, Val: 0.003762, Total: 0.001955, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  829: Train: 0.001621, Val: 0.004788, Total: 0.002074, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  830: Train: 0.001451, Val: 0.003657, Total: 0.001766, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  831: Train: 0.001404, Val: 0.004435, Total: 0.001837, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  832: Train: 0.001388, Val: 0.003587, Total: 0.001702, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  833: Train: 0.001271, Val: 0.004360, Total: 0.001713, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  834: Train: 0.001923, Val: 0.002847, Total: 0.002055, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  835: Train: 0.001699, Val: 0.004101, Total: 0.002042, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  836: Train: 0.001456, Val: 0.003498, Total: 0.001748, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  837: Train: 0.001227, Val: 0.002896, Total: 0.001466, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  838: Train: 0.001337, Val: 0.003406, Total: 0.001632, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  839: Train: 0.001329, Val: 0.003259, Total: 0.001605, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  840: Train: 0.001144, Val: 0.003303, Total: 0.001453, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  841: Train: 0.001206, Val: 0.003416, Total: 0.001522, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  842: Train: 0.001180, Val: 0.002881, Total: 0.001423, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  843: Train: 0.001241, Val: 0.003148, Total: 0.001513, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  844: Train: 0.001194, Val: 0.003478, Total: 0.001520, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  845: Train: 0.001121, Val: 0.002910, Total: 0.001377, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  846: Train: 0.001147, Val: 0.003349, Total: 0.001462, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  847: Train: 0.001099, Val: 0.003670, Total: 0.001466, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  848: Train: 0.001147, Val: 0.003254, Total: 0.001448, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  849: Train: 0.001145, Val: 0.003242, Total: 0.001444, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  850: Train: 0.001166, Val: 0.003111, Total: 0.001444, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  851: Train: 0.001295, Val: 0.002862, Total: 0.001518, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  852: Train: 0.001295, Val: 0.003733, Total: 0.001643, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  853: Train: 0.001248, Val: 0.002909, Total: 0.001486, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  854: Train: 0.001341, Val: 0.004131, Total: 0.001740, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  855: Train: 0.001142, Val: 0.003031, Total: 0.001412, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  856: Train: 0.001067, Val: 0.003043, Total: 0.001349, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  857: Train: 0.001175, Val: 0.003754, Total: 0.001543, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  858: Train: 0.001125, Val: 0.003024, Total: 0.001396, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  859: Train: 0.001533, Val: 0.003507, Total: 0.001815, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  860: Train: 0.001186, Val: 0.003907, Total: 0.001575, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  861: Train: 0.001201, Val: 0.002760, Total: 0.001423, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  862: Train: 0.001288, Val: 0.003358, Total: 0.001584, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  863: Train: 0.001157, Val: 0.003823, Total: 0.001538, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  864: Train: 0.001285, Val: 0.002824, Total: 0.001505, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  865: Train: 0.001138, Val: 0.003641, Total: 0.001495, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  866: Train: 0.001167, Val: 0.003275, Total: 0.001468, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  867: Train: 0.001218, Val: 0.002981, Total: 0.001470, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  868: Train: 0.001191, Val: 0.003420, Total: 0.001509, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  869: Train: 0.001285, Val: 0.003151, Total: 0.001552, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  870: Train: 0.001248, Val: 0.003370, Total: 0.001551, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  871: Train: 0.001231, Val: 0.003408, Total: 0.001542, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  872: Train: 0.001235, Val: 0.003189, Total: 0.001515, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  873: Train: 0.001148, Val: 0.003258, Total: 0.001449, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  874: Train: 0.001273, Val: 0.003618, Total: 0.001608, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  875: Train: 0.001206, Val: 0.003676, Total: 0.001559, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  876: Train: 0.001083, Val: 0.003034, Total: 0.001361, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  877: Train: 0.001184, Val: 0.003122, Total: 0.001461, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  878: Train: 0.001141, Val: 0.003146, Total: 0.001427, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  879: Train: 0.001085, Val: 0.003101, Total: 0.001373, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  880: Train: 0.001142, Val: 0.003464, Total: 0.001474, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  881: Train: 0.001092, Val: 0.003248, Total: 0.001400, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  882: Train: 0.001146, Val: 0.003271, Total: 0.001450, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  883: Train: 0.001111, Val: 0.003710, Total: 0.001482, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  884: Train: 0.001069, Val: 0.003173, Total: 0.001369, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  885: Train: 0.001089, Val: 0.003462, Total: 0.001428, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  886: Train: 0.001178, Val: 0.003239, Total: 0.001473, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  887: Train: 0.001091, Val: 0.003188, Total: 0.001390, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  888: Train: 0.001109, Val: 0.003585, Total: 0.001463, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  889: Train: 0.001052, Val: 0.003202, Total: 0.001359, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  890: Train: 0.001105, Val: 0.003246, Total: 0.001411, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  891: Train: 0.001170, Val: 0.003278, Total: 0.001471, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  892: Train: 0.001061, Val: 0.003585, Total: 0.001421, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  893: Train: 0.001071, Val: 0.003295, Total: 0.001389, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  894: Train: 0.001028, Val: 0.003204, Total: 0.001339, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  895: Train: 0.001072, Val: 0.003396, Total: 0.001404, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  896: Train: 0.001056, Val: 0.003363, Total: 0.001385, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  897: Train: 0.001179, Val: 0.003066, Total: 0.001449, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  898: Train: 0.001085, Val: 0.003978, Total: 0.001499, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  899: Train: 0.001108, Val: 0.003144, Total: 0.001399, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  900: Train: 0.001344, Val: 0.003198, Total: 0.001609, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  901: Train: 0.001094, Val: 0.004067, Total: 0.001519, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  902: Train: 0.001426, Val: 0.003195, Total: 0.001679, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  903: Train: 0.001196, Val: 0.003274, Total: 0.001493, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  904: Train: 0.001070, Val: 0.003241, Total: 0.001380, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  905: Train: 0.001196, Val: 0.003032, Total: 0.001458, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  906: Train: 0.001245, Val: 0.003592, Total: 0.001581, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  907: Train: 0.001096, Val: 0.003121, Total: 0.001385, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  908: Train: 0.001279, Val: 0.002943, Total: 0.001517, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  909: Train: 0.001161, Val: 0.003596, Total: 0.001509, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  910: Train: 0.001273, Val: 0.002958, Total: 0.001514, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  911: Train: 0.001359, Val: 0.003440, Total: 0.001656, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  912: Train: 0.001300, Val: 0.003385, Total: 0.001598, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  913: Train: 0.001238, Val: 0.003208, Total: 0.001519, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  914: Train: 0.001257, Val: 0.003190, Total: 0.001533, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  915: Train: 0.001205, Val: 0.003359, Total: 0.001513, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  916: Train: 0.001162, Val: 0.003070, Total: 0.001435, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  917: Train: 0.001411, Val: 0.003430, Total: 0.001699, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  918: Train: 0.001297, Val: 0.003550, Total: 0.001619, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  919: Train: 0.001293, Val: 0.002863, Total: 0.001518, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  920: Train: 0.001167, Val: 0.003572, Total: 0.001511, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  921: Train: 0.001218, Val: 0.003484, Total: 0.001541, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  922: Train: 0.001202, Val: 0.003094, Total: 0.001472, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  923: Train: 0.001102, Val: 0.003447, Total: 0.001437, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  924: Train: 0.001139, Val: 0.003258, Total: 0.001442, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  925: Train: 0.001146, Val: 0.003204, Total: 0.001440, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  926: Train: 0.001069, Val: 0.003466, Total: 0.001412, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  927: Train: 0.001099, Val: 0.003256, Total: 0.001408, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  928: Train: 0.001106, Val: 0.003310, Total: 0.001420, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  929: Train: 0.001059, Val: 0.003457, Total: 0.001402, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  930: Train: 0.001142, Val: 0.003244, Total: 0.001443, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  931: Train: 0.001033, Val: 0.003564, Total: 0.001395, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  932: Train: 0.001039, Val: 0.003243, Total: 0.001354, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  933: Train: 0.001122, Val: 0.003878, Total: 0.001516, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  934: Train: 0.001061, Val: 0.003231, Total: 0.001371, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  935: Train: 0.001085, Val: 0.003461, Total: 0.001424, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  936: Train: 0.001024, Val: 0.003263, Total: 0.001344, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  937: Train: 0.001096, Val: 0.003415, Total: 0.001428, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  938: Train: 0.000986, Val: 0.003471, Total: 0.001341, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  939: Train: 0.001026, Val: 0.002963, Total: 0.001303, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  940: Train: 0.001019, Val: 0.003153, Total: 0.001324, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  941: Train: 0.001015, Val: 0.003307, Total: 0.001342, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  942: Train: 0.000983, Val: 0.002975, Total: 0.001268, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  943: Train: 0.000996, Val: 0.003435, Total: 0.001345, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  944: Train: 0.001097, Val: 0.003060, Total: 0.001377, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  945: Train: 0.001049, Val: 0.003204, Total: 0.001357, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  946: Train: 0.000960, Val: 0.003167, Total: 0.001275, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  947: Train: 0.001000, Val: 0.002982, Total: 0.001283, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  948: Train: 0.000955, Val: 0.003472, Total: 0.001315, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  949: Train: 0.000981, Val: 0.002940, Total: 0.001261, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  950: Train: 0.001009, Val: 0.003085, Total: 0.001305, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  951: Train: 0.000980, Val: 0.003494, Total: 0.001339, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  952: Train: 0.000963, Val: 0.003162, Total: 0.001277, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  953: Train: 0.001018, Val: 0.003344, Total: 0.001350, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  954: Train: 0.000945, Val: 0.003198, Total: 0.001267, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  955: Train: 0.000982, Val: 0.003005, Total: 0.001271, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  956: Train: 0.000982, Val: 0.003315, Total: 0.001315, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  957: Train: 0.000987, Val: 0.002926, Total: 0.001264, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  958: Train: 0.001004, Val: 0.003368, Total: 0.001342, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  959: Train: 0.001003, Val: 0.003470, Total: 0.001356, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  960: Train: 0.000927, Val: 0.003303, Total: 0.001266, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  961: Train: 0.000968, Val: 0.003171, Total: 0.001283, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  962: Train: 0.000980, Val: 0.003204, Total: 0.001298, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  963: Train: 0.000948, Val: 0.003056, Total: 0.001249, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  964: Train: 0.000923, Val: 0.003205, Total: 0.001249, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  965: Train: 0.001181, Val: 0.003001, Total: 0.001441, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  966: Train: 0.001109, Val: 0.004211, Total: 0.001552, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  967: Train: 0.001283, Val: 0.003220, Total: 0.001560, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  968: Train: 0.001188, Val: 0.003382, Total: 0.001501, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  969: Train: 0.001141, Val: 0.003510, Total: 0.001480, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  970: Train: 0.001164, Val: 0.003365, Total: 0.001479, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  971: Train: 0.001208, Val: 0.003382, Total: 0.001519, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  972: Train: 0.001233, Val: 0.003135, Total: 0.001504, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  973: Train: 0.001118, Val: 0.003596, Total: 0.001472, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  974: Train: 0.001030, Val: 0.002927, Total: 0.001301, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  975: Train: 0.001156, Val: 0.003471, Total: 0.001487, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  976: Train: 0.001289, Val: 0.003277, Total: 0.001573, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  977: Train: 0.001131, Val: 0.003526, Total: 0.001473, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  978: Train: 0.001207, Val: 0.003383, Total: 0.001518, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  979: Train: 0.001168, Val: 0.003265, Total: 0.001468, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  980: Train: 0.001081, Val: 0.003797, Total: 0.001469, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  981: Train: 0.001032, Val: 0.003495, Total: 0.001384, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  982: Train: 0.001064, Val: 0.003293, Total: 0.001383, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  983: Train: 0.000992, Val: 0.003247, Total: 0.001315, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  984: Train: 0.001011, Val: 0.003373, Total: 0.001348, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  985: Train: 0.000982, Val: 0.003411, Total: 0.001329, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  986: Train: 0.000993, Val: 0.003083, Total: 0.001292, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  987: Train: 0.000982, Val: 0.003028, Total: 0.001275, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  988: Train: 0.001021, Val: 0.002937, Total: 0.001295, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  989: Train: 0.000976, Val: 0.003376, Total: 0.001319, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  990: Train: 0.001130, Val: 0.003319, Total: 0.001443, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  991: Train: 0.001107, Val: 0.003071, Total: 0.001387, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  992: Train: 0.001216, Val: 0.002996, Total: 0.001470, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  993: Train: 0.001131, Val: 0.002988, Total: 0.001397, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  994: Train: 0.001184, Val: 0.002972, Total: 0.001439, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  995: Train: 0.001169, Val: 0.003125, Total: 0.001448, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  996: Train: 0.000994, Val: 0.003380, Total: 0.001335, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  997: Train: 0.001083, Val: 0.003326, Total: 0.001403, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  998: Train: 0.001027, Val: 0.003209, Total: 0.001338, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch  999: Train: 0.001007, Val: 0.003124, Total: 0.001309, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1000: Train: 0.001001, Val: 0.003275, Total: 0.001326, LR: 1.98e-03 [WARMUP]\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1001: Train: 0.000977, Val: 0.003159, Total: 0.001289, LR: 1.98e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1002: Train: 0.001010, Val: 0.003274, Total: 0.001333, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1003: Train: 0.000997, Val: 0.003280, Total: 0.001323, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1004: Train: 0.000950, Val: 0.003019, Total: 0.001246, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1005: Train: 0.001100, Val: 0.003270, Total: 0.001410, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1006: Train: 0.001073, Val: 0.004037, Total: 0.001496, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1007: Train: 0.001175, Val: 0.003814, Total: 0.001552, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1008: Train: 0.001129, Val: 0.003468, Total: 0.001463, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1009: Train: 0.001069, Val: 0.003550, Total: 0.001424, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1010: Train: 0.001125, Val: 0.003197, Total: 0.001421, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1011: Train: 0.001114, Val: 0.003310, Total: 0.001428, LR: 1.97e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1012: Train: 0.001143, Val: 0.003310, Total: 0.001452, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1013: Train: 0.001160, Val: 0.003185, Total: 0.001449, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1014: Train: 0.001022, Val: 0.003921, Total: 0.001436, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1015: Train: 0.001081, Val: 0.002873, Total: 0.001337, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1016: Train: 0.001011, Val: 0.004593, Total: 0.001522, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1017: Train: 0.001376, Val: 0.002682, Total: 0.001563, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1018: Train: 0.001358, Val: 0.003276, Total: 0.001632, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1019: Train: 0.001133, Val: 0.003731, Total: 0.001504, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1020: Train: 0.000981, Val: 0.002971, Total: 0.001265, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1021: Train: 0.001021, Val: 0.003233, Total: 0.001337, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1022: Train: 0.000997, Val: 0.003148, Total: 0.001304, LR: 1.96e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1023: Train: 0.001000, Val: 0.003034, Total: 0.001291, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1024: Train: 0.001066, Val: 0.002935, Total: 0.001333, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1025: Train: 0.001019, Val: 0.003250, Total: 0.001338, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1026: Train: 0.000941, Val: 0.002780, Total: 0.001203, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1027: Train: 0.001051, Val: 0.003297, Total: 0.001372, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1028: Train: 0.001083, Val: 0.003173, Total: 0.001382, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1029: Train: 0.001021, Val: 0.003161, Total: 0.001327, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1030: Train: 0.000988, Val: 0.003089, Total: 0.001288, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1031: Train: 0.000917, Val: 0.003248, Total: 0.001250, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1032: Train: 0.000965, Val: 0.003275, Total: 0.001295, LR: 1.95e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1033: Train: 0.001011, Val: 0.003494, Total: 0.001366, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1034: Train: 0.000977, Val: 0.003093, Total: 0.001279, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1035: Train: 0.000963, Val: 0.003450, Total: 0.001319, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1036: Train: 0.001090, Val: 0.003252, Total: 0.001399, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1037: Train: 0.000996, Val: 0.003324, Total: 0.001328, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1038: Train: 0.000924, Val: 0.003234, Total: 0.001254, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1039: Train: 0.000988, Val: 0.003427, Total: 0.001337, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1040: Train: 0.000907, Val: 0.003424, Total: 0.001266, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1041: Train: 0.000930, Val: 0.003362, Total: 0.001278, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1042: Train: 0.000940, Val: 0.003242, Total: 0.001269, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1043: Train: 0.000981, Val: 0.003293, Total: 0.001311, LR: 1.94e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1044: Train: 0.000945, Val: 0.003159, Total: 0.001261, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1045: Train: 0.000908, Val: 0.003631, Total: 0.001297, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1046: Train: 0.000972, Val: 0.002817, Total: 0.001236, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1047: Train: 0.000965, Val: 0.003539, Total: 0.001333, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1048: Train: 0.000960, Val: 0.003099, Total: 0.001266, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1049: Train: 0.001018, Val: 0.002866, Total: 0.001282, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1050: Train: 0.001006, Val: 0.003118, Total: 0.001308, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1051: Train: 0.001196, Val: 0.003020, Total: 0.001456, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1052: Train: 0.001045, Val: 0.003630, Total: 0.001415, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1053: Train: 0.001100, Val: 0.003740, Total: 0.001477, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1054: Train: 0.001100, Val: 0.003461, Total: 0.001437, LR: 1.93e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1055: Train: 0.001094, Val: 0.004062, Total: 0.001518, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1056: Train: 0.002481, Val: 0.002760, Total: 0.002521, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1057: Train: 0.001475, Val: 0.004683, Total: 0.001933, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1058: Train: 0.001309, Val: 0.002976, Total: 0.001547, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1059: Train: 0.003006, Val: 0.006566, Total: 0.003515, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1060: Train: 0.001568, Val: 0.003322, Total: 0.001819, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1061: Train: 0.001717, Val: 0.004191, Total: 0.002070, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1062: Train: 0.001439, Val: 0.003960, Total: 0.001799, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1063: Train: 0.001284, Val: 0.002541, Total: 0.001464, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1064: Train: 0.001770, Val: 0.005797, Total: 0.002345, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1065: Train: 0.001684, Val: 0.002556, Total: 0.001809, LR: 1.92e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1066: Train: 0.001908, Val: 0.002985, Total: 0.002062, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1067: Train: 0.001592, Val: 0.004196, Total: 0.001964, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1068: Train: 0.001316, Val: 0.002578, Total: 0.001496, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1069: Train: 0.001332, Val: 0.002456, Total: 0.001493, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1070: Train: 0.001113, Val: 0.003013, Total: 0.001385, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1071: Train: 0.001151, Val: 0.003026, Total: 0.001419, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1072: Train: 0.001040, Val: 0.002716, Total: 0.001279, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1073: Train: 0.001101, Val: 0.003170, Total: 0.001397, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1074: Train: 0.001111, Val: 0.003327, Total: 0.001427, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1075: Train: 0.001219, Val: 0.002699, Total: 0.001430, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1076: Train: 0.001116, Val: 0.003766, Total: 0.001494, LR: 1.91e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1077: Train: 0.001177, Val: 0.002670, Total: 0.001390, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1078: Train: 0.001257, Val: 0.003165, Total: 0.001530, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1079: Train: 0.001119, Val: 0.003079, Total: 0.001399, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1080: Train: 0.001052, Val: 0.002655, Total: 0.001281, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1081: Train: 0.001100, Val: 0.003279, Total: 0.001411, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1082: Train: 0.001141, Val: 0.002690, Total: 0.001362, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1083: Train: 0.001114, Val: 0.003010, Total: 0.001385, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1084: Train: 0.001074, Val: 0.003583, Total: 0.001432, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1085: Train: 0.001035, Val: 0.002809, Total: 0.001289, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1086: Train: 0.001095, Val: 0.003088, Total: 0.001380, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1087: Train: 0.001031, Val: 0.003142, Total: 0.001333, LR: 1.90e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1088: Train: 0.001138, Val: 0.002830, Total: 0.001380, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1089: Train: 0.001080, Val: 0.002808, Total: 0.001327, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1090: Train: 0.001100, Val: 0.003085, Total: 0.001383, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1091: Train: 0.001172, Val: 0.002952, Total: 0.001426, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1092: Train: 0.001240, Val: 0.003085, Total: 0.001503, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1093: Train: 0.001149, Val: 0.002934, Total: 0.001404, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1094: Train: 0.001065, Val: 0.003140, Total: 0.001362, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1095: Train: 0.001026, Val: 0.002963, Total: 0.001302, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1096: Train: 0.001051, Val: 0.003141, Total: 0.001350, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1097: Train: 0.000981, Val: 0.003370, Total: 0.001322, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1098: Train: 0.001019, Val: 0.003277, Total: 0.001341, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1099: Train: 0.001025, Val: 0.002767, Total: 0.001274, LR: 1.89e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1100: Train: 0.001062, Val: 0.003124, Total: 0.001357, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1101: Train: 0.000965, Val: 0.003209, Total: 0.001286, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1102: Train: 0.000949, Val: 0.002863, Total: 0.001222, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1103: Train: 0.000960, Val: 0.003046, Total: 0.001258, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1104: Train: 0.000967, Val: 0.003292, Total: 0.001299, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1105: Train: 0.000888, Val: 0.002752, Total: 0.001154, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1106: Train: 0.000960, Val: 0.003231, Total: 0.001284, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1107: Train: 0.000966, Val: 0.003112, Total: 0.001273, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1108: Train: 0.000953, Val: 0.003094, Total: 0.001259, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1109: Train: 0.000884, Val: 0.003126, Total: 0.001205, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1110: Train: 0.000895, Val: 0.003232, Total: 0.001229, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1111: Train: 0.000974, Val: 0.003032, Total: 0.001268, LR: 1.88e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1112: Train: 0.001009, Val: 0.002896, Total: 0.001278, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1113: Train: 0.000964, Val: 0.003426, Total: 0.001315, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1114: Train: 0.000994, Val: 0.003129, Total: 0.001299, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1115: Train: 0.000963, Val: 0.002984, Total: 0.001251, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1116: Train: 0.000922, Val: 0.003355, Total: 0.001269, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1117: Train: 0.000939, Val: 0.003094, Total: 0.001247, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1118: Train: 0.000963, Val: 0.003252, Total: 0.001290, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1119: Train: 0.000980, Val: 0.003124, Total: 0.001286, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1120: Train: 0.000995, Val: 0.003456, Total: 0.001347, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1121: Train: 0.001016, Val: 0.003233, Total: 0.001333, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1122: Train: 0.001127, Val: 0.003022, Total: 0.001398, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1123: Train: 0.000960, Val: 0.003531, Total: 0.001327, LR: 1.87e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1124: Train: 0.000999, Val: 0.003020, Total: 0.001288, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1125: Train: 0.000973, Val: 0.003568, Total: 0.001344, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1126: Train: 0.001000, Val: 0.003279, Total: 0.001326, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1127: Train: 0.000943, Val: 0.003011, Total: 0.001238, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1128: Train: 0.000907, Val: 0.003104, Total: 0.001221, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1129: Train: 0.000911, Val: 0.002974, Total: 0.001205, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1130: Train: 0.000901, Val: 0.003192, Total: 0.001228, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1131: Train: 0.000901, Val: 0.003191, Total: 0.001228, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1132: Train: 0.000970, Val: 0.003155, Total: 0.001282, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1133: Train: 0.000928, Val: 0.003251, Total: 0.001260, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1134: Train: 0.000919, Val: 0.003117, Total: 0.001233, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1135: Train: 0.000999, Val: 0.003041, Total: 0.001291, LR: 1.86e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1136: Train: 0.000974, Val: 0.003150, Total: 0.001285, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1137: Train: 0.001005, Val: 0.003211, Total: 0.001320, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1138: Train: 0.000893, Val: 0.003007, Total: 0.001195, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1139: Train: 0.000887, Val: 0.003249, Total: 0.001224, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1140: Train: 0.000899, Val: 0.002957, Total: 0.001193, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1141: Train: 0.000908, Val: 0.003373, Total: 0.001260, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1142: Train: 0.000904, Val: 0.003153, Total: 0.001225, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1143: Train: 0.000946, Val: 0.003106, Total: 0.001255, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1144: Train: 0.000931, Val: 0.003155, Total: 0.001249, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1145: Train: 0.000905, Val: 0.002913, Total: 0.001192, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1146: Train: 0.000910, Val: 0.003322, Total: 0.001255, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1147: Train: 0.000936, Val: 0.003127, Total: 0.001249, LR: 1.85e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1148: Train: 0.000969, Val: 0.003135, Total: 0.001278, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1149: Train: 0.000935, Val: 0.003138, Total: 0.001250, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1150: Train: 0.000913, Val: 0.003203, Total: 0.001240, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1151: Train: 0.000886, Val: 0.003332, Total: 0.001235, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1152: Train: 0.000970, Val: 0.003131, Total: 0.001279, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1153: Train: 0.000887, Val: 0.003031, Total: 0.001193, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1154: Train: 0.000995, Val: 0.003034, Total: 0.001286, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1155: Train: 0.000915, Val: 0.003138, Total: 0.001232, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1156: Train: 0.000990, Val: 0.003465, Total: 0.001344, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1157: Train: 0.000914, Val: 0.003114, Total: 0.001228, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1158: Train: 0.000929, Val: 0.002994, Total: 0.001224, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1159: Train: 0.000959, Val: 0.003047, Total: 0.001257, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1160: Train: 0.001018, Val: 0.002999, Total: 0.001301, LR: 1.84e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1161: Train: 0.000906, Val: 0.003290, Total: 0.001247, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1162: Train: 0.000965, Val: 0.003114, Total: 0.001272, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1163: Train: 0.000902, Val: 0.003195, Total: 0.001230, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1164: Train: 0.000916, Val: 0.003278, Total: 0.001254, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1165: Train: 0.000944, Val: 0.003151, Total: 0.001260, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1166: Train: 0.000912, Val: 0.003453, Total: 0.001275, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1167: Train: 0.000874, Val: 0.003088, Total: 0.001190, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1168: Train: 0.000920, Val: 0.003733, Total: 0.001322, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1169: Train: 0.000907, Val: 0.002771, Total: 0.001173, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1170: Train: 0.000949, Val: 0.003164, Total: 0.001265, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1171: Train: 0.001030, Val: 0.003046, Total: 0.001318, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1172: Train: 0.000940, Val: 0.003296, Total: 0.001276, LR: 1.83e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1173: Train: 0.000952, Val: 0.003003, Total: 0.001245, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1174: Train: 0.000917, Val: 0.003313, Total: 0.001259, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1175: Train: 0.000917, Val: 0.003105, Total: 0.001230, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1176: Train: 0.000919, Val: 0.003033, Total: 0.001221, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1177: Train: 0.000937, Val: 0.003509, Total: 0.001304, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1178: Train: 0.000876, Val: 0.003167, Total: 0.001203, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1179: Train: 0.000893, Val: 0.003118, Total: 0.001210, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1180: Train: 0.000932, Val: 0.003014, Total: 0.001229, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1181: Train: 0.000913, Val: 0.003265, Total: 0.001249, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1182: Train: 0.000936, Val: 0.003173, Total: 0.001256, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1183: Train: 0.000917, Val: 0.003242, Total: 0.001249, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1184: Train: 0.000894, Val: 0.003035, Total: 0.001200, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1185: Train: 0.000948, Val: 0.003077, Total: 0.001252, LR: 1.82e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1186: Train: 0.000901, Val: 0.003223, Total: 0.001233, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1187: Train: 0.000948, Val: 0.003053, Total: 0.001249, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1188: Train: 0.000879, Val: 0.003059, Total: 0.001191, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1189: Train: 0.000887, Val: 0.003002, Total: 0.001189, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1190: Train: 0.000899, Val: 0.003196, Total: 0.001227, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1191: Train: 0.000895, Val: 0.003074, Total: 0.001207, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1192: Train: 0.000939, Val: 0.003157, Total: 0.001256, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1193: Train: 0.000966, Val: 0.002953, Total: 0.001250, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1194: Train: 0.000963, Val: 0.002946, Total: 0.001247, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1195: Train: 0.000940, Val: 0.003487, Total: 0.001304, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1196: Train: 0.000915, Val: 0.002991, Total: 0.001212, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1197: Train: 0.000930, Val: 0.002871, Total: 0.001207, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1198: Train: 0.000885, Val: 0.003149, Total: 0.001209, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1199: Train: 0.000900, Val: 0.002981, Total: 0.001197, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1200: Train: 0.000898, Val: 0.003106, Total: 0.001213, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1201: Train: 0.000867, Val: 0.003078, Total: 0.001183, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1202: Train: 0.000914, Val: 0.003175, Total: 0.001237, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1203: Train: 0.000892, Val: 0.003097, Total: 0.001207, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1204: Train: 0.000893, Val: 0.003123, Total: 0.001211, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1205: Train: 0.000909, Val: 0.003800, Total: 0.001322, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1206: Train: 0.000897, Val: 0.003011, Total: 0.001199, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1207: Train: 0.000849, Val: 0.002954, Total: 0.001149, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1208: Train: 0.000883, Val: 0.003214, Total: 0.001216, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1209: Train: 0.000869, Val: 0.002971, Total: 0.001169, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1210: Train: 0.000846, Val: 0.003122, Total: 0.001171, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1211: Train: 0.000912, Val: 0.002969, Total: 0.001206, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1212: Train: 0.000968, Val: 0.003102, Total: 0.001273, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1213: Train: 0.000977, Val: 0.003021, Total: 0.001269, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1214: Train: 0.000950, Val: 0.002824, Total: 0.001218, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1215: Train: 0.000924, Val: 0.003427, Total: 0.001282, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1216: Train: 0.001044, Val: 0.002681, Total: 0.001278, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1217: Train: 0.000958, Val: 0.003984, Total: 0.001390, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1218: Train: 0.000996, Val: 0.002899, Total: 0.001268, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1219: Train: 0.001025, Val: 0.003546, Total: 0.001385, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1220: Train: 0.001005, Val: 0.002993, Total: 0.001289, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1221: Train: 0.000987, Val: 0.002906, Total: 0.001261, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1222: Train: 0.000953, Val: 0.003151, Total: 0.001267, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1223: Train: 0.000968, Val: 0.002955, Total: 0.001251, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1224: Train: 0.000926, Val: 0.003310, Total: 0.001267, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1225: Train: 0.000940, Val: 0.003024, Total: 0.001238, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1226: Train: 0.000922, Val: 0.002987, Total: 0.001217, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1227: Train: 0.000913, Val: 0.003247, Total: 0.001247, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1228: Train: 0.000886, Val: 0.003010, Total: 0.001189, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1229: Train: 0.000951, Val: 0.002969, Total: 0.001239, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1230: Train: 0.000940, Val: 0.003176, Total: 0.001260, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1231: Train: 0.000902, Val: 0.003120, Total: 0.001219, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1232: Train: 0.000924, Val: 0.002979, Total: 0.001217, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1233: Train: 0.000945, Val: 0.003005, Total: 0.001239, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1234: Train: 0.000886, Val: 0.003210, Total: 0.001218, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1235: Train: 0.000953, Val: 0.003121, Total: 0.001263, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1236: Train: 0.000992, Val: 0.002992, Total: 0.001277, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1237: Train: 0.000944, Val: 0.003199, Total: 0.001266, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1238: Train: 0.000917, Val: 0.003262, Total: 0.001252, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1239: Train: 0.000938, Val: 0.003221, Total: 0.001264, LR: 1.78e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1240: Train: 0.000875, Val: 0.003142, Total: 0.001199, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1241: Train: 0.000887, Val: 0.003095, Total: 0.001202, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1242: Train: 0.000884, Val: 0.002919, Total: 0.001175, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1243: Train: 0.000891, Val: 0.003110, Total: 0.001208, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1244: Train: 0.000854, Val: 0.003090, Total: 0.001174, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1245: Train: 0.000870, Val: 0.003002, Total: 0.001175, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1246: Train: 0.000842, Val: 0.003117, Total: 0.001167, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1247: Train: 0.000894, Val: 0.003254, Total: 0.001231, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1248: Train: 0.000889, Val: 0.003189, Total: 0.001218, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1249: Train: 0.000837, Val: 0.002923, Total: 0.001135, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1250: Train: 0.000869, Val: 0.003128, Total: 0.001191, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1251: Train: 0.000849, Val: 0.003024, Total: 0.001160, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1252: Train: 0.000875, Val: 0.003094, Total: 0.001192, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1253: Train: 0.000810, Val: 0.003134, Total: 0.001142, LR: 1.77e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1254: Train: 0.000838, Val: 0.003194, Total: 0.001175, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1255: Train: 0.000913, Val: 0.003155, Total: 0.001233, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1256: Train: 0.000860, Val: 0.003063, Total: 0.001174, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1257: Train: 0.000946, Val: 0.003074, Total: 0.001250, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1258: Train: 0.000851, Val: 0.003160, Total: 0.001181, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1259: Train: 0.000891, Val: 0.003173, Total: 0.001217, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1260: Train: 0.000833, Val: 0.003088, Total: 0.001155, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1261: Train: 0.000877, Val: 0.003125, Total: 0.001198, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1262: Train: 0.000883, Val: 0.003340, Total: 0.001234, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1263: Train: 0.000902, Val: 0.002842, Total: 0.001179, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1264: Train: 0.000938, Val: 0.003176, Total: 0.001258, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1265: Train: 0.000958, Val: 0.003362, Total: 0.001302, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1266: Train: 0.000972, Val: 0.003246, Total: 0.001297, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1267: Train: 0.000963, Val: 0.003524, Total: 0.001329, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1268: Train: 0.000994, Val: 0.003219, Total: 0.001312, LR: 1.76e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1269: Train: 0.000913, Val: 0.003327, Total: 0.001258, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1270: Train: 0.000924, Val: 0.003173, Total: 0.001245, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1271: Train: 0.000883, Val: 0.003205, Total: 0.001215, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1272: Train: 0.000868, Val: 0.003093, Total: 0.001186, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1273: Train: 0.000888, Val: 0.003015, Total: 0.001192, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1274: Train: 0.000898, Val: 0.003143, Total: 0.001219, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1275: Train: 0.000909, Val: 0.003066, Total: 0.001217, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1276: Train: 0.000877, Val: 0.003101, Total: 0.001195, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1277: Train: 0.000874, Val: 0.003306, Total: 0.001222, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1278: Train: 0.000914, Val: 0.003082, Total: 0.001224, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1279: Train: 0.000864, Val: 0.003368, Total: 0.001222, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1280: Train: 0.000917, Val: 0.002972, Total: 0.001210, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1281: Train: 0.000960, Val: 0.003428, Total: 0.001313, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1282: Train: 0.000998, Val: 0.002788, Total: 0.001253, LR: 1.75e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1283: Train: 0.000980, Val: 0.002880, Total: 0.001251, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1284: Train: 0.000943, Val: 0.003971, Total: 0.001376, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1285: Train: 0.001074, Val: 0.002955, Total: 0.001343, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1286: Train: 0.001105, Val: 0.003832, Total: 0.001494, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1287: Train: 0.001062, Val: 0.002712, Total: 0.001298, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1288: Train: 0.001101, Val: 0.003161, Total: 0.001395, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1289: Train: 0.000938, Val: 0.003537, Total: 0.001310, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1290: Train: 0.000959, Val: 0.002734, Total: 0.001212, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1291: Train: 0.000867, Val: 0.003177, Total: 0.001197, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1292: Train: 0.000977, Val: 0.002897, Total: 0.001251, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1293: Train: 0.000908, Val: 0.003552, Total: 0.001285, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1294: Train: 0.000919, Val: 0.003139, Total: 0.001236, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1295: Train: 0.000838, Val: 0.002975, Total: 0.001144, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1296: Train: 0.000893, Val: 0.003205, Total: 0.001223, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1297: Train: 0.000953, Val: 0.003119, Total: 0.001262, LR: 1.74e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1298: Train: 0.000973, Val: 0.003428, Total: 0.001323, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1299: Train: 0.001000, Val: 0.003336, Total: 0.001333, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1300: Train: 0.000947, Val: 0.003406, Total: 0.001298, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1301: Train: 0.000972, Val: 0.003249, Total: 0.001297, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1302: Train: 0.001035, Val: 0.003228, Total: 0.001349, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1303: Train: 0.000995, Val: 0.003621, Total: 0.001370, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1304: Train: 0.000876, Val: 0.003434, Total: 0.001242, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1305: Train: 0.000991, Val: 0.003476, Total: 0.001346, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1306: Train: 0.000895, Val: 0.003206, Total: 0.001225, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1307: Train: 0.000927, Val: 0.003240, Total: 0.001257, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1308: Train: 0.000972, Val: 0.003460, Total: 0.001328, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1309: Train: 0.000958, Val: 0.003132, Total: 0.001269, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1310: Train: 0.000903, Val: 0.003361, Total: 0.001254, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1311: Train: 0.000947, Val: 0.003001, Total: 0.001241, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1312: Train: 0.000941, Val: 0.003097, Total: 0.001249, LR: 1.73e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1313: Train: 0.000896, Val: 0.003266, Total: 0.001234, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1314: Train: 0.000854, Val: 0.003143, Total: 0.001181, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1315: Train: 0.000895, Val: 0.003091, Total: 0.001209, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1316: Train: 0.000876, Val: 0.003289, Total: 0.001221, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1317: Train: 0.000821, Val: 0.003175, Total: 0.001157, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1318: Train: 0.000884, Val: 0.003426, Total: 0.001247, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1319: Train: 0.000853, Val: 0.003285, Total: 0.001200, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1320: Train: 0.000889, Val: 0.002992, Total: 0.001190, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1321: Train: 0.000911, Val: 0.003232, Total: 0.001243, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1322: Train: 0.000896, Val: 0.003102, Total: 0.001211, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1323: Train: 0.000872, Val: 0.003272, Total: 0.001215, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1324: Train: 0.000906, Val: 0.003090, Total: 0.001218, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1325: Train: 0.000888, Val: 0.003027, Total: 0.001193, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1326: Train: 0.000850, Val: 0.003128, Total: 0.001175, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1327: Train: 0.000832, Val: 0.003182, Total: 0.001167, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1328: Train: 0.000883, Val: 0.003225, Total: 0.001217, LR: 1.72e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1329: Train: 0.000843, Val: 0.003097, Total: 0.001165, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1330: Train: 0.000872, Val: 0.003068, Total: 0.001186, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1331: Train: 0.000899, Val: 0.003192, Total: 0.001226, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1332: Train: 0.000904, Val: 0.003122, Total: 0.001221, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1333: Train: 0.000881, Val: 0.002974, Total: 0.001180, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1334: Train: 0.000853, Val: 0.003165, Total: 0.001183, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1335: Train: 0.000837, Val: 0.003255, Total: 0.001183, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1336: Train: 0.000876, Val: 0.003090, Total: 0.001192, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1337: Train: 0.000832, Val: 0.003213, Total: 0.001172, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1338: Train: 0.000792, Val: 0.003137, Total: 0.001127, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1339: Train: 0.000784, Val: 0.003285, Total: 0.001141, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1340: Train: 0.000847, Val: 0.003078, Total: 0.001166, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1341: Train: 0.000801, Val: 0.003261, Total: 0.001152, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1342: Train: 0.000850, Val: 0.002919, Total: 0.001146, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1343: Train: 0.000790, Val: 0.003251, Total: 0.001142, LR: 1.71e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1344: Train: 0.000809, Val: 0.003088, Total: 0.001135, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1345: Train: 0.000781, Val: 0.003141, Total: 0.001118, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1346: Train: 0.000841, Val: 0.003213, Total: 0.001180, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1347: Train: 0.001070, Val: 0.002972, Total: 0.001342, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1348: Train: 0.000880, Val: 0.003351, Total: 0.001233, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1349: Train: 0.000870, Val: 0.003049, Total: 0.001181, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1350: Train: 0.000944, Val: 0.003295, Total: 0.001280, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1351: Train: 0.000824, Val: 0.003290, Total: 0.001177, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1352: Train: 0.000826, Val: 0.003587, Total: 0.001220, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1353: Train: 0.000907, Val: 0.003501, Total: 0.001278, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1354: Train: 0.000829, Val: 0.003076, Total: 0.001150, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1355: Train: 0.000867, Val: 0.002917, Total: 0.001160, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1356: Train: 0.000810, Val: 0.003114, Total: 0.001139, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1357: Train: 0.000817, Val: 0.003099, Total: 0.001143, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1358: Train: 0.000844, Val: 0.003132, Total: 0.001171, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1359: Train: 0.000843, Val: 0.003201, Total: 0.001180, LR: 1.70e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1360: Train: 0.000815, Val: 0.003201, Total: 0.001155, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1361: Train: 0.000794, Val: 0.003256, Total: 0.001146, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1362: Train: 0.000854, Val: 0.002884, Total: 0.001144, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1363: Train: 0.000838, Val: 0.003278, Total: 0.001186, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1364: Train: 0.000843, Val: 0.003124, Total: 0.001169, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1365: Train: 0.000788, Val: 0.003045, Total: 0.001111, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1366: Train: 0.000893, Val: 0.003050, Total: 0.001201, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1367: Train: 0.000929, Val: 0.003069, Total: 0.001235, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1368: Train: 0.000845, Val: 0.003363, Total: 0.001205, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1369: Train: 0.000905, Val: 0.002955, Total: 0.001198, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1370: Train: 0.000776, Val: 0.003373, Total: 0.001147, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1371: Train: 0.000819, Val: 0.002902, Total: 0.001117, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1372: Train: 0.000806, Val: 0.003598, Total: 0.001205, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1373: Train: 0.000783, Val: 0.003075, Total: 0.001111, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1374: Train: 0.000774, Val: 0.003087, Total: 0.001104, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1375: Train: 0.000835, Val: 0.003192, Total: 0.001172, LR: 1.69e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1376: Train: 0.000860, Val: 0.003368, Total: 0.001218, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1377: Train: 0.000810, Val: 0.003510, Total: 0.001195, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1378: Train: 0.000737, Val: 0.003381, Total: 0.001115, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1379: Train: 0.000763, Val: 0.003246, Total: 0.001118, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1380: Train: 0.000769, Val: 0.003193, Total: 0.001116, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1381: Train: 0.000741, Val: 0.003350, Total: 0.001113, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1382: Train: 0.000722, Val: 0.002959, Total: 0.001042, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1383: Train: 0.000785, Val: 0.003440, Total: 0.001164, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1384: Train: 0.000784, Val: 0.003052, Total: 0.001108, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1385: Train: 0.000803, Val: 0.003593, Total: 0.001201, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1386: Train: 0.000884, Val: 0.002865, Total: 0.001167, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1387: Train: 0.000870, Val: 0.003177, Total: 0.001199, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1388: Train: 0.000787, Val: 0.003159, Total: 0.001126, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1389: Train: 0.000743, Val: 0.003247, Total: 0.001101, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1390: Train: 0.000749, Val: 0.003357, Total: 0.001121, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1391: Train: 0.000763, Val: 0.003187, Total: 0.001109, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1392: Train: 0.000719, Val: 0.002864, Total: 0.001026, LR: 1.68e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1393: Train: 0.000788, Val: 0.003395, Total: 0.001161, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1394: Train: 0.000761, Val: 0.002875, Total: 0.001063, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1395: Train: 0.000798, Val: 0.003198, Total: 0.001141, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1396: Train: 0.000736, Val: 0.003162, Total: 0.001082, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1397: Train: 0.000787, Val: 0.003110, Total: 0.001119, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1398: Train: 0.000743, Val: 0.002914, Total: 0.001053, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1399: Train: 0.000879, Val: 0.003086, Total: 0.001194, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1400: Train: 0.000952, Val: 0.003485, Total: 0.001314, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1401: Train: 0.000903, Val: 0.003081, Total: 0.001214, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1402: Train: 0.000948, Val: 0.003295, Total: 0.001284, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1403: Train: 0.000858, Val: 0.002875, Total: 0.001146, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1404: Train: 0.000894, Val: 0.003144, Total: 0.001215, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1405: Train: 0.000841, Val: 0.003439, Total: 0.001212, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1406: Train: 0.000782, Val: 0.002864, Total: 0.001080, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1407: Train: 0.000782, Val: 0.003364, Total: 0.001151, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1408: Train: 0.000848, Val: 0.003097, Total: 0.001169, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1409: Train: 0.000836, Val: 0.003375, Total: 0.001199, LR: 1.67e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1410: Train: 0.000913, Val: 0.002701, Total: 0.001169, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1411: Train: 0.000860, Val: 0.003177, Total: 0.001191, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1412: Train: 0.000878, Val: 0.003394, Total: 0.001237, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1413: Train: 0.000832, Val: 0.003190, Total: 0.001169, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1414: Train: 0.000790, Val: 0.003040, Total: 0.001112, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1415: Train: 0.000813, Val: 0.003214, Total: 0.001156, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1416: Train: 0.000786, Val: 0.003001, Total: 0.001102, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1417: Train: 0.000862, Val: 0.003413, Total: 0.001227, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1418: Train: 0.000811, Val: 0.003299, Total: 0.001167, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1419: Train: 0.000845, Val: 0.002913, Total: 0.001140, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1420: Train: 0.000781, Val: 0.003250, Total: 0.001133, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1421: Train: 0.000768, Val: 0.003075, Total: 0.001098, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1422: Train: 0.000741, Val: 0.003333, Total: 0.001111, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1423: Train: 0.000738, Val: 0.002950, Total: 0.001054, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1424: Train: 0.000726, Val: 0.003209, Total: 0.001080, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1425: Train: 0.000826, Val: 0.003100, Total: 0.001151, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1426: Train: 0.000783, Val: 0.003159, Total: 0.001122, LR: 1.66e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1427: Train: 0.000839, Val: 0.003223, Total: 0.001179, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1428: Train: 0.000805, Val: 0.002764, Total: 0.001085, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1429: Train: 0.000907, Val: 0.003442, Total: 0.001269, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1430: Train: 0.000889, Val: 0.003413, Total: 0.001250, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1431: Train: 0.000792, Val: 0.002982, Total: 0.001105, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1432: Train: 0.000901, Val: 0.003100, Total: 0.001215, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1433: Train: 0.000814, Val: 0.003316, Total: 0.001172, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1434: Train: 0.000820, Val: 0.002738, Total: 0.001094, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1435: Train: 0.000739, Val: 0.003102, Total: 0.001077, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1436: Train: 0.000741, Val: 0.002816, Total: 0.001038, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1437: Train: 0.000744, Val: 0.003173, Total: 0.001091, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1438: Train: 0.000736, Val: 0.002869, Total: 0.001041, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1439: Train: 0.000775, Val: 0.002718, Total: 0.001052, LR: 1.65e-03\n",
      "          Best: Train: 0.000722, Val: 0.002804, Total: 0.001020 (Epoch 778)\n",
      "Epoch 1440: Train: 0.000709, Val: 0.002662, Total: 0.000988, LR: 1.65e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1441: Train: 0.000735, Val: 0.003290, Total: 0.001100, LR: 1.65e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1442: Train: 0.000799, Val: 0.003034, Total: 0.001118, LR: 1.65e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1443: Train: 0.000782, Val: 0.003203, Total: 0.001128, LR: 1.65e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1444: Train: 0.000699, Val: 0.003013, Total: 0.001030, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1445: Train: 0.000811, Val: 0.003264, Total: 0.001161, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1446: Train: 0.000932, Val: 0.002898, Total: 0.001212, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1447: Train: 0.000887, Val: 0.003397, Total: 0.001246, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1448: Train: 0.000812, Val: 0.003108, Total: 0.001140, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1449: Train: 0.000812, Val: 0.003300, Total: 0.001168, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1450: Train: 0.000753, Val: 0.003224, Total: 0.001106, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1451: Train: 0.000785, Val: 0.003364, Total: 0.001154, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1452: Train: 0.000806, Val: 0.002897, Total: 0.001105, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1453: Train: 0.000708, Val: 0.003503, Total: 0.001107, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1454: Train: 0.000690, Val: 0.002976, Total: 0.001016, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1455: Train: 0.000735, Val: 0.003291, Total: 0.001100, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1456: Train: 0.000779, Val: 0.002765, Total: 0.001063, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1457: Train: 0.000991, Val: 0.004301, Total: 0.001464, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1458: Train: 0.001058, Val: 0.003275, Total: 0.001374, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1459: Train: 0.000955, Val: 0.002857, Total: 0.001227, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1460: Train: 0.000834, Val: 0.002868, Total: 0.001124, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1461: Train: 0.000819, Val: 0.003274, Total: 0.001170, LR: 1.64e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1462: Train: 0.000792, Val: 0.002912, Total: 0.001095, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1463: Train: 0.000802, Val: 0.003060, Total: 0.001124, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1464: Train: 0.000785, Val: 0.003065, Total: 0.001110, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1465: Train: 0.000765, Val: 0.003107, Total: 0.001100, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1466: Train: 0.000807, Val: 0.003105, Total: 0.001135, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1467: Train: 0.000785, Val: 0.003680, Total: 0.001199, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1468: Train: 0.001004, Val: 0.003563, Total: 0.001370, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1469: Train: 0.001016, Val: 0.003741, Total: 0.001405, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1470: Train: 0.001040, Val: 0.003074, Total: 0.001331, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1471: Train: 0.000992, Val: 0.003234, Total: 0.001312, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1472: Train: 0.004038, Val: 0.003360, Total: 0.003941, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1473: Train: 0.004845, Val: 0.002663, Total: 0.004533, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1474: Train: 0.005782, Val: 0.002638, Total: 0.005333, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1475: Train: 0.005434, Val: 0.003621, Total: 0.005175, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1476: Train: 0.005289, Val: 0.003014, Total: 0.004964, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1477: Train: 0.004681, Val: 0.002901, Total: 0.004426, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1478: Train: 0.003411, Val: 0.005570, Total: 0.003720, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1479: Train: 0.004199, Val: 0.003860, Total: 0.004151, LR: 1.63e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1480: Train: 0.002333, Val: 0.003466, Total: 0.002495, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1481: Train: 0.002249, Val: 0.004290, Total: 0.002540, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1482: Train: 0.005989, Val: 0.003475, Total: 0.005630, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1483: Train: 0.005630, Val: 0.003804, Total: 0.005369, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1484: Train: 0.005891, Val: 0.003429, Total: 0.005539, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1485: Train: 0.005310, Val: 0.003141, Total: 0.005000, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1486: Train: 0.005372, Val: 0.002803, Total: 0.005005, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1487: Train: 0.004932, Val: 0.002711, Total: 0.004615, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1488: Train: 0.004995, Val: 0.002736, Total: 0.004673, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1489: Train: 0.004714, Val: 0.002710, Total: 0.004428, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1490: Train: 0.004884, Val: 0.002678, Total: 0.004569, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1491: Train: 0.004956, Val: 0.002637, Total: 0.004624, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1492: Train: 0.006908, Val: 0.003894, Total: 0.006477, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1493: Train: 0.005604, Val: 0.003358, Total: 0.005283, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1494: Train: 0.005900, Val: 0.003397, Total: 0.005543, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1495: Train: 0.005366, Val: 0.003408, Total: 0.005086, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1496: Train: 0.005349, Val: 0.003399, Total: 0.005071, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1497: Train: 0.006328, Val: 0.003428, Total: 0.005914, LR: 1.62e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1498: Train: 0.005570, Val: 0.003418, Total: 0.005263, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1499: Train: 0.005632, Val: 0.003440, Total: 0.005318, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1500: Train: 0.005504, Val: 0.003275, Total: 0.005185, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1501: Train: 0.005358, Val: 0.003186, Total: 0.005048, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1502: Train: 0.005647, Val: 0.002997, Total: 0.005268, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1503: Train: 0.005196, Val: 0.002909, Total: 0.004870, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1504: Train: 0.005021, Val: 0.002761, Total: 0.004698, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1505: Train: 0.005177, Val: 0.002920, Total: 0.004855, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1506: Train: 0.004984, Val: 0.002934, Total: 0.004692, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1507: Train: 0.004762, Val: 0.002866, Total: 0.004491, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1508: Train: 0.004810, Val: 0.002870, Total: 0.004532, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1509: Train: 0.004898, Val: 0.002752, Total: 0.004592, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1510: Train: 0.004774, Val: 0.002701, Total: 0.004478, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1511: Train: 0.005278, Val: 0.002773, Total: 0.004920, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1512: Train: 0.004993, Val: 0.002860, Total: 0.004688, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1513: Train: 0.005154, Val: 0.002889, Total: 0.004831, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1514: Train: 0.005005, Val: 0.002855, Total: 0.004698, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1515: Train: 0.004869, Val: 0.002792, Total: 0.004572, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1516: Train: 0.004956, Val: 0.002713, Total: 0.004635, LR: 1.61e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1517: Train: 0.004754, Val: 0.002712, Total: 0.004463, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1518: Train: 0.005017, Val: 0.002774, Total: 0.004696, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1519: Train: 0.004777, Val: 0.002696, Total: 0.004480, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1520: Train: 0.004706, Val: 0.002693, Total: 0.004418, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1521: Train: 0.004893, Val: 0.002641, Total: 0.004571, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1522: Train: 0.004902, Val: 0.002676, Total: 0.004584, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1523: Train: 0.004855, Val: 0.002707, Total: 0.004548, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1524: Train: 0.004727, Val: 0.002650, Total: 0.004431, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1525: Train: 0.004968, Val: 0.002658, Total: 0.004638, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1526: Train: 0.004948, Val: 0.002647, Total: 0.004619, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1527: Train: 0.004512, Val: 0.002601, Total: 0.004239, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1528: Train: 0.004517, Val: 0.002560, Total: 0.004237, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1529: Train: 0.004375, Val: 0.003108, Total: 0.004194, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1530: Train: 0.004948, Val: 0.002771, Total: 0.004637, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1531: Train: 0.003811, Val: 0.002692, Total: 0.003651, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1532: Train: 0.004255, Val: 0.002626, Total: 0.004022, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1533: Train: 0.003910, Val: 0.002966, Total: 0.003775, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1534: Train: 0.004013, Val: 0.004333, Total: 0.004059, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1535: Train: 0.004062, Val: 0.004308, Total: 0.004097, LR: 1.60e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1536: Train: 0.003449, Val: 0.004385, Total: 0.003583, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1537: Train: 0.002562, Val: 0.005495, Total: 0.002981, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1538: Train: 0.002161, Val: 0.005836, Total: 0.002686, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1539: Train: 0.003176, Val: 0.003001, Total: 0.003151, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1540: Train: 0.003242, Val: 0.003144, Total: 0.003228, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1541: Train: 0.003149, Val: 0.003920, Total: 0.003259, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1542: Train: 0.003118, Val: 0.003413, Total: 0.003160, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1543: Train: 0.003095, Val: 0.003979, Total: 0.003221, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1544: Train: 0.003036, Val: 0.003501, Total: 0.003102, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1545: Train: 0.003228, Val: 0.003183, Total: 0.003222, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1546: Train: 0.002897, Val: 0.003758, Total: 0.003020, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1547: Train: 0.003034, Val: 0.003754, Total: 0.003137, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1548: Train: 0.003352, Val: 0.003812, Total: 0.003418, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1549: Train: 0.005870, Val: 0.002743, Total: 0.005423, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1550: Train: 0.004159, Val: 0.002779, Total: 0.003962, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1551: Train: 0.003983, Val: 0.002951, Total: 0.003836, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1552: Train: 0.003139, Val: 0.003688, Total: 0.003217, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1553: Train: 0.002160, Val: 0.005733, Total: 0.002670, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1554: Train: 0.002609, Val: 0.006309, Total: 0.003138, LR: 1.59e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1555: Train: 0.002526, Val: 0.005553, Total: 0.002959, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1556: Train: 0.002413, Val: 0.004590, Total: 0.002724, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1557: Train: 0.002421, Val: 0.003179, Total: 0.002530, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1558: Train: 0.002216, Val: 0.005122, Total: 0.002631, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1559: Train: 0.002148, Val: 0.005934, Total: 0.002689, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1560: Train: 0.002122, Val: 0.003845, Total: 0.002368, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1561: Train: 0.002053, Val: 0.003953, Total: 0.002324, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1562: Train: 0.001853, Val: 0.004125, Total: 0.002178, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1563: Train: 0.001805, Val: 0.004594, Total: 0.002203, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1564: Train: 0.001907, Val: 0.004664, Total: 0.002301, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1565: Train: 0.001828, Val: 0.004663, Total: 0.002233, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1566: Train: 0.001831, Val: 0.004738, Total: 0.002246, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1567: Train: 0.002188, Val: 0.005027, Total: 0.002594, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1568: Train: 0.001886, Val: 0.004601, Total: 0.002274, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1569: Train: 0.001765, Val: 0.003961, Total: 0.002079, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1570: Train: 0.001725, Val: 0.004263, Total: 0.002087, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1571: Train: 0.001644, Val: 0.004091, Total: 0.001994, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1572: Train: 0.001803, Val: 0.004132, Total: 0.002136, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1573: Train: 0.001730, Val: 0.004735, Total: 0.002159, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1574: Train: 0.001797, Val: 0.004040, Total: 0.002117, LR: 1.58e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1575: Train: 0.001650, Val: 0.004567, Total: 0.002067, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1576: Train: 0.001657, Val: 0.004372, Total: 0.002045, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1577: Train: 0.001671, Val: 0.004582, Total: 0.002087, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1578: Train: 0.001779, Val: 0.004394, Total: 0.002152, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1579: Train: 0.001738, Val: 0.004658, Total: 0.002155, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1580: Train: 0.001677, Val: 0.004251, Total: 0.002045, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1581: Train: 0.001670, Val: 0.004152, Total: 0.002025, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1582: Train: 0.001677, Val: 0.004164, Total: 0.002033, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1583: Train: 0.001797, Val: 0.004888, Total: 0.002239, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1584: Train: 0.001916, Val: 0.003520, Total: 0.002145, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1585: Train: 0.001730, Val: 0.004065, Total: 0.002063, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1586: Train: 0.001746, Val: 0.004873, Total: 0.002193, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1587: Train: 0.001735, Val: 0.004527, Total: 0.002134, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1588: Train: 0.001574, Val: 0.003993, Total: 0.001920, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1589: Train: 0.001696, Val: 0.003882, Total: 0.002008, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1590: Train: 0.001689, Val: 0.004519, Total: 0.002093, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1591: Train: 0.001645, Val: 0.004350, Total: 0.002031, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1592: Train: 0.001551, Val: 0.003842, Total: 0.001878, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1593: Train: 0.001548, Val: 0.003824, Total: 0.001873, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1594: Train: 0.001633, Val: 0.004419, Total: 0.002031, LR: 1.57e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1595: Train: 0.001602, Val: 0.003999, Total: 0.001945, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1596: Train: 0.001626, Val: 0.004210, Total: 0.001995, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1597: Train: 0.001583, Val: 0.004311, Total: 0.001972, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1598: Train: 0.001516, Val: 0.004351, Total: 0.001921, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1599: Train: 0.001707, Val: 0.003452, Total: 0.001956, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1600: Train: 0.001594, Val: 0.003073, Total: 0.001806, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1601: Train: 0.001483, Val: 0.003610, Total: 0.001786, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1602: Train: 0.001295, Val: 0.003048, Total: 0.001546, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1603: Train: 0.001451, Val: 0.003731, Total: 0.001776, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1604: Train: 0.001393, Val: 0.003117, Total: 0.001639, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1605: Train: 0.001516, Val: 0.004088, Total: 0.001883, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1606: Train: 0.001371, Val: 0.003569, Total: 0.001685, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1607: Train: 0.001437, Val: 0.003074, Total: 0.001671, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1608: Train: 0.001368, Val: 0.003209, Total: 0.001631, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1609: Train: 0.001543, Val: 0.003298, Total: 0.001793, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1610: Train: 0.001568, Val: 0.004113, Total: 0.001932, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1611: Train: 0.001508, Val: 0.003269, Total: 0.001759, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1612: Train: 0.001385, Val: 0.002961, Total: 0.001610, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1613: Train: 0.001346, Val: 0.003582, Total: 0.001666, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1614: Train: 0.001451, Val: 0.003643, Total: 0.001764, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1615: Train: 0.001368, Val: 0.003137, Total: 0.001620, LR: 1.56e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1616: Train: 0.001431, Val: 0.002896, Total: 0.001641, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1617: Train: 0.001328, Val: 0.003255, Total: 0.001603, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1618: Train: 0.001340, Val: 0.003373, Total: 0.001630, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1619: Train: 0.001295, Val: 0.003311, Total: 0.001583, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1620: Train: 0.001375, Val: 0.003038, Total: 0.001613, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1621: Train: 0.001281, Val: 0.003494, Total: 0.001597, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1622: Train: 0.001388, Val: 0.004032, Total: 0.001766, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1623: Train: 0.001376, Val: 0.003286, Total: 0.001649, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1624: Train: 0.001421, Val: 0.002777, Total: 0.001615, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1625: Train: 0.001470, Val: 0.003771, Total: 0.001798, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1626: Train: 0.001417, Val: 0.003145, Total: 0.001664, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1627: Train: 0.001350, Val: 0.003038, Total: 0.001591, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1628: Train: 0.001368, Val: 0.003410, Total: 0.001660, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1629: Train: 0.001329, Val: 0.003085, Total: 0.001580, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1630: Train: 0.001361, Val: 0.003177, Total: 0.001620, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1631: Train: 0.001273, Val: 0.003310, Total: 0.001564, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1632: Train: 0.001292, Val: 0.003298, Total: 0.001578, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1633: Train: 0.001397, Val: 0.003061, Total: 0.001635, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1634: Train: 0.001297, Val: 0.002902, Total: 0.001526, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1635: Train: 0.001354, Val: 0.003966, Total: 0.001727, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1636: Train: 0.001388, Val: 0.003128, Total: 0.001636, LR: 1.55e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1637: Train: 0.001302, Val: 0.002827, Total: 0.001520, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1638: Train: 0.001402, Val: 0.003834, Total: 0.001750, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1639: Train: 0.001379, Val: 0.003483, Total: 0.001679, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1640: Train: 0.001211, Val: 0.003082, Total: 0.001478, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1641: Train: 0.001442, Val: 0.003328, Total: 0.001711, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1642: Train: 0.001351, Val: 0.003200, Total: 0.001615, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1643: Train: 0.001336, Val: 0.003278, Total: 0.001614, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1644: Train: 0.001318, Val: 0.003273, Total: 0.001597, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1645: Train: 0.001193, Val: 0.003187, Total: 0.001478, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1646: Train: 0.001294, Val: 0.003334, Total: 0.001585, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1647: Train: 0.001315, Val: 0.003380, Total: 0.001610, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1648: Train: 0.001292, Val: 0.003526, Total: 0.001611, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1649: Train: 0.001326, Val: 0.003429, Total: 0.001626, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1650: Train: 0.001345, Val: 0.003470, Total: 0.001649, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1651: Train: 0.001291, Val: 0.003324, Total: 0.001582, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1652: Train: 0.001223, Val: 0.003568, Total: 0.001558, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1653: Train: 0.001305, Val: 0.003248, Total: 0.001583, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1654: Train: 0.001226, Val: 0.003230, Total: 0.001512, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1655: Train: 0.001252, Val: 0.003436, Total: 0.001564, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1656: Train: 0.001293, Val: 0.003391, Total: 0.001593, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1657: Train: 0.001271, Val: 0.003018, Total: 0.001521, LR: 1.54e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1658: Train: 0.001418, Val: 0.003824, Total: 0.001762, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1659: Train: 0.001829, Val: 0.002948, Total: 0.001989, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1660: Train: 0.002022, Val: 0.002672, Total: 0.002115, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1661: Train: 0.001922, Val: 0.005572, Total: 0.002444, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1662: Train: 0.001972, Val: 0.003154, Total: 0.002141, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1663: Train: 0.002243, Val: 0.002604, Total: 0.002294, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1664: Train: 0.002926, Val: 0.002579, Total: 0.002876, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1665: Train: 0.002229, Val: 0.002803, Total: 0.002311, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1666: Train: 0.002029, Val: 0.002777, Total: 0.002136, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1667: Train: 0.001369, Val: 0.002960, Total: 0.001596, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1668: Train: 0.001408, Val: 0.003055, Total: 0.001643, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1669: Train: 0.001289, Val: 0.003204, Total: 0.001563, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1670: Train: 0.001366, Val: 0.003348, Total: 0.001649, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1671: Train: 0.001420, Val: 0.003153, Total: 0.001668, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1672: Train: 0.001497, Val: 0.003200, Total: 0.001740, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1673: Train: 0.001269, Val: 0.003648, Total: 0.001609, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1674: Train: 0.001263, Val: 0.002802, Total: 0.001483, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1675: Train: 0.001301, Val: 0.002864, Total: 0.001525, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1676: Train: 0.001369, Val: 0.003106, Total: 0.001617, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1677: Train: 0.001217, Val: 0.002943, Total: 0.001463, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1678: Train: 0.001483, Val: 0.003145, Total: 0.001720, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1679: Train: 0.002812, Val: 0.003356, Total: 0.002890, LR: 1.53e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1680: Train: 0.003951, Val: 0.005075, Total: 0.004112, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1681: Train: 0.002367, Val: 0.003743, Total: 0.002564, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1682: Train: 0.001885, Val: 0.004305, Total: 0.002230, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1683: Train: 0.003285, Val: 0.003285, Total: 0.003285, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1684: Train: 0.003083, Val: 0.003161, Total: 0.003094, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1685: Train: 0.002835, Val: 0.003187, Total: 0.002885, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1686: Train: 0.001922, Val: 0.003718, Total: 0.002178, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1687: Train: 0.001857, Val: 0.006285, Total: 0.002490, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1688: Train: 0.002478, Val: 0.004097, Total: 0.002709, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1689: Train: 0.001929, Val: 0.003561, Total: 0.002162, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1690: Train: 0.001744, Val: 0.004070, Total: 0.002076, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1691: Train: 0.001728, Val: 0.003924, Total: 0.002042, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1692: Train: 0.001640, Val: 0.004163, Total: 0.002001, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1693: Train: 0.001704, Val: 0.004465, Total: 0.002099, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1694: Train: 0.001700, Val: 0.003883, Total: 0.002012, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1695: Train: 0.001686, Val: 0.004490, Total: 0.002087, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1696: Train: 0.001681, Val: 0.004144, Total: 0.002033, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1697: Train: 0.001615, Val: 0.004146, Total: 0.001976, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1698: Train: 0.001714, Val: 0.004054, Total: 0.002048, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1699: Train: 0.001619, Val: 0.004597, Total: 0.002044, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1700: Train: 0.001652, Val: 0.003812, Total: 0.001961, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1701: Train: 0.001645, Val: 0.004214, Total: 0.002012, LR: 1.52e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1702: Train: 0.001790, Val: 0.004770, Total: 0.002216, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1703: Train: 0.001922, Val: 0.004043, Total: 0.002225, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1704: Train: 0.003384, Val: 0.004182, Total: 0.003498, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1705: Train: 0.006013, Val: 0.002425, Total: 0.005500, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1706: Train: 0.005677, Val: 0.002866, Total: 0.005275, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1707: Train: 0.003827, Val: 0.003277, Total: 0.003749, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1708: Train: 0.002747, Val: 0.004445, Total: 0.002990, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1709: Train: 0.002092, Val: 0.005915, Total: 0.002638, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1710: Train: 0.002539, Val: 0.004273, Total: 0.002787, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1711: Train: 0.002024, Val: 0.004898, Total: 0.002434, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1712: Train: 0.002067, Val: 0.004039, Total: 0.002349, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1713: Train: 0.001818, Val: 0.004551, Total: 0.002209, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1714: Train: 0.001851, Val: 0.004384, Total: 0.002213, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1715: Train: 0.001767, Val: 0.004143, Total: 0.002107, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1716: Train: 0.001642, Val: 0.004572, Total: 0.002061, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1717: Train: 0.001600, Val: 0.004594, Total: 0.002028, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1718: Train: 0.001621, Val: 0.006469, Total: 0.002313, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1719: Train: 0.001875, Val: 0.004404, Total: 0.002237, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1720: Train: 0.001730, Val: 0.004207, Total: 0.002084, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1721: Train: 0.002142, Val: 0.003365, Total: 0.002317, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1722: Train: 0.001888, Val: 0.005934, Total: 0.002466, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1723: Train: 0.002319, Val: 0.004847, Total: 0.002680, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1724: Train: 0.003458, Val: 0.004747, Total: 0.003642, LR: 1.51e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1725: Train: 0.003706, Val: 0.002967, Total: 0.003600, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1726: Train: 0.003056, Val: 0.003487, Total: 0.003118, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1727: Train: 0.002558, Val: 0.004408, Total: 0.002822, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1728: Train: 0.002005, Val: 0.005318, Total: 0.002478, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1729: Train: 0.002235, Val: 0.004612, Total: 0.002574, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1730: Train: 0.001908, Val: 0.004788, Total: 0.002319, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1731: Train: 0.002913, Val: 0.003662, Total: 0.003020, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1732: Train: 0.002833, Val: 0.002864, Total: 0.002838, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1733: Train: 0.002185, Val: 0.003423, Total: 0.002362, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1734: Train: 0.001690, Val: 0.005000, Total: 0.002163, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1735: Train: 0.001813, Val: 0.005650, Total: 0.002361, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1736: Train: 0.001726, Val: 0.004351, Total: 0.002101, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1737: Train: 0.001932, Val: 0.003405, Total: 0.002142, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1738: Train: 0.001628, Val: 0.003869, Total: 0.001948, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1739: Train: 0.001603, Val: 0.004708, Total: 0.002046, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1740: Train: 0.001637, Val: 0.004899, Total: 0.002103, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1741: Train: 0.001585, Val: 0.003984, Total: 0.001927, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1742: Train: 0.001429, Val: 0.004513, Total: 0.001870, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1743: Train: 0.001469, Val: 0.004752, Total: 0.001938, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1744: Train: 0.001514, Val: 0.004698, Total: 0.001969, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1745: Train: 0.001553, Val: 0.004001, Total: 0.001902, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1746: Train: 0.001495, Val: 0.004055, Total: 0.001861, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1747: Train: 0.001451, Val: 0.004869, Total: 0.001940, LR: 1.50e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1748: Train: 0.001391, Val: 0.004713, Total: 0.001865, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1749: Train: 0.001375, Val: 0.004201, Total: 0.001778, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1750: Train: 0.001503, Val: 0.004127, Total: 0.001878, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1751: Train: 0.001593, Val: 0.004677, Total: 0.002033, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1752: Train: 0.001443, Val: 0.005083, Total: 0.001963, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1753: Train: 0.001415, Val: 0.004443, Total: 0.001848, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1754: Train: 0.001371, Val: 0.003812, Total: 0.001719, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1755: Train: 0.001505, Val: 0.003817, Total: 0.001835, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1756: Train: 0.001378, Val: 0.004248, Total: 0.001788, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1757: Train: 0.001309, Val: 0.003823, Total: 0.001668, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1758: Train: 0.001447, Val: 0.003612, Total: 0.001756, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1759: Train: 0.001415, Val: 0.003267, Total: 0.001680, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1760: Train: 0.001276, Val: 0.005084, Total: 0.001820, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1761: Train: 0.001540, Val: 0.002832, Total: 0.001724, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1762: Train: 0.001279, Val: 0.002951, Total: 0.001518, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1763: Train: 0.001226, Val: 0.003666, Total: 0.001574, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1764: Train: 0.001284, Val: 0.003133, Total: 0.001548, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1765: Train: 0.001201, Val: 0.003019, Total: 0.001461, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1766: Train: 0.001208, Val: 0.003257, Total: 0.001501, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1767: Train: 0.001260, Val: 0.003252, Total: 0.001545, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1768: Train: 0.001170, Val: 0.003049, Total: 0.001438, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1769: Train: 0.001253, Val: 0.003255, Total: 0.001539, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1770: Train: 0.001229, Val: 0.003268, Total: 0.001521, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1771: Train: 0.001194, Val: 0.002998, Total: 0.001452, LR: 1.49e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1772: Train: 0.001183, Val: 0.003386, Total: 0.001497, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1773: Train: 0.001171, Val: 0.003518, Total: 0.001506, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1774: Train: 0.001183, Val: 0.003388, Total: 0.001498, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1775: Train: 0.001086, Val: 0.003109, Total: 0.001375, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1776: Train: 0.001199, Val: 0.002928, Total: 0.001446, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1777: Train: 0.001171, Val: 0.003058, Total: 0.001441, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1778: Train: 0.001199, Val: 0.003250, Total: 0.001492, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1779: Train: 0.001178, Val: 0.003401, Total: 0.001495, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1780: Train: 0.001180, Val: 0.003279, Total: 0.001480, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1781: Train: 0.001194, Val: 0.003280, Total: 0.001492, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1782: Train: 0.001198, Val: 0.003360, Total: 0.001507, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1783: Train: 0.001271, Val: 0.004100, Total: 0.001675, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1784: Train: 0.001225, Val: 0.002884, Total: 0.001462, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1785: Train: 0.001232, Val: 0.003244, Total: 0.001520, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1786: Train: 0.001415, Val: 0.003199, Total: 0.001670, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1787: Train: 0.001301, Val: 0.002914, Total: 0.001531, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1788: Train: 0.001407, Val: 0.004281, Total: 0.001818, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1789: Train: 0.001492, Val: 0.004575, Total: 0.001932, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1790: Train: 0.001180, Val: 0.002997, Total: 0.001439, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1791: Train: 0.001267, Val: 0.002913, Total: 0.001502, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1792: Train: 0.001108, Val: 0.003330, Total: 0.001426, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1793: Train: 0.001238, Val: 0.003258, Total: 0.001526, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1794: Train: 0.001169, Val: 0.002972, Total: 0.001427, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1795: Train: 0.001159, Val: 0.003327, Total: 0.001469, LR: 1.48e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1796: Train: 0.001278, Val: 0.003617, Total: 0.001613, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1797: Train: 0.001266, Val: 0.003003, Total: 0.001514, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1798: Train: 0.001283, Val: 0.003007, Total: 0.001529, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1799: Train: 0.001308, Val: 0.003620, Total: 0.001638, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1800: Train: 0.001183, Val: 0.003342, Total: 0.001492, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1801: Train: 0.001284, Val: 0.003015, Total: 0.001531, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1802: Train: 0.001205, Val: 0.003084, Total: 0.001474, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1803: Train: 0.001234, Val: 0.003332, Total: 0.001534, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1804: Train: 0.001267, Val: 0.003350, Total: 0.001564, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1805: Train: 0.001239, Val: 0.003156, Total: 0.001513, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1806: Train: 0.001226, Val: 0.003186, Total: 0.001506, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1807: Train: 0.001281, Val: 0.003419, Total: 0.001587, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1808: Train: 0.001253, Val: 0.003320, Total: 0.001548, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1809: Train: 0.001286, Val: 0.003188, Total: 0.001557, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1810: Train: 0.001203, Val: 0.003277, Total: 0.001499, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1811: Train: 0.001345, Val: 0.003114, Total: 0.001598, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1812: Train: 0.001286, Val: 0.003176, Total: 0.001556, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1813: Train: 0.001225, Val: 0.003451, Total: 0.001543, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1814: Train: 0.001167, Val: 0.003594, Total: 0.001514, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1815: Train: 0.001218, Val: 0.003064, Total: 0.001482, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1816: Train: 0.001134, Val: 0.003087, Total: 0.001413, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1817: Train: 0.001122, Val: 0.003371, Total: 0.001443, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1818: Train: 0.001226, Val: 0.003648, Total: 0.001572, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1819: Train: 0.001138, Val: 0.003093, Total: 0.001417, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1820: Train: 0.001195, Val: 0.003015, Total: 0.001455, LR: 1.47e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1821: Train: 0.001111, Val: 0.003117, Total: 0.001398, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1822: Train: 0.001137, Val: 0.003332, Total: 0.001451, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1823: Train: 0.001101, Val: 0.003276, Total: 0.001412, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1824: Train: 0.001115, Val: 0.003195, Total: 0.001412, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1825: Train: 0.001136, Val: 0.003419, Total: 0.001463, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1826: Train: 0.001186, Val: 0.003129, Total: 0.001464, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1827: Train: 0.001201, Val: 0.003170, Total: 0.001483, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1828: Train: 0.001123, Val: 0.003620, Total: 0.001480, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1829: Train: 0.001046, Val: 0.003444, Total: 0.001389, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1830: Train: 0.001123, Val: 0.003044, Total: 0.001397, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1831: Train: 0.001136, Val: 0.003141, Total: 0.001423, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1832: Train: 0.001132, Val: 0.003271, Total: 0.001437, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1833: Train: 0.001041, Val: 0.003359, Total: 0.001372, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1834: Train: 0.001128, Val: 0.003403, Total: 0.001453, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1835: Train: 0.001154, Val: 0.003191, Total: 0.001445, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1836: Train: 0.001092, Val: 0.003088, Total: 0.001377, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1837: Train: 0.001008, Val: 0.003200, Total: 0.001321, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1838: Train: 0.001050, Val: 0.003572, Total: 0.001410, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1839: Train: 0.001151, Val: 0.003585, Total: 0.001498, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1840: Train: 0.001064, Val: 0.003118, Total: 0.001358, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1841: Train: 0.001114, Val: 0.003144, Total: 0.001404, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1842: Train: 0.001086, Val: 0.003056, Total: 0.001367, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1843: Train: 0.001190, Val: 0.003102, Total: 0.001463, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1844: Train: 0.001105, Val: 0.003600, Total: 0.001461, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1845: Train: 0.001222, Val: 0.003371, Total: 0.001529, LR: 1.46e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1846: Train: 0.001043, Val: 0.002981, Total: 0.001320, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1847: Train: 0.001136, Val: 0.003156, Total: 0.001424, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1848: Train: 0.001100, Val: 0.003188, Total: 0.001398, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1849: Train: 0.001090, Val: 0.003241, Total: 0.001398, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1850: Train: 0.001201, Val: 0.003069, Total: 0.001468, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1851: Train: 0.001105, Val: 0.003153, Total: 0.001398, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1852: Train: 0.001083, Val: 0.003424, Total: 0.001417, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1853: Train: 0.001285, Val: 0.003295, Total: 0.001572, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1854: Train: 0.001164, Val: 0.003055, Total: 0.001434, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1855: Train: 0.001172, Val: 0.003030, Total: 0.001438, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1856: Train: 0.001206, Val: 0.003335, Total: 0.001510, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1857: Train: 0.001190, Val: 0.003062, Total: 0.001458, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1858: Train: 0.001279, Val: 0.003087, Total: 0.001537, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1859: Train: 0.001136, Val: 0.003824, Total: 0.001520, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1860: Train: 0.001246, Val: 0.003467, Total: 0.001563, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1861: Train: 0.001098, Val: 0.003005, Total: 0.001371, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1862: Train: 0.001136, Val: 0.003461, Total: 0.001468, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1863: Train: 0.001134, Val: 0.003605, Total: 0.001487, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1864: Train: 0.001071, Val: 0.003286, Total: 0.001387, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1865: Train: 0.001132, Val: 0.003073, Total: 0.001409, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1866: Train: 0.001146, Val: 0.003331, Total: 0.001458, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1867: Train: 0.001086, Val: 0.003017, Total: 0.001362, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1868: Train: 0.001126, Val: 0.003158, Total: 0.001416, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1869: Train: 0.001091, Val: 0.003350, Total: 0.001414, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1870: Train: 0.001142, Val: 0.003186, Total: 0.001434, LR: 1.45e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1871: Train: 0.001186, Val: 0.003229, Total: 0.001477, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1872: Train: 0.001150, Val: 0.003359, Total: 0.001466, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1873: Train: 0.001066, Val: 0.003227, Total: 0.001375, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1874: Train: 0.001092, Val: 0.003077, Total: 0.001376, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1875: Train: 0.001112, Val: 0.003212, Total: 0.001412, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1876: Train: 0.001133, Val: 0.003376, Total: 0.001453, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1877: Train: 0.001052, Val: 0.003114, Total: 0.001346, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1878: Train: 0.001070, Val: 0.003056, Total: 0.001354, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1879: Train: 0.001053, Val: 0.003395, Total: 0.001387, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1880: Train: 0.001117, Val: 0.003451, Total: 0.001451, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1881: Train: 0.001060, Val: 0.003437, Total: 0.001399, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1882: Train: 0.001208, Val: 0.003123, Total: 0.001482, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1883: Train: 0.001081, Val: 0.002957, Total: 0.001349, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1884: Train: 0.001129, Val: 0.003726, Total: 0.001500, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1885: Train: 0.001221, Val: 0.003382, Total: 0.001529, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1886: Train: 0.001203, Val: 0.002974, Total: 0.001456, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1887: Train: 0.001085, Val: 0.003279, Total: 0.001398, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1888: Train: 0.001097, Val: 0.003391, Total: 0.001425, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1889: Train: 0.001155, Val: 0.003087, Total: 0.001431, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1890: Train: 0.001113, Val: 0.003159, Total: 0.001405, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1891: Train: 0.001112, Val: 0.003270, Total: 0.001420, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1892: Train: 0.001041, Val: 0.003296, Total: 0.001363, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1893: Train: 0.001106, Val: 0.003269, Total: 0.001415, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1894: Train: 0.001168, Val: 0.003253, Total: 0.001466, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1895: Train: 0.001179, Val: 0.003282, Total: 0.001479, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1896: Train: 0.001055, Val: 0.003244, Total: 0.001367, LR: 1.44e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1897: Train: 0.001138, Val: 0.002962, Total: 0.001399, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1898: Train: 0.001159, Val: 0.003352, Total: 0.001472, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1899: Train: 0.001081, Val: 0.003263, Total: 0.001393, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1900: Train: 0.001111, Val: 0.003127, Total: 0.001399, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1901: Train: 0.001122, Val: 0.003314, Total: 0.001435, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1902: Train: 0.001080, Val: 0.003290, Total: 0.001396, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1903: Train: 0.001055, Val: 0.003365, Total: 0.001385, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1904: Train: 0.001104, Val: 0.003013, Total: 0.001377, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1905: Train: 0.001035, Val: 0.002960, Total: 0.001310, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1906: Train: 0.001048, Val: 0.003373, Total: 0.001380, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1907: Train: 0.001085, Val: 0.003309, Total: 0.001402, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1908: Train: 0.001180, Val: 0.003119, Total: 0.001457, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1909: Train: 0.001122, Val: 0.003067, Total: 0.001400, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1910: Train: 0.001007, Val: 0.003147, Total: 0.001313, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1911: Train: 0.001007, Val: 0.003275, Total: 0.001331, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1912: Train: 0.001022, Val: 0.003251, Total: 0.001340, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1913: Train: 0.001054, Val: 0.003293, Total: 0.001374, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1914: Train: 0.001067, Val: 0.003397, Total: 0.001400, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1915: Train: 0.001058, Val: 0.003157, Total: 0.001358, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1916: Train: 0.001058, Val: 0.003081, Total: 0.001347, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1917: Train: 0.001042, Val: 0.003254, Total: 0.001358, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1918: Train: 0.001058, Val: 0.003219, Total: 0.001366, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1919: Train: 0.001029, Val: 0.003186, Total: 0.001337, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1920: Train: 0.001075, Val: 0.003261, Total: 0.001387, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1921: Train: 0.001084, Val: 0.003124, Total: 0.001376, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1922: Train: 0.001060, Val: 0.003145, Total: 0.001358, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1923: Train: 0.001073, Val: 0.003059, Total: 0.001357, LR: 1.43e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1924: Train: 0.001139, Val: 0.003499, Total: 0.001476, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1925: Train: 0.001066, Val: 0.003263, Total: 0.001380, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1926: Train: 0.001032, Val: 0.002822, Total: 0.001288, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1927: Train: 0.001094, Val: 0.003308, Total: 0.001410, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1928: Train: 0.001109, Val: 0.003387, Total: 0.001434, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1929: Train: 0.001031, Val: 0.002971, Total: 0.001308, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1930: Train: 0.001127, Val: 0.003154, Total: 0.001416, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1931: Train: 0.001039, Val: 0.003519, Total: 0.001393, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1932: Train: 0.001068, Val: 0.002873, Total: 0.001326, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1933: Train: 0.001167, Val: 0.003056, Total: 0.001437, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1934: Train: 0.001093, Val: 0.003706, Total: 0.001466, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1935: Train: 0.001066, Val: 0.003240, Total: 0.001376, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1936: Train: 0.001032, Val: 0.002978, Total: 0.001310, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1937: Train: 0.001036, Val: 0.003273, Total: 0.001356, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1938: Train: 0.001115, Val: 0.003257, Total: 0.001421, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1939: Train: 0.001092, Val: 0.003178, Total: 0.001390, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1940: Train: 0.001088, Val: 0.003566, Total: 0.001442, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1941: Train: 0.001080, Val: 0.002908, Total: 0.001341, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1942: Train: 0.001056, Val: 0.003271, Total: 0.001372, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1943: Train: 0.001019, Val: 0.003498, Total: 0.001373, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1944: Train: 0.001107, Val: 0.003058, Total: 0.001386, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1945: Train: 0.001097, Val: 0.003415, Total: 0.001428, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1946: Train: 0.001044, Val: 0.003905, Total: 0.001453, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1947: Train: 0.001173, Val: 0.002969, Total: 0.001430, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1948: Train: 0.001187, Val: 0.002946, Total: 0.001438, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1949: Train: 0.001131, Val: 0.003848, Total: 0.001519, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1950: Train: 0.001233, Val: 0.003813, Total: 0.001602, LR: 1.42e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1951: Train: 0.001119, Val: 0.003116, Total: 0.001404, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1952: Train: 0.001136, Val: 0.003004, Total: 0.001403, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1953: Train: 0.001113, Val: 0.003392, Total: 0.001438, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1954: Train: 0.001084, Val: 0.002949, Total: 0.001351, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1955: Train: 0.001066, Val: 0.003248, Total: 0.001378, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1956: Train: 0.001051, Val: 0.003410, Total: 0.001388, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1957: Train: 0.001018, Val: 0.003085, Total: 0.001314, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1958: Train: 0.001058, Val: 0.003278, Total: 0.001375, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1959: Train: 0.001043, Val: 0.003427, Total: 0.001383, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1960: Train: 0.001024, Val: 0.003267, Total: 0.001344, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1961: Train: 0.001044, Val: 0.003140, Total: 0.001343, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1962: Train: 0.001064, Val: 0.003188, Total: 0.001368, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1963: Train: 0.001041, Val: 0.003367, Total: 0.001373, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1964: Train: 0.001028, Val: 0.003294, Total: 0.001352, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1965: Train: 0.001118, Val: 0.003102, Total: 0.001401, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1966: Train: 0.001188, Val: 0.002981, Total: 0.001444, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1967: Train: 0.001158, Val: 0.003044, Total: 0.001427, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1968: Train: 0.001180, Val: 0.003103, Total: 0.001455, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1969: Train: 0.001183, Val: 0.002955, Total: 0.001436, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1970: Train: 0.001119, Val: 0.003062, Total: 0.001396, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1971: Train: 0.001208, Val: 0.003455, Total: 0.001529, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1972: Train: 0.001111, Val: 0.003340, Total: 0.001429, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1973: Train: 0.001181, Val: 0.003104, Total: 0.001456, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1974: Train: 0.001050, Val: 0.003094, Total: 0.001342, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1975: Train: 0.001069, Val: 0.003210, Total: 0.001375, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1976: Train: 0.001072, Val: 0.002764, Total: 0.001314, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1977: Train: 0.001081, Val: 0.003150, Total: 0.001376, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1978: Train: 0.001106, Val: 0.003476, Total: 0.001445, LR: 1.41e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1979: Train: 0.001005, Val: 0.002852, Total: 0.001269, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1980: Train: 0.001109, Val: 0.003401, Total: 0.001437, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1981: Train: 0.000990, Val: 0.003693, Total: 0.001376, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1982: Train: 0.001082, Val: 0.002772, Total: 0.001324, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1983: Train: 0.001091, Val: 0.003116, Total: 0.001381, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1984: Train: 0.001206, Val: 0.003504, Total: 0.001534, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1985: Train: 0.001006, Val: 0.002625, Total: 0.001238, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1986: Train: 0.001091, Val: 0.002879, Total: 0.001346, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1987: Train: 0.001120, Val: 0.003587, Total: 0.001473, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1988: Train: 0.001078, Val: 0.002864, Total: 0.001333, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1989: Train: 0.001187, Val: 0.003052, Total: 0.001453, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1990: Train: 0.001036, Val: 0.003800, Total: 0.001431, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1991: Train: 0.001005, Val: 0.002913, Total: 0.001278, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1992: Train: 0.001071, Val: 0.002666, Total: 0.001298, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1993: Train: 0.001061, Val: 0.003052, Total: 0.001345, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1994: Train: 0.000981, Val: 0.003431, Total: 0.001331, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1995: Train: 0.001001, Val: 0.003150, Total: 0.001308, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1996: Train: 0.000979, Val: 0.002950, Total: 0.001261, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1997: Train: 0.001017, Val: 0.003270, Total: 0.001339, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1998: Train: 0.000983, Val: 0.003087, Total: 0.001284, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 1999: Train: 0.001109, Val: 0.003013, Total: 0.001381, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2000: Train: 0.000986, Val: 0.003109, Total: 0.001289, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2001: Train: 0.000985, Val: 0.003329, Total: 0.001320, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2002: Train: 0.001014, Val: 0.003137, Total: 0.001318, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2003: Train: 0.001073, Val: 0.003224, Total: 0.001380, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2004: Train: 0.000942, Val: 0.003053, Total: 0.001243, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2005: Train: 0.000963, Val: 0.002913, Total: 0.001241, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2006: Train: 0.000985, Val: 0.003014, Total: 0.001275, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2007: Train: 0.001016, Val: 0.003292, Total: 0.001341, LR: 1.40e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2008: Train: 0.000979, Val: 0.002933, Total: 0.001258, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2009: Train: 0.001024, Val: 0.002966, Total: 0.001301, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2010: Train: 0.000917, Val: 0.003138, Total: 0.001234, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2011: Train: 0.000938, Val: 0.003043, Total: 0.001238, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2012: Train: 0.001001, Val: 0.002835, Total: 0.001263, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2013: Train: 0.000950, Val: 0.002911, Total: 0.001230, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2014: Train: 0.000965, Val: 0.003037, Total: 0.001261, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2015: Train: 0.000910, Val: 0.003007, Total: 0.001209, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2016: Train: 0.000951, Val: 0.003065, Total: 0.001253, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2017: Train: 0.000971, Val: 0.002947, Total: 0.001253, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2018: Train: 0.001002, Val: 0.002900, Total: 0.001273, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2019: Train: 0.000948, Val: 0.002913, Total: 0.001229, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2020: Train: 0.000910, Val: 0.002824, Total: 0.001184, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2021: Train: 0.000962, Val: 0.002754, Total: 0.001218, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2022: Train: 0.000980, Val: 0.003102, Total: 0.001283, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2023: Train: 0.001032, Val: 0.002886, Total: 0.001296, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2024: Train: 0.000961, Val: 0.002802, Total: 0.001224, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2025: Train: 0.000969, Val: 0.003237, Total: 0.001293, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2026: Train: 0.001051, Val: 0.002956, Total: 0.001323, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2027: Train: 0.000973, Val: 0.002695, Total: 0.001219, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2028: Train: 0.001042, Val: 0.003337, Total: 0.001370, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2029: Train: 0.001004, Val: 0.003443, Total: 0.001353, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2030: Train: 0.000999, Val: 0.002645, Total: 0.001234, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2031: Train: 0.001025, Val: 0.002826, Total: 0.001283, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2032: Train: 0.001120, Val: 0.003354, Total: 0.001439, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2033: Train: 0.001141, Val: 0.003449, Total: 0.001471, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2034: Train: 0.001347, Val: 0.003093, Total: 0.001597, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2035: Train: 0.001459, Val: 0.003031, Total: 0.001684, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2036: Train: 0.001353, Val: 0.003843, Total: 0.001709, LR: 1.39e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2037: Train: 0.001171, Val: 0.003141, Total: 0.001452, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2038: Train: 0.001271, Val: 0.003268, Total: 0.001556, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2039: Train: 0.001139, Val: 0.003585, Total: 0.001489, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2040: Train: 0.001160, Val: 0.002952, Total: 0.001416, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2041: Train: 0.001122, Val: 0.003169, Total: 0.001415, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2042: Train: 0.001002, Val: 0.003122, Total: 0.001305, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2043: Train: 0.001121, Val: 0.002854, Total: 0.001369, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2044: Train: 0.001036, Val: 0.003175, Total: 0.001342, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2045: Train: 0.001038, Val: 0.003369, Total: 0.001371, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2046: Train: 0.001016, Val: 0.002864, Total: 0.001280, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2047: Train: 0.000976, Val: 0.002987, Total: 0.001263, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2048: Train: 0.000952, Val: 0.002830, Total: 0.001220, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2049: Train: 0.001009, Val: 0.002930, Total: 0.001284, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2050: Train: 0.001044, Val: 0.003314, Total: 0.001369, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2051: Train: 0.001106, Val: 0.002853, Total: 0.001356, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2052: Train: 0.001019, Val: 0.002904, Total: 0.001288, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2053: Train: 0.001077, Val: 0.003160, Total: 0.001375, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2054: Train: 0.001035, Val: 0.002809, Total: 0.001288, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2055: Train: 0.000985, Val: 0.003043, Total: 0.001279, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2056: Train: 0.000966, Val: 0.002830, Total: 0.001232, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2057: Train: 0.001006, Val: 0.002908, Total: 0.001277, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2058: Train: 0.000970, Val: 0.003583, Total: 0.001343, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2059: Train: 0.000995, Val: 0.003295, Total: 0.001324, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2060: Train: 0.000943, Val: 0.002810, Total: 0.001209, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2061: Train: 0.000942, Val: 0.003052, Total: 0.001243, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2062: Train: 0.000918, Val: 0.003236, Total: 0.001249, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2063: Train: 0.000952, Val: 0.002839, Total: 0.001222, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2064: Train: 0.001041, Val: 0.002973, Total: 0.001317, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2065: Train: 0.001092, Val: 0.003435, Total: 0.001427, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2066: Train: 0.001196, Val: 0.002418, Total: 0.001371, LR: 1.38e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2067: Train: 0.001108, Val: 0.003058, Total: 0.001387, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2068: Train: 0.001047, Val: 0.003904, Total: 0.001455, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2069: Train: 0.000972, Val: 0.002726, Total: 0.001223, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2070: Train: 0.001035, Val: 0.002720, Total: 0.001275, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2071: Train: 0.000921, Val: 0.003281, Total: 0.001258, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2072: Train: 0.001009, Val: 0.003094, Total: 0.001307, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2073: Train: 0.000988, Val: 0.002930, Total: 0.001265, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2074: Train: 0.000976, Val: 0.003183, Total: 0.001291, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2075: Train: 0.000903, Val: 0.002954, Total: 0.001196, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2076: Train: 0.000992, Val: 0.002910, Total: 0.001266, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2077: Train: 0.000917, Val: 0.003115, Total: 0.001231, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2078: Train: 0.001009, Val: 0.002638, Total: 0.001242, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2079: Train: 0.000981, Val: 0.002954, Total: 0.001263, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2080: Train: 0.000923, Val: 0.003291, Total: 0.001262, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2081: Train: 0.000955, Val: 0.002803, Total: 0.001219, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2082: Train: 0.000890, Val: 0.002728, Total: 0.001153, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2083: Train: 0.000969, Val: 0.003084, Total: 0.001271, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2084: Train: 0.000982, Val: 0.003013, Total: 0.001272, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2085: Train: 0.000960, Val: 0.002888, Total: 0.001235, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2086: Train: 0.000926, Val: 0.002975, Total: 0.001219, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2087: Train: 0.000978, Val: 0.003112, Total: 0.001283, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2088: Train: 0.000961, Val: 0.002903, Total: 0.001239, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2089: Train: 0.000969, Val: 0.002754, Total: 0.001224, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2090: Train: 0.000965, Val: 0.002826, Total: 0.001231, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2091: Train: 0.000908, Val: 0.002872, Total: 0.001189, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2092: Train: 0.000981, Val: 0.003051, Total: 0.001277, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2093: Train: 0.000944, Val: 0.002749, Total: 0.001202, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2094: Train: 0.000928, Val: 0.002954, Total: 0.001218, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2095: Train: 0.000894, Val: 0.003160, Total: 0.001217, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2096: Train: 0.000951, Val: 0.002855, Total: 0.001223, LR: 1.37e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2097: Train: 0.001002, Val: 0.002946, Total: 0.001280, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2098: Train: 0.000981, Val: 0.003004, Total: 0.001270, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2099: Train: 0.000965, Val: 0.002692, Total: 0.001211, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2100: Train: 0.000979, Val: 0.002938, Total: 0.001258, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2101: Train: 0.000881, Val: 0.003007, Total: 0.001184, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2102: Train: 0.000947, Val: 0.003008, Total: 0.001242, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2103: Train: 0.000983, Val: 0.002874, Total: 0.001253, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2104: Train: 0.000935, Val: 0.002959, Total: 0.001224, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2105: Train: 0.000958, Val: 0.002960, Total: 0.001244, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2106: Train: 0.000960, Val: 0.002920, Total: 0.001240, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2107: Train: 0.000955, Val: 0.002974, Total: 0.001244, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2108: Train: 0.000953, Val: 0.003032, Total: 0.001250, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2109: Train: 0.000921, Val: 0.002801, Total: 0.001189, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2110: Train: 0.000952, Val: 0.003008, Total: 0.001246, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2111: Train: 0.000901, Val: 0.002996, Total: 0.001200, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2112: Train: 0.000908, Val: 0.002891, Total: 0.001192, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2113: Train: 0.000916, Val: 0.002920, Total: 0.001202, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2114: Train: 0.000987, Val: 0.002921, Total: 0.001263, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2115: Train: 0.000972, Val: 0.002799, Total: 0.001233, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2116: Train: 0.000934, Val: 0.003056, Total: 0.001237, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2117: Train: 0.000977, Val: 0.003068, Total: 0.001276, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2118: Train: 0.000963, Val: 0.002693, Total: 0.001210, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2119: Train: 0.001007, Val: 0.002861, Total: 0.001272, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2120: Train: 0.000948, Val: 0.002911, Total: 0.001228, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2121: Train: 0.000943, Val: 0.003036, Total: 0.001242, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2122: Train: 0.000933, Val: 0.002892, Total: 0.001213, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2123: Train: 0.000920, Val: 0.002734, Total: 0.001179, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2124: Train: 0.000972, Val: 0.002879, Total: 0.001245, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2125: Train: 0.000982, Val: 0.002839, Total: 0.001247, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2126: Train: 0.000928, Val: 0.002919, Total: 0.001213, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2127: Train: 0.001063, Val: 0.002930, Total: 0.001329, LR: 1.36e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2128: Train: 0.001047, Val: 0.003133, Total: 0.001345, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2129: Train: 0.000914, Val: 0.002795, Total: 0.001183, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2130: Train: 0.000932, Val: 0.002900, Total: 0.001213, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2131: Train: 0.000974, Val: 0.002865, Total: 0.001244, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2132: Train: 0.000906, Val: 0.002992, Total: 0.001204, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2133: Train: 0.000924, Val: 0.003044, Total: 0.001227, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2134: Train: 0.000968, Val: 0.002532, Total: 0.001191, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2135: Train: 0.000968, Val: 0.003167, Total: 0.001282, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2136: Train: 0.001044, Val: 0.002845, Total: 0.001302, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2137: Train: 0.000978, Val: 0.002864, Total: 0.001247, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2138: Train: 0.000936, Val: 0.003156, Total: 0.001253, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2139: Train: 0.000902, Val: 0.003087, Total: 0.001214, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2140: Train: 0.001021, Val: 0.002771, Total: 0.001271, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2141: Train: 0.000916, Val: 0.002950, Total: 0.001207, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2142: Train: 0.000897, Val: 0.002979, Total: 0.001194, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2143: Train: 0.000971, Val: 0.002945, Total: 0.001253, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2144: Train: 0.000957, Val: 0.003012, Total: 0.001250, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2145: Train: 0.000956, Val: 0.003238, Total: 0.001282, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2146: Train: 0.000955, Val: 0.002586, Total: 0.001188, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2147: Train: 0.000954, Val: 0.002810, Total: 0.001219, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2148: Train: 0.000937, Val: 0.003149, Total: 0.001253, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2149: Train: 0.000977, Val: 0.002806, Total: 0.001239, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2150: Train: 0.000875, Val: 0.002861, Total: 0.001159, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2151: Train: 0.000878, Val: 0.003055, Total: 0.001189, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2152: Train: 0.000964, Val: 0.003057, Total: 0.001263, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2153: Train: 0.000917, Val: 0.002842, Total: 0.001192, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2154: Train: 0.000892, Val: 0.003095, Total: 0.001206, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2155: Train: 0.000943, Val: 0.002884, Total: 0.001220, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2156: Train: 0.000955, Val: 0.003019, Total: 0.001250, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2157: Train: 0.000943, Val: 0.002685, Total: 0.001192, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2158: Train: 0.001011, Val: 0.002889, Total: 0.001279, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2159: Train: 0.000983, Val: 0.003188, Total: 0.001298, LR: 1.35e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2160: Train: 0.000909, Val: 0.002844, Total: 0.001185, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2161: Train: 0.000967, Val: 0.002972, Total: 0.001253, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2162: Train: 0.000933, Val: 0.003260, Total: 0.001266, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2163: Train: 0.000922, Val: 0.002808, Total: 0.001192, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2164: Train: 0.000937, Val: 0.002906, Total: 0.001219, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2165: Train: 0.000892, Val: 0.003008, Total: 0.001195, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2166: Train: 0.000929, Val: 0.003018, Total: 0.001227, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2167: Train: 0.000885, Val: 0.002992, Total: 0.001186, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2168: Train: 0.000902, Val: 0.003053, Total: 0.001209, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2169: Train: 0.000938, Val: 0.002945, Total: 0.001225, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2170: Train: 0.000885, Val: 0.003073, Total: 0.001197, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2171: Train: 0.000949, Val: 0.002995, Total: 0.001242, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2172: Train: 0.000949, Val: 0.003140, Total: 0.001262, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2173: Train: 0.000971, Val: 0.003307, Total: 0.001305, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2174: Train: 0.000993, Val: 0.002946, Total: 0.001272, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2175: Train: 0.000939, Val: 0.003136, Total: 0.001252, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2176: Train: 0.000986, Val: 0.003017, Total: 0.001276, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2177: Train: 0.000954, Val: 0.002923, Total: 0.001235, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2178: Train: 0.000932, Val: 0.002983, Total: 0.001225, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2179: Train: 0.000891, Val: 0.003162, Total: 0.001216, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2180: Train: 0.000944, Val: 0.002846, Total: 0.001216, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2181: Train: 0.000951, Val: 0.002915, Total: 0.001231, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2182: Train: 0.000958, Val: 0.003425, Total: 0.001310, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2183: Train: 0.000950, Val: 0.003197, Total: 0.001271, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2184: Train: 0.000973, Val: 0.002925, Total: 0.001252, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2185: Train: 0.000908, Val: 0.003095, Total: 0.001221, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2186: Train: 0.000956, Val: 0.003016, Total: 0.001250, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2187: Train: 0.000960, Val: 0.003243, Total: 0.001286, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2188: Train: 0.000913, Val: 0.003260, Total: 0.001248, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2189: Train: 0.000910, Val: 0.003224, Total: 0.001240, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2190: Train: 0.000962, Val: 0.003260, Total: 0.001290, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2191: Train: 0.000914, Val: 0.003208, Total: 0.001242, LR: 1.34e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2192: Train: 0.001028, Val: 0.003114, Total: 0.001326, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2193: Train: 0.001124, Val: 0.003155, Total: 0.001415, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2194: Train: 0.001020, Val: 0.002805, Total: 0.001275, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2195: Train: 0.001022, Val: 0.003299, Total: 0.001347, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2196: Train: 0.001061, Val: 0.003185, Total: 0.001364, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2197: Train: 0.000974, Val: 0.002719, Total: 0.001223, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2198: Train: 0.000962, Val: 0.003027, Total: 0.001257, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2199: Train: 0.000923, Val: 0.002904, Total: 0.001206, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2200: Train: 0.000973, Val: 0.002880, Total: 0.001245, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2201: Train: 0.000919, Val: 0.003151, Total: 0.001238, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2202: Train: 0.000944, Val: 0.002840, Total: 0.001215, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2203: Train: 0.000943, Val: 0.002856, Total: 0.001216, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2204: Train: 0.000950, Val: 0.003191, Total: 0.001270, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2205: Train: 0.000971, Val: 0.002924, Total: 0.001250, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2206: Train: 0.000924, Val: 0.003077, Total: 0.001231, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2207: Train: 0.000928, Val: 0.002934, Total: 0.001215, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2208: Train: 0.000881, Val: 0.002690, Total: 0.001140, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2209: Train: 0.000997, Val: 0.003338, Total: 0.001332, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2210: Train: 0.000915, Val: 0.002845, Total: 0.001191, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2211: Train: 0.000921, Val: 0.002994, Total: 0.001217, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2212: Train: 0.000953, Val: 0.002841, Total: 0.001223, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2213: Train: 0.000955, Val: 0.002869, Total: 0.001228, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2214: Train: 0.000872, Val: 0.002936, Total: 0.001167, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2215: Train: 0.000868, Val: 0.002944, Total: 0.001165, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2216: Train: 0.000927, Val: 0.003521, Total: 0.001298, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2217: Train: 0.000915, Val: 0.002929, Total: 0.001203, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2218: Train: 0.000948, Val: 0.003020, Total: 0.001244, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2219: Train: 0.000886, Val: 0.003184, Total: 0.001214, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2220: Train: 0.000916, Val: 0.002986, Total: 0.001212, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2221: Train: 0.000981, Val: 0.002968, Total: 0.001265, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2222: Train: 0.000863, Val: 0.003160, Total: 0.001191, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2223: Train: 0.000921, Val: 0.002989, Total: 0.001216, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2224: Train: 0.000891, Val: 0.003129, Total: 0.001211, LR: 1.33e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2225: Train: 0.000940, Val: 0.002851, Total: 0.001213, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2226: Train: 0.000884, Val: 0.003110, Total: 0.001202, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2227: Train: 0.000874, Val: 0.002950, Total: 0.001171, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2228: Train: 0.000937, Val: 0.003249, Total: 0.001267, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2229: Train: 0.000903, Val: 0.002936, Total: 0.001193, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2230: Train: 0.000909, Val: 0.003059, Total: 0.001217, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2231: Train: 0.000951, Val: 0.003011, Total: 0.001245, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2232: Train: 0.000933, Val: 0.003053, Total: 0.001236, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2233: Train: 0.000880, Val: 0.002775, Total: 0.001151, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2234: Train: 0.000875, Val: 0.003146, Total: 0.001200, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2235: Train: 0.000948, Val: 0.003196, Total: 0.001269, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2236: Train: 0.000937, Val: 0.002977, Total: 0.001228, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2237: Train: 0.000879, Val: 0.003003, Total: 0.001183, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2238: Train: 0.000917, Val: 0.003242, Total: 0.001249, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2239: Train: 0.000988, Val: 0.002949, Total: 0.001268, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2240: Train: 0.000915, Val: 0.003104, Total: 0.001228, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2241: Train: 0.000865, Val: 0.002974, Total: 0.001166, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2242: Train: 0.000947, Val: 0.002986, Total: 0.001238, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2243: Train: 0.000832, Val: 0.003141, Total: 0.001162, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2244: Train: 0.000924, Val: 0.003563, Total: 0.001301, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2245: Train: 0.001048, Val: 0.003286, Total: 0.001368, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2246: Train: 0.000913, Val: 0.002962, Total: 0.001206, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2247: Train: 0.000945, Val: 0.003083, Total: 0.001250, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2248: Train: 0.001065, Val: 0.003307, Total: 0.001386, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2249: Train: 0.001075, Val: 0.003369, Total: 0.001403, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2250: Train: 0.001105, Val: 0.003205, Total: 0.001405, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2251: Train: 0.001242, Val: 0.003251, Total: 0.001529, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2252: Train: 0.001126, Val: 0.003545, Total: 0.001471, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2253: Train: 0.001129, Val: 0.003239, Total: 0.001431, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2254: Train: 0.001267, Val: 0.003714, Total: 0.001616, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2255: Train: 0.001103, Val: 0.003262, Total: 0.001412, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2256: Train: 0.001085, Val: 0.003473, Total: 0.001426, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2257: Train: 0.001061, Val: 0.002922, Total: 0.001327, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2258: Train: 0.001083, Val: 0.003251, Total: 0.001393, LR: 1.32e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2259: Train: 0.001011, Val: 0.003365, Total: 0.001348, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2260: Train: 0.001008, Val: 0.003112, Total: 0.001309, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2261: Train: 0.001014, Val: 0.003251, Total: 0.001334, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2262: Train: 0.000966, Val: 0.003353, Total: 0.001307, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2263: Train: 0.001014, Val: 0.003399, Total: 0.001355, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2264: Train: 0.001049, Val: 0.003366, Total: 0.001380, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2265: Train: 0.001007, Val: 0.003339, Total: 0.001340, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2266: Train: 0.001009, Val: 0.003182, Total: 0.001319, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2267: Train: 0.001093, Val: 0.003387, Total: 0.001421, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2268: Train: 0.001062, Val: 0.003459, Total: 0.001404, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2269: Train: 0.000993, Val: 0.003114, Total: 0.001296, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2270: Train: 0.001178, Val: 0.003570, Total: 0.001520, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2271: Train: 0.001231, Val: 0.003323, Total: 0.001530, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2272: Train: 0.001215, Val: 0.003515, Total: 0.001544, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2273: Train: 0.001180, Val: 0.003822, Total: 0.001557, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2274: Train: 0.001147, Val: 0.003344, Total: 0.001461, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2275: Train: 0.001084, Val: 0.003299, Total: 0.001400, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2276: Train: 0.001078, Val: 0.003543, Total: 0.001430, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2277: Train: 0.000982, Val: 0.003405, Total: 0.001328, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2278: Train: 0.000992, Val: 0.003405, Total: 0.001336, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2279: Train: 0.001011, Val: 0.003340, Total: 0.001344, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2280: Train: 0.001034, Val: 0.003337, Total: 0.001363, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2281: Train: 0.001034, Val: 0.003685, Total: 0.001413, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2282: Train: 0.001016, Val: 0.003097, Total: 0.001313, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2283: Train: 0.001000, Val: 0.003787, Total: 0.001398, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2284: Train: 0.001087, Val: 0.003680, Total: 0.001457, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2285: Train: 0.001040, Val: 0.003216, Total: 0.001351, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2286: Train: 0.001011, Val: 0.003575, Total: 0.001377, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2287: Train: 0.001000, Val: 0.003266, Total: 0.001323, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2288: Train: 0.001003, Val: 0.003282, Total: 0.001328, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2289: Train: 0.001003, Val: 0.003400, Total: 0.001346, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2290: Train: 0.000970, Val: 0.003272, Total: 0.001299, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2291: Train: 0.000982, Val: 0.003333, Total: 0.001318, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2292: Train: 0.001036, Val: 0.003351, Total: 0.001367, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2293: Train: 0.001079, Val: 0.003422, Total: 0.001414, LR: 1.31e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2294: Train: 0.001050, Val: 0.002996, Total: 0.001328, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2295: Train: 0.001001, Val: 0.003595, Total: 0.001371, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2296: Train: 0.000953, Val: 0.003309, Total: 0.001290, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2297: Train: 0.000980, Val: 0.003158, Total: 0.001291, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2298: Train: 0.001054, Val: 0.003369, Total: 0.001385, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2299: Train: 0.000930, Val: 0.003163, Total: 0.001249, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2300: Train: 0.001003, Val: 0.003456, Total: 0.001354, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2301: Train: 0.001007, Val: 0.003343, Total: 0.001341, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2302: Train: 0.001004, Val: 0.003281, Total: 0.001330, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2303: Train: 0.001020, Val: 0.003742, Total: 0.001409, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2304: Train: 0.001001, Val: 0.003414, Total: 0.001345, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2305: Train: 0.000964, Val: 0.003219, Total: 0.001286, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2306: Train: 0.000990, Val: 0.003468, Total: 0.001344, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2307: Train: 0.001007, Val: 0.003246, Total: 0.001327, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2308: Train: 0.001011, Val: 0.003297, Total: 0.001338, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2309: Train: 0.000980, Val: 0.003383, Total: 0.001323, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2310: Train: 0.000991, Val: 0.003173, Total: 0.001303, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2311: Train: 0.000973, Val: 0.003420, Total: 0.001322, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2312: Train: 0.000959, Val: 0.003405, Total: 0.001309, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2313: Train: 0.000996, Val: 0.003132, Total: 0.001301, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2314: Train: 0.000940, Val: 0.003636, Total: 0.001326, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2315: Train: 0.000950, Val: 0.003276, Total: 0.001282, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2316: Train: 0.001110, Val: 0.003258, Total: 0.001417, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2317: Train: 0.001050, Val: 0.003582, Total: 0.001411, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2318: Train: 0.000961, Val: 0.003257, Total: 0.001289, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2319: Train: 0.001009, Val: 0.003364, Total: 0.001346, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2320: Train: 0.000959, Val: 0.003117, Total: 0.001267, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2321: Train: 0.000971, Val: 0.003411, Total: 0.001319, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2322: Train: 0.000920, Val: 0.003386, Total: 0.001273, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2323: Train: 0.000997, Val: 0.003283, Total: 0.001324, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2324: Train: 0.000993, Val: 0.003318, Total: 0.001325, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2325: Train: 0.000933, Val: 0.003258, Total: 0.001265, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2326: Train: 0.000954, Val: 0.003173, Total: 0.001271, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2327: Train: 0.000949, Val: 0.003695, Total: 0.001341, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2328: Train: 0.001004, Val: 0.003410, Total: 0.001347, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2329: Train: 0.001032, Val: 0.003136, Total: 0.001332, LR: 1.30e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2330: Train: 0.000969, Val: 0.003374, Total: 0.001313, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2331: Train: 0.001017, Val: 0.003451, Total: 0.001365, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2332: Train: 0.001009, Val: 0.003220, Total: 0.001325, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2333: Train: 0.001022, Val: 0.003169, Total: 0.001329, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2334: Train: 0.000992, Val: 0.003427, Total: 0.001339, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2335: Train: 0.001026, Val: 0.003301, Total: 0.001351, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2336: Train: 0.000983, Val: 0.003402, Total: 0.001328, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2337: Train: 0.000993, Val: 0.003490, Total: 0.001349, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2338: Train: 0.000937, Val: 0.003274, Total: 0.001271, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2339: Train: 0.001035, Val: 0.003186, Total: 0.001342, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2340: Train: 0.000974, Val: 0.003434, Total: 0.001325, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2341: Train: 0.000992, Val: 0.003500, Total: 0.001350, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2342: Train: 0.000951, Val: 0.003372, Total: 0.001297, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2343: Train: 0.000929, Val: 0.003225, Total: 0.001257, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2344: Train: 0.001004, Val: 0.003289, Total: 0.001330, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2345: Train: 0.000979, Val: 0.003249, Total: 0.001304, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2346: Train: 0.000947, Val: 0.003322, Total: 0.001286, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2347: Train: 0.000941, Val: 0.003539, Total: 0.001312, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2348: Train: 0.000962, Val: 0.003316, Total: 0.001299, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2349: Train: 0.000957, Val: 0.003285, Total: 0.001290, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2350: Train: 0.000937, Val: 0.003744, Total: 0.001338, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2351: Train: 0.001039, Val: 0.003444, Total: 0.001383, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2352: Train: 0.001056, Val: 0.003522, Total: 0.001408, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2353: Train: 0.000929, Val: 0.003281, Total: 0.001265, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2354: Train: 0.000955, Val: 0.003213, Total: 0.001278, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2355: Train: 0.000947, Val: 0.003440, Total: 0.001303, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2356: Train: 0.000987, Val: 0.003377, Total: 0.001329, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2357: Train: 0.000934, Val: 0.003221, Total: 0.001261, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2358: Train: 0.000962, Val: 0.003440, Total: 0.001316, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2359: Train: 0.000953, Val: 0.003324, Total: 0.001292, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2360: Train: 0.000929, Val: 0.003127, Total: 0.001243, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2361: Train: 0.000953, Val: 0.003348, Total: 0.001296, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2362: Train: 0.000959, Val: 0.003272, Total: 0.001289, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2363: Train: 0.000951, Val: 0.003495, Total: 0.001315, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2364: Train: 0.000997, Val: 0.003157, Total: 0.001306, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2365: Train: 0.000960, Val: 0.003436, Total: 0.001314, LR: 1.29e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2366: Train: 0.000963, Val: 0.003353, Total: 0.001304, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2367: Train: 0.001051, Val: 0.003283, Total: 0.001370, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2368: Train: 0.000956, Val: 0.003463, Total: 0.001314, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2369: Train: 0.000954, Val: 0.003504, Total: 0.001318, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2370: Train: 0.000940, Val: 0.003186, Total: 0.001260, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2371: Train: 0.001017, Val: 0.003297, Total: 0.001343, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2372: Train: 0.001005, Val: 0.003243, Total: 0.001325, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2373: Train: 0.000929, Val: 0.003411, Total: 0.001284, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2374: Train: 0.000972, Val: 0.003273, Total: 0.001300, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2375: Train: 0.000934, Val: 0.003135, Total: 0.001249, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2376: Train: 0.000945, Val: 0.003309, Total: 0.001283, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2377: Train: 0.000997, Val: 0.003321, Total: 0.001329, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2378: Train: 0.000973, Val: 0.003280, Total: 0.001303, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2379: Train: 0.000961, Val: 0.003142, Total: 0.001273, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2380: Train: 0.001052, Val: 0.003305, Total: 0.001374, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2381: Train: 0.001025, Val: 0.002882, Total: 0.001290, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2382: Train: 0.001151, Val: 0.003495, Total: 0.001485, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2383: Train: 0.001080, Val: 0.003405, Total: 0.001412, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2384: Train: 0.000980, Val: 0.003240, Total: 0.001303, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2385: Train: 0.000977, Val: 0.003105, Total: 0.001281, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2386: Train: 0.001010, Val: 0.003125, Total: 0.001312, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2387: Train: 0.000999, Val: 0.003431, Total: 0.001347, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2388: Train: 0.000936, Val: 0.003190, Total: 0.001258, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2389: Train: 0.001020, Val: 0.003085, Total: 0.001315, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2390: Train: 0.001077, Val: 0.003077, Total: 0.001363, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2391: Train: 0.000966, Val: 0.003155, Total: 0.001278, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2392: Train: 0.000966, Val: 0.003205, Total: 0.001286, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2393: Train: 0.000935, Val: 0.003282, Total: 0.001270, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2394: Train: 0.000951, Val: 0.003153, Total: 0.001265, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2395: Train: 0.000934, Val: 0.002994, Total: 0.001228, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2396: Train: 0.000930, Val: 0.003138, Total: 0.001245, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2397: Train: 0.001119, Val: 0.003100, Total: 0.001402, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2398: Train: 0.000888, Val: 0.003303, Total: 0.001233, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2399: Train: 0.000981, Val: 0.003564, Total: 0.001350, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2400: Train: 0.000997, Val: 0.003276, Total: 0.001323, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2401: Train: 0.000913, Val: 0.003385, Total: 0.001266, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2402: Train: 0.000934, Val: 0.003392, Total: 0.001285, LR: 1.28e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2403: Train: 0.000927, Val: 0.003187, Total: 0.001250, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2404: Train: 0.000894, Val: 0.003631, Total: 0.001285, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2405: Train: 0.000958, Val: 0.003162, Total: 0.001273, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2406: Train: 0.000938, Val: 0.003158, Total: 0.001255, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2407: Train: 0.000973, Val: 0.003257, Total: 0.001299, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2408: Train: 0.000893, Val: 0.003233, Total: 0.001227, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2409: Train: 0.000923, Val: 0.003388, Total: 0.001275, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2410: Train: 0.000982, Val: 0.003212, Total: 0.001300, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2411: Train: 0.000945, Val: 0.003246, Total: 0.001274, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2412: Train: 0.000975, Val: 0.003326, Total: 0.001311, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2413: Train: 0.000893, Val: 0.003046, Total: 0.001200, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2414: Train: 0.000894, Val: 0.003243, Total: 0.001229, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2415: Train: 0.000848, Val: 0.003040, Total: 0.001161, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2416: Train: 0.000941, Val: 0.003220, Total: 0.001267, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2417: Train: 0.000916, Val: 0.003183, Total: 0.001240, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2418: Train: 0.000913, Val: 0.003032, Total: 0.001216, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2419: Train: 0.000824, Val: 0.003115, Total: 0.001151, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2420: Train: 0.000919, Val: 0.003116, Total: 0.001233, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2421: Train: 0.000877, Val: 0.003332, Total: 0.001227, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2422: Train: 0.000854, Val: 0.003073, Total: 0.001171, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2423: Train: 0.000934, Val: 0.002958, Total: 0.001223, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2424: Train: 0.000950, Val: 0.003182, Total: 0.001269, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2425: Train: 0.001033, Val: 0.003116, Total: 0.001330, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2426: Train: 0.000902, Val: 0.003251, Total: 0.001238, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2427: Train: 0.001023, Val: 0.003474, Total: 0.001373, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2428: Train: 0.000970, Val: 0.003354, Total: 0.001310, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2429: Train: 0.000992, Val: 0.003722, Total: 0.001382, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2430: Train: 0.001023, Val: 0.003166, Total: 0.001329, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2431: Train: 0.001040, Val: 0.003099, Total: 0.001334, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2432: Train: 0.001173, Val: 0.004691, Total: 0.001676, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2433: Train: 0.001404, Val: 0.002523, Total: 0.001564, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2434: Train: 0.002855, Val: 0.002507, Total: 0.002806, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2435: Train: 0.002205, Val: 0.003636, Total: 0.002410, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2436: Train: 0.001999, Val: 0.005530, Total: 0.002504, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2437: Train: 0.002037, Val: 0.004698, Total: 0.002417, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2438: Train: 0.001756, Val: 0.002887, Total: 0.001918, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2439: Train: 0.001597, Val: 0.005781, Total: 0.002195, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Epoch 2440: Train: 0.001816, Val: 0.004421, Total: 0.002188, LR: 1.27e-03\n",
      "          Best: Train: 0.000709, Val: 0.002662, Total: 0.000988 (Epoch 1440)\n",
      "Early stopping at epoch 2440\n",
      "\n",
      "Training completed!\n",
      "============================================================\n",
      "Best Performance (Epoch 1440):\n",
      "  Best Total Loss:  0.000988\n",
      "  Best Train Loss:  0.000709\n",
      "  Best Val Loss:    0.002662\n",
      "============================================================\n",
      "Final Performance (Epoch 2440):\n",
      "  Final Total Loss: 0.002188\n",
      "  Final Train Loss: 0.001816\n",
      "  Final Val Loss:   0.004421\n",
      "  Final LR:         1.27e-03\n",
      "============================================================\n",
      "Warmup completed at epoch 1000 with peak LR: 1.98e-03\n"
     ]
    }
   ],
   "source": [
    "# Training loop with Noam scheduler (epoch-based) - based on train_single_fold function\n",
    "print(\"Starting training with Noam scheduler (epoch-based)...\")\n",
    "\n",
    "# 실제 데이터셋 크기 기반 동적 가중치 계산\n",
    "train_samples = len(train_loader.dataset)\n",
    "val_samples = len(val_loader.dataset)\n",
    "total_samples = train_samples + val_samples\n",
    "\n",
    "train_weight = train_samples / total_samples\n",
    "val_weight = val_samples / total_samples\n",
    "\n",
    "print(f\"데이터 분포 - Train: {train_samples}({train_weight:.3f}), Val: {val_samples}({val_weight:.3f})\")\n",
    "\n",
    "best_total_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "total_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 에포크 시작 시 학습률 업데이트\n",
    "    current_lr = scheduler.step_epoch()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "    \n",
    "    for input_seq, seq_lengths in train_loader:\n",
    "        try:\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_lengths = seq_lengths.to(device)\n",
    "            \n",
    "            # Teacher forcing 데이터 준비 (전류 제외한 input, 전류 포함한 target)\n",
    "            inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs, target_seq_lengths)\n",
    "            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 그래디언트 클리핑\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Training batch error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if train_batches == 0:\n",
    "        print(\"No valid training batches\")\n",
    "        break\n",
    "    \n",
    "    train_loss = train_loss / train_batches\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_seq, seq_lengths in val_loader:\n",
    "            try:\n",
    "                input_seq = input_seq.to(device)\n",
    "                seq_lengths = seq_lengths.to(device)\n",
    "                \n",
    "                inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "                predictions = model(inputs, target_seq_lengths)\n",
    "                loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Validation batch error: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if val_batches == 0:\n",
    "        print(\"No valid validation batches\")\n",
    "        break\n",
    "    \n",
    "    val_loss = val_loss / val_batches\n",
    "    \n",
    "    # Total loss 계산 (실제 데이터 분포 기반 동적 가중치)\n",
    "    total_loss = train_weight * train_loss + val_weight * val_loss\n",
    "    \n",
    "    # 기록 저장\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    total_losses.append(total_loss)\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Early stopping (total_loss 기준)\n",
    "    if total_loss < best_total_loss:\n",
    "        best_total_loss = total_loss\n",
    "        best_train_loss = train_loss\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        # 베스트 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_bmed_noam_model.pth')\n",
    "        best_status = \" ★ NEW BEST\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        best_status = \"\"\n",
    "    \n",
    "    # Warmup 구간 표시\n",
    "    if epoch + 1 <= warmup_epochs:\n",
    "        warmup_status = \" [WARMUP]\"\n",
    "    else:\n",
    "        warmup_status = \"\"\n",
    "    \n",
    "    # 매 에포크마다 로깅 - best 성능 정보 포함\n",
    "    print(f\"Epoch {epoch+1:4d}: Train: {train_loss:.6f}, Val: {val_loss:.6f}, Total: {total_loss:.6f}, LR: {current_lr:.2e}{best_status}{warmup_status}\")\n",
    "    \n",
    "    # Best 성능 정보 추가 표시 (매 에포크)\n",
    "    if epoch == 0:\n",
    "        print(f\"          Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f} (Epoch {best_epoch})\")\n",
    "    elif total_loss < best_total_loss:\n",
    "        print(f\"          ✓ Updated Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f}\")\n",
    "    else:\n",
    "        print(f\"          Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f} (Epoch {best_epoch})\")\n",
    "    \n",
    "    # Early stopping 체크 (total_loss 기준)\n",
    "    if epoch >= min_epochs and patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Best Performance (Epoch {best_epoch}):\")\n",
    "print(f\"  Best Total Loss:  {best_total_loss:.6f}\")\n",
    "print(f\"  Best Train Loss:  {best_train_loss:.6f}\")\n",
    "print(f\"  Best Val Loss:    {best_val_loss:.6f}\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Final Performance (Epoch {len(train_losses)}):\")\n",
    "print(f\"  Final Total Loss: {total_losses[-1]:.6f}\")\n",
    "print(f\"  Final Train Loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"  Final Val Loss:   {val_losses[-1]:.6f}\")\n",
    "print(f\"  Final LR:         {current_lr:.2e}\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Warmup completed at epoch {warmup_epochs} with peak LR: {max(learning_rates):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1m06cppxd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Statistics ===\n",
      "Total epochs: 2440\n",
      "Best total loss: 0.000988\n",
      "Final train loss: 0.001816\n",
      "Final validation loss: 0.004421\n",
      "Final total loss: 0.002188\n",
      "Initial learning rate: 1.98e-06\n",
      "Final learning rate: 1.27e-03\n",
      "Max learning rate: 1.98e-03\n",
      "Min learning rate: 1.98e-06\n",
      "\n",
      "=== Noam Scheduler Analysis ===\n",
      "Model size (hidden_size): 256\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoamScheduler' object has no attribute 'warmup_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Noam Scheduler Analysis ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel size (hidden_size): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler.model_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarmup steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFactor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler.factor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m warmup_lr = scheduler.factor * (scheduler.model_size ** (-\u001b[32m0.5\u001b[39m) * scheduler.warmup_steps ** (-\u001b[32m0.5\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoamScheduler' object has no attribute 'warmup_steps'"
     ]
    }
   ],
   "source": [
    "# 학습 결과 시각화 - total_loss 포함\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. 손실 함수 변화 (train, val, total)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "axes[0, 0].plot(epochs, train_losses, label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(epochs, val_losses, label='Validation Loss', alpha=0.7)\n",
    "axes[0, 0].plot(epochs, total_losses, label='Total Loss (Weighted)', alpha=0.7, linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training, Validation, and Total Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 학습률 변화 (Noam scheduler)\n",
    "axes[0, 1].plot(epochs, learning_rates, label='Learning Rate', color='orange', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Learning Rate')\n",
    "axes[0, 1].set_title('Noam Scheduler Learning Rate')\n",
    "axes[0, 1].set_yscale('log')  # 로그 스케일로 표시\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 학습률과 Total 손실의 관계\n",
    "scatter = axes[1, 0].scatter(learning_rates, total_losses, alpha=0.6, c=epochs, cmap='viridis', s=30)\n",
    "axes[1, 0].set_xlabel('Learning Rate')\n",
    "axes[1, 0].set_ylabel('Total Loss')\n",
    "axes[1, 0].set_title('Learning Rate vs Total Loss')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter, ax=axes[1, 0])\n",
    "cbar1.set_label('Epoch')\n",
    "\n",
    "# 4. Train vs Validation Loss 산점도\n",
    "scatter2 = axes[1, 1].scatter(train_losses, val_losses, alpha=0.6, c=epochs, cmap='plasma', s=30)\n",
    "axes[1, 1].set_xlabel('Train Loss')\n",
    "axes[1, 1].set_ylabel('Validation Loss')\n",
    "axes[1, 1].set_title('Train vs Validation Loss')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "# 대각선 추가 (perfect correlation)\n",
    "min_loss = min(min(train_losses), min(val_losses))\n",
    "max_loss = max(max(train_losses), max(val_losses))\n",
    "axes[1, 1].plot([min_loss, max_loss], [min_loss, max_loss], 'r--', alpha=0.5, label='Perfect Correlation')\n",
    "axes[1, 1].legend()\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1, 1])\n",
    "cbar2.set_label('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 학습 통계 출력\n",
    "print(\"\\n=== Training Statistics ===\")\n",
    "print(f\"Total epochs: {len(train_losses)}\")\n",
    "print(f\"Best total loss: {best_total_loss:.6f}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.6f}\")\n",
    "print(f\"Final total loss: {total_losses[-1]:.6f}\")\n",
    "print(f\"Initial learning rate: {learning_rates[0]:.2e}\")\n",
    "print(f\"Final learning rate: {learning_rates[-1]:.2e}\")\n",
    "print(f\"Max learning rate: {max(learning_rates):.2e}\")\n",
    "print(f\"Min learning rate: {min(learning_rates):.2e}\")\n",
    "\n",
    "# Noam scheduler 특성 분석\n",
    "print(f\"\\n=== Noam Scheduler Analysis ===\")\n",
    "print(f\"Model size (hidden_size): {scheduler.model_size}\")\n",
    "print(f\"Warmup steps: {scheduler.warmup_steps}\")\n",
    "print(f\"Factor: {scheduler.factor}\")\n",
    "warmup_lr = scheduler.factor * (scheduler.model_size ** (-0.5) * scheduler.warmup_steps ** (-0.5))\n",
    "print(f\"Peak learning rate at warmup: {warmup_lr:.2e}\")\n",
    "\n",
    "# 데이터 분포 가중치 정보\n",
    "print(f\"\\n=== Data Distribution Weights ===\")\n",
    "print(f\"Train samples: {train_samples} (weight: {train_weight:.3f})\")\n",
    "print(f\"Validation samples: {val_samples} (weight: {val_weight:.3f})\")\n",
    "print(f\"Total loss formula: {train_weight:.3f} * train_loss + {val_weight:.3f} * val_loss\")\n",
    "\n",
    "# 최고 성능 에포크 찾기\n",
    "best_epoch = total_losses.index(min(total_losses)) + 1\n",
    "print(f\"\\n=== Best Performance ===\")\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "print(f\"Best total loss: {min(total_losses):.6f}\")\n",
    "print(f\"Train loss at best epoch: {train_losses[best_epoch-1]:.6f}\")\n",
    "print(f\"Val loss at best epoch: {val_losses[best_epoch-1]:.6f}\")\n",
    "print(f\"Learning rate at best epoch: {learning_rates[best_epoch-1]:.2e}\")\n",
    "\n",
    "# 모델 저장 정보\n",
    "print(f\"\\n=== Model Saved ===\")\n",
    "print(f\"Best model saved as: best_bmed_noam_model.pth\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df73717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
