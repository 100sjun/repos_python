{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9342def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from optuna.trial import TrialState\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbeb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormLSTM(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "\n",
    "        self.w_i = nn.Linear(input_node, 4*hidden_node, bias=False)\n",
    "        self.w_h = nn.Linear(hidden_node, 4*hidden_node, bias=False)\n",
    "\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)\n",
    "        self.ln_f = nn.LayerNorm(hidden_node)\n",
    "        self.ln_w = nn.LayerNorm(hidden_node)\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        gi = self.w_i(input)\n",
    "        gh = self.w_h(h_prev)\n",
    "        i_i, i_f, i_w, i_o = gi.chunk(4, dim=-1)\n",
    "        h_i, h_f, h_w, h_o = gh.chunk(4, dim=-1)\n",
    "\n",
    "        i_g = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_g = torch.sigmoid(self.ln_f(i_f + h_f))\n",
    "        w_g = torch.tanh(self.ln_w(i_w + h_w))\n",
    "        o_g = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "        \n",
    "\n",
    "        c_new = f_g * c_prev + i_g * w_g\n",
    "        c_new = self.ln_c(c_new)\n",
    "\n",
    "        h_new = o_g * torch.tanh(c_new)\n",
    "\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8de49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.n_layer = n_layer\n",
    "        self.input_node = input_node\n",
    "\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        self.lstm_cells.append(LayerNormLSTM(input_node, hidden_node))\n",
    "        for _ in range(n_layer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTM(hidden_node, hidden_node))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(hidden_node)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        batch_size, max_len, input_node = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "        for _ in range(self.n_layer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]\n",
    "            layer_input = x_t\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "\n",
    "                if layer_idx < len(self.lstm_cells) - 1:\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "            outputs.append(layer_input)\n",
    "        \n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)\n",
    "        masked_output = output_tensor * mask\n",
    "        normalized = self.final_layer_norm(masked_output)\n",
    "        return self.final_dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    def __init__(self, input_node, output_node, n_layer, hidden_node, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_node, hidden_node))\n",
    "        self.layers.append(nn.LayerNorm(hidden_node))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        for i in range(n_layer - 1):\n",
    "            self.layers.append(nn.Linear(hidden_node, hidden_node))\n",
    "            self.layers.append(nn.LayerNorm(hidden_node))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Linear(hidden_node, output_node))\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564cd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentPredictor(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_node, hidden_node))\n",
    "        self.layers.append(nn.LayerNorm(hidden_node))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        for i in range(n_layer - 1):\n",
    "            self.layers.append(nn.Linear(hidden_node, hidden_node))\n",
    "            self.layers.append(nn.LayerNorm(hidden_node))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.layers.append(nn.Linear(hidden_node, 1))\n",
    "    \n",
    "    def forward(self, new_state):\n",
    "        x = new_state\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f65d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    def __init__(self, range_mm, current_predictor, eps=1e-2):\n",
    "        super().__init__()\n",
    "        self.sps = eps\n",
    "        self.current_predictor = current_predictor\n",
    "        self.register_buffer('range_mm_tensor', self._convert_range_to_tensor(range_mm))\n",
    "\n",
    "    def _convert_range_to_tensor(self, range_mm):\n",
    "        feature_names = ['V','E','VF','VA','VB','CFLA','CALA','CFK','CBK','I']\n",
    "        ranges = torch.zeros(len(feature_names),2)\n",
    "        for i, name in enumerate(feature_names):\n",
    "            if name in range_mm:\n",
    "                ranges[i, 0] = range_mm[name]['min']\n",
    "                ranges[i, 1] = range_mm[name]['max']\n",
    "        return ranges\n",
    "    \n",
    "    def normalize(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    def denormalize(self, data, feature_idx):\n",
    "        min_val = self.range_mm_tensor[feature_idx, 0]\n",
    "        max_val = self.range_mm_tensor[feature_idx, 1]\n",
    "        return data * (max_val - min_val) + min_val\n",
    "\n",
    "    def forward(self, physical_changes, current_state):\n",
    "        V_idx, E_idx, VF_idx, VA_idx, VB_idx = 0, 1, 2, 3, 4\n",
    "        CFLA_idx, CALA_idx, CFK_idx, CBK_idx, I_idx = 5, 6, 7, 8, 9\n",
    "\n",
    "        VF = self.denormalize(current_state[..., 2:3], VF_idx)\n",
    "        VA = self.denormalize(current_state[..., 3:4], VA_idx)\n",
    "        VB = self.denormalize(current_state[..., 4:5], VB_idx)\n",
    "        CFLA = self.denormalize(current_state[..., 5:6], CFLA_idx)\n",
    "        CALA = self.denormalize(current_state[..., 6:7], CALA_idx)\n",
    "        CFK = self.denormalize(current_state[..., 7:8], CFK_idx)\n",
    "        CBK = self.denormalize(current_state[..., 8:9], CBK_idx)\n",
    "\n",
    "        dVA = physical_changes[..., 0:1]\n",
    "        dVB = physical_changes[..., 1:2]\n",
    "        rratio = physical_changes[..., 2:3]\n",
    "        dNBK = physical_changes[..., 3:4]\n",
    "\n",
    "        ratio = torch.sigmoid(rratio)\n",
    "        dNALA = ratio * dNBK\n",
    "\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA\n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        # tensor ë¹„êµë¥¼ torch.whereë¡œ ë³€ê²½\n",
    "        condition1 = VF < dVA + dVB\n",
    "        dVA = torch.where(condition1, torch.zeros_like(dVA), dVA)\n",
    "        dVB = torch.where(condition1, torch.zeros_like(dVB), dVB)\n",
    "        \n",
    "        condition2 = NFLA < dNALA\n",
    "        dNALA = torch.where(condition2, torch.zeros_like(dNALA), dNALA)\n",
    "        \n",
    "        condition3 = NFK < dNBK\n",
    "        dNBK = torch.where(condition3, torch.zeros_like(dNBK), dNBK)\n",
    "\n",
    "        nVF = VF - dVA - dVB\n",
    "        nVA = VA + dVA\n",
    "        nVB = VB + dVB\n",
    "\n",
    "        nVF = torch.clamp(nVF, min=self.sps)\n",
    "        nVA = torch.clamp(nVA, min=self.sps)\n",
    "        nVB = torch.clamp(nVB, min=self.sps)\n",
    "        \n",
    "        nNFLA = NFLA - dNALA\n",
    "        nNALA = NALA + dNALA\n",
    "        nNFK = NFK - dNBK\n",
    "        nNBK = NBK + dNBK\n",
    "\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCFK = nNFK / nVF\n",
    "        nCBK = nNBK / nVB\n",
    "\n",
    "        V = current_state[..., 0:1]\n",
    "        E = current_state[..., 1:2]\n",
    "        nVF_norm = self.normalize(nVF, VF_idx)\n",
    "        nVA_norm = self.normalize(nVA, VA_idx)\n",
    "        nVB_norm = self.normalize(nVB, VB_idx)\n",
    "        nCFLA_norm = self.normalize(nCFLA, CFLA_idx)\n",
    "        nCALA_norm = self.normalize(nCALA, CALA_idx)\n",
    "        nCFK_norm = self.normalize(nCFK, CFK_idx)\n",
    "        nCBK_norm = self.normalize(nCBK, CBK_idx)\n",
    "\n",
    "        temp_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm\n",
    "        ], dim=-1)\n",
    "        \n",
    "        nI_pred_norm = self.current_predictor(temp_state)\n",
    "        nI_real = self.denormalize(nI_pred_norm, I_idx)\n",
    "        nI_real = torch.clamp(nI_real, min=0.0)\n",
    "        nI_norm = self.normalize(nI_real, I_idx)\n",
    "\n",
    "        next_state = torch.cat([\n",
    "            V, E, nVF_norm, nVA_norm, nVB_norm, nCFLA_norm, nCALA_norm, nCFK_norm, nCBK_norm, nI_norm\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77ec51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    def __init__(self, state_extr_params, decoder_params, current_predictor_params, range_mm):\n",
    "        super().__init__()\n",
    "        self.state_extr = StateExtr(**state_extr_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.current_predictor = CurrentPredictor(**current_predictor_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer(range_mm, self.current_predictor)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        hidden_states = self.state_extr(x, seq_len)\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        new_x = self.physics_constraint(physical_changes, x)\n",
    "        return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3917c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamScheduler:\n",
    "    def __init__(self, optimizer, model_size, warmup_epochs, factor=1.0):\n",
    "        self.optimizer = optimizer\n",
    "        self.model_size = model_size\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.factor = 1\n",
    "        self.epoch_num = 0\n",
    "\n",
    "    def step_epoch(self):\n",
    "        self.epoch_num += 1\n",
    "        lr = self.factor * (\n",
    "            self.model_size ** (-0.5) *\n",
    "            min(self.epoch_num ** (-0.5), self.epoch_num * self.warmup_epochs ** (-1.5))\n",
    "        )\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1c08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "def df_treat(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "\n",
    "    exp_num_list = sorted(ndf['exp'].unique())\n",
    "    return df, ndf, range_mm, exp_num_list\n",
    "\n",
    "def seq_data(ndf, exp_num_list):\n",
    "    seq = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    for exp in exp_num_list:\n",
    "        exp_df = ndf[ndf['exp'] == exp]\n",
    "        seq.append(exp_df[feature_cols].values)\n",
    "    return seq\n",
    "\n",
    "def pad_seq(seq):\n",
    "    max_len = max([len(s) for s in seq])\n",
    "    seq_len = [len(s) for s in seq]\n",
    "    pad_seq = pad_sequence([torch.tensor(s) for s in seq], batch_first=True, padding_value=-1)\n",
    "    return pad_seq, seq_len, max_len\n",
    "\n",
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset\n",
    "\n",
    "def masked_mse_loss(pred, target, seq_len):\n",
    "    batch_size, max_len, features = pred.shape\n",
    "    seq_len_cpu = seq_len.detach().cpu().long()\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "    mask = mask.float().to(pred.device)\n",
    "    loss = F.mse_loss(pred, target, reduction='none')\n",
    "    masked_loss = loss * mask.unsqueeze(-1)\n",
    "    total_loss = masked_loss.sum()\n",
    "    total_elements = mask.sum()\n",
    "    masked_loss = total_loss / total_elements\n",
    "    return masked_loss\n",
    "\n",
    "def tf_data(input_seq, seq_len):\n",
    "    inputs = input_seq[:, :-1, :-1]\n",
    "    targets = input_seq[:, 1:, :]\n",
    "    target_seq_len = seq_len - 1\n",
    "    return inputs, targets, target_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816cee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna ëª©ì  í•¨ìˆ˜\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna trialì„ ìœ„í•œ ëª©ì  í•¨ìˆ˜\n",
    "    K-fold cross validationì„ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ\n",
    "    # LSTM StateExtractor íŒŒë¼ë¯¸í„°\n",
    "    lstm_hidden_size = trial.suggest_categorical('lstm_hidden_size', [16, 32, 48, 64, 72, 96])\n",
    "    lstm_n_layers = trial.suggest_int('lstm_n_layers', 2, 6, step=1)\n",
    "    lstm_dropout = trial.suggest_float('lstm_dropout', 0.1, 0.5, step=0.1)\n",
    "    \n",
    "    # PhysicalChangeDecoder íŒŒë¼ë¯¸í„°\n",
    "    decoder_hidden_size = trial.suggest_categorical('decoder_hidden_size', [16, 32, 48, 64, 72, 96])\n",
    "    decoder_n_layers = trial.suggest_int('decoder_n_layers', 2, 6, step=1)\n",
    "    decoder_dropout = trial.suggest_float('decoder_dropout', 0.1, 0.6, step=0.1)\n",
    "    \n",
    "    # CurrentPredictor íŒŒë¼ë¯¸í„°\n",
    "    current_hidden_size = trial.suggest_categorical('current_hidden_size', [16, 32, 48, 64, 72, 96])\n",
    "    current_n_layers = trial.suggest_int('current_n_layers', 2, 6, step=1)\n",
    "    current_dropout = trial.suggest_float('current_dropout', 0.1, 0.6, step=0.1)\n",
    "    \n",
    "    # 2. K-fold Cross Validation\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    n_splits = 5\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_losses = []\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ (global ë³€ìˆ˜ ì‚¬ìš©)\n",
    "    indices = list(range(len(dataset)))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "        print(f\"  ðŸ”„ Trial {trial.number}, Fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # í´ë“œë³„ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=3, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=3, shuffle=False)\n",
    "        \n",
    "        # 3. ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        state_extr_params = {\n",
    "            'input_node': 9,\n",
    "            'hidden_node': lstm_hidden_size,\n",
    "            'n_layer': lstm_n_layers,\n",
    "            'dropout': lstm_dropout\n",
    "        }\n",
    "        \n",
    "        decoder_params = {\n",
    "            'input_node': lstm_hidden_size,\n",
    "            'hidden_node': decoder_hidden_size,\n",
    "            'n_layer': decoder_n_layers,\n",
    "            'dropout': decoder_dropout,\n",
    "            'output_node': 4\n",
    "        }\n",
    "        \n",
    "        current_predictor_params = {\n",
    "            'input_node': 9,\n",
    "            'hidden_node': current_hidden_size,\n",
    "            'n_layer': current_n_layers,\n",
    "            'dropout': current_dropout\n",
    "        }\n",
    "        \n",
    "        # 4. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        model = BMEDAutoregressiveModel(state_extr_params, decoder_params, current_predictor_params, range_mm)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 5. ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1.0)\n",
    "        \n",
    "        # ì´ ì—í¬í¬ ìˆ˜ì™€ warmup ì—í¬í¬ ê³„ì‚°\n",
    "        total_epochs = 100  # Optuna ìµœì í™”ë¥¼ ìœ„í•´ ì—í¬í¬ ìˆ˜ ê°ì†Œ\n",
    "        warmup_epochs = int(total_epochs * 0.1)\n",
    "        \n",
    "        scheduler = NoamScheduler(\n",
    "            optimizer, \n",
    "            model_size=lstm_hidden_size,\n",
    "            warmup_epochs=warmup_epochs,\n",
    "            factor=1\n",
    "        )\n",
    "        \n",
    "        # 6. í›ˆë ¨\n",
    "        best_total_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(total_epochs):\n",
    "            # Learning rate ì—…ë°ì´íŠ¸\n",
    "            current_lr = scheduler.step_epoch()\n",
    "            \n",
    "            # í›ˆë ¨\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for input_seq, seq_len in train_loader:\n",
    "                try:\n",
    "                    input_seq = input_seq.to(device)\n",
    "                    seq_len = seq_len.to(device)\n",
    "                    \n",
    "                    inputs, targets, target_seq_len = tf_data(input_seq, seq_len)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(inputs, target_seq_len)\n",
    "                    loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                    train_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error in training: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if train_batches == 0:\n",
    "                break\n",
    "                \n",
    "            train_loss = train_loss / train_batches\n",
    "            \n",
    "            # ê²€ì¦\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for input_seq, seq_len in val_loader:\n",
    "                    try:\n",
    "                        input_seq = input_seq.to(device)\n",
    "                        seq_len = seq_len.to(device)\n",
    "                        \n",
    "                        inputs, targets, target_seq_len = tf_data(input_seq, seq_len)\n",
    "                        \n",
    "                        pred = model(inputs, target_seq_len)\n",
    "                        loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "                        \n",
    "                        val_loss += loss.item()\n",
    "                        val_batches += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            \n",
    "            if val_batches == 0:\n",
    "                break\n",
    "                \n",
    "            val_loss = val_loss / val_batches\n",
    "            \n",
    "            # Calculate total loss\n",
    "            total_loss = train_loss + val_loss\n",
    "            \n",
    "            # Early stopping\n",
    "            if total_loss < best_total_loss:\n",
    "                best_total_loss = total_loss\n",
    "        \n",
    "        fold_losses.append(best_total_loss)\n",
    "        print(f\"    Fold {fold+1} best total loss: {best_total_loss:.6f}\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        del model, optimizer, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 7. K-fold í‰ê·  ì†ì‹¤ ë°˜í™˜\n",
    "    avg_loss = np.mean(fold_losses)\n",
    "    std_loss = np.std(fold_losses)\n",
    "    \n",
    "    print(f\"  ðŸ“Š Trial {trial.number} - Average CV Loss: {avg_loss:.6f} (Â±{std_loss:.6f})\")\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17421f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ BMED TF Model Hyperparameter Optimization with Optuna\n",
      "================================================================================\n",
      "ðŸ“‹ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "   - ì´ ì‹¤í—˜ ê°œìˆ˜: 15\n",
      "   - ì´ ë°ì´í„° í¬ì¸íŠ¸: 15\n",
      "   - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:23:09,187] Using an existing study with name 'bmed_tf_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” ìµœì í™” ì‹œìž‘ (ì´ 100 trials)\n",
      "  ðŸ”„ Trial 49, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007661\n",
      "  ðŸ”„ Trial 49, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319122\n",
      "  ðŸ”„ Trial 49, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017220\n",
      "  ðŸ”„ Trial 49, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012732\n",
      "  ðŸ”„ Trial 49, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:26:44,182] Trial 49 finished with value: 0.07380131604149938 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 32, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012272\n",
      "  ðŸ“Š Trial 49 - Average CV Loss: 0.073801 (Â±0.122698)\n",
      "  ðŸ”„ Trial 50, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009122\n",
      "  ðŸ”„ Trial 50, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317891\n",
      "  ðŸ”„ Trial 50, Fold 3/5\n",
      "    Fold 3 best total loss: 0.021509\n",
      "  ðŸ”„ Trial 50, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011721\n",
      "  ðŸ”„ Trial 50, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:30:22,773] Trial 50 finished with value: 0.07575069691520184 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.5, 'decoder_hidden_size': 32, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.018510\n",
      "  ðŸ“Š Trial 50 - Average CV Loss: 0.075751 (Â±0.121153)\n",
      "  ðŸ”„ Trial 51, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008506\n",
      "  ðŸ”„ Trial 51, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020730\n",
      "  ðŸ”„ Trial 51, Fold 3/5\n",
      "    Fold 3 best total loss: 0.224590\n",
      "  ðŸ”„ Trial 51, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013597\n",
      "  ðŸ”„ Trial 51, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:33:59,542] Trial 51 finished with value: 0.05638162192190066 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 32, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 4, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014485\n",
      "  ðŸ“Š Trial 51 - Average CV Loss: 0.056382 (Â±0.084194)\n",
      "  ðŸ”„ Trial 52, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008885\n",
      "  ðŸ”„ Trial 52, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021410\n",
      "  ðŸ”„ Trial 52, Fold 3/5\n",
      "    Fold 3 best total loss: 0.014410\n",
      "  ðŸ”„ Trial 52, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012235\n",
      "  ðŸ”„ Trial 52, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:39:11,666] Trial 52 finished with value: 0.014062341768294573 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013371\n",
      "  ðŸ“Š Trial 52 - Average CV Loss: 0.014062 (Â±0.004116)\n",
      "  ðŸ”„ Trial 53, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009288\n",
      "  ðŸ”„ Trial 53, Fold 2/5\n",
      "    Fold 2 best total loss: 0.014960\n",
      "  ðŸ”„ Trial 53, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015203\n",
      "  ðŸ”„ Trial 53, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012697\n",
      "  ðŸ”„ Trial 53, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:44:25,560] Trial 53 finished with value: 0.012575168663170188 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010727\n",
      "  ðŸ“Š Trial 53 - Average CV Loss: 0.012575 (Â±0.002316)\n",
      "  ðŸ”„ Trial 54, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007511\n",
      "  ðŸ”„ Trial 54, Fold 2/5\n",
      "    Fold 2 best total loss: 0.011121\n",
      "  ðŸ”„ Trial 54, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016557\n",
      "  ðŸ”„ Trial 54, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013232\n",
      "  ðŸ”„ Trial 54, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:49:38,449] Trial 54 finished with value: 0.012998328567482531 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016571\n",
      "  ðŸ“Š Trial 54 - Average CV Loss: 0.012998 (Â±0.003438)\n",
      "  ðŸ”„ Trial 55, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007997\n",
      "  ðŸ”„ Trial 55, Fold 2/5\n",
      "    Fold 2 best total loss: 0.015990\n",
      "  ðŸ”„ Trial 55, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015530\n",
      "  ðŸ”„ Trial 55, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012677\n",
      "  ðŸ”„ Trial 55, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 08:54:54,167] Trial 55 finished with value: 0.012991745653562248 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012764\n",
      "  ðŸ“Š Trial 55 - Average CV Loss: 0.012992 (Â±0.002847)\n",
      "  ðŸ”„ Trial 56, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007507\n",
      "  ðŸ”„ Trial 56, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317821\n",
      "  ðŸ”„ Trial 56, Fold 3/5\n",
      "    Fold 3 best total loss: 0.011723\n",
      "  ðŸ”„ Trial 56, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013515\n",
      "  ðŸ”„ Trial 56, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:00:01,886] Trial 56 finished with value: 0.07247555266367271 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.4, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011811\n",
      "  ðŸ“Š Trial 56 - Average CV Loss: 0.072476 (Â±0.122689)\n",
      "  ðŸ”„ Trial 57, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007246\n",
      "  ðŸ”„ Trial 57, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317908\n",
      "  ðŸ”„ Trial 57, Fold 3/5\n",
      "    Fold 3 best total loss: 0.222840\n",
      "  ðŸ”„ Trial 57, Fold 4/5\n",
      "    Fold 4 best total loss: 0.200503\n",
      "  ðŸ”„ Trial 57, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:05:04,932] Trial 57 finished with value: 0.21841515807900577 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 64, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.343579\n",
      "  ðŸ“Š Trial 57 - Average CV Loss: 0.218415 (Â±0.118742)\n",
      "  ðŸ”„ Trial 58, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008575\n",
      "  ðŸ”„ Trial 58, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020240\n",
      "  ðŸ”„ Trial 58, Fold 3/5\n",
      "    Fold 3 best total loss: 0.222583\n",
      "  ðŸ”„ Trial 58, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010009\n",
      "  ðŸ”„ Trial 58, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:10:03,918] Trial 58 finished with value: 0.05475541808409616 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012370\n",
      "  ðŸ“Š Trial 58 - Average CV Loss: 0.054755 (Â±0.084011)\n",
      "  ðŸ”„ Trial 59, Fold 1/5\n",
      "    Fold 1 best total loss: 0.314981\n",
      "  ðŸ”„ Trial 59, Fold 2/5\n",
      "    Fold 2 best total loss: 0.316982\n",
      "  ðŸ”„ Trial 59, Fold 3/5\n",
      "    Fold 3 best total loss: 0.013795\n",
      "  ðŸ”„ Trial 59, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010420\n",
      "  ðŸ”„ Trial 59, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:15:04,563] Trial 59 finished with value: 0.20004435373703017 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 96, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344043\n",
      "  ðŸ“Š Trial 59 - Average CV Loss: 0.200044 (Â±0.153796)\n",
      "  ðŸ”„ Trial 60, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007969\n",
      "  ðŸ”„ Trial 60, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016528\n",
      "  ðŸ”„ Trial 60, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016492\n",
      "  ðŸ”„ Trial 60, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009173\n",
      "  ðŸ”„ Trial 60, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:20:02,928] Trial 60 finished with value: 0.012227280775550752 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010975\n",
      "  ðŸ“Š Trial 60 - Average CV Loss: 0.012227 (Â±0.003625)\n",
      "  ðŸ”„ Trial 61, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009167\n",
      "  ðŸ”„ Trial 61, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318417\n",
      "  ðŸ”„ Trial 61, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017297\n",
      "  ðŸ”„ Trial 61, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016645\n",
      "  ðŸ”„ Trial 61, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:25:02,993] Trial 61 finished with value: 0.07525223020929843 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014735\n",
      "  ðŸ“Š Trial 61 - Average CV Loss: 0.075252 (Â±0.121616)\n",
      "  ðŸ”„ Trial 62, Fold 1/5\n",
      "    Fold 1 best total loss: 0.012827\n",
      "  ðŸ”„ Trial 62, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317828\n",
      "  ðŸ”„ Trial 62, Fold 3/5\n",
      "    Fold 3 best total loss: 0.027124\n",
      "  ðŸ”„ Trial 62, Fold 4/5\n",
      "    Fold 4 best total loss: 0.017491\n",
      "  ðŸ”„ Trial 62, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:30:16,917] Trial 62 finished with value: 0.07837464853655547 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 5, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016604\n",
      "  ðŸ“Š Trial 62 - Average CV Loss: 0.078375 (Â±0.119819)\n",
      "  ðŸ”„ Trial 63, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008489\n",
      "  ðŸ”„ Trial 63, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019665\n",
      "  ðŸ”„ Trial 63, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015498\n",
      "  ðŸ”„ Trial 63, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012614\n",
      "  ðŸ”„ Trial 63, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:35:22,512] Trial 63 finished with value: 0.013702389679383486 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012245\n",
      "  ðŸ“Š Trial 63 - Average CV Loss: 0.013702 (Â±0.003722)\n",
      "  ðŸ”„ Trial 64, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008771\n",
      "  ðŸ”„ Trial 64, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019033\n",
      "  ðŸ”„ Trial 64, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017066\n",
      "  ðŸ”„ Trial 64, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013599\n",
      "  ðŸ”„ Trial 64, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:40:25,019] Trial 64 finished with value: 0.08057899868581445 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344426\n",
      "  ðŸ“Š Trial 64 - Average CV Loss: 0.080579 (Â±0.131970)\n",
      "  ðŸ”„ Trial 65, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008680\n",
      "  ðŸ”„ Trial 65, Fold 2/5\n",
      "    Fold 2 best total loss: 0.015287\n",
      "  ðŸ”„ Trial 65, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015972\n",
      "  ðŸ”„ Trial 65, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009045\n",
      "  ðŸ”„ Trial 65, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:45:30,688] Trial 65 finished with value: 0.012160248798318207 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011818\n",
      "  ðŸ“Š Trial 65 - Average CV Loss: 0.012160 (Â±0.003041)\n",
      "  ðŸ”„ Trial 66, Fold 1/5\n",
      "    Fold 1 best total loss: 0.225108\n",
      "  ðŸ”„ Trial 66, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318471\n",
      "  ðŸ”„ Trial 66, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017227\n",
      "  ðŸ”„ Trial 66, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011120\n",
      "  ðŸ”„ Trial 66, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:50:44,290] Trial 66 finished with value: 0.11649624025449157 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010555\n",
      "  ðŸ“Š Trial 66 - Average CV Loss: 0.116496 (Â±0.130209)\n",
      "  ðŸ”„ Trial 67, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008554\n",
      "  ðŸ”„ Trial 67, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016675\n",
      "  ðŸ”„ Trial 67, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017502\n",
      "  ðŸ”„ Trial 67, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014377\n",
      "  ðŸ”„ Trial 67, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 09:55:56,854] Trial 67 finished with value: 0.013678834622260183 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011286\n",
      "  ðŸ“Š Trial 67 - Average CV Loss: 0.013679 (Â±0.003348)\n",
      "  ðŸ”„ Trial 68, Fold 1/5\n",
      "    Fold 1 best total loss: 0.165398\n",
      "  ðŸ”„ Trial 68, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019802\n",
      "  ðŸ”„ Trial 68, Fold 3/5\n",
      "    Fold 3 best total loss: 0.014460\n",
      "  ðŸ”„ Trial 68, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012276\n",
      "  ðŸ”„ Trial 68, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:06:03,803] Trial 68 finished with value: 0.11133796066278592 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 6, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 64, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344754\n",
      "  ðŸ“Š Trial 68 - Average CV Loss: 0.111338 (Â±0.130371)\n",
      "  ðŸ”„ Trial 69, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008485\n",
      "  ðŸ”„ Trial 69, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020923\n",
      "  ðŸ”„ Trial 69, Fold 3/5\n",
      "    Fold 3 best total loss: 0.013807\n",
      "  ðŸ”„ Trial 69, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014725\n",
      "  ðŸ”„ Trial 69, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:11:17,950] Trial 69 finished with value: 0.014079901180230081 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012459\n",
      "  ðŸ“Š Trial 69 - Average CV Loss: 0.014080 (Â±0.004031)\n",
      "  ðŸ”„ Trial 70, Fold 1/5\n",
      "    Fold 1 best total loss: 0.316638\n",
      "  ðŸ”„ Trial 70, Fold 2/5\n",
      "    Fold 2 best total loss: 0.015472\n",
      "  ðŸ”„ Trial 70, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015813\n",
      "  ðŸ”„ Trial 70, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010113\n",
      "  ðŸ”„ Trial 70, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:15:11,742] Trial 70 finished with value: 0.07414941079914569 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 6, 'decoder_dropout': 0.6, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012712\n",
      "  ðŸ“Š Trial 70 - Average CV Loss: 0.074149 (Â±0.121262)\n",
      "  ðŸ”„ Trial 71, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008828\n",
      "  ðŸ”„ Trial 71, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020422\n",
      "  ðŸ”„ Trial 71, Fold 3/5\n",
      "    Fold 3 best total loss: 0.019231\n",
      "  ðŸ”„ Trial 71, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014863\n",
      "  ðŸ”„ Trial 71, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:20:36,263] Trial 71 finished with value: 0.01606491677230224 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.30000000000000004, 'decoder_hidden_size': 64, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016980\n",
      "  ðŸ“Š Trial 71 - Average CV Loss: 0.016065 (Â±0.004090)\n",
      "  ðŸ”„ Trial 72, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009796\n",
      "  ðŸ”„ Trial 72, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019344\n",
      "  ðŸ”„ Trial 72, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016983\n",
      "  ðŸ”„ Trial 72, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013949\n",
      "  ðŸ”„ Trial 72, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:25:46,204] Trial 72 finished with value: 0.014941592118702829 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 2, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014636\n",
      "  ðŸ“Š Trial 72 - Average CV Loss: 0.014942 (Â±0.003197)\n",
      "  ðŸ”„ Trial 73, Fold 1/5\n",
      "    Fold 1 best total loss: 0.010719\n",
      "  ðŸ”„ Trial 73, Fold 2/5\n",
      "    Fold 2 best total loss: 0.021570\n",
      "  ðŸ”„ Trial 73, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015669\n",
      "  ðŸ”„ Trial 73, Fold 4/5\n",
      "    Fold 4 best total loss: 0.201712\n",
      "  ðŸ”„ Trial 73, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:30:54,776] Trial 73 finished with value: 0.11875228049466387 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344091\n",
      "  ðŸ“Š Trial 73 - Average CV Loss: 0.118752 (Â±0.133718)\n",
      "  ðŸ”„ Trial 74, Fold 1/5\n",
      "    Fold 1 best total loss: 0.317448\n",
      "  ðŸ”„ Trial 74, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022032\n",
      "  ðŸ”„ Trial 74, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015203\n",
      "  ðŸ”„ Trial 74, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011058\n",
      "  ðŸ”„ Trial 74, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:36:09,253] Trial 74 finished with value: 0.07564449964556844 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012481\n",
      "  ðŸ“Š Trial 74 - Average CV Loss: 0.075644 (Â±0.120961)\n",
      "  ðŸ”„ Trial 75, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008932\n",
      "  ðŸ”„ Trial 75, Fold 2/5\n",
      "    Fold 2 best total loss: 0.014945\n",
      "  ðŸ”„ Trial 75, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017696\n",
      "  ðŸ”„ Trial 75, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012107\n",
      "  ðŸ”„ Trial 75, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:41:19,443] Trial 75 finished with value: 0.013292913150507957 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012785\n",
      "  ðŸ“Š Trial 75 - Average CV Loss: 0.013293 (Â±0.002925)\n",
      "  ðŸ”„ Trial 76, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008002\n",
      "  ðŸ”„ Trial 76, Fold 2/5\n",
      "    Fold 2 best total loss: 0.013307\n",
      "  ðŸ”„ Trial 76, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015958\n",
      "  ðŸ”„ Trial 76, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011305\n",
      "  ðŸ”„ Trial 76, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:46:27,591] Trial 76 finished with value: 0.012380060809664428 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013328\n",
      "  ðŸ“Š Trial 76 - Average CV Loss: 0.012380 (Â±0.002641)\n",
      "  ðŸ”„ Trial 77, Fold 1/5\n",
      "    Fold 1 best total loss: 0.006438\n",
      "  ðŸ”„ Trial 77, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317852\n",
      "  ðŸ”„ Trial 77, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015114\n",
      "  ðŸ”„ Trial 77, Fold 4/5\n",
      "    Fold 4 best total loss: 0.202358\n",
      "  ðŸ”„ Trial 77, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:51:37,115] Trial 77 finished with value: 0.17749308639904485 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 96, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.345704\n",
      "  ðŸ“Š Trial 77 - Average CV Loss: 0.177493 (Â±0.144389)\n",
      "  ðŸ”„ Trial 78, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008670\n",
      "  ðŸ”„ Trial 78, Fold 2/5\n",
      "    Fold 2 best total loss: 0.020204\n",
      "  ðŸ”„ Trial 78, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016853\n",
      "  ðŸ”„ Trial 78, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013312\n",
      "  ðŸ”„ Trial 78, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 10:55:10,084] Trial 78 finished with value: 0.08072472477797418 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344584\n",
      "  ðŸ“Š Trial 78 - Average CV Loss: 0.080725 (Â±0.131985)\n",
      "  ðŸ”„ Trial 79, Fold 1/5\n",
      "    Fold 1 best total loss: 0.226005\n",
      "  ðŸ”„ Trial 79, Fold 2/5\n",
      "    Fold 2 best total loss: 0.318038\n",
      "  ðŸ”„ Trial 79, Fold 3/5\n",
      "    Fold 3 best total loss: 0.221060\n",
      "  ðŸ”„ Trial 79, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009707\n",
      "  ðŸ”„ Trial 79, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:00:19,330] Trial 79 finished with value: 0.15764561225660145 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 72, 'current_n_layers': 5, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013417\n",
      "  ðŸ“Š Trial 79 - Average CV Loss: 0.157646 (Â±0.124184)\n",
      "  ðŸ”„ Trial 80, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007946\n",
      "  ðŸ”„ Trial 80, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319689\n",
      "  ðŸ”„ Trial 80, Fold 3/5\n",
      "    Fold 3 best total loss: 0.013316\n",
      "  ðŸ”„ Trial 80, Fold 4/5\n",
      "    Fold 4 best total loss: 0.198806\n",
      "  ðŸ”„ Trial 80, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:06:59,789] Trial 80 finished with value: 0.11115607861429452 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.016023\n",
      "  ðŸ“Š Trial 80 - Average CV Loss: 0.111156 (Â±0.126842)\n",
      "  ðŸ”„ Trial 81, Fold 1/5\n",
      "    Fold 1 best total loss: 0.314055\n",
      "  ðŸ”„ Trial 81, Fold 2/5\n",
      "    Fold 2 best total loss: 0.316850\n",
      "  ðŸ”„ Trial 81, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017047\n",
      "  ðŸ”„ Trial 81, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014822\n",
      "  ðŸ”„ Trial 81, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:12:08,116] Trial 81 finished with value: 0.1365126925520599 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 64, 'decoder_n_layers': 6, 'decoder_dropout': 0.4, 'current_hidden_size': 32, 'current_n_layers': 3, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.019788\n",
      "  ðŸ“Š Trial 81 - Average CV Loss: 0.136513 (Â±0.146115)\n",
      "  ðŸ”„ Trial 82, Fold 1/5\n",
      "    Fold 1 best total loss: 0.009931\n",
      "  ðŸ”„ Trial 82, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016871\n",
      "  ðŸ”„ Trial 82, Fold 3/5\n",
      "    Fold 3 best total loss: 0.020703\n",
      "  ðŸ”„ Trial 82, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016752\n",
      "  ðŸ”„ Trial 82, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:18:55,591] Trial 82 finished with value: 0.01673024898627773 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 4, 'lstm_dropout': 0.4, 'decoder_hidden_size': 16, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 4, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.019394\n",
      "  ðŸ“Š Trial 82 - Average CV Loss: 0.016730 (Â±0.003718)\n",
      "  ðŸ”„ Trial 83, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007881\n",
      "  ðŸ”„ Trial 83, Fold 2/5\n",
      "    Fold 2 best total loss: 0.019152\n",
      "  ðŸ”„ Trial 83, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018772\n",
      "  ðŸ”„ Trial 83, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012333\n",
      "  ðŸ”„ Trial 83, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:24:04,840] Trial 83 finished with value: 0.013823672966100275 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010981\n",
      "  ðŸ“Š Trial 83 - Average CV Loss: 0.013824 (Â±0.004438)\n",
      "  ðŸ”„ Trial 84, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008209\n",
      "  ðŸ”„ Trial 84, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018530\n",
      "  ðŸ”„ Trial 84, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017191\n",
      "  ðŸ”„ Trial 84, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014435\n",
      "  ðŸ”„ Trial 84, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:29:12,211] Trial 84 finished with value: 0.01480989110423252 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015685\n",
      "  ðŸ“Š Trial 84 - Average CV Loss: 0.014810 (Â±0.003577)\n",
      "  ðŸ”„ Trial 85, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007891\n",
      "  ðŸ”„ Trial 85, Fold 2/5\n",
      "    Fold 2 best total loss: 0.315973\n",
      "  ðŸ”„ Trial 85, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016655\n",
      "  ðŸ”„ Trial 85, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009989\n",
      "  ðŸ”„ Trial 85, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:34:22,434] Trial 85 finished with value: 0.07278906374704093 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.013437\n",
      "  ðŸ“Š Trial 85 - Average CV Loss: 0.072789 (Â±0.121629)\n",
      "  ðŸ”„ Trial 86, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007337\n",
      "  ðŸ”„ Trial 86, Fold 2/5\n",
      "    Fold 2 best total loss: 0.014438\n",
      "  ðŸ”„ Trial 86, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016713\n",
      "  ðŸ”„ Trial 86, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011111\n",
      "  ðŸ”„ Trial 86, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:39:26,613] Trial 86 finished with value: 0.01205747943604365 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.010689\n",
      "  ðŸ“Š Trial 86 - Average CV Loss: 0.012057 (Â±0.003237)\n",
      "  ðŸ”„ Trial 87, Fold 1/5\n",
      "    Fold 1 best total loss: 0.314176\n",
      "  ðŸ”„ Trial 87, Fold 2/5\n",
      "    Fold 2 best total loss: 0.016590\n",
      "  ðŸ”„ Trial 87, Fold 3/5\n",
      "    Fold 3 best total loss: 0.013878\n",
      "  ðŸ”„ Trial 87, Fold 4/5\n",
      "    Fold 4 best total loss: 0.199850\n",
      "  ðŸ”„ Trial 87, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:42:56,624] Trial 87 finished with value: 0.11868225806392729 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 72, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.048917\n",
      "  ðŸ“Š Trial 87 - Average CV Loss: 0.118682 (Â±0.119231)\n",
      "  ðŸ”„ Trial 88, Fold 1/5\n",
      "    Fold 1 best total loss: 0.315808\n",
      "  ðŸ”„ Trial 88, Fold 2/5\n",
      "    Fold 2 best total loss: 0.012777\n",
      "  ðŸ”„ Trial 88, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017166\n",
      "  ðŸ”„ Trial 88, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009143\n",
      "  ðŸ”„ Trial 88, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:47:58,861] Trial 88 finished with value: 0.07289152217563241 and parameters: {'lstm_hidden_size': 32, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 96, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.009564\n",
      "  ðŸ“Š Trial 88 - Average CV Loss: 0.072892 (Â±0.121492)\n",
      "  ðŸ”„ Trial 89, Fold 1/5\n",
      "    Fold 1 best total loss: 0.314239\n",
      "  ðŸ”„ Trial 89, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317489\n",
      "  ðŸ”„ Trial 89, Fold 3/5\n",
      "    Fold 3 best total loss: 0.018254\n",
      "  ðŸ”„ Trial 89, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011783\n",
      "  ðŸ”„ Trial 89, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:54:33,598] Trial 89 finished with value: 0.13552333873230965 and parameters: {'lstm_hidden_size': 16, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.015851\n",
      "  ðŸ“Š Trial 89 - Average CV Loss: 0.135523 (Â±0.147266)\n",
      "  ðŸ”„ Trial 90, Fold 1/5\n",
      "    Fold 1 best total loss: 0.226023\n",
      "  ðŸ”„ Trial 90, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317056\n",
      "  ðŸ”„ Trial 90, Fold 3/5\n",
      "    Fold 3 best total loss: 0.014322\n",
      "  ðŸ”„ Trial 90, Fold 4/5\n",
      "    Fold 4 best total loss: 0.008754\n",
      "  ðŸ”„ Trial 90, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 11:58:04,046] Trial 90 finished with value: 0.18205405394546686 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 72, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 64, 'current_n_layers': 2, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.344116\n",
      "  ðŸ“Š Trial 90 - Average CV Loss: 0.182054 (Â±0.144630)\n",
      "  ðŸ”„ Trial 91, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007221\n",
      "  ðŸ”„ Trial 91, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317329\n",
      "  ðŸ”„ Trial 91, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015954\n",
      "  ðŸ”„ Trial 91, Fold 4/5\n",
      "    Fold 4 best total loss: 0.014000\n",
      "  ðŸ”„ Trial 91, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:03:07,921] Trial 91 finished with value: 0.07323384324554354 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 5, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011665\n",
      "  ðŸ“Š Trial 91 - Average CV Loss: 0.073234 (Â±0.122082)\n",
      "  ðŸ”„ Trial 92, Fold 1/5\n",
      "    Fold 1 best total loss: 0.011647\n",
      "  ðŸ”„ Trial 92, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022683\n",
      "  ðŸ”„ Trial 92, Fold 3/5\n",
      "    Fold 3 best total loss: 0.022731\n",
      "  ðŸ”„ Trial 92, Fold 4/5\n",
      "    Fold 4 best total loss: 0.015702\n",
      "  ðŸ”„ Trial 92, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:08:13,609] Trial 92 finished with value: 0.01809443477541208 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.2, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 16, 'current_n_layers': 3, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.017709\n",
      "  ðŸ“Š Trial 92 - Average CV Loss: 0.018094 (Â±0.004242)\n",
      "  ðŸ”„ Trial 93, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007534\n",
      "  ðŸ”„ Trial 93, Fold 2/5\n",
      "    Fold 2 best total loss: 0.022239\n",
      "  ðŸ”„ Trial 93, Fold 3/5\n",
      "    Fold 3 best total loss: 0.017122\n",
      "  ðŸ”„ Trial 93, Fold 4/5\n",
      "    Fold 4 best total loss: 0.010172\n",
      "  ðŸ”„ Trial 93, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:13:19,277] Trial 93 finished with value: 0.013816012197639792 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.2, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012013\n",
      "  ðŸ“Š Trial 93 - Average CV Loss: 0.013816 (Â±0.005251)\n",
      "  ðŸ”„ Trial 94, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007871\n",
      "  ðŸ”„ Trial 94, Fold 2/5\n",
      "    Fold 2 best total loss: 0.014492\n",
      "  ðŸ”„ Trial 94, Fold 3/5\n",
      "    Fold 3 best total loss: 0.015727\n",
      "  ðŸ”„ Trial 94, Fold 4/5\n",
      "    Fold 4 best total loss: 0.009745\n",
      "  ðŸ”„ Trial 94, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:18:25,480] Trial 94 finished with value: 0.012077829521149396 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012555\n",
      "  ðŸ“Š Trial 94 - Average CV Loss: 0.012078 (Â±0.002916)\n",
      "  ðŸ”„ Trial 95, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008732\n",
      "  ðŸ”„ Trial 95, Fold 2/5\n",
      "    Fold 2 best total loss: 0.013833\n",
      "  ðŸ”„ Trial 95, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016663\n",
      "  ðŸ”„ Trial 95, Fold 4/5\n",
      "    Fold 4 best total loss: 0.016128\n",
      "  ðŸ”„ Trial 95, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:23:33,569] Trial 95 finished with value: 0.013412799581419676 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.011708\n",
      "  ðŸ“Š Trial 95 - Average CV Loss: 0.013413 (Â±0.002930)\n",
      "  ðŸ”„ Trial 96, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008142\n",
      "  ðŸ”„ Trial 96, Fold 2/5\n",
      "    Fold 2 best total loss: 0.015187\n",
      "  ðŸ”„ Trial 96, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016931\n",
      "  ðŸ”„ Trial 96, Fold 4/5\n",
      "    Fold 4 best total loss: 0.011356\n",
      "  ðŸ”„ Trial 96, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:28:43,564] Trial 96 finished with value: 0.01317641066852957 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.014266\n",
      "  ðŸ“Š Trial 96 - Average CV Loss: 0.013176 (Â±0.003098)\n",
      "  ðŸ”„ Trial 97, Fold 1/5\n",
      "    Fold 1 best total loss: 0.314598\n",
      "  ðŸ”„ Trial 97, Fold 2/5\n",
      "    Fold 2 best total loss: 0.317449\n",
      "  ðŸ”„ Trial 97, Fold 3/5\n",
      "    Fold 3 best total loss: 0.011683\n",
      "  ðŸ”„ Trial 97, Fold 4/5\n",
      "    Fold 4 best total loss: 0.199061\n",
      "  ðŸ”„ Trial 97, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:33:54,411] Trial 97 finished with value: 0.23734210729016922 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 72, 'current_n_layers': 2, 'current_dropout': 0.1}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.343920\n",
      "  ðŸ“Š Trial 97 - Average CV Loss: 0.237342 (Â±0.123395)\n",
      "  ðŸ”„ Trial 98, Fold 1/5\n",
      "    Fold 1 best total loss: 0.008279\n",
      "  ðŸ”„ Trial 98, Fold 2/5\n",
      "    Fold 2 best total loss: 0.018672\n",
      "  ðŸ”„ Trial 98, Fold 3/5\n",
      "    Fold 3 best total loss: 0.016436\n",
      "  ðŸ”„ Trial 98, Fold 4/5\n",
      "    Fold 4 best total loss: 0.012266\n",
      "  ðŸ”„ Trial 98, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:39:03,798] Trial 98 finished with value: 0.013547220977488904 and parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012083\n",
      "  ðŸ“Š Trial 98 - Average CV Loss: 0.013547 (Â±0.003637)\n",
      "  ðŸ”„ Trial 99, Fold 1/5\n",
      "    Fold 1 best total loss: 0.007757\n",
      "  ðŸ”„ Trial 99, Fold 2/5\n",
      "    Fold 2 best total loss: 0.017473\n",
      "  ðŸ”„ Trial 99, Fold 3/5\n",
      "    Fold 3 best total loss: 0.014152\n",
      "  ðŸ”„ Trial 99, Fold 4/5\n",
      "    Fold 4 best total loss: 0.013435\n",
      "  ðŸ”„ Trial 99, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:42:40,357] Trial 99 finished with value: 0.013038744864752516 and parameters: {'lstm_hidden_size': 64, 'lstm_n_layers': 2, 'lstm_dropout': 0.1, 'decoder_hidden_size': 16, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 48, 'current_n_layers': 2, 'current_dropout': 0.2}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.012377\n",
      "  ðŸ“Š Trial 99 - Average CV Loss: 0.013039 (Â±0.003143)\n",
      "  ðŸ”„ Trial 100, Fold 1/5\n",
      "    Fold 1 best total loss: 0.315213\n",
      "  ðŸ”„ Trial 100, Fold 2/5\n",
      "    Fold 2 best total loss: 0.319503\n",
      "  ðŸ”„ Trial 100, Fold 3/5\n",
      "    Fold 3 best total loss: 0.221528\n",
      "  ðŸ”„ Trial 100, Fold 4/5\n",
      "    Fold 4 best total loss: 0.202100\n",
      "  ðŸ”„ Trial 100, Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-16 12:49:34,691] Trial 100 finished with value: 0.2806893017143011 and parameters: {'lstm_hidden_size': 72, 'lstm_n_layers': 4, 'lstm_dropout': 0.1, 'decoder_hidden_size': 64, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 96, 'current_n_layers': 6, 'current_dropout': 0.30000000000000004}. Best is trial 35 with value: 0.011858979251701384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5 best total loss: 0.345103\n",
      "  ðŸ“Š Trial 100 - Average CV Loss: 0.280689 (Â±0.057487)\n",
      "  ðŸ”„ Trial 101, Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-09-16 12:49:48,353] Trial 101 failed with parameters: {'lstm_hidden_size': 48, 'lstm_n_layers': 3, 'lstm_dropout': 0.1, 'decoder_hidden_size': 48, 'decoder_n_layers': 6, 'decoder_dropout': 0.1, 'current_hidden_size': 32, 'current_n_layers': 2, 'current_dropout': 0.2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_5480/3899643224.py\", line 105, in objective\n",
      "    pred = model(inputs, target_seq_len)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_5480/1083247530.py\", line 10, in forward\n",
      "    hidden_states = self.state_extr(x, seq_len)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_5480/4018163025.py\", line 32, in forward\n",
      "    h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_5480/85641908.py\", line 31, in forward\n",
      "    c_new = self.ln_c(c_new)\n",
      "            ^^^^^^^^^\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1918, in __getattr__\n",
      "    def __getattr__(self, name: str) -> Any:\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2025-09-16 12:49:48,356] Trial 101 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ ìµœì í™”ê°€ ì‚¬ìš©ìžì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š OPTIMIZATION RESULTS\n",
      "================================================================================\n",
      "âœ… ì™„ë£Œëœ trials: 102\n",
      "ðŸ† ìµœê³  ì„±ëŠ¥ trial: 35\n",
      "ðŸ’¯ ìµœê³  ì„±ëŠ¥ ê°’: 0.011859\n",
      "\n",
      "ðŸŽ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\n",
      "   lstm_hidden_size: 72\n",
      "   lstm_n_layers: 4\n",
      "   lstm_dropout: 0.1\n",
      "   decoder_hidden_size: 32\n",
      "   decoder_n_layers: 6\n",
      "   decoder_dropout: 0.1\n",
      "   current_hidden_size: 72\n",
      "   current_n_layers: 2\n",
      "   current_dropout: 0.30000000000000004\n",
      "\n",
      "ðŸ“ˆ ìƒìœ„ 5ê°œ Trials:\n",
      "   1. Trial 35: 0.011859\n",
      "   2. Trial 86: 0.012057\n",
      "   3. Trial 94: 0.012078\n",
      "   4. Trial 47: 0.012124\n",
      "   5. Trial 65: 0.012160\n",
      "ðŸ’¾ ëª¨ë“  trials ê²°ê³¼ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤: bmed_optuna_trials_20250916_124948.csv\n",
      "ðŸ’¾ SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì‹¤ì‹œê°„ ì €ìž¥ë¨: sqlite:///bmed_optuna_study_20250915_234452.db\n",
      "   - ì¤‘ë‹¨ í›„ ìž¬ì‹œìž‘ ì‹œ ìžë™ìœ¼ë¡œ ê¸°ì¡´ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤\n",
      "   - ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
      "================================================================================\n",
      "ðŸŽ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë©”ì¸ ìµœì í™” í•¨ìˆ˜\n",
    "def run_optuna_optimization():\n",
    "    \"\"\"Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ BMED TF Model Hyperparameter Optimization with Optuna\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ì „ì—­ ë°ì´í„° ë¡œë“œ\n",
    "    global dataset, range_mm\n",
    "    \n",
    "    print(\"ðŸ“‹ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    df, ndf, range_mm, exp_num_list = df_treat('BMED_DATA_AG.csv')\n",
    "    seq = seq_data(ndf, exp_num_list)\n",
    "    pad, seq_len, max_len = pad_seq(seq)\n",
    "    dataset = gen_dataset(pad, seq_len)\n",
    "    \n",
    "    print(f\"   - ì´ ì‹¤í—˜ ê°œìˆ˜: {len(exp_num_list)}\")\n",
    "    print(f\"   - ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(dataset)}\")\n",
    "    print(f\"   - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_len}\")\n",
    "    \n",
    "    # SQLite ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•œ Optuna study ìƒì„±\n",
    "    #timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    timestamp = '20250915_234452'\n",
    "    db_url = f\"sqlite:///bmed_optuna_study_{timestamp}.db\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name='bmed_tf_optimization',\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        storage=db_url,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    # ìµœì í™” ì‹¤í–‰\n",
    "    n_trials = 100\n",
    "    print(f\"ðŸ” ìµœì í™” ì‹œìž‘ (ì´ {n_trials} trials)\")\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=n_trials, timeout=None)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ ìµœì í™”ê°€ ì‚¬ìš©ìžì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"âœ… ì™„ë£Œëœ trials: {len(study.trials)}\")\n",
    "    print(f\"ðŸ† ìµœê³  ì„±ëŠ¥ trial: {study.best_trial.number}\")\n",
    "    print(f\"ðŸ’¯ ìµœê³  ì„±ëŠ¥ ê°’: {study.best_value:.6f}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # ìƒìœ„ 5ê°œ trial ì •ë³´\n",
    "    print(f\"\\nðŸ“ˆ ìƒìœ„ 5ê°œ Trials:\")\n",
    "    trials_df = study.trials_dataframe().sort_values('value').head(5)\n",
    "    for idx, (_, trial) in enumerate(trials_df.iterrows()):\n",
    "        print(f\"   {idx+1}. Trial {int(trial['number'])}: {trial['value']:.6f}\")\n",
    "    \n",
    "    # ê²°ê³¼ ì €ìž¥\n",
    "    result_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Trials ê²°ê³¼ CSVë¡œ ì €ìž¥\n",
    "    trials_file = f\"bmed_optuna_trials_{result_timestamp}.csv\"\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_df.to_csv(trials_file, index=False)\n",
    "    print(f\"ðŸ’¾ ëª¨ë“  trials ê²°ê³¼ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤: {trials_file}\")\n",
    "    \n",
    "    # SQLite ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´\n",
    "    print(f\"ðŸ’¾ SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì‹¤ì‹œê°„ ì €ìž¥ë¨: {db_url}\")\n",
    "    print(f\"   - ì¤‘ë‹¨ í›„ ìž¬ì‹œìž‘ ì‹œ ìžë™ìœ¼ë¡œ ê¸°ì¡´ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤\")\n",
    "    print(f\"   - ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸŽ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = run_optuna_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
