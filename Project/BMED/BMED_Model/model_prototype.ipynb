{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bsjun\\miniforge3\\envs\\NN_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import optuna\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# Fix OpenMP runtime duplicate initialization error\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('BMED_data_v5.csv')\n",
    "\n",
    "# Prepare data for all experiments\n",
    "X_batches = []\n",
    "S_batches = []\n",
    "Y_batches = []\n",
    "times_list = []\n",
    "\n",
    "max_points = max(len(df[df['exp'] == exp_id]) for exp_id in df['exp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_id in df['exp'].unique():\n",
    "    df_exp = df[df['exp'] == exp_id]\n",
    "    \n",
    "    X = df_exp[['T','V','E','Ci','Ki']].iloc[0]\n",
    "    S = df_exp[['NF_LA','NA_LA','NF_K','NB_K','VF','VA','VB']].iloc[0]\n",
    "    Y = df_exp[['NF_LA','NA_LA','NF_K','NB_K','VF','VA','VB']].values\n",
    "    times = df_exp['t'].values\n",
    "    \n",
    "    # Pad Y with the last values to match max_points\n",
    "    if len(Y) < max_points:\n",
    "        pad_length = max_points - len(Y)\n",
    "        Y = np.pad(Y, ((0, pad_length), (0, 0)), mode='edge')\n",
    "        times = np.pad(times, (0, pad_length), mode='edge')\n",
    "    \n",
    "    X_batches.append(torch.FloatTensor(X.values))\n",
    "    S_batches.append(torch.FloatTensor(S.values))\n",
    "    Y_batches.append(torch.FloatTensor(Y))\n",
    "    times_list.append(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to batches\n",
    "X_batch = torch.stack(X_batches)\n",
    "S_batch = torch.stack(S_batches)\n",
    "Y_batch = torch.stack(Y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.0000e-01,  0.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 4.9166e-01,  8.3435e-03,  1.0124e+00,  ...,  1.0200e+00,\n",
       "           9.9000e-01,  9.8000e-01],\n",
       "         [ 4.6336e-01,  3.6636e-02,  8.2681e-01,  ...,  1.0200e+00,\n",
       "           9.9000e-01,  9.8000e-01],\n",
       "         ...,\n",
       "         [ 1.0178e-01,  3.9822e-01,  2.0147e-01,  ...,  9.1000e-01,\n",
       "           9.8000e-01,  1.1200e+00],\n",
       "         [ 1.0178e-01,  3.9822e-01,  2.0147e-01,  ...,  9.1000e-01,\n",
       "           9.8000e-01,  1.1200e+00],\n",
       "         [ 1.0178e-01,  3.9822e-01,  2.0147e-01,  ...,  9.1000e-01,\n",
       "           9.8000e-01,  1.1200e+00]],\n",
       "\n",
       "        [[ 5.0000e-01,  0.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 5.0314e-01, -3.1369e-03,  9.9587e-01,  ...,  1.0400e+00,\n",
       "           9.8000e-01,  9.7000e-01],\n",
       "         [ 5.1203e-01, -1.2032e-02,  1.0871e+00,  ...,  1.0900e+00,\n",
       "           9.8000e-01,  9.6000e-01],\n",
       "         ...,\n",
       "         [ 1.9763e-01,  3.0237e-01,  2.9929e-01,  ...,  1.0100e+00,\n",
       "           8.3000e-01,  1.0900e+00],\n",
       "         [ 1.6124e-01,  3.3876e-01,  2.7380e-01,  ...,  9.9000e-01,\n",
       "           8.1000e-01,  1.0900e+00],\n",
       "         [ 1.2511e-01,  3.7489e-01,  2.4507e-01,  ...,  9.4000e-01,\n",
       "           8.0000e-01,  1.2100e+00]],\n",
       "\n",
       "        [[ 5.0000e-01,  0.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 4.9035e-01,  9.6540e-03,  9.9931e-01,  ...,  1.0200e+00,\n",
       "           1.0000e+00,  9.6000e-01],\n",
       "         [ 3.7010e-01,  1.2990e-01,  5.7652e-01,  ...,  1.0100e+00,\n",
       "           9.9000e-01,  9.7000e-01],\n",
       "         ...,\n",
       "         [-5.1327e-03,  5.0513e-01,  3.3306e-03,  ...,  8.0000e-01,\n",
       "           1.1000e+00,  1.1100e+00],\n",
       "         [-5.1327e-03,  5.0513e-01,  3.3306e-03,  ...,  8.0000e-01,\n",
       "           1.1000e+00,  1.1100e+00],\n",
       "         [-5.1327e-03,  5.0513e-01,  3.3306e-03,  ...,  8.0000e-01,\n",
       "           1.1000e+00,  1.1100e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.0000e+00,  0.0000e+00,  6.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  2.0000e+00],\n",
       "         [ 2.6043e+00,  3.9573e-01,  5.5246e+00,  ...,  1.1000e+00,\n",
       "           9.8000e-01,  1.9000e+00],\n",
       "         [ 2.2562e+00,  7.4383e-01,  4.0831e+00,  ...,  1.0300e+00,\n",
       "           1.0000e+00,  1.9000e+00],\n",
       "         ...,\n",
       "         [ 6.0852e-01,  2.3915e+00,  7.1682e-01,  ...,  5.0000e-01,\n",
       "           1.3000e+00,  2.1300e+00],\n",
       "         [ 6.0852e-01,  2.3915e+00,  7.1682e-01,  ...,  5.0000e-01,\n",
       "           1.3000e+00,  2.1300e+00],\n",
       "         [ 6.0852e-01,  2.3915e+00,  7.1682e-01,  ...,  5.0000e-01,\n",
       "           1.3000e+00,  2.1300e+00]],\n",
       "\n",
       "        [[ 3.0000e+00,  0.0000e+00,  6.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  2.0000e+00],\n",
       "         [ 2.1349e+00,  8.6505e-01,  3.5785e+00,  ...,  9.8000e-01,\n",
       "           1.0200e+00,  1.9300e+00],\n",
       "         [ 1.6355e+00,  1.3645e+00,  2.1412e+00,  ...,  8.3000e-01,\n",
       "           1.1200e+00,  2.0000e+00],\n",
       "         ...,\n",
       "         [ 2.5154e-01,  2.7485e+00,  2.8317e-01,  ...,  3.3000e-01,\n",
       "           1.4000e+00,  2.1700e+00],\n",
       "         [ 2.5154e-01,  2.7485e+00,  2.8317e-01,  ...,  3.3000e-01,\n",
       "           1.4000e+00,  2.1700e+00],\n",
       "         [ 2.5154e-01,  2.7485e+00,  2.8317e-01,  ...,  3.3000e-01,\n",
       "           1.4000e+00,  2.1700e+00]],\n",
       "\n",
       "        [[ 3.0000e+00,  0.0000e+00,  6.0000e+00,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  2.0000e+00],\n",
       "         [ 2.6602e+00,  3.3977e-01,  5.2887e+00,  ...,  1.0800e+00,\n",
       "           9.8000e-01,  1.9000e+00],\n",
       "         [ 2.3509e+00,  6.4910e-01,  3.8428e+00,  ...,  1.0300e+00,\n",
       "           1.0000e+00,  1.9300e+00],\n",
       "         ...,\n",
       "         [ 6.6805e-02,  2.9332e+00,  6.0555e-02,  ...,  2.8000e-01,\n",
       "           1.4000e+00,  2.2000e+00],\n",
       "         [ 1.0262e-02,  2.9897e+00,  6.6985e-03,  ...,  2.3000e-01,\n",
       "           1.4000e+00,  2.2500e+00],\n",
       "         [ 1.0262e-02,  2.9897e+00,  6.6985e-03,  ...,  2.3000e-01,\n",
       "           1.4000e+00,  2.2500e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sequence length to Y data length\n",
    "seq_length = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_batch = X.unsqueeze(0).repeat(1, seq_length, 1)  # [1, seq_length, x_size]\n",
    "S_batch = S.unsqueeze(0)  # [1, s_size]\n",
    "Y_batch = Y.unsqueeze(0)  # [1, seq_length, s_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDLSTM(nn.Module):\n",
    "    def __init__(self, x_size, s_size, hidden_size, num_layers=2):\n",
    "        super(BMEDLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.s_size = s_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(x_size + s_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, s_size)\n",
    "        \n",
    "    def forward(self, x, s0, dt, max_time):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # 초기 상태 설정\n",
    "        current_s = s0.unsqueeze(1)  # [batch_size, 1, s_size]\n",
    "        outputs = []\n",
    "        cal_times = []\n",
    "        cal_t = 0.0\n",
    "        \n",
    "        # dt 간격으로 계산 진행\n",
    "        while cal_t <= max_time:\n",
    "            # 현재 입력 x와 상태 s 결합\n",
    "            combined_input = torch.cat([x[:, 0:1], current_s], dim=2)  # 모든 시간에서 같은 x 사용\n",
    "            \n",
    "            # LSTM 순전파\n",
    "            lstm_out, (h0, c0) = self.lstm(combined_input, (h0, c0))\n",
    "            step_output = self.fc(lstm_out)\n",
    "            \n",
    "            # 상태 업데이트 (S(n+1) = S(n) + output*dt)\n",
    "            current_s = current_s + step_output * dt\n",
    "            \n",
    "            outputs.append(current_s)\n",
    "            cal_times.append(cal_t)\n",
    "            cal_t += dt\n",
    "        \n",
    "        # 모든 출력을 시퀀스로 결합\n",
    "        outputs = torch.cat(outputs, dim=1)  # [batch_size, num_steps, s_size]\n",
    "        cal_times = torch.tensor(cal_times).to(x.device)\n",
    "        \n",
    "        return outputs, cal_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter settings\n",
    "x_size = X.shape[0]\n",
    "s_size = S.shape[0]\n",
    "hidden_size = 32\n",
    "dt = 0.01\n",
    "max_time = times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BMEDLSTM(x_size, s_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.3144\n",
      "Epoch [20/100], Loss: 0.0458\n",
      "Epoch [30/100], Loss: 0.0459\n",
      "Epoch [40/100], Loss: 0.0236\n",
      "Epoch [50/100], Loss: 0.0239\n",
      "Epoch [60/100], Loss: 0.0213\n",
      "Epoch [70/100], Loss: 0.0210\n",
      "Epoch [80/100], Loss: 0.0205\n",
      "Epoch [90/100], Loss: 0.0201\n",
      "Epoch [100/100], Loss: 0.0199\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, cal_times = model(X_batch, S_batch, dt, max_time)\n",
    "    \n",
    "    # Find closest calculation results to actual data times\n",
    "    loss = 0\n",
    "    for i, t in enumerate(times):\n",
    "        # Find index of closest time\n",
    "        idx = torch.abs(cal_times - t).argmin()\n",
    "        loss += criterion(outputs[:, idx:idx+1], Y_batch[:, i:i+1])\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Results:\n",
      "tensor([[ 4.9901e-01, -3.0024e-04,  1.0001e+00,  ...,  9.9968e-01,\n",
      "          1.0011e+00,  1.0012e+00],\n",
      "        [ 4.9813e-01, -5.7878e-04,  9.9981e-01,  ...,  9.9956e-01,\n",
      "          1.0018e+00,  1.0022e+00],\n",
      "        [ 4.9733e-01, -7.8765e-04,  9.9924e-01,  ...,  9.9958e-01,\n",
      "          1.0022e+00,  1.0031e+00],\n",
      "        ...,\n",
      "        [ 2.0340e-01,  3.1039e-01,  2.3304e-01,  ...,  9.2477e-01,\n",
      "          9.8915e-01,  1.0612e+00],\n",
      "        [ 2.0283e-01,  3.1103e-01,  2.3147e-01,  ...,  9.2456e-01,\n",
      "          9.8910e-01,  1.0613e+00],\n",
      "        [ 2.0226e-01,  3.1168e-01,  2.2990e-01,  ...,  9.2435e-01,\n",
      "          9.8905e-01,  1.0615e+00]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions, cal_times = model(X_batch, S_batch, dt, max_time)\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "y_names = ['NF_LA', 'NA_LA', 'NF_K', 'NB_K', 'VF', 'VA', 'VB']  # Column names of Y data\n",
    "for i in range(len(y_names)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    # Plot experimental data as scatter points\n",
    "    plt.scatter(times, Y_batch[0, :, i].numpy(), c='b', label='Experimental', alpha=0.6)\n",
    "    # Plot model predictions as continuous line\n",
    "    plt.plot(cal_times.numpy(), predictions[0, :, i].numpy(), 'r-', label='Model Prediction', linewidth=1.5)\n",
    "    plt.title(f'{y_names[i]}')\n",
    "    plt.xlabel('Time (t)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
