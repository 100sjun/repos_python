{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import optuna\n",
    "from optuna.samplers import GPSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1dade153bd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward network for migration prediction\n",
    "class MigrationPredictor(nn.Module):\n",
    "    def __init__(self, hidden_nodes = 64, hidden_layers = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_features = 7\n",
    "        n_outputs = 4\n",
    "\n",
    "        # Layer configuration\n",
    "        layers = []\n",
    "        # input layer\n",
    "        layers.append(nn.Linear(n_features, hidden_nodes))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # hidden layers\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_nodes, hidden_nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_nodes, n_outputs))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical Layers for State update\n",
    "class PhysicalLayer:\n",
    "    def __init__(self, dt = 0.1):\n",
    "        self.dt = dt\n",
    "    \n",
    "    def update_state(self, cur_states, migrations):\n",
    "        # Current States\n",
    "        T = cur_states[0]\n",
    "        V = cur_states[1]\n",
    "        E = cur_states[2]\n",
    "        CF_LA = cur_states[3]\n",
    "        CA_LA = cur_states[4]\n",
    "        CF_K = cur_states[5]\n",
    "        CB_K = cur_states[6]\n",
    "        VF = cur_states[7]\n",
    "        VA = cur_states[8]\n",
    "        VB = cur_states[9]\n",
    "        \n",
    "        # Migration\n",
    "        dNLA = migrations[0] * self.dt\n",
    "        dNK = migrations[1] * self.dt\n",
    "        dVA = migrations[2] * self.dt\n",
    "        dVB = migrations[3] * self.dt\n",
    "\n",
    "        # Fixed variables\n",
    "        nT = T\n",
    "        nV = V\n",
    "        nE = E     \n",
    "        \n",
    "        # New Volumes\n",
    "        nVF = VF - dVA - dVB\n",
    "        nVA = VA + dVA\n",
    "        nVB = VB + dVB\n",
    "\n",
    "        # New Concentrations\n",
    "        nCF_LA = (CF_LA * VF - dNLA) / nVF\n",
    "        nCA_LA = (CA_LA * VA + dNLA) / nVA\n",
    "        nCF_K = (CF_K * VF - dNK) / nVF\n",
    "        nCB_K = (CB_K * VB + dNK) / nVB\n",
    "\n",
    "        # New States\n",
    "        new_states = cur_states.clone()\n",
    "        new_states[0] = nT\n",
    "        new_states[1] = nV\n",
    "        new_states[2] = nE\n",
    "        new_states[3] = nCF_LA\n",
    "        new_states[4] = nCA_LA\n",
    "        new_states[5] = nCF_K\n",
    "        new_states[6] = nCB_K\n",
    "        new_states[7] = nVF\n",
    "        new_states[8] = nVA\n",
    "        new_states[9] = nVB\n",
    "        \n",
    "        return new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDDataset(Dataset):\n",
    "    def __init__(self, dict_spline):\n",
    "        self.states = ['T', 'V', 'E', 'CF_LA', 'CA_LA', 'CF_K', 'CB_K', 'VF', 'VA', 'VB']\n",
    "        self.experiments = []\n",
    "\n",
    "        for exp_id, exp_data in dict_spline.items():\n",
    "            # Save whole data of each experiment in one sample\n",
    "            exp_array = exp_data[self.states].values\n",
    "            times = exp_data['t'].values\n",
    "            self.experiments.append({\n",
    "                'init_state': torch.tensor(exp_array[0], dtype = torch.float32), # initial state\n",
    "                'measured_state': torch.tensor(exp_array, dtype = torch.float32), # whole measurements\n",
    "                'times': torch.tensor(times, dtype = torch.float32) # time points\n",
    "            })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.experiments)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.experiments[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDModel(nn.Module):\n",
    "    def __init__(self, hidden_nodes = 32, hidden_layers = 3, dt = 0.1, scaler = None):\n",
    "        super().__init__()\n",
    "        self.migration_predictor = MigrationPredictor(hidden_nodes, hidden_layers)\n",
    "        self.physical_layer = PhysicalLayer(dt)\n",
    "        self.scaler = scaler\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, init_state, times):\n",
    "\n",
    "        cur_state = init_state # batch size 1\n",
    "        cur_time = 0.0\n",
    "        pred_states = []\n",
    "        measured_indices = []\n",
    "\n",
    "        times = times\n",
    "        times_np = times[0].numpy()\n",
    "        max_time = times_np[-1]\n",
    "        measured_indices.append(0)\n",
    "\n",
    "        # 초기 상태 저장\n",
    "        pred_states.append(cur_state)\n",
    "\n",
    "        while cur_time < max_time:\n",
    "            # input_feature에 해당하는 변수만 정규화\n",
    "            input_state = cur_state[:, :7]  # input feature 추출, 2차원 유지지\n",
    "            \n",
    "            norm_input = self.scaler.transform(input_state.detach().numpy())\n",
    "            norm_input = torch.tensor(norm_input)\n",
    "            \n",
    "            # 상태 예측\n",
    "            migration = self.migration_predictor(norm_input)  # (1, 6) -> (1, 3)\n",
    "            cur_state = self.physical_layer.update_state(cur_state[0], migration[0]).unsqueeze(0)  # (1,8)\n",
    "            pred_states.append(cur_state)  # (1, 8)\n",
    "            cur_time += self.dt\n",
    "\n",
    "            # 측정 시간과 매칭\n",
    "            for t in times_np:\n",
    "                if abs(cur_time - t) < self.dt/2:\n",
    "                    measured_indices.append(len(pred_states) - 1)\n",
    "\n",
    "        # 현재 배치의 예측 상태들을 스택\n",
    "        pred_states = torch.cat(pred_states, dim=0)  # (n_steps, 8)\n",
    "\n",
    "        return pred_states, measured_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred_states, measured_indices, measured_states):\n",
    "    total_loss = 0\n",
    "    for idx, measured_state in zip(measured_indices, measured_states[0]):\n",
    "        predicted_state = pred_states[idx]\n",
    "        total_loss += torch.mean((predicted_state - measured_state) ** 2)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs = 100, learning_rate = 0.001, weight_decay = 1e-5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay= weight_decay)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for exp in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            init_state = exp['init_state']\n",
    "            measured_state = exp['measured_state']\n",
    "            times = exp['times']\n",
    "\n",
    "            # Simulation\n",
    "            pred_state, measured_indices = model(init_state, times)\n",
    "\n",
    "            # Loss\n",
    "            loss = custom_loss(pred_state, measured_indices, measured_state)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_calculator(pred_states, measured_indices, measured_states):\n",
    "\n",
    "    pred_value = pred_states[measured_indices][:,3:].numpy()\n",
    "    target_value = measured_states[0][:,3:].numpy()\n",
    "    r2_scores = []\n",
    "    for col in range(pred_value.shape[1]):\n",
    "        col_r2 = r2_score(pred_value[:,col], target_value[:,col])\n",
    "        r2_scores.append(col_r2)\n",
    "\n",
    "    return np.mean(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_r2 = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for exp in val_loader:\n",
    "            init_state = exp['init_state']\n",
    "            measured_states = exp['measured_state']\n",
    "            times = exp['times']\n",
    "\n",
    "            pred_states, measured_indices = model(init_state, times)\n",
    "            r2 = r2_calculator(pred_states, measured_indices, measured_states)\n",
    "\n",
    "            total_r2 += r2\n",
    "            total_samples += 1\n",
    "\n",
    "    avg_r2 = total_r2 / total_samples\n",
    "    return avg_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df_path, exp_idx = None):\n",
    "    # Load raw data\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    if exp_idx is not None:\n",
    "        df = df[df['exp'].isin(exp_idx)]\n",
    "\n",
    "    # split the data by experiment number\n",
    "    dict_spline = {}\n",
    "    for exp in df['exp'].unique():\n",
    "        dict_spline[exp] = df[df['exp'] == exp].sort_values('t')\n",
    "\n",
    "    # scaler\n",
    "    scaler = StandardScaler()\n",
    "    col_to_scale = ['T', 'V', 'E', 'CF_LA', 'CA_LA', 'CF_K', 'CB_K']\n",
    "    scaler.fit(df[col_to_scale].values)\n",
    "    return dict_spline, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, dataset, exp_idx=0):\n",
    "    # 데이터 준비\n",
    "    exp = dataset.experiments[exp_idx]\n",
    "    init_state = torch.tensor(exp['init_state'], dtype=torch.float32).unsqueeze(0)\n",
    "    times = torch.tensor(exp['times'], dtype=torch.float32).unsqueeze(0)\n",
    "    measured_state = torch.tensor(exp['measured_state'], dtype=torch.float32)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        pred_states, measured_indices = model(init_state, times)\n",
    "    \n",
    "    # 예측을 위한 시간 포인트 생성 (dt = 0.1 간격)\n",
    "    t_pred = torch.arange(0, times[0][-1].item() + 0.1, 0.1)\n",
    "    \n",
    "    # 변수 이름과 단위\n",
    "    var_names = {\n",
    "        'T': 'Temperature (°C)',\n",
    "        'V': 'Voltage (V)',\n",
    "        'E': 'Electric Field (V/cm)',\n",
    "        'CF_LA': 'Feed LA Conc. (M)',\n",
    "        'CA_LA': 'Acid LA Conc. (M)',\n",
    "        'CF_K': 'Feed K Conc. (M)',\n",
    "        'CB_K': 'Base K Conc. (M)',\n",
    "        'VF': 'Feed Volume (L)',\n",
    "        'VA': 'Acid Volume (L)',\n",
    "        'VB': 'Base Volume (L)'\n",
    "    }\n",
    "    \n",
    "    # 그래프 그리기\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (var, label) in enumerate(var_names.items()):\n",
    "        ax = axes[i]\n",
    "        # 실제 측정값 (점으로 표시)\n",
    "        ax.plot(times[0].numpy(), measured_state[:, i].numpy(), \n",
    "                'bo', label='Measured', markersize=6)\n",
    "        # 예측값 (연속 선으로 표시)\n",
    "        ax.plot(t_pred.numpy(), pred_states[:, i].numpy(), \n",
    "                'r-', label='Predicted', linewidth=2)\n",
    "        \n",
    "        ax.set_title(label, fontsize=12, pad=10)\n",
    "        ax.set_xlabel('Time (hr)', fontsize=10)\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # load data\n",
    "    df_path = '../data/BMED_data_v8.csv'\n",
    "    dict_spline, scaler = prepare_data(df_path)\n",
    "\n",
    "    # Hyperparameter 설정\n",
    "    hidden_nodes = trial.suggest_int('hidden_nodes', 16, 128, step = 16)\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 1, 10)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log = True)\n",
    "    wd = trial.suggest_float('weight_decay', 1e-6, 1e-3, log = True)\n",
    "    epochs = trial.suggest_int('epochs', 50, 1000, step = 50)\n",
    "    dt = 0.1\n",
    "\n",
    "    # 5-fold 설정\n",
    "    kfolds = 5\n",
    "    kf = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "    # dataset 생성\n",
    "    dataset = BMEDDataset(dict_spline)\n",
    "\n",
    "    # k-fold 교차 검증 스코어 저장\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        # kfold로 전체 dataset에 대해서 train과 validation subset을 생성\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Dataloader 생성\n",
    "        train_loader = DataLoader(train_subset, batch_size = 1, shuffle = True)\n",
    "        val_loader = DataLoader(val_subset, batch_size = 1, shuffle = False)\n",
    "\n",
    "        # 모델 생성\n",
    "        model = BMEDModel(hidden_nodes=hidden_nodes, hidden_layers=hidden_layers, dt = dt, scaler=scaler)\n",
    "\n",
    "        # 모델 학습\n",
    "        train_model(model = model, train_loader = train_loader, epochs = epochs, learning_rate = lr, weight_decay = wd)   \n",
    "\n",
    "        # 모델 평가\n",
    "        r2_score = evaluate_model(model, val_loader)  \n",
    "        fold_scores.append(r2_score)\n",
    "    \n",
    "    return np.mean(fold_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42464\\2405133046.py:3: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler = GPSampler(n_startup_trials=10, seed=42)\n",
      "[I 2025-04-18 08:28:48,919] Using an existing study with name 'hpOpt' instead of creating a new one.\n",
      "[I 2025-04-18 08:29:29,440] Trial 13 finished with value: -58.118504817741254 and parameters: {'hidden_nodes': 22, 'hidden_layers': 2, 'lr': 0.001570297088405539, 'weight_decay': 6.251373574521755e-05, 'epochs': 5}. Best is trial 10 with value: -26.892350514105384.\n",
      "[I 2025-04-18 08:30:36,428] Trial 14 finished with value: -6.786731049673898 and parameters: {'hidden_nodes': 18, 'hidden_layers': 1, 'lr': 0.003967605077052989, 'weight_decay': 6.358358856676247e-05, 'epochs': 9}. Best is trial 14 with value: -6.786731049673898.\n",
      "[W 2025-04-18 08:30:45,859] Trial 15 failed with parameters: {'hidden_nodes': 16, 'hidden_layers': 2, 'lr': 0.00314288089084011, 'weight_decay': 4.335281794951567e-06, 'epochs': 6} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42464\\2430927991.py\", line 37, in objective\n",
      "    train_model(model = model, train_loader = train_loader, epochs = epochs, learning_rate = lr, weight_decay = wd)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42464\\3019731543.py\", line 15, in train_model\n",
      "    pred_state, measured_indices = model(init_state, times)\n",
      "                                   ~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42464\\4061281966.py\", line 32, in forward\n",
      "    migration = self.migration_predictor(norm_input)  # (1, 6) -> (1, 3)\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_42464\\2485144059.py\", line 26, in forward\n",
      "    return self.model(x)\n",
      "           ~~~~~~~~~~^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-18 08:30:45,865] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m study = optuna.create_study(\n\u001b[32m      6\u001b[39m     study_name = \u001b[33m'\u001b[39m\u001b[33mhpOpt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     storage = storage_name,\n\u001b[32m      8\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     sampler=sampler,\n\u001b[32m     10\u001b[39m     load_if_exists = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# optimize the hyperparameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# return the best hyperparameters\u001b[39;00m\n\u001b[32m     16\u001b[39m best_params = study.best_trial.params\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     34\u001b[39m model = BMEDModel(hidden_nodes=hidden_nodes, hidden_layers=hidden_layers, dt = dt, scaler=scaler)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 모델 평가\u001b[39;00m\n\u001b[32m     40\u001b[39m r2_score = evaluate_model(model, val_loader)  \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, epochs, learning_rate, weight_decay)\u001b[39m\n\u001b[32m     12\u001b[39m times = exp[\u001b[33m'\u001b[39m\u001b[33mtimes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Simulation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m pred_state, measured_indices = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m     18\u001b[39m loss = custom_loss(pred_state, measured_indices, measured_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mBMEDModel.forward\u001b[39m\u001b[34m(self, init_state, times)\u001b[39m\n\u001b[32m     29\u001b[39m norm_input = torch.tensor(norm_input)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 상태 예측\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m migration = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmigration_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_input\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1, 6) -> (1, 3)\u001b[39;00m\n\u001b[32m     33\u001b[39m cur_state = \u001b[38;5;28mself\u001b[39m.physical_layer.update_state(cur_state[\u001b[32m0\u001b[39m], migration[\u001b[32m0\u001b[39m]).unsqueeze(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# (1,8)\u001b[39;00m\n\u001b[32m     34\u001b[39m pred_states.append(cur_state)  \u001b[38;5;66;03m# (1, 8)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mMigrationPredictor.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\repos_python\\Project\\BMED\\BMED_Model\\bmed-NN\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# generate study with gaussian process sampler\n",
    "storage_name = f'sqlite:///hpOpt.db'\n",
    "sampler = GPSampler(n_startup_trials=10, seed=42)\n",
    "n_trials = 100\n",
    "study = optuna.create_study(\n",
    "    study_name = 'hpOpt',\n",
    "    storage = storage_name,\n",
    "    direction='maximize',\n",
    "    sampler=sampler,\n",
    "    load_if_exists = True)\n",
    "\n",
    "# optimize the hyperparameters\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# return the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "best_value = study.best_value\n",
    "\n",
    "# optimize the model with the best hyperparameters\n",
    "results = {\n",
    "    'best_params': best_params,\n",
    "    'best_value': best_value,\n",
    "    'study': study\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = {\n",
    "            'best_params': results['best_params'],\n",
    "            'best_r2_score': float(results['best_value']),\n",
    "        }\n",
    "\n",
    "with open('hpOpt.json', 'w') as f:\n",
    "    json.dump(save_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmed-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
