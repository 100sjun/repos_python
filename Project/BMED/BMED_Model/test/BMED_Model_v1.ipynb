{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDDataset(Dataset):\n",
    "    '''BMED 데이터로부터 PyTorch 데이터셋 생성'''\n",
    "    def __init__(self, data_path, sequence_length=10, train=True, train_ratio=0.8):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.train = train\n",
    "\n",
    "        # Spline 데이터 로드\n",
    "        self.df = pd.read_excel(data_path, sheet_name='spline_data')\n",
    "\n",
    "        # 실험 번호별로 데이터 분리\n",
    "        self.dic_spline = {}\n",
    "        for exp in self.df['exp'].unique():\n",
    "            self.dic_spline[exp] = self.df[self.df['exp'] == exp].sort_values('t')\n",
    "        \n",
    "        # 훈련/테스트 셋 분리 (실험 번호 기준)\n",
    "        all_exps = list(self.dic_spline.keys())\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(all_exps)\n",
    "        np.random.seed(None)\n",
    "        \n",
    "        split_idx = int(len(all_exps) * train_ratio)\n",
    "        \n",
    "        if train:\n",
    "            self.exps_to_use = all_exps[:split_idx]\n",
    "        else:\n",
    "            self.exps_to_use = all_exps[split_idx:]\n",
    "            \n",
    "        # Data preparation\n",
    "        self.prepare_data()\n",
    "\n",
    "        # Save the indices of each experiments for batch processing\n",
    "        self.exp_indices = []\n",
    "        cur_idx = 0\n",
    "        for exp_id in self.exps_to_use:\n",
    "            exp_data = self.dic_spline[exp_id]\n",
    "            n_samples = len(exp_data) - sequence_length\n",
    "            indices = list(range(cur_idx, cur_idx + n_samples))\n",
    "            self.exp_indices.append((exp_id, indices))\n",
    "            cur_idx += n_samples\n",
    "\n",
    "    def prepare_data(self):\n",
    "        features_list = []\n",
    "        mol_changes_targets_list= []\n",
    "        states_targets_list = []\n",
    "\n",
    "        for exp in self.exps_to_use:\n",
    "            exp_data = self.dic_spline[exp]\n",
    "\n",
    "            # Input data as LSTM sequence\n",
    "            for i in range(len(exp_data) - self.sequence_length):\n",
    "                seq_data = exp_data.iloc[i:i+self.sequence_length]\n",
    "\n",
    "                # Feature vector\n",
    "                features = []\n",
    "                for _, row in seq_data.iterrows():\n",
    "                    feature = [\n",
    "                        row['T'], row['V'], row['E'],\n",
    "                        row['CF_LA'], row['CF_K'], row['CA_LA'], row['CB_K'],\n",
    "                        row['VF'], row['VA'], row['VB']\n",
    "                    ]\n",
    "                    features.append(feature)\n",
    "                \n",
    "                # Target vectors\n",
    "                mol_change_targets = []\n",
    "                state_targets = []\n",
    "                for j in range(self.sequence_length-1):\n",
    "                    cur = seq_data.iloc[j]\n",
    "                    next = seq_data.iloc[j+1]\n",
    "                    \n",
    "                    # Time interval\n",
    "                    dt = next['t'] - cur['t']\n",
    "\n",
    "                    # Mole of LA and K+ (mol)\n",
    "                    cur_NA_LA = cur['CA_LA'] * cur['VA']\n",
    "                    cur_NB_K = cur['CB_K'] * cur['VB']\n",
    "                    next_NA_LA = next['CA_LA'] * next['VA']\n",
    "                    next_NB_K = next['CB_K'] * next['VB']\n",
    "\n",
    "                    # Mole change (mol/hr)\n",
    "                    dNLA = (next_NA_LA - cur_NA_LA) / dt\n",
    "                    dNK = (next_NB_K - cur_NB_K) / dt\n",
    "\n",
    "                    # Water change (L/hr)\n",
    "                    dVA = (next['VA'] - cur['VA']) / dt\n",
    "                    dVB = (next['VB'] - cur['VB']) / dt\n",
    "\n",
    "                    # Change vector\n",
    "                    mol_change = [dNLA, dNK, dVA, dVB]\n",
    "                    mol_change_targets.append(mol_change)\n",
    "\n",
    "                    # State vector\n",
    "                    state = [\n",
    "                        next['T'], next['V'], next['E'],\n",
    "                        next['CF_LA'], next['CF_K'], next['CA_LA'], next['CB_K'],\n",
    "                        next['VF'], next['VA'], next['VB']\n",
    "                    ]\n",
    "                    state_targets.append(state)\n",
    "\n",
    "                # End point of the sequence\n",
    "                cur = seq_data.iloc[-1]\n",
    "                if i + self.sequence_length < len(exp_data):\n",
    "                    next = exp_data.iloc[i + self.sequence_length]\n",
    "\n",
    "                    # Time interval \n",
    "                    dt = next['t'] - cur['t']\n",
    "\n",
    "                    # Mole of LA and K+ (mol)\n",
    "                    cur_NA_LA = cur['CA_LA'] * cur['VA']\n",
    "                    cur_NB_K = cur['CB_K'] * cur['VB']\n",
    "                    next_NA_LA = next['CA_LA'] * next['VA']\n",
    "                    next_NB_K = next['CB_K'] * next['VB']\n",
    "\n",
    "                    # Mole change (mol/hr)\n",
    "                    dNLA = (next_NA_LA - cur_NA_LA) / dt\n",
    "                    dNK = (next_NB_K - cur_NB_K) / dt\n",
    "\n",
    "                    # Water change (L/hr)\n",
    "                    dVA = (next['VA'] - cur['VA']) / dt\n",
    "                    dVB = (next['VB'] - cur['VB']) / dt\n",
    "\n",
    "                    # Change vector\n",
    "                    mol_change = [dNLA, dNK, dVA, dVB]\n",
    "                    mol_change_targets.append(mol_change)\n",
    "\n",
    "                    # State vector\n",
    "                    state = [\n",
    "                        next['T'], next['V'], next['E'],\n",
    "                        next['CF_LA'], next['CF_K'], next['CA_LA'], next['CB_K'],\n",
    "                        next['VF'], next['VA'], next['VB']\n",
    "                    ]\n",
    "                    state_targets.append(state)\n",
    "                else:\n",
    "                    mol_change_targets.append(mol_change_targets[-1])\n",
    "                    state_targets.append(state_targets[-1])\n",
    "\n",
    "                features_list.append(features)\n",
    "                mol_changes_targets_list.append(mol_change_targets)\n",
    "                states_targets_list.append(state_targets)\n",
    "        self.features = np.array(features_list, dtype=np.float32)\n",
    "        self.mol_changes_targets = np.array(mol_changes_targets_list, dtype=np.float32)\n",
    "        self.states_targets = np.array(states_targets_list, dtype=np.float32)\n",
    "\n",
    "        print(f\"Data loaded: {len(self.features)} sequences, feature shape: {self.features.shape}\")\n",
    "        print(f\"Mol change targets shape: {self.mol_changes_targets.shape}\")\n",
    "        print(f\"State targets shape: {self.states_targets.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "                        \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.features[idx]),\n",
    "            torch.FloatTensor(self.mol_changes_targets[idx]),\n",
    "            torch.FloatTensor(self.states_targets[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsLayer(nn.Module):\n",
    "    '''\n",
    "    물리적 법칙을 반영하는 레이어\n",
    "    몰 변화량 예측값을 받아 물질수지와 부피 변화를 계산\n",
    "    '''\n",
    "    def __init__(self, time_step=0.1):\n",
    "        super(PhysicsLayer, self).__init__()\n",
    "        self.time_step = time_step # unit: hour\n",
    "\n",
    "    def forward(self, mol_changes, features):\n",
    "        '''현재 시간 단계 상태 추출'''\n",
    "        T = features[..., 0:1] # 현재 상태 온도 [C]\n",
    "        V = features[..., 1:2] # 현재 상태 전압 [V]\n",
    "        E = features[..., 2:3] # 현재 상태 전해질 농도 [mol/L]\n",
    "        CFLA = features[..., 3:4] # 현재 상태 Feed LA 농도 [mol/L]\n",
    "        CFK = features[..., 4:5] # 현재 상태 Feed K+ 농도 [mol/L]\n",
    "        CALA = features[..., 5:6] # 현재 상태 Acid LA 농도 [mol/L]\n",
    "        CBK = features[..., 6:7] # 현재 상태 Base K+ 농도 [mol/L]\n",
    "        VF = features[..., 7:8] # 현재 상태 Feed 부피 [L]\n",
    "        VA = features[..., 8:9] # 현재 상태 Acid 부피 [L]\n",
    "        VB = features[..., 9:10] # 현재 상태 Base 부피 [L]\n",
    "        \n",
    "        '''현재 시간 단계 몰 계산'''\n",
    "        NFLA = CFLA * VF # 현재 상태 Feed LA 몰수 [mol]\n",
    "        NFK = CFK * VF # 현재 상태 Feed K+ 몰수 [mol]\n",
    "        NALA = CALA * VA # 현재 상태 Acid LA 몰수 [mol]\n",
    "        NBK = CBK * VB # 현재 상태 Base K+ 몰수 [mol]\n",
    "\n",
    "        '''변화량 상태 추출'''\n",
    "        JLA = mol_changes[..., 0:1] # 시간당 LA 몰 변화량 [mol/h]\n",
    "        JK = mol_changes[..., 1:2] # 시간당 K+ 몰 변화량 [mol/h]\n",
    "        JVA = mol_changes[..., 2:3] # 시간당 물 부피 변화량 (Acid) [L/h]\n",
    "        JVB = mol_changes[..., 3:4] # 시간당 물 부피 변화량 (Base) [L/h]\n",
    "\n",
    "        '''time step에서의 변화량 계산'''\n",
    "        dLA = JLA * self.time_step # LA 몰 변화량 [mol]\n",
    "        dK = JK * self.time_step # K+ 몰 변화량[mol]\n",
    "        dVA = JVA * self.time_step # 물 부피 변화량 (Acid) [L]\n",
    "        dVB = JVB * self.time_step # 물 부피 변화량 (Base) [L]\n",
    "\n",
    "        '''부피 업데이트'''\n",
    "        nVF = VF - dVA - dVB # 다음 상태 Feed 부피 [L]\n",
    "        nVA = VA + dVA # 다음 상태 Acid 부피 [L]\n",
    "        nVB = VB + dVB # 다음 상태 Base 부피 [L]\n",
    "\n",
    "        '''몰수 업데이트'''\n",
    "        nNFLA = NFLA - dLA # 다음 상태 Feed LA 몰수 [mol]\n",
    "        nNFK = NFK - dK # 다음 상태 Feed K+ 몰수 [mol]\n",
    "        nNALA = NALA + dLA # 다음 상태 Acid LA 몰수 [mol]\n",
    "        nNBK = NBK + dK # 다음 상태 Base K+ 몰수 [mol]\n",
    "        \n",
    "        '''농도 업데이트'''\n",
    "        eps = 1e-6 # 0으로 나누기 방지\n",
    "        nCFLA = nNFLA / (nVF + eps) # 다음 상태 Feed LA 농도 [mol/L]\n",
    "        nCFK = nNFK / (nVF + eps) # 다음 상태 Feed K+ 농도 [mol/L]\n",
    "        nCALA = nNALA / (nVA + eps) # 다음 상태 Acid LA 농도 [mol/L]\n",
    "        nCBK = nNBK / (nVB + eps) # 다음 상태 Base K+ 농도 [mol/L]\n",
    "\n",
    "        '''결과 출력'''\n",
    "        new_states = torch.cat([\n",
    "            T, V, E, nCFLA, nCFK, nCALA, nCBK, nVF, nVA, nVB\n",
    "        ], dim=-1)\n",
    "\n",
    "        return new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MembraneSystemModel(nn.Module):\n",
    "    '''멤브레인 시스템 모델링을 위한 Physics-Informed LSTM 모델'''\n",
    "    def __init__(self, lstm_units=64, lstm_layer=3, fc_units=64, fc_layer=5,time_step=0.1, sequence_length=10):\n",
    "        super(MembraneSystemModel, self).__init__()\n",
    "        self.lstm_units = lstm_units\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.fc_units = fc_units\n",
    "        self.fc_layer = fc_layer\n",
    "        self.time_step = time_step\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        '''LSMT layer'''\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=10, # [T, V, E, CF_LA, CF_K, CA_LA, CB_K, VF, VA, VB]\n",
    "            hidden_size=self.lstm_units,\n",
    "            num_layers = self.lstm_layer,\n",
    "            batch_first=True, #(batch, seq, feature) 형태 입력\n",
    "        )\n",
    "\n",
    "        '''FC layer'''\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.lstm_units, self.fc_units),\n",
    "            nn.ReLU(),\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(self.fc_units, self.fc_units),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(self.fc_layer - 2)],\n",
    "            nn.Linear(self.fc_units, 4)  # 4개의 flux 값 출력 (LA 몰 변화량, K+ 몰 변화량, Acid 방향 물 변화량, Base 방향 물 변화량)\n",
    "        )\n",
    "\n",
    "        '''Physics layer'''\n",
    "        self.physics_layer = PhysicsLayer(time_step=self.time_step)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''LSTM 처리'''\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        '''몰 변화량 예측 - 각 시간 단계별로 동일한 FC 적용'''\n",
    "        batch_size, seq_len, _ = lstm_out.size()\n",
    "        mol_changes_list = []\n",
    "\n",
    "        for i in range(seq_len): # 시간별 LSTM out으로 flux 예측\n",
    "            step_lstm_out = lstm_out[:, i, :]\n",
    "            step_mol_changes = self.fc(step_lstm_out)\n",
    "            mol_changes_list.append(step_mol_changes.unsqueeze(1))\n",
    "        \n",
    "        # 모든 시간 단계의 몰 변화량 예측 결과 결합\n",
    "        mol_changes = torch.cat(mol_changes_list, dim=1)\n",
    "\n",
    "        '''물리 법칙 적용: 질량 보존'''\n",
    "        new_states_list = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            new_state = self.physics_layer(mol_changes[:, i, :], x[:, i, :]) # x는 현재 상태의 state를 의미함\n",
    "            new_states_list.append(new_state.unsqueeze(1))\n",
    "        \n",
    "        # 모든 시간 단계 결과 결합\n",
    "        new_states = torch.cat(new_states_list, dim=1)\n",
    "\n",
    "        return mol_changes, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MembraneSystemTrainer:\n",
    "    \"\"\"\n",
    "    멤브레인 시스템 모델 훈련 및 시뮬레이션을 위한 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu',epochs=100):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "        # 손실 함수는 상태함수를 기준으로 실시\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        \"\"\"\n",
    "        모델 훈련\n",
    "        \n",
    "        입력:\n",
    "        - train_loader: 훈련 데이터 로더\n",
    "        - val_loader: 검증 데이터 로더 (옵션)\n",
    "        - epochs: 훈련 에폭 수\n",
    "        - mol_change_weight: 몰 변화량 손실 가중치\n",
    "        - state_weight: 상태 손실 가중치\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            for batch_idx, (features, mol_change_targets, state_targets) in enumerate(train_loader):\n",
    "                features = features.to(self.device)\n",
    "                mol_change_targets = mol_change_targets.to(self.device)\n",
    "                state_targets = state_targets.to(self.device)\n",
    "\n",
    "                # initialize gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                _, state_predictions = self.model(features)\n",
    "\n",
    "                # loss calculation\n",
    "                loss = self.criterion(state_predictions, state_targets)\n",
    "\n",
    "                # back propagation and optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # epoch average loss\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_loss)\n",
    "\n",
    "            if val_loader is not None:\n",
    "                self.model.eval()\n",
    "                val_loss = 0.0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for features, mol_change_targets, state_targets in val_loader:\n",
    "                        features = features.to(self.device)\n",
    "                        mol_change_targets = mol_change_targets.to(self.device)\n",
    "                        state_targets = state_targets.to(self.device)\n",
    "                        \n",
    "                        _, state_predictions = self.model(features)\n",
    "                        \n",
    "                        loss = self.criterion(state_predictions, state_targets)\n",
    "                        val_loss += loss.item()\n",
    "                \n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                val_losses.append(avg_val_loss)\n",
    "\n",
    "                print(f'Epoch {epoch+1}/{self.epochs}, Train Loss: {avg_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "                \n",
    "                self.model.train()\n",
    "            else:\n",
    "                print(f'Epoch {epoch+1}/{self.epochs}, Train Loss: {avg_loss:.6f}')\n",
    "\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def evaluate_model(self, test_loader):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, mol_change_targets, state_targets in test_loader:\n",
    "                features = features.to(self.device)\n",
    "                mol_change_targets = mol_change_targets.to(self.device)\n",
    "                state_targets = state_targets.to(self.device)\n",
    "\n",
    "                # 모델 예측\n",
    "                mol_change_predictions, state_predictions = self.model(features)\n",
    "\n",
    "                # 손실 계산\n",
    "                loss = self.criterion(state_predictions, state_targets)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predictions.append(state_predictions.cpu().numpy())\n",
    "                actuals.append(state_targets.cpu().numpy())\n",
    "                \n",
    "                # 예측값과 실제값 저장\n",
    "                predictions.append(state_predictions.cpu().numpy())\n",
    "                actuals.append(state_targets.cpu().numpy())\n",
    "         \n",
    "        # 전체 테스트 세트에 대한 평균 손실\n",
    "        avg_test_loss = test_loss / len(test_loader)                \n",
    "                \n",
    "        # 예측값과 실제값을 하나의 배열로 결합\n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "        # R2 점수 계산\n",
    "        r2_scores = {}\n",
    "        for i, var_name in enumerate(['CF_LA', 'CF_K', 'CA_LA', 'acid_k', 'base_la', 'CB_K', 'VF', 'VA', 'VB']):\n",
    "            r2 = r2_score(actuals[:, :, i], predictions[:, :, i])\n",
    "            r2_scores[var_name] = r2\n",
    "        \n",
    "        return {\n",
    "            'test_loss': avg_test_loss,\n",
    "            'predictions': predictions,\n",
    "            'actuals': actuals,\n",
    "            'r2_scores': r2_scores\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentBatchSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"\n",
    "    실험 단위로 배치를 구성하는 샘플러\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # 실험별로 인덱스를 섞어 배치 구성\n",
    "        all_indices = []\n",
    "        for exp_id, indices in self.dataset.exp_indices:\n",
    "            # 각 실험 내 인덱스는 순서대로 유지\n",
    "            all_indices.extend(indices)\n",
    "            \n",
    "        # 배치 크기에 맞게 인덱스 그룹화\n",
    "        batches = [all_indices[i:i + self.batch_size] \n",
    "                   for i in range(0, len(all_indices), self.batch_size)]\n",
    "        \n",
    "        # 배치 순서는 섞음\n",
    "        np.random.shuffle(batches)\n",
    "        \n",
    "        for batch in batches:\n",
    "            yield batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.dataset) + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loaders_from_csv(data_path, sequence_length=10, batch_size=2, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 훈련 및 검증 데이터 로더 생성\n",
    "    \"\"\"\n",
    "    train_dataset = BMEDDataset(data_path, sequence_length=sequence_length, train=True, train_ratio=train_ratio)\n",
    "    test_dataset = BMEDDataset(data_path, sequence_length=sequence_length, train=False, train_ratio=train_ratio)\n",
    "    \n",
    "    # 실험 단위 배치 샘플러 사용\n",
    "    train_batch_sampler = ExperimentBatchSampler(train_dataset, batch_size)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_sampler=train_batch_sampler\n",
    "    )\n",
    "    \n",
    "    # 테스트 데이터는 순서대로 (shuffle=False)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_from_csv(data_path, lstm_units=64, lstm_layer = 3, fc_units=64, fc_layer=5, time_step=0.1, sequence_length=10, \n",
    "                        batch_size=32, epochs=100, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 모델 훈련을 위한 편의 함수\n",
    "    \"\"\"\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, test_loader = data_loaders_from_csv(\n",
    "        data_path, sequence_length, batch_size, train_ratio\n",
    "    )\n",
    "    # 모델 생성\n",
    "    model = MembraneSystemModel(lstm_units=lstm_units, lstm_layer=lstm_layer, fc_units=fc_units, fc_layer=fc_layer, time_step=time_step, sequence_length=sequence_length)\n",
    "    trainer = MembraneSystemTrainer(model,epochs=epochs)\n",
    "    \n",
    "    # 모델 훈련\n",
    "    train_losses, val_losses = trainer.train(\n",
    "        train_loader, \n",
    "        test_loader\n",
    "    )\n",
    "    \n",
    "    return model, trainer, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 2402 sequences, feature shape: (2402, 3, 10)\n",
      "Mol change targets shape: (2402, 3, 4)\n",
      "State targets shape: (2402, 3, 10)\n",
      "Data loaded: 701 sequences, feature shape: (701, 3, 10)\n",
      "Mol change targets shape: (701, 3, 4)\n",
      "State targets shape: (701, 3, 10)\n",
      "Epoch 1/10, Train Loss: 0.000119, Val Loss: 0.000149\n",
      "Epoch 2/10, Train Loss: 0.000095, Val Loss: 0.000161\n",
      "Epoch 3/10, Train Loss: 0.000090, Val Loss: 0.000131\n",
      "Epoch 4/10, Train Loss: 0.000087, Val Loss: 0.000118\n",
      "Epoch 5/10, Train Loss: 0.000086, Val Loss: 0.000124\n",
      "Epoch 6/10, Train Loss: 0.000086, Val Loss: 0.000131\n",
      "Epoch 7/10, Train Loss: 0.000083, Val Loss: 0.000162\n",
      "Epoch 8/10, Train Loss: 0.000086, Val Loss: 0.000142\n",
      "Epoch 9/10, Train Loss: 0.000084, Val Loss: 0.000116\n",
      "Epoch 10/10, Train Loss: 0.000083, Val Loss: 0.000138\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # CSV 파일 경로\n",
    "    data_path = '../data/BMED_data_v6+spline.xlsx'\n",
    "    \n",
    "    # 모델 훈련\n",
    "    model, trainer, train_losses, val_losses = train_model_from_csv(\n",
    "        data_path=data_path,\n",
    "        lstm_units=64,\n",
    "        lstm_layer=3,\n",
    "        fc_units=64,\n",
    "        fc_layer=5,\n",
    "        sequence_length=3,  # 이전 3개 시점 데이터 사용\n",
    "        epochs = 10,\n",
    "        time_step=0.1,\n",
    "        batch_size=2,\n",
    "        train_ratio=0.8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00011859559774028621, 9.530309842103046e-05, 8.955542542232723e-05, 8.695013664874257e-05, 8.632441883914081e-05, 8.630296426948957e-05, 8.288242281260564e-05, 8.598667902002377e-05, 8.364564446635435e-05, 8.30280610192414e-05]\n",
      "[0.00014860953726326736, 0.0001608758378167225, 0.00013089146583903735, 0.00011810305078632574, 0.0001237199631522308, 0.0001310038229125881, 0.00016220245415778198, 0.0001422219706119953, 0.00011621248467883142, 0.00013818239342896035]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses)\n",
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MembraneSystemModel(\n",
       "  (lstm): LSTM(10, 64, num_layers=3, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (5): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       "  (physics_layer): PhysicsLayer()\n",
       ")"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl 파일 로드\n",
    "with open('hpOpt_study.pkl', 'rb') as f:\n",
    "    study = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 trial 수: 173\n",
      "완료된 trial 수: 103\n",
      "실패한 trial 수: 0\n",
      "진행 중인 trial 수: 70\n"
     ]
    }
   ],
   "source": [
    "# 현재 trials 수 출력\n",
    "print(f\"현재 trial 수: {len(study.trials)}\")\n",
    "print(f\"완료된 trial 수: {len(study.get_trials(states=[TrialState.COMPLETE]))}\")\n",
    "print(f\"실패한 trial 수: {len(study.get_trials(states=[TrialState.FAIL]))}\")\n",
    "print(f\"진행 중인 trial 수: {len(study.get_trials(states=[TrialState.RUNNING]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmed-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
