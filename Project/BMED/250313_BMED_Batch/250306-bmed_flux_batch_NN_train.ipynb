{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "class RawDataLoader():\n",
    "    def __init__(self, path='BMED_train_data_v2.xlsx'):\n",
    "        self.path = path\n",
    "        self.X_data, self.Y_data = self.RawData()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def RawData(self):\n",
    "        df = pd.read_excel(self.path, sheet_name='Sheet2')\n",
    "        X_data = df[['T','V','E','CF_LA','CF_K','CA_LA','CB_K']].values\n",
    "        Y_data = df[['dNLA','dNK','dVF','dVA','dVB']].values\n",
    "        return X_data, Y_data\n",
    "    \n",
    "    def PrepareData(self, test_size=0.2, random_state=42):\n",
    "        # Split the data into training and test sets\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            self.X_data, self.Y_data, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "            )\n",
    "        \n",
    "        # Normalize the data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_Y = StandardScaler()\n",
    "\n",
    "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "        Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "        Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "        # Convert to PyTorch tensors and move to appropriate device\n",
    "        X_train_tensor = torch.FloatTensor(X_train_scaled).to(self.device)\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(self.device)\n",
    "        Y_train_tensor = torch.FloatTensor(Y_train_scaled).to(self.device)\n",
    "        Y_test_tensor = torch.FloatTensor(Y_test_scaled).to(self.device)\n",
    "\n",
    "        return X_train_tensor, X_test_tensor, Y_train_tensor, Y_test_tensor, scaler_X, scaler_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the NN architecture\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, hidden_layers=10, hidden_nodes = 85):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        nodes = 7\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(nodes, hidden_nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "            nodes = hidden_nodes\n",
    "        layers.append(nn.Linear(hidden_nodes, 5))\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hidden(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters\n",
    "class NNmodel():\n",
    "    def __init__(self, hidden_layers=10, hidden_nodes = 85, learning_rate=0.000266709606875957, num_epochs=9271, batch_size=16, weight_decay=5.2171808135365869e-05, title='bmed_flux_batch_NN_model.pth'):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        self.model = CustomModel(hidden_layers=self.hidden_layers, hidden_nodes=self.hidden_nodes).to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        self.train_losses = []\n",
    "        self.title = title\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def train(self, X_train, Y_train, X_test, Y_test):\n",
    "        X_train_gpu = X_train\n",
    "        Y_train_gpu = Y_train\n",
    "        X_test_gpu = X_test\n",
    "        Y_test_gpu = Y_test\n",
    "\n",
    "        dataset = TensorDataset(X_train_gpu, Y_train_gpu)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            batch_count = 0\n",
    "\n",
    "            for X_batch, Y_batch in dataloader:\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                Y_batch = Y_batch.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                train_outputs = self.model(X_batch)\n",
    "                train_loss = self.criterion(train_outputs, Y_batch)\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += train_loss.item()\n",
    "                batch_count += 1\n",
    "            # Calculate the average loss for the epoch\n",
    "            avg_loss = epoch_loss / batch_count\n",
    "            self.train_losses.append(avg_loss)\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'\\rEpoch [{epoch}/{self.num_epochs}] Train Loss: {avg_loss:.4f}', end='',flush=True)\n",
    "        \n",
    "        # Model evaluation with test set\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = self.model(X_test_gpu)\n",
    "            test_loss = self.criterion(test_outputs, Y_test_gpu)\n",
    "        \n",
    "        # Visualize the learning curves\n",
    "        self.plot_learning_curves()\n",
    "\n",
    "        # Save the model\n",
    "        self.save_model(self.title)\n",
    "\n",
    "        return test_loss.item()\n",
    "    \n",
    "    def save_model(self, title):\n",
    "        model_state = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'hyperparameters': {\n",
    "                'train_losses': self.train_losses,\n",
    "                'hidden_layers': self.hidden_layers,\n",
    "                'hidden_nodes': self.hidden_nodes,\n",
    "                'learning_rate': self.learning_rate,\n",
    "                'num_epochs': self.num_epochs,\n",
    "                'batch_size': self.batch_size,\n",
    "                'weight_decay': self.weight_decay\n",
    "            },\n",
    "            'train_losses': self.train_losses\n",
    "        }\n",
    "        torch.save(model_state, title)\n",
    "        print(f\"Model saved to {title}\")            \n",
    "        \n",
    "    def load_model(self, filepath):\n",
    "        model_state = torch.load(filepath)\n",
    "\n",
    "        # load hyperparameters\n",
    "        hyperparameters = model_state['hyperparameters']\n",
    "        self.hidden_layers = hyperparameters['hidden_layers']\n",
    "        self.hidden_nodes = hyperparameters['hidden_nodes']\n",
    "        self.learning_rate = hyperparameters['learning_rate']\n",
    "        self.num_epochs = hyperparameters['num_epochs']\n",
    "        self.batch_size = hyperparameters['batch_size']\n",
    "        self.weight_decay = hyperparameters['weight_decay']\n",
    "\n",
    "        # load connection weights of the model\n",
    "        self.model.load_state_dict(model_state['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(model_state['optimizer_state_dict'])\n",
    "        self.train_losses = model_state['train_losses']\n",
    "\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        \n",
    "    \n",
    "    def plot_learning_curves(self):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Curves')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NNmodel' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train model \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mNNmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbmed_flux_batch_NN_model_v0.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mNNmodel.__init__\u001b[39m\u001b[34m(self, hidden_layers, hidden_nodes, learning_rate, num_epochs, batch_size, weight_decay, title)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_size = batch_size\n\u001b[32m      9\u001b[39m \u001b[38;5;28mself\u001b[39m.weight_decay = weight_decay\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28mself\u001b[39m.model = CustomModel(hidden_layers=\u001b[38;5;28mself\u001b[39m.hidden_layers, hidden_nodes=\u001b[38;5;28mself\u001b[39m.hidden_nodes).to(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.criterion = nn.MSELoss()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optim.Adam(\u001b[38;5;28mself\u001b[39m.model.parameters(), lr=\u001b[38;5;28mself\u001b[39m.learning_rate, weight_decay=\u001b[38;5;28mself\u001b[39m.weight_decay)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NNmodel' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "# train model \n",
    "model = NNmodel(title='bmed_flux_batch_NN_model_v0.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
