{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Treatment\n",
    "data_path = \"C:/Users/USER/Documents/workspace/BMED/DB_bench_BMED_for_LA.xlsx\"\n",
    "#data_path = \"C:/Users/bsjun/Documents/workspace/BMED/DB_bench_BMED_for_LA.xlsx\"\n",
    "raw_Data= pd.read_excel(data_path,sheet_name=\"data_for_ML\")\n",
    "\n",
    "MVs = raw_Data[['T_operation','V_operation','E_operation','C_F_LA','C_A_LA']]\n",
    "CVs = raw_Data[['SEC','J_LA']]\n",
    "\n",
    "X = MVs.values\n",
    "Y = CVs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter('ignore')\n",
    "        return model.predict(X, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrgate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best1, best2 = min([i[0] for i in yhat]), max([i[1] for i in yhat])\n",
    "\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "\n",
    "    # Calculate the expected improvement (EI)\n",
    "    # Clip std to avoid division by zero\n",
    "    std = np.clip(std, 1e-9, None)  # Replace None with a suitable upper bound if needed\n",
    "    std2 = [i[0] for i in std]\n",
    "    z = score2 - best / std2\n",
    "    ei = (score2 - best) * stats.norm.cdf(z) + std2 * stats.norm.pdf(z)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "    # grid search, generate samples\n",
    "    Tsample = np.linspace(25,35,31)\n",
    "    Vsample = np.linspace(10,35,31)\n",
    "    Esample = np.linspace(0.25,1,31)\n",
    "    Fsample = np.linspace(-0.1,5.2,31)\n",
    "    Asample = np.linspace(-0.1,2.2,31)\n",
    "    Xsamples = np.asarray(list(itertools.product(Tsample,Vsample,Esample,Fsample,Asample)))\n",
    "    \n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    return Xsamples[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot real observation vs surrogate function\n",
    "def plot(X, y, model):\n",
    "    # Split inputs\n",
    "    Xe1 = [X[i][0] for i in range(len(X))]\n",
    "    Xe2 = [X[i][1] for i in range(len(X))]\n",
    "    Xe3 = [X[i][2] for i in range(len(X))]\n",
    "    ye1 = [y[i][0] for i in range(len(y))]\n",
    "    ye2 = [y[i][1] for i in range(len(y))]\n",
    "\n",
    "    # scatter plot of imputs\n",
    "    fig, axes = plt.subplots(2,3)\n",
    "    axes[0,0].scatter(Xe1, ye1)\n",
    "    axes[0,1].scatter(Xe2, ye1)\n",
    "    axes[0,2].scatter(Xe3, ye1)\n",
    "    axes[1,0].scatter(Xe1, ye2)\n",
    "    axes[1,1].scatter(Xe2, ye2)\n",
    "    axes[1,2].scatter(Xe3, ye2)\n",
    "\n",
    "    # line plot of surragte function acorss domain\n",
    "    Xp1 = np.append(Xe1,10 + 10*np.random.random(20))\n",
    "    Xp2 = np.append(Xe2,2*np.random.random(20))\n",
    "    Xp3 = np.append(Xe3,-10 + 20*np.random.random(20))\n",
    "    Xpred = np.asarray(list(itertools.product(Xp1,Xp2,Xp3)))\n",
    "\n",
    "    ypred, _ = surrogate(model, Xpred)\n",
    "    yp1 = [i[0] for i in ypred]\n",
    "    yp2 = [i[1] for i in ypred]\n",
    "\n",
    "    Xpl1 = [i[0] for i in Xpred]\n",
    "    Xpl2 = [i[1] for i in Xpred]\n",
    "    Xpl3 = [i[2] for i in Xpred]\n",
    "\n",
    "    axes[0,0].scatter(Xpl1, yp1, s=1)\n",
    "    axes[0,1].scatter(Xpl2, yp1, s=1)\n",
    "    axes[0,2].scatter(Xpl3, yp1, s=1)\n",
    "    axes[1,0].scatter(Xpl1, yp2, s=1)\n",
    "    axes[1,1].scatter(Xpl2, yp2, s=1)\n",
    "    axes[1,2].scatter(Xpl3, yp2, s=1)\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8778715562075377\n",
      "3.330318313931372\n"
     ]
    }
   ],
   "source": [
    "# Train Set Normalization\n",
    "# split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "\n",
    "T = [i[0] for i in X_train]\n",
    "V = [i[1] for i in X_train]\n",
    "E = [i[2] for i in X_train]\n",
    "F = [i[3] for i in X_train]\n",
    "A = [i[4] for i in X_train]\n",
    "\n",
    "SEC = [i[0] for i in Y_train]\n",
    "JLA = [i[1] for i in Y_train]\n",
    "\n",
    "rX_train = list(range(len(X_train)))\n",
    "rY_train = list(range(len(X_train)))\n",
    "\n",
    "# Z-score normalization\n",
    "for i in range(len(X_train)):\n",
    "    iX = [(T[i]-np.average(T))/np.std(T),(V[i]-np.average(V))/np.std(V),(E[i]-np.average(E))/np.std(E),(F[i]-np.average(F))/np.std(F),(A[i]-np.average(A))/np.std(A)]\n",
    "    iY = [(SEC[i]-np.average(SEC))/np.std(SEC),(JLA[i]-np.average(JLA))/np.std(JLA)]\n",
    "    rX_train[i] = iX\n",
    "    rY_train[i] = iY\n",
    "rX_train = np.asarray(rX_train)\n",
    "rY_train = np.asarray(rY_train)\n",
    "\n",
    "model = GaussianProcessRegressor()\n",
    "model.fit(rX_train,rY_train)\n",
    "\n",
    "yhat, _ = surrogate(model, rX_train)\n",
    "best1, best2 = min([i[0] for i in yhat]), max([i[1] for i in yhat])\n",
    "print(best1)\n",
    "print(best2)\n",
    "Tsample = np.linspace(25,35,3)\n",
    "Vsample = np.linspace(10,35,3)\n",
    "Esample = np.linspace(0.25,1,3)\n",
    "Fsample = np.linspace(-0.1,5.2,3)\n",
    "Asample = np.linspace(-0.1,2.2,3)\n",
    "Xsamples = np.asarray(list(itertools.product(Tsample,Vsample,Esample,Fsample,Asample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, std = surrogate(model, Xsamples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06732994, 0.06732994],\n",
       "       [0.15208167, 0.15208167],\n",
       "       [0.83110497, 0.83110497],\n",
       "       [0.05398342, 0.05398342],\n",
       "       [0.28429014, 0.28429014],\n",
       "       [0.86711934, 0.86711934],\n",
       "       [0.11384449, 0.11384449],\n",
       "       [0.80553667, 0.80553667],\n",
       "       [0.9940368 , 0.9940368 ],\n",
       "       [0.36759157, 0.36759157],\n",
       "       [0.38894681, 0.38894681],\n",
       "       [0.8551645 , 0.8551645 ],\n",
       "       [0.36567315, 0.36567315],\n",
       "       [0.44877984, 0.44877984],\n",
       "       [0.88568813, 0.88568813],\n",
       "       [0.37741924, 0.37741924],\n",
       "       [0.83363647, 0.83363647],\n",
       "       [0.99482112, 0.99482112],\n",
       "       [0.65787551, 0.65787551],\n",
       "       [0.66587956, 0.66587956],\n",
       "       [0.90762679, 0.90762679],\n",
       "       [0.65717398, 0.65717398],\n",
       "       [0.69012139, 0.69012139],\n",
       "       [0.92662537, 0.92662537],\n",
       "       [0.66151484, 0.66151484],\n",
       "       [0.89439542, 0.89439542],\n",
       "       [0.99660665, 0.99660665],\n",
       "       [0.99905054, 0.99905054],\n",
       "       [0.99903773, 0.99903773],\n",
       "       [0.99953932, 0.99953932],\n",
       "       [0.99903494, 0.99903494],\n",
       "       [0.99905773, 0.99905773],\n",
       "       [0.99957607, 0.99957607],\n",
       "       [0.99993579, 0.99993579],\n",
       "       [0.99998501, 0.99998501],\n",
       "       [0.99999942, 0.99999942],\n",
       "       [0.99917515, 0.99917515],\n",
       "       [0.99916402, 0.99916402],\n",
       "       [0.99959977, 0.99959977],\n",
       "       [0.99916159, 0.99916159],\n",
       "       [0.99918139, 0.99918139],\n",
       "       [0.99963169, 0.99963169],\n",
       "       [0.99994422, 0.99994422],\n",
       "       [0.99998698, 0.99998698],\n",
       "       [0.9999995 , 0.9999995 ],\n",
       "       [0.99945913, 0.99945913],\n",
       "       [0.99945183, 0.99945183],\n",
       "       [0.99973754, 0.99973754],\n",
       "       [0.99945024, 0.99945024],\n",
       "       [0.99946322, 0.99946322],\n",
       "       [0.99975847, 0.99975847],\n",
       "       [0.99996342, 0.99996342],\n",
       "       [0.99999146, 0.99999146],\n",
       "       [0.99999967, 0.99999967],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [0.99725979, 0.99725979],\n",
       "       [0.94080774, 0.94080774],\n",
       "       [0.88641272, 0.88641272],\n",
       "       [0.45831222, 0.45831222],\n",
       "       [0.30493978, 0.30493978],\n",
       "       [0.80727988, 0.80727988],\n",
       "       [0.99818711, 0.99818711],\n",
       "       [0.99937836, 0.99937836],\n",
       "       [0.99994447, 0.99994447],\n",
       "       [0.99750742, 0.99750742],\n",
       "       [0.94747313, 0.94747313],\n",
       "       [0.90072008, 0.90072008],\n",
       "       [0.36605993, 0.36605993],\n",
       "       [0.25391217, 0.25391217],\n",
       "       [0.80969429, 0.80969429],\n",
       "       [0.99685818, 0.99685818],\n",
       "       [0.99901754, 0.99901754],\n",
       "       [0.99993703, 0.99993703],\n",
       "       [0.99806307, 0.99806307],\n",
       "       [0.96472566, 0.96472566],\n",
       "       [0.93558069, 0.93558069],\n",
       "       [0.3461297 , 0.3461297 ],\n",
       "       [0.28387352, 0.28387352],\n",
       "       [0.82845467, 0.82845467],\n",
       "       [0.99592219, 0.99592219],\n",
       "       [0.99877124, 0.99877124],\n",
       "       [0.99994363, 0.99994363]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "    model = GaussianProcessRegressor()\n",
    "    model.fit(X_train_fold,Y_train_fold)\n",
    "\n",
    "\n",
    "\n",
    "# # define the model\n",
    "# model = GaussianProcessRegressor()\n",
    "# model.fit(X,y)\n",
    "\n",
    "# x = opt_acquisition(X, y, model)\n",
    "# actual = [67.06,49.637]\n",
    "# est, _ = surrogate(model, [X[2]])\n",
    "# print(f'>x = {x}, f()={est}, actual={actual}')\n",
    "# print(np.exp(x[0]),np.exp(x[0])*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:10: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# best result\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m score3\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[43my\u001b[49m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)):\n\u001b[0;32m      4\u001b[0m         score3[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(y[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# best result\n",
    "score3=np.zeros(len(y))\n",
    "for i in range(len(y)):\n",
    "        score3[i] = eval(y[i])\n",
    "ix = np.argmin(score3)\n",
    "print(X[ix], y[ix])\n",
    "\n",
    "plt.scatter(score3)\n",
    "\n",
    ",[16.0505649,1.19114408,-0.68813221]\n",
    ",[67.19,49.637]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
