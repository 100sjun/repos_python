{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Treatment\n",
    "# data_path = \"C:/Users/USER/Documents/workspace/BMED/DB_bench_BMED_for_LA.xlsx\"\n",
    "data_path = \"C:/Users/bsjun/Documents/workspace/BMED/DB_bench_BMED_for_LA.xlsx\"\n",
    "raw_Data= pd.read_excel(data_path,sheet_name=\"data_for_ML\")\n",
    "\n",
    "MVs = raw_Data[['T_operation','V_operation','E_operation','C_F_LA','C_A_LA']]\n",
    "CVs = raw_Data[['SEC','J_LA']]\n",
    "\n",
    "X = MVs.values\n",
    "Y = CVs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter('ignore')\n",
    "        return model.predict(X, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrgate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best1, best2 = min([i[0] for i in yhat]), max([i[1] for i in yhat])\n",
    "\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "\n",
    "    # Calculate the expected improvement (EI)\n",
    "    # Clip std to avoid division by zero\n",
    "    std = np.clip(std, 1e-9, None)  # Replace None with a suitable upper bound if needed\n",
    "    std2 = [i[0] for i in std]\n",
    "    z = score2 - best / std2\n",
    "    ei = (score2 - best) * stats.norm.cdf(z) + std2 * stats.norm.pdf(z)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "    # grid search, generate samples\n",
    "    Tsample = np.linspace(25,35,31)\n",
    "    Vsample = np.linspace(10,35,31)\n",
    "    Esample = np.linspace(0.25,1,31)\n",
    "    Fsample = np.linspace(-0.1,5.2,31)\n",
    "    Asample = np.linspace(-0.1,2.2,31)\n",
    "    Xsamples = np.asarray(list(itertools.product(Tsample,Vsample,Esample,Fsample,Asample)))\n",
    "    \n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    return Xsamples[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot real observation vs surrogate function\n",
    "def plot(X, y, model):\n",
    "    # Split inputs\n",
    "    Xe1 = [X[i][0] for i in range(len(X))]\n",
    "    Xe2 = [X[i][1] for i in range(len(X))]\n",
    "    Xe3 = [X[i][2] for i in range(len(X))]\n",
    "    ye1 = [y[i][0] for i in range(len(y))]\n",
    "    ye2 = [y[i][1] for i in range(len(y))]\n",
    "\n",
    "    # scatter plot of imputs\n",
    "    fig, axes = plt.subplots(2,3)\n",
    "    axes[0,0].scatter(Xe1, ye1)\n",
    "    axes[0,1].scatter(Xe2, ye1)\n",
    "    axes[0,2].scatter(Xe3, ye1)\n",
    "    axes[1,0].scatter(Xe1, ye2)\n",
    "    axes[1,1].scatter(Xe2, ye2)\n",
    "    axes[1,2].scatter(Xe3, ye2)\n",
    "\n",
    "    # line plot of surragte function acorss domain\n",
    "    Xp1 = np.append(Xe1,10 + 10*np.random.random(20))\n",
    "    Xp2 = np.append(Xe2,2*np.random.random(20))\n",
    "    Xp3 = np.append(Xe3,-10 + 20*np.random.random(20))\n",
    "    Xpred = np.asarray(list(itertools.product(Xp1,Xp2,Xp3)))\n",
    "\n",
    "    ypred, _ = surrogate(model, Xpred)\n",
    "    yp1 = [i[0] for i in ypred]\n",
    "    yp2 = [i[1] for i in ypred]\n",
    "\n",
    "    Xpl1 = [i[0] for i in Xpred]\n",
    "    Xpl2 = [i[1] for i in Xpred]\n",
    "    Xpl3 = [i[2] for i in Xpred]\n",
    "\n",
    "    axes[0,0].scatter(Xpl1, yp1, s=1)\n",
    "    axes[0,1].scatter(Xpl2, yp1, s=1)\n",
    "    axes[0,2].scatter(Xpl3, yp1, s=1)\n",
    "    axes[1,0].scatter(Xpl1, yp2, s=1)\n",
    "    axes[1,1].scatter(Xpl2, yp2, s=1)\n",
    "    axes[1,2].scatter(Xpl3, yp2, s=1)\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7768268501263265, 0.16068809742046142, -3.235962301116615, 0.28887491698287704, 0.7233762573323474, -8.944991716267623, 1.195716589672827, -0.7661732567313493, -0.5624614579235185, 5.474865152190432, 0.23293795783411042, -4.690803480859358, 0.4187536828630982, 1.0486246888240203, -12.96651653271374, 1.7333060848109767, -1.110617045995923, -0.8152697024615918, 1.7708355195584318, 0.0753535945900694, -1.5171804236711068, 0.13544910230245932, 0.3392182792078984, -4.193830264958706, 0.5606388463640712, -0.35918491925338003, -0.26356382469013795, -1.6802684653250708, 0.40944392657456774, 1.0138025573442064, 0.42964945774178886, -4.012005408573032, 4.642035495677646, 1.6436096554561743, -4.629428825927562, -16.460055010484623, -2.435700916924816, 0.5935932293918995, 1.4699293196529197, 0.6228459913681945, -5.8155025799756, 6.730117623719934, 2.3825994873277807, -6.710516199189101, -23.859542784894643, -0.7878126946507109, 0.1921195842007819, 0.4760573792219702, 0.20150658957783207, -1.880502083674969, 2.1788190244047883, 0.7706988606232841, -2.1699995278874553, -7.715721557598428, -1.075189103806622, 1.4892398020140831, 2.7196902665911438, -1.5429731405382228, 0.9726322606854296, 8.776281759966125, 1.2741303937617054, -1.725909213969576, -5.758660517878798, -1.5585719580608384, 2.158968956094782, 3.943322142778783, -2.2366071590556658, 1.4106586558817185, 12.724857654102394, 1.8470602292067433, -2.501131537327403, -8.34544318830525, -0.5040900617946136, 0.6986434346420083, 1.2770961895113047, -0.7232972401965085, 0.4576423236107132, 4.121115833408716, 0.5975661767358158, -0.8076374670881865, -2.695031616141838, 4.4885387480612735, 0.19107637323395466, -3.8452542187715153, 0.34302981268410804, 0.8600107875518006, -10.629157663153592, 1.4205139869084746, -0.9105157178380523, -0.6671851798341777, 6.5065715192558855, 0.27713938516535563, -5.573279676373204, 0.49732224203808073, 1.247319821882229, -15.405465083972558, 2.059246924881336, -1.3192255084790077, -0.965129880375116, 2.104562126769679, 0.0899319966783878, -1.8012157526288775, 0.16097238780230327, 0.40465585276297134, -4.9781817286261685, 0.6661819243068123, -0.425504936412608, -0.30836867503217036, -1.9972767137637675, 0.4878822496516477, 1.211141080960033, 0.5072173225848928, -4.764296381722943, 5.534998270581241, 1.9469313174399758, -5.501331540017418, -19.546696291305267, -2.8950754128245535, 0.7091047797212013, 1.764977822768742, 0.7360787810000602, -6.898457990112092, 8.053423177409286, 2.823203167781685, -7.966873227846349, -28.31057695474891, -0.9361188748123368, 0.232857342606394, 0.5882760077698777, 0.23945570087732904, -2.216752807737521, 2.6610585562264646, 0.9146277971507857, -2.5625287721944687, -9.111428919520378, -1.278776926113494, 1.7733078319678839, 3.249037678188614, -1.842841202697997, 1.166012299728095, 10.478789262220857, 1.497073724638728, -2.049786510436846, -6.803072403699659, -1.8532670388950123, 2.5755890247922935, 4.734707390639699, -2.6691780215026597, 1.7112100467209075, 15.270048598035473, 2.172673471297756, -2.95042843079748, -9.796966061109789, -0.5986658528253628, 0.8424301382824524, 1.5779778775997286, -0.8596686618172669, 0.5923895096957494, 5.089413514169792, 0.7066749967350816, -0.9159412269788874, -3.0468808201808475, 1.1900744732428166, 0.05134636701245654, -1.0163520252245917, 0.08916468033089586, 0.23005280043594212, -2.8090091374210147, 0.3732938512062134, -0.24117858270932402, -0.16884933333096797, 1.7252116074268997, 0.07542328148429078, -1.4683662371434139, 0.1296865046703033, 0.33763153111613065, -4.056080838421849, 0.5416239974100279, -0.34546977953340274, -0.2319560353533916, 0.5581687221251741, 0.026247693402410732, -0.46573044303158895, 0.04267338883920502, 0.11690361594514798, -1.2821834178803044, 0.1759644458183942, -0.1041495962648753, -0.050900165028004096, -0.5319340720052423, 0.13749288923600034, 0.36108081750597876, 0.11292491021532669, -1.2394579006964932, 1.5831157944074903, 0.47555798232619395, -1.4555874558534754, -5.0865592054590465, -0.7700443452356467, 0.2112023927231803, 0.5825500005129243, 0.16889843730723442, -1.7469683979155661, 2.4848213487219937, 0.6953558646185911, -2.060355190768604, -7.2198822032589405, -0.24724293029152022, 0.09052170163278106, 0.29885573701633916, 0.06334147770721188, -0.4727579378548512, 1.160408894493571, 0.23423059164679216, -0.5753860820730381, -2.045977332925826, -0.3452536782239264, 0.4919600763491019, 0.9683586177580992, -0.5464151122115339, 0.3732347821591091, 3.0873707386490175, 0.28802819423278336, -0.5348649115124715, -1.5450100547884853, -0.49768447565897134, 0.7449630180538804, 1.5619253236497386, -0.7781590038430011, 0.6741217704453959, 4.983628123639313, 0.4335498283481014, -0.6424859471446052, -1.8287868210691691, -0.1560885165513639, 0.3003753676316592, 0.8006558122517973, -0.22838648927482552, 0.4649768848003646, 2.566277302492834, 0.16516366643668334, 0.03574142589826579, 0.18243935327973304]\n"
     ]
    }
   ],
   "source": [
    "# Train Set Normalization\n",
    "# split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "\n",
    "T = [i[0] for i in X_train]\n",
    "V = [i[1] for i in X_train]\n",
    "E = [i[2] for i in X_train]\n",
    "F = [i[3] for i in X_train]\n",
    "A = [i[4] for i in X_train]\n",
    "\n",
    "SEC = [i[0] for i in Y_train]\n",
    "JLA = [i[1] for i in Y_train]\n",
    "\n",
    "rX_train = list(range(len(X_train)))\n",
    "rY_train = list(range(len(X_train)))\n",
    "\n",
    "# Z-score normalization\n",
    "for i in range(len(X_train)):\n",
    "    iX = [(T[i]-np.average(T))/np.std(T),(V[i]-np.average(V))/np.std(V),(E[i]-np.average(E))/np.std(E),(F[i]-np.average(F))/np.std(F),(A[i]-np.average(A))/np.std(A)]\n",
    "    iY = [(SEC[i]-np.average(SEC))/np.std(SEC),(JLA[i]-np.average(JLA))/np.std(JLA)]\n",
    "    rX_train[i] = iX\n",
    "    rY_train[i] = iY\n",
    "rX_train = np.asarray(rX_train)\n",
    "rY_train = np.asarray(rY_train)\n",
    "\n",
    "model = GaussianProcessRegressor()\n",
    "model.fit(rX_train,rY_train)\n",
    "\n",
    "yhat, _ = surrogate(model, rX_train)\n",
    "best1, best2 = min([i[0] for i in yhat]), max([i[1] for i in yhat])\n",
    "\n",
    "Ts = np.linspace(25,35,3)\n",
    "Vs = np.linspace(10,35,3)\n",
    "Es = np.linspace(0.25,1,3)\n",
    "Fs = np.linspace(-0.1,5.2,3)\n",
    "As = np.linspace(-0.1,2.2,3)\n",
    "Xs = np.asarray(list(itertools.product(Ts,Vs,Es,Fs,As)))\n",
    "\n",
    "rTs = [i[0] for i in Xs]\n",
    "rVs = [i[1] for i in Xs]\n",
    "rEs = [i[2] for i in Xs]\n",
    "rFs = [i[3] for i in Xs]\n",
    "rAs = [i[4] for i in Xs]\n",
    "rX_sample = list(range(len(Xs)))\n",
    "for i in range(len(rX_sample)):\n",
    "    iXs = [(rTs[i]-np.average(rTs))/np.std(rTs),(rVs[i]-np.average(rVs))/np.std(rVs),(rEs[i]-np.average(rEs))/np.std(rEs),(rFs[i]-np.average(rFs))/np.std(rFs),(rAs[i]-np.average(rAs))/np.std(rAs)]\n",
    "    rX_sample[i] = iXs\n",
    "\n",
    "mu, std = surrogate(model, rX_sample)\n",
    "\n",
    "mu1 = [i[0] for i in mu]\n",
    "mu2 = [i[1] for i in mu]\n",
    "std1 = [i[0] for i in std]\n",
    "std1 = [i[1] for i in std]\n",
    "\n",
    "\n",
    "# std = np.clip(std, 1e-9, None)  # Replace None with a suitable upper bound if needed\n",
    "# std2 = [i[0] for i in std]\n",
    "# z = score2 - best / std2\n",
    "# ei = (score2 - best) * stats.norm.cdf(z) + std2 * stats.norm.pdf(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, std = surrogate(model, Xsamples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "    model = GaussianProcessRegressor()\n",
    "    model.fit(X_train_fold,Y_train_fold)\n",
    "\n",
    "\n",
    "\n",
    "# # define the model\n",
    "# model = GaussianProcessRegressor()\n",
    "# model.fit(X,y)\n",
    "\n",
    "# x = opt_acquisition(X, y, model)\n",
    "# actual = [67.06,49.637]\n",
    "# est, _ = surrogate(model, [X[2]])\n",
    "# print(f'>x = {x}, f()={est}, actual={actual}')\n",
    "# print(np.exp(x[0]),np.exp(x[0])*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:10: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: 'list' object is not callable; perhaps you missed a comma?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# best result\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m score3\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[43my\u001b[49m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)):\n\u001b[0;32m      4\u001b[0m         score3[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(y[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# best result\n",
    "score3=np.zeros(len(y))\n",
    "for i in range(len(y)):\n",
    "        score3[i] = eval(y[i])\n",
    "ix = np.argmin(score3)\n",
    "print(X[ix], y[ix])\n",
    "\n",
    "plt.scatter(score3)\n",
    "\n",
    ",[16.0505649,1.19114408,-0.68813221]\n",
    ",[67.19,49.637]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
