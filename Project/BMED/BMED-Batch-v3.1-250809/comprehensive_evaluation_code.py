# ê¸°ì¡´ notebookì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ” comprehensive evaluation ì½”ë“œ
# ê¸°ì¡´ ë³€ìˆ˜ë“¤ (best_model, dataloader, ndf, range_mm ë“±)ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì‹¤í—˜ ë°ì´í„° ì‹œê°í™”

# ëª¨ë“  ì‹¤í—˜ ë°ì´í„°ì— ëŒ€í•œ comprehensive evaluation
print("ğŸš€ ì „ì²´ ì‹¤í—˜ ë°ì´í„° comprehensive evaluation ì‹œì‘...")

# Device í™•ì¸
device = next(best_model.parameters()).device if best_model is not None else next(model.parameters()).device
evaluation_model = best_model if best_model is not None else model

# feature ì •ë³´ ì¬ì •ì˜
feature_names = ['VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']
feature_indices = [2, 3, 4, 5, 6, 7, 8, 9]
feature_units = ['L', 'L', 'L', 'mol/L', 'mol/L', 'mol/L', 'mol/L', 'A']
feature_titles = ['Feed Volume', 'Acid Volume', 'Base Volume', 'Feed LA Conc.', 'Acid LA Conc.', 'Feed K Conc.', 'Base K Conc.', 'Current']

# ì „ì²´ ì‹¤í—˜ ë°ì´í„° ìˆ˜ì§‘
all_experiment_results = {}
available_exp_nums = sorted(ndf['exp'].unique())
total_experiments = len(available_exp_nums)

# ì‹¤í—˜ ë²ˆí˜¸ ë§¤í•‘ (ê¸°ì¡´ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)
exp_num_to_dataloader_idx = {}
for i, exp_num in enumerate(available_exp_nums):
    exp_num_to_dataloader_idx[exp_num] = i

print(f"ğŸ“‹ ì „ì²´ {total_experiments}ê°œ ì‹¤í—˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

evaluation_model.eval()
with torch.no_grad():
    for dataloader_idx, (input_seq, seq_lengths) in enumerate(dataloader):
        try:
            # í•´ë‹¹ ë°ì´í„°ë¡œë” ì¸ë±ìŠ¤ì˜ ì‹¤í—˜ ë²ˆí˜¸ ì°¾ê¸°
            actual_exp_num = available_exp_nums[dataloader_idx]
            
            input_seq = input_seq.to(device)
            seq_lengths = seq_lengths.to(device)
            
            # Teacher forcing ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
            inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            predictions = evaluation_model(inputs, target_seq_lengths)
            
            # CPUë¡œ ì´ë™
            predictions_cpu = predictions.cpu().numpy()
            targets_cpu = targets.cpu().numpy()
            input_seq_cpu = input_seq.cpu().numpy()
            
            # ì²« ë²ˆì§¸ ìƒ˜í”Œ ì‚¬ìš©
            pred_sample = predictions_cpu[0]
            actual_sample = targets_cpu[0]
            initial_sample = input_seq_cpu[0]
            seq_len = target_seq_lengths[0].item()
            full_seq_len = seq_lengths[0].item()
            
            # ì‹¤ì œ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ë§Œ ì‚¬ìš©
            pred_sample = pred_sample[:seq_len]
            actual_sample = actual_sample[:seq_len]
            initial_sample = initial_sample[:full_seq_len]
            
            # ì‹œê°„ ì¶• ìƒì„±
            time_points = np.arange(full_seq_len) * 0.25
            
            # ì˜ˆì¸¡ê°’ì„ ì´ˆê¸°ê°’ê³¼ ì—°ê²°
            prediction_full = np.zeros((full_seq_len, 10))
            prediction_full[0] = initial_sample[0]
            prediction_full[1:seq_len+1] = pred_sample
            
            # ì‹¤í—˜ ì¡°ê±´ ì •ë³´
            voltage = denormalize_data(initial_sample[0, 0], 'V')
            electrolyte = denormalize_data(initial_sample[0, 1], 'E')
            
            # ê²°ê³¼ ì €ì¥
            all_experiment_results[actual_exp_num] = {
                'time_points': time_points,
                'actual_data': initial_sample,
                'predicted_data': prediction_full,
                'seq_len': seq_len,
                'full_seq_len': full_seq_len,
                'voltage': voltage,
                'electrolyte': electrolyte,
                'actual_sample': actual_sample,
                'pred_sample': pred_sample
            }
            
            print(f"âœ… ì‹¤í—˜ {actual_exp_num}: {full_seq_len*0.25:.1f}h, {voltage:.1f}V, {electrolyte:.3f}M")
            
        except Exception as e:
            print(f"âŒ ì‹¤í—˜ {dataloader_idx} ì˜¤ë¥˜: {str(e)}")
            continue

print(f"ğŸ“Š ì´ {len(all_experiment_results)}ê°œ ì‹¤í—˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")

# ì„œë¸Œí”Œë¡¯ ë°°ì¹˜ ê³„ì‚°
import math
sqrt_exp = math.ceil(math.sqrt(total_experiments))
if sqrt_exp * (sqrt_exp - 1) >= total_experiments:
    grid_rows, grid_cols = sqrt_exp - 1, sqrt_exp
else:
    grid_rows, grid_cols = sqrt_exp, sqrt_exp

print(f"ğŸ“ ê° featureë‹¹ {grid_rows}x{grid_cols} ì„œë¸Œí”Œë¡¯ ê·¸ë¦¬ë“œ ì‚¬ìš©")

# 8ê°œ featureë³„ë¡œ ê°œë³„ figure ìƒì„±
for feature_idx, (feature_name, feature_index, unit, title) in enumerate(zip(feature_names, feature_indices, feature_units, feature_titles)):
    print(f"ğŸ¨ Feature {feature_idx+1}/8: {feature_name} ({title}) ìƒì„± ì¤‘...")
    
    # ìƒˆ figure ìƒì„±
    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(4*grid_cols, 3*grid_rows))
    if best_model is not None:
        suptitle = f'{title} ({feature_name}) - All Experiments\nBest Model (Epoch {best_epoch}, Loss: {best_train_loss:.6f})'
    else:
        suptitle = f'{title} ({feature_name}) - All Experiments\nCurrent Model'
    fig.suptitle(suptitle, fontsize=16, fontweight='bold')
    
    # axes ì²˜ë¦¬ (1ì°¨ì›ìœ¼ë¡œ ë³€í™˜)
    if grid_rows * grid_cols == 1:
        axes = [axes]
    else:
        axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]
    
    # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
    rmse_values = []
    r2_values = []
    
    # ê° ì‹¤í—˜ë³„ subplot
    for plot_idx, exp_num in enumerate(sorted(all_experiment_results.keys())):
        if plot_idx >= len(axes):
            break
            
        ax = axes[plot_idx]
        exp_data = all_experiment_results[exp_num]
        
        # ë°ì´í„° denormalize
        actual_denorm = denormalize_data(exp_data['actual_data'][:, feature_index], feature_name)
        pred_denorm = denormalize_data(exp_data['predicted_data'][:exp_data['seq_len']+1, feature_index], feature_name)
        
        # í”Œë¡¯ ìƒì„±
        ax.plot(exp_data['time_points'], actual_denorm, 'b-', linewidth=1.5, label='Actual', alpha=0.8)
        ax.plot(exp_data['time_points'][:exp_data['seq_len']+1], pred_denorm, 'r--', linewidth=1.5, label='Predicted', alpha=0.8)
        
        # ì‹œì‘ì  í‘œì‹œ
        ax.plot(exp_data['time_points'][0], actual_denorm[0], 'go', markersize=3)
        ax.axvline(x=exp_data['time_points'][1], color='gray', linestyle=':', alpha=0.5)
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        actual_pred_denorm = denormalize_data(exp_data['actual_sample'][:, feature_index], feature_name)
        pred_pred_denorm = denormalize_data(exp_data['pred_sample'][:, feature_index], feature_name)
        
        rmse = np.sqrt(np.mean((actual_pred_denorm - pred_pred_denorm)**2))
        if np.sum((actual_pred_denorm - np.mean(actual_pred_denorm))**2) > 0:
            r2 = 1 - (np.sum((actual_pred_denorm - pred_pred_denorm)**2) / np.sum((actual_pred_denorm - np.mean(actual_pred_denorm))**2))
        else:
            r2 = 0.0
            
        rmse_values.append(rmse)
        r2_values.append(r2)
        
        # ì„œë¸Œí”Œë¡¯ ì„¤ì •
        condition_text = f'{exp_data["voltage"]:.1f}V, {exp_data["electrolyte"]:.2f}M'
        ax.set_title(f'Exp {exp_num}: {condition_text}\nRMSE: {rmse:.3f} {unit}', fontsize=9)
        ax.set_xlabel('Time (hours)', fontsize=8)
        ax.set_ylabel(f'{feature_name} ({unit})', fontsize=8)
        ax.grid(True, alpha=0.3)
        ax.tick_params(labelsize=7)
        
        # ì²« ë²ˆì§¸ subplotì—ë§Œ ë²”ë¡€ ì¶”ê°€
        if plot_idx == 0:
            ax.legend(fontsize=8, loc='upper right')
    
    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
    for plot_idx in range(len(all_experiment_results), len(axes)):
        axes[plot_idx].set_visible(False)
    
    # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
    avg_rmse = np.mean(rmse_values)
    std_rmse = np.std(rmse_values)
    avg_r2 = np.mean(r2_values)
    std_r2 = np.std(r2_values)
    
    # ì„±ëŠ¥ ìš”ì•½ í…ìŠ¤íŠ¸ ë°•ìŠ¤
    summary_text = f'Overall Performance:\nRMSE: {avg_rmse:.4f} Â± {std_rmse:.4f} {unit}\nRÂ²: {avg_r2:.3f} Â± {std_r2:.3f}\nExperiments: {len(rmse_values)}'
    fig.text(0.02, 0.02, summary_text, fontsize=10, 
             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.92, bottom=0.12, left=0.05, right=0.98)
    plt.show()
    
    print(f"âœ… {feature_name} ì™„ë£Œ: í‰ê·  RMSE = {avg_rmse:.4f} {unit}, í‰ê·  RÂ² = {avg_r2:.3f}")

# ì „ì²´ ìš”ì•½ ì¶œë ¥
print("\n" + "="*80)
print("COMPREHENSIVE EVALUATION SUMMARY - ALL EXPERIMENTS")
print("="*80)

for feature_idx, (feature_name, feature_index, unit) in enumerate(zip(feature_names, feature_indices, feature_units)):
    # ê° featureë³„ ì „ì²´ ì„±ëŠ¥ í†µê³„
    all_rmse = []
    all_mae = []
    all_r2 = []
    
    for exp_num in sorted(all_experiment_results.keys()):
        exp_data = all_experiment_results[exp_num]
        
        actual_pred_denorm = denormalize_data(exp_data['actual_sample'][:, feature_index], feature_name)
        pred_pred_denorm = denormalize_data(exp_data['pred_sample'][:, feature_index], feature_name)
        
        rmse = np.sqrt(np.mean((actual_pred_denorm - pred_pred_denorm)**2))
        mae = np.mean(np.abs(actual_pred_denorm - pred_pred_denorm))
        
        if np.sum((actual_pred_denorm - np.mean(actual_pred_denorm))**2) > 0:
            r2 = 1 - (np.sum((actual_pred_denorm - pred_pred_denorm)**2) / np.sum((actual_pred_denorm - np.mean(actual_pred_denorm))**2))
        else:
            r2 = 0.0
        
        all_rmse.append(rmse)
        all_mae.append(mae)
        all_r2.append(r2)
    
    print(f"{feature_name:6s}: RMSE={np.mean(all_rmse):.4f}Â±{np.std(all_rmse):.4f} {unit}, "
          f"MAE={np.mean(all_mae):.4f}Â±{np.std(all_mae):.4f} {unit}, "
          f"RÂ²={np.mean(all_r2):.3f}Â±{np.std(all_r2):.3f}")

print("-"*80)
print(f"ğŸ“Š Total experiments analyzed: {len(all_experiment_results)}")
if best_model is not None:
    print(f"ğŸ† Best model used: Epoch {best_epoch}, Loss: {best_train_loss:.6f}")
else:
    print("ğŸ“‹ Current model used")
print("="*80)

print("ğŸ‰ Comprehensive evaluation ì™„ë£Œ! 8ê°œì˜ featureë³„ í”Œë¡¯ì´ ëª¨ë“  ì‹¤í—˜ ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")