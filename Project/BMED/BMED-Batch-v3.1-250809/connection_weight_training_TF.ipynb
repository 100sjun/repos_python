{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993e6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "import math\n",
    "import optuna\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42dc2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53a49cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "\n",
    "    # Get the unique experiment numbers in order\n",
    "    exp_num_list = sorted(ndf['exp'].unique())\n",
    "    return ndf, exp_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d900108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data(ndf):\n",
    "    seq = []\n",
    "    # CBLA, CAK만 제거: 학습 불안정성 때문에\n",
    "    # 전류(I)는 포함: ground truth로 사용하여 예측 성능 비교\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CFK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        seq.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c2021b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    max_len = max([len(seq) for seq in seq])\n",
    "    seq_len = [len(seq) for seq in seq]\n",
    "    pad_seq = pad_sequence([torch.tensor(seq) for seq in seq], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return pad_seq, seq_len, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0ddc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d67ed67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(dataset, exp_num_list, batch_size=4):\n",
    "    \"\"\"\n",
    "    Split the dataset into train/val/test with 8:1:1 ratio\n",
    "    \n",
    "    Args:\n",
    "        dataset: TensorDataset\n",
    "        exp_num_list: list of experiment numbers\n",
    "        batch_size: batch size\n",
    "        random_state: random seed\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # required train experiment numbers\n",
    "    required_train_exps = [0, 2, 4, 5, 8, 9, 10, 13, 15, 17, 20, 22, 24, 26, 33, 34]\n",
    "    \n",
    "    # all experiment numbers\n",
    "    all_exps = exp_num_list\n",
    "    total_exps = len(all_exps)\n",
    "    \n",
    "    # batch_size\n",
    "    batch_size = math.ceil(len(dataset)/10)\n",
    "\n",
    "    # 8:1:1 ratio\n",
    "    train_count = int(total_exps * 0.8)\n",
    "    val_count = math.ceil(total_exps * 0.1)\n",
    "    \n",
    "    # remaining experiments\n",
    "    remaining_exps = [exp for exp in all_exps if exp not in required_train_exps]\n",
    "    \n",
    "    # number of experiments to add to train\n",
    "    additional_train_needed = train_count - len(required_train_exps)\n",
    "    \n",
    "    if additional_train_needed < 0:\n",
    "        raise ValueError(\"The number of required train experiments is greater than the total train set. Please adjust required_train_exps.\")\n",
    "    \n",
    "    # shuffle remaining experiments\n",
    "    np.random.shuffle(remaining_exps)\n",
    "    \n",
    "    # split remaining experiments into train, val, test\n",
    "    train_exps = required_train_exps + remaining_exps[:additional_train_needed]\n",
    "    val_exps = remaining_exps[additional_train_needed:additional_train_needed + val_count]\n",
    "    test_exps = remaining_exps[additional_train_needed + val_count:]\n",
    "    \n",
    "    print(f\"Actual split:\")\n",
    "    print(f\"  Train: {sorted(train_exps)} ({len(train_exps)} experiments)\")\n",
    "    print(f\"  Val: {sorted(val_exps)} ({len(val_exps)} experiments)\")  \n",
    "    print(f\"  Test: {sorted(test_exps)} ({len(test_exps)} experiments)\")\n",
    "    \n",
    "    # find indices of each experiment (exp_num_list and dataset have the same order)\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    for idx, exp in enumerate(all_exps):\n",
    "        if exp in train_exps:\n",
    "            train_indices.append(idx)\n",
    "        elif exp in val_exps:\n",
    "            val_indices.append(idx)\n",
    "        elif exp in test_exps:\n",
    "            test_indices.append(idx)\n",
    "    \n",
    "    # split dataset into train, val, test\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "    \n",
    "    # create DataLoader\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nCompleted DataLoader creation:\")\n",
    "    print(f\"  Train: {len(train_subset) if train_subset else 0} sequences\")\n",
    "    print(f\"  Val: {len(val_subset) if val_subset else 0} sequences\")\n",
    "    print(f\"  Test: {len(test_subset) if test_subset else 0} sequences\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07f3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormLSTMCell(nn.Module):\n",
    "    \"\"\"LSTM Cell with Layer Normalization applied to gates\"\"\"\n",
    "    def __init__(self, input_node, hidden_node):\n",
    "        super().__init__()\n",
    "        self.input_node = input_node\n",
    "        self.hidden_node = hidden_node\n",
    "        \n",
    "        # Input-to-hidden and hidden-to-hidden transformations\n",
    "        self.weight_ih = nn.Linear(input_node, 4 * hidden_node, bias=False)\n",
    "        self.weight_hh = nn.Linear(hidden_node, 4 * hidden_node, bias=False)\n",
    "        \n",
    "        # Layer normalization for each gate\n",
    "        self.ln_i = nn.LayerNorm(hidden_node)  # Input gate\n",
    "        self.ln_f = nn.LayerNorm(hidden_node)  # Forget gate  \n",
    "        self.ln_g = nn.LayerNorm(hidden_node)  # Cell gate\n",
    "        self.ln_o = nn.LayerNorm(hidden_node)  # Output gate\n",
    "        \n",
    "        # Cell state layer norm\n",
    "        self.ln_c = nn.LayerNorm(hidden_node)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        \n",
    "        # Input-to-hidden and hidden-to-hidden transformations\n",
    "        gi = self.weight_ih(input)    # [batch, 4*hidden_size] - 입력에 대한 4개 게이트 계산\n",
    "        gh = self.weight_hh(h_prev)   # [batch, 4*hidden_size] - 이전 히든 상태에 대한 4개 게이트 계산\n",
    "        i_i, i_f, i_g, i_o = gi.chunk(4, 1)\n",
    "        h_i, h_f, h_g, h_o = gh.chunk(4, 1)\n",
    "        \n",
    "        # Apply layer normalization to each gate\n",
    "        i_gate = torch.sigmoid(self.ln_i(i_i + h_i))\n",
    "        f_gate = torch.sigmoid(self.ln_f(i_f + h_f))  \n",
    "        g_gate = torch.tanh(self.ln_g(i_g + h_g))\n",
    "        o_gate = torch.sigmoid(self.ln_o(i_o + h_o))\n",
    "        \n",
    "        # Update cell state with layer norm\n",
    "        c_new = f_gate * c_prev + i_gate * g_gate\n",
    "        c_new = self.ln_c(c_new)\n",
    "        \n",
    "        # Update hidden state\n",
    "        h_new = o_gate * torch.tanh(c_new)\n",
    "        \n",
    "        return h_new, c_new\n",
    "\n",
    "class StateExtr(nn.Module):\n",
    "    def __init__(self, input_node, hidden_node, nlayer, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_node = hidden_node\n",
    "        self.nlayer = nlayer\n",
    "        self.input_size = input_node\n",
    "        \n",
    "        # Create LayerNorm LSTM layers\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        \n",
    "        # First layer: input_size -> hidden_size\n",
    "        self.lstm_cells.append(LayerNormLSTMCell(input_node, hidden_node))\n",
    "        \n",
    "        # Additional layers: hidden_size -> hidden_size\n",
    "        for _ in range(nlayer - 1):\n",
    "            self.lstm_cells.append(LayerNormLSTMCell(hidden_node, hidden_node))\n",
    "        \n",
    "        # Dropout between layers (only applied if nlayer > 1)\n",
    "        self.dropout = nn.Dropout(dropout) if nlayer > 1 else nn.Identity()\n",
    "        \n",
    "        # Final layer norm and dropout\n",
    "        self.final_layer_norm = nn.LayerNorm(hidden_node)\n",
    "        self.final_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        시계열 상태 시퀀스를 처리하여 각 시점의 hidden state 추출\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size] - BMED 시스템 상태 시퀀스\n",
    "            seq_len: [batch_size] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 각 시점의 누적된 hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        # 입력 검증\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        batch_size, max_len, input_node = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # 초기 hidden/cell states 초기화\n",
    "        h_states = []\n",
    "        c_states = []\n",
    "        for _ in range(self.nlayer):\n",
    "            h_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "            c_states.append(torch.zeros(batch_size, self.hidden_node, device=device))\n",
    "        \n",
    "        # 각 시점별 출력 저장\n",
    "        outputs = []\n",
    "        \n",
    "        # 시점별로 순차 처리\n",
    "        for t in range(max_len):\n",
    "            x_t = x[:, t, :]  # [batch_size, input_node]\n",
    "            \n",
    "            # 각 LSTM layer 순차 처리\n",
    "            layer_input = x_t\n",
    "            for layer_idx, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_new, c_new = lstm_cell(layer_input, (h_states[layer_idx], c_states[layer_idx]))\n",
    "                \n",
    "                # 상태 업데이트\n",
    "                h_states[layer_idx] = h_new\n",
    "                c_states[layer_idx] = c_new\n",
    "                \n",
    "                # 다음 레이어 입력 준비 (dropout 적용)\n",
    "                if layer_idx < len(self.lstm_cells) - 1:  # 마지막 레이어가 아닌 경우\n",
    "                    layer_input = self.dropout(h_new)\n",
    "                else:\n",
    "                    layer_input = h_new\n",
    "            \n",
    "            outputs.append(layer_input)\n",
    "        \n",
    "        # [batch_size, seq_len, hidden_size] 형태로 변환\n",
    "        output_tensor = torch.stack(outputs, dim=1)\n",
    "        \n",
    "        # 시퀀스 길이에 따른 마스킹 (패딩 부분 0으로 설정)\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        \n",
    "        # 시퀀스 길이 유효성 검사\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "        \n",
    "        # 마스크 생성 및 적용\n",
    "        mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "        mask = mask.float().to(device).unsqueeze(-1)  # [batch, seq_len, 1]\n",
    "        \n",
    "        # 마스킹 적용\n",
    "        masked_output = output_tensor * mask\n",
    "        \n",
    "        # Final normalization and dropout\n",
    "        normalized = self.final_layer_norm(masked_output)\n",
    "        return self.final_dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be1c313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden state로부터 BMED 시스템의 물리적 변화량과 새로운 전류값을 디코딩하는 MLP\n",
    "    출력: [dVA, dVB, dNALA, dNBK, nI] - 5개 물리적 변화량 (CBLA, CAK 제거로 dNBLA, dNAK 불필요)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # 첫 번째 레이어: hidden_size → num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 중간 은닉층들: num_nodes → num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # 마지막 출력층: num_nodes → output_size (5개 물리적 변화량)\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Hidden state를 물리적 변화량으로 디코딩\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - 시점별 hidden state\n",
    "            \n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, 5] - 물리적 변화량\n",
    "                [dVA, dVB, dNALA, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e0213a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    물리적 변화량을 실제 시스템 상태로 변환하면서 물리적 제약 조건을 적용\n",
    "    Bipolar membrane electrodialysis 시스템의 물리 법칙 기반 상태 업데이트\n",
    "    CBLA, CAK는 완전히 제거되어 더 이상 존재하지 않음\n",
    "    전류는 dependent variable이므로 input에 포함하지 않고 output으로만 예측\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-1):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # division by zero 방지\n",
    "        \n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        물리적 변화량을 현재 상태에 적용하여 다음 상태 계산\n",
    "        \n",
    "        Args:\n",
    "            physical_changes: [batch, seq, 5] - [dVA, dVB, dNALA, dNBK, nI]\n",
    "            current_state: [batch, seq, 9] - 현재 BMED 시스템 상태 (전류 제외)\n",
    "                V, E, VF, VA, VB, CFLA, CALA, CFK, CBK\n",
    "                \n",
    "        Returns:\n",
    "            next_state: [batch, seq, 10] - 물리 제약이 적용된 다음 상태\n",
    "                V, E, VF, VA, VB, CFLA, CALA, CFK, CBK, I\n",
    "        \"\"\"\n",
    "        # 입력 차원 검증\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 9:\n",
    "            raise ValueError(f\"Expected 9 state features, got {current_state.size(-1)}\")\n",
    "            \n",
    "        if physical_changes.size(-1) != 5:\n",
    "            raise ValueError(f\"Expected 5 physical changes, got {physical_changes.size(-1)}\")\n",
    "        \n",
    "        # 현재 상태 변수 추출 (9개)\n",
    "        V = current_state[..., 0:1]     # 전압 (고정값)\n",
    "        E = current_state[..., 1:2]     # 외부 전해질 농도 (고정값)\n",
    "        VF = current_state[..., 2:3]    # Feed 부피\n",
    "        VA = current_state[..., 3:4]    # Acid 부피\n",
    "        VB = current_state[..., 4:5]    # Base 부피\n",
    "        CFLA = current_state[..., 5:6]  # Feed LA 농도\n",
    "        CALA = current_state[..., 6:7]  # Acid LA 농도\n",
    "        CFK = current_state[..., 7:8]   # Feed K 농도\n",
    "        CBK = current_state[..., 8:9]   # Base K 농도\n",
    "\n",
    "        # 물질량 계산 (농도 × 부피) - CBLA, CAK 관련은 완전 제거\n",
    "        NFLA = CFLA * VF\n",
    "        NALA = CALA * VA  \n",
    "        NFK = CFK * VF\n",
    "        NBK = CBK * VB\n",
    "\n",
    "        # 물리적 변화량 추출 (5개)\n",
    "        dVA = physical_changes[..., 0:1]    # Acid 부피 변화량\n",
    "        dVB = physical_changes[..., 1:2]    # Base 부피 변화량\n",
    "        dNALA = physical_changes[..., 2:3]  # Acid LA 물질량 변화량 (F→A)\n",
    "        dNBK = physical_changes[..., 3:4]   # Base K 물질량 변화량 (F→B)\n",
    "        nI = physical_changes[..., 4:5]     # 새로운 전류값 (모델이 예측)\n",
    "\n",
    "        # 새로운 부피 계산\n",
    "        nVF = VF - dVA - dVB\n",
    "        nVA = VA + dVA        \n",
    "        nVB = VB + dVB        \n",
    "        \n",
    "        # 물질 이동량을 일방향으로 제한\n",
    "        dNALA_clipped = torch.clamp(dNALA, min=0)  # F→A 이동만\n",
    "        dNBK_clipped = torch.clamp(dNBK, min=0)    # F→B 이동만\n",
    "        \n",
    "        # 새로운 물질량 계산 (CBLA, CAK 관련 제거)\n",
    "        nNFLA = NFLA - dNALA_clipped  # Feed에서 LA 유출\n",
    "        nNALA = NALA + dNALA_clipped  # Acid로 LA 유입\n",
    "        nNFK = NFK - dNBK_clipped     # Feed에서 K 유출  \n",
    "        nNBK = NBK + dNBK_clipped     # Base로 K 유입\n",
    "        \n",
    "        # 물리적 제약 조건 적용 (양수 유지)\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        \n",
    "        # 물질량 음수 방지\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        \n",
    "        # 새로운 농도 계산\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCFK = nNFK / nVF\n",
    "        nCBK = nNBK / nVB\n",
    "        \n",
    "        # 전류는 양수 제약\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # 새로운 상태 조립 (10개 변수, CBLA, CAK 완전 제거, 전류는 예측 결과로 추가)\n",
    "        next_state = torch.cat([\n",
    "            V, E,  # 고정값: 전압, 외부 전해질 농도\n",
    "            nVF, nVA, nVB,  # 새로운 부피\n",
    "            nCFLA, nCALA,   # 새로운 LA 농도 (CBLA 제거)\n",
    "            nCFK, nCBK,     # 새로운 K 농도 (CAK 제거)\n",
    "            nI  # 새로운 전류 (모델이 예측한 dependent variable)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c20aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED 시스템의 시계열 상태 예측을 위한 자기회귀 모델\n",
    "    \n",
    "    구조:\n",
    "    1. StateExtr: LSTM으로 시계열 패턴의 hidden state 추출\n",
    "    2. PhysicalChangeDecoder: Hidden state를 물리적 변화량으로 디코딩  \n",
    "    3. PhysicsConstraintLayer: 물리 법칙 적용하여 다음 상태 계산\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = StateExtr(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_states, seq_lengths):\n",
    "        \"\"\"\n",
    "        현재 시점까지의 상태들로부터 다음 상태들 예측\n",
    "        \n",
    "        Args:\n",
    "            current_states: [batch, seq_len, 9] - 현재까지의 전류를 제외한한 BMED 시스템 상태들\n",
    "            seq_lengths: [batch] - 각 시퀀스의 실제 길이\n",
    "            \n",
    "        Returns:\n",
    "            next_states: [batch, seq_len, 10] - 예측된 다음 시점 상태들 (전류 포함)\n",
    "        \"\"\"\n",
    "        # 1. LSTM으로 각 시점의 hidden state 추출 (과거 정보 누적)\n",
    "        hidden_states = self.state_extractor(current_states, seq_lengths)\n",
    "        \n",
    "        # 2. Hidden state를 물리적 변화량으로 디코딩\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        \n",
    "        # 3. 물리적 제약 조건을 적용하여 다음 상태 계산\n",
    "        next_states = self.physics_constraint(physical_changes, current_states)\n",
    "        \n",
    "        return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b58e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(predictions, targets, seq_lengths):\n",
    "    \"\"\"\n",
    "    개선된 마스킹된 MSE 손실 함수 - device 호환성, 안정성 강화\n",
    "    물리적 의미가 개선되어 feature별 가중치 불필요\n",
    "    \n",
    "    Args:\n",
    "        predictions: 모델 예측값 [batch_size, seq_len, features]\n",
    "        targets: 실제 타겟값 [batch_size, seq_len, features]  \n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        masked_loss: 패딩 부분을 제외한 평균 MSE 손실\n",
    "    \"\"\"\n",
    "    # 입력 검증\n",
    "    if predictions.shape != targets.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {predictions.shape} vs targets {targets.shape}\")\n",
    "    \n",
    "    if predictions.size(0) != seq_lengths.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {predictions.size(0)} vs seq_lengths {seq_lengths.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = predictions.shape\n",
    "    \n",
    "    # seq_lengths를 CPU로 이동하여 arange와 호환되도록 처리\n",
    "    seq_lengths_cpu = seq_lengths.detach().cpu().long()\n",
    "    \n",
    "    # 시퀀스 길이 유효성 검사\n",
    "    if (seq_lengths_cpu <= 0).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu <= 0]\n",
    "        raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "    \n",
    "    # 최대 길이 초과 검사\n",
    "    if (seq_lengths_cpu > max_len).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu > max_len]\n",
    "        raise ValueError(f\"Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}\")\n",
    "    \n",
    "    # 마스크 생성: 실제 시퀀스 길이만큼만 True\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_lengths_cpu[:, None]\n",
    "    mask = mask.float().to(predictions.device)\n",
    "    \n",
    "    # 각 요소별 MSE 계산 (reduction='none')\n",
    "    loss = F.mse_loss(predictions, targets, reduction='none')  # [batch, seq_len, features]\n",
    "    \n",
    "    # 마스크 적용하여 패딩 부분 제거\n",
    "    masked_loss = loss * mask.unsqueeze(-1)  # [batch, seq_len, features]\n",
    "    \n",
    "    # 전체 손실 합계와 전체 valid elements 계산\n",
    "    total_loss = masked_loss.sum()\n",
    "    total_elements = mask.sum() * features\n",
    "    \n",
    "    # 0으로 나누기 방지\n",
    "    if total_elements == 0:\n",
    "        raise ValueError(\"No valid elements found after masking. Check sequence lengths and data.\")\n",
    "    \n",
    "    masked_loss = total_loss / total_elements\n",
    "    \n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bf439fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_teacher_forcing_data(input_sequences, seq_lengths):\n",
    "    \"\"\"\n",
    "    Teacher Forcing을 위한 입력-타겟 데이터 준비\n",
    "    전류는 dependent variable이므로 input에서 제외하고 output에만 포함\n",
    "    \n",
    "    Args:\n",
    "        input_sequences: 전체 시퀀스 [batch_size, seq_len, 10] (CBLA, CAK 제거된 상태)\n",
    "        seq_lengths: 각 시퀀스의 실제 길이 [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        inputs: [t0, t1, ..., t_{n-1}] 현재 상태들 [batch_size, seq_len-1, 9] (전류 제외)\n",
    "        targets: [t1, t2, ..., t_n] 다음 상태들 [batch_size, seq_len-1, 10] (전류 포함)\n",
    "        target_seq_lengths: 타겟 시퀀스 길이 (1씩 감소)\n",
    "    \"\"\"\n",
    "    # 입력: 마지막 시점 제외 [:-1] 및 전류 제외 [:-1]\n",
    "    inputs = input_sequences[:, :-1, :-1]  # 전류 제외하여 9개 features\n",
    "    \n",
    "    # 타겟: 첫 번째 시점 제외 [1:], 전류 포함하여 10개 features\n",
    "    targets = input_sequences[:, 1:, :]\n",
    "    \n",
    "    # 타겟 시퀀스 길이는 1씩 감소 (마지막 시점 예측 불가)\n",
    "    if (seq_lengths - 1 < 1).any():\n",
    "        invalid_lengths = seq_lengths[seq_lengths - 1 < 1]\n",
    "        raise ValueError(f\"타겟 시퀀스 길이가 0보다 작아질 수 없습니다. 잘못된 seq_lengths: {invalid_lengths.tolist()}\")\n",
    "    target_seq_lengths = seq_lengths - 1\n",
    "    \n",
    "    return inputs, targets, target_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1c8fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Dataset created with 36 experiments\n",
      "Max sequence length: 33\n",
      "Experiment numbers: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35)]\n",
      "Actual split:\n",
      "  Train: [0, np.int64(1), 2, np.int64(3), 4, 5, np.int64(6), 8, 9, 10, np.int64(11), np.int64(12), 13, 15, 17, 20, 22, np.int64(23), 24, np.int64(25), 26, np.int64(27), np.int64(28), np.int64(31), np.int64(32), 33, 34, np.int64(35)] (28 experiments)\n",
      "  Val: [np.int64(7), np.int64(14), np.int64(21), np.int64(29)] (4 experiments)\n",
      "  Test: [np.int64(16), np.int64(18), np.int64(19), np.int64(30)] (4 experiments)\n",
      "\n",
      "Completed DataLoader creation:\n",
      "  Train: 28 sequences\n",
      "  Val: 4 sequences\n",
      "  Test: 4 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load data and create dataloaders\n",
    "print(\"Loading and preprocessing data...\")\n",
    "ndf, exp_num_list = norm_data('BMED_DATA_AG.csv')\n",
    "sequences = seq_data(ndf)\n",
    "padded_seq, seq_len, max_seq_len = pad_seq(sequences)\n",
    "dataset = gen_dataset(padded_seq, seq_len)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} experiments\")\n",
    "print(f\"Max sequence length: {max_seq_len}\")\n",
    "print(f\"Experiment numbers: {sorted(exp_num_list)}\")\n",
    "\n",
    "# Create train/val/test dataloaders with stratified split\n",
    "train_loader, val_loader, test_loader = dataloaders(dataset, exp_num_list, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95396be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Model architecture:\n",
      "  Input features: 9 (without current)\n",
      "  Hidden size: 256\n",
      "  LSTM layers: 5\n",
      "  Output features: 5 (physical changes)\n",
      "  Model parameters: 2,714,629\n",
      "\n",
      "Training configuration:\n",
      "  Total epochs: 10,000\n",
      "  Warmup epochs: 1,000 (5%)\n",
      "  Min epochs: 2,000\n",
      "  Patience: 1,000\n",
      "  Peak learning rate: 9.88e-04\n"
     ]
    }
   ],
   "source": [
    "class NoamScheduler:\n",
    "    \"\"\"\n",
    "    Transformer에서 사용하는 Noam 학습률 스케줄러\n",
    "    LSTM에 맞게 epoch 기반으로 수정\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, model_size, warmup_epochs, factor=1.0):\n",
    "        self.optimizer = optimizer\n",
    "        self.model_size = model_size\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.factor = factor\n",
    "        self.epoch_num = 0\n",
    "        \n",
    "    def step_epoch(self):\n",
    "        \"\"\"에포크마다 학습률 업데이트\"\"\"\n",
    "        self.epoch_num += 1\n",
    "        lr = self.factor * (\n",
    "            self.model_size ** (-0.5) *\n",
    "            min(self.epoch_num ** (-0.5), self.epoch_num * self.warmup_epochs ** (-1.5))\n",
    "        )\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        return lr\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "# Model parameters - 입력 차원 수정\n",
    "state_extr_params = {\n",
    "    'input_node': 9,   # 수정: 10 -> 9 (전류 제외한 입력)\n",
    "    'hidden_node': 256,\n",
    "    'nlayer': 5,\n",
    "    'dropout': 0.3\n",
    "}\n",
    "\n",
    "decoder_params = {\n",
    "    'hidden_size': 256,\n",
    "    'output_size': 5,  # [dVA, dVB, dNALA, dNBK, nI]\n",
    "    'num_layers': 5,\n",
    "    'num_nodes': 256,\n",
    "    'dropout': 0.3\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = BMEDAutoregressiveModel(state_extr_params, decoder_params)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(f\"  Input features: {state_extr_params['input_node']} (without current)\")\n",
    "print(f\"  Hidden size: {state_extr_params['hidden_node']}\")\n",
    "print(f\"  LSTM layers: {state_extr_params['nlayer']}\")\n",
    "print(f\"  Output features: {decoder_params['output_size']} (physical changes)\")\n",
    "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Training setup with Noam scheduler (epoch-based)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1.0)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10000\n",
    "\n",
    "\n",
    "# Noam 스케줄러 설정 (epoch 기반)\n",
    "warmup_epochs = int(num_epochs * 0.1)  # 전체 epoch의 5%\n",
    "scheduler = NoamScheduler(\n",
    "    optimizer, \n",
    "    model_size=256,  # hidden_size와 동일\n",
    "    warmup_epochs=warmup_epochs,  # 500 epochs\n",
    "    factor=1  # 학습률 스케일링 팩터\n",
    ")\n",
    "\n",
    "min_epochs = warmup_epochs + 1000\n",
    "patience = 1000\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Total epochs: {num_epochs:,}\")\n",
    "print(f\"  Warmup epochs: {warmup_epochs:,} (5%)\")\n",
    "print(f\"  Min epochs: {min_epochs:,}\")\n",
    "print(f\"  Patience: {patience:,}\")\n",
    "peak_lr = 0.5 * (256 ** (-0.5)) * (warmup_epochs ** (-0.5))\n",
    "print(f\"  Peak learning rate: {peak_lr:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thtkmdiuz0l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with Noam scheduler (epoch-based)...\n",
      "데이터 분포 - Train: 28(0.875), Val: 4(0.125)\n",
      "Epoch    1: Train: 0.510713, Val: 0.156391, Total: 0.466423, LR: 1.98e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.510713, Val: 0.156391, Total: 0.466423 (Epoch 1)\n",
      "Epoch    2: Train: 0.539900, Val: 0.141994, Total: 0.490162, LR: 3.95e-06 [WARMUP]\n",
      "          Best: Train: 0.510713, Val: 0.156391, Total: 0.466423 (Epoch 1)\n",
      "Epoch    3: Train: 0.449467, Val: 0.130434, Total: 0.409588, LR: 5.93e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.449467, Val: 0.130434, Total: 0.409588 (Epoch 3)\n",
      "Epoch    4: Train: 0.353121, Val: 0.100340, Total: 0.321523, LR: 7.91e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.353121, Val: 0.100340, Total: 0.321523 (Epoch 4)\n",
      "Epoch    5: Train: 0.343005, Val: 0.083252, Total: 0.310536, LR: 9.88e-06 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.343005, Val: 0.083252, Total: 0.310536 (Epoch 5)\n",
      "Epoch    6: Train: 0.285123, Val: 0.079276, Total: 0.259392, LR: 1.19e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.285123, Val: 0.079276, Total: 0.259392 (Epoch 6)\n",
      "Epoch    7: Train: 0.238720, Val: 0.070108, Total: 0.217644, LR: 1.38e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.238720, Val: 0.070108, Total: 0.217644 (Epoch 7)\n",
      "Epoch    8: Train: 0.234827, Val: 0.066492, Total: 0.213785, LR: 1.58e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.234827, Val: 0.066492, Total: 0.213785 (Epoch 8)\n",
      "Epoch    9: Train: 0.165471, Val: 0.074139, Total: 0.154055, LR: 1.78e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.165471, Val: 0.074139, Total: 0.154055 (Epoch 9)\n",
      "Epoch   10: Train: 0.174928, Val: 0.078604, Total: 0.162887, LR: 1.98e-05 [WARMUP]\n",
      "          Best: Train: 0.165471, Val: 0.074139, Total: 0.154055 (Epoch 9)\n",
      "Epoch   11: Train: 0.131937, Val: 0.073332, Total: 0.124611, LR: 2.17e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.131937, Val: 0.073332, Total: 0.124611 (Epoch 11)\n",
      "Epoch   12: Train: 0.148445, Val: 0.070578, Total: 0.138712, LR: 2.37e-05 [WARMUP]\n",
      "          Best: Train: 0.131937, Val: 0.073332, Total: 0.124611 (Epoch 11)\n",
      "Epoch   13: Train: 0.132511, Val: 0.071303, Total: 0.124860, LR: 2.57e-05 [WARMUP]\n",
      "          Best: Train: 0.131937, Val: 0.073332, Total: 0.124611 (Epoch 11)\n",
      "Epoch   14: Train: 0.099974, Val: 0.067394, Total: 0.095902, LR: 2.77e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.099974, Val: 0.067394, Total: 0.095902 (Epoch 14)\n",
      "Epoch   15: Train: 0.110167, Val: 0.055121, Total: 0.103287, LR: 2.96e-05 [WARMUP]\n",
      "          Best: Train: 0.099974, Val: 0.067394, Total: 0.095902 (Epoch 14)\n",
      "Epoch   16: Train: 0.110445, Val: 0.048891, Total: 0.102751, LR: 3.16e-05 [WARMUP]\n",
      "          Best: Train: 0.099974, Val: 0.067394, Total: 0.095902 (Epoch 14)\n",
      "Epoch   17: Train: 0.108046, Val: 0.064442, Total: 0.102595, LR: 3.36e-05 [WARMUP]\n",
      "          Best: Train: 0.099974, Val: 0.067394, Total: 0.095902 (Epoch 14)\n",
      "Epoch   18: Train: 0.099129, Val: 0.067380, Total: 0.095161, LR: 3.56e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.099129, Val: 0.067380, Total: 0.095161 (Epoch 18)\n",
      "Epoch   19: Train: 0.092991, Val: 0.045393, Total: 0.087041, LR: 3.76e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.092991, Val: 0.045393, Total: 0.087041 (Epoch 19)\n",
      "Epoch   20: Train: 0.113899, Val: 0.038866, Total: 0.104520, LR: 3.95e-05 [WARMUP]\n",
      "          Best: Train: 0.092991, Val: 0.045393, Total: 0.087041 (Epoch 19)\n",
      "Epoch   21: Train: 0.091970, Val: 0.039004, Total: 0.085349, LR: 4.15e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.091970, Val: 0.039004, Total: 0.085349 (Epoch 21)\n",
      "Epoch   22: Train: 0.096019, Val: 0.027944, Total: 0.087509, LR: 4.35e-05 [WARMUP]\n",
      "          Best: Train: 0.091970, Val: 0.039004, Total: 0.085349 (Epoch 21)\n",
      "Epoch   23: Train: 0.098330, Val: 0.038621, Total: 0.090867, LR: 4.55e-05 [WARMUP]\n",
      "          Best: Train: 0.091970, Val: 0.039004, Total: 0.085349 (Epoch 21)\n",
      "Epoch   24: Train: 0.077914, Val: 0.038796, Total: 0.073024, LR: 4.74e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.077914, Val: 0.038796, Total: 0.073024 (Epoch 24)\n",
      "Epoch   25: Train: 0.104149, Val: 0.029550, Total: 0.094824, LR: 4.94e-05 [WARMUP]\n",
      "          Best: Train: 0.077914, Val: 0.038796, Total: 0.073024 (Epoch 24)\n",
      "Epoch   26: Train: 0.076927, Val: 0.035086, Total: 0.071697, LR: 5.14e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.076927, Val: 0.035086, Total: 0.071697 (Epoch 26)\n",
      "Epoch   27: Train: 0.077833, Val: 0.033714, Total: 0.072318, LR: 5.34e-05 [WARMUP]\n",
      "          Best: Train: 0.076927, Val: 0.035086, Total: 0.071697 (Epoch 26)\n",
      "Epoch   28: Train: 0.082213, Val: 0.029944, Total: 0.075680, LR: 5.53e-05 [WARMUP]\n",
      "          Best: Train: 0.076927, Val: 0.035086, Total: 0.071697 (Epoch 26)\n",
      "Epoch   29: Train: 0.062460, Val: 0.025190, Total: 0.057801, LR: 5.73e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.062460, Val: 0.025190, Total: 0.057801 (Epoch 29)\n",
      "Epoch   30: Train: 0.062537, Val: 0.021744, Total: 0.057438, LR: 5.93e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.062537, Val: 0.021744, Total: 0.057438 (Epoch 30)\n",
      "Epoch   31: Train: 0.064532, Val: 0.016643, Total: 0.058546, LR: 6.13e-05 [WARMUP]\n",
      "          Best: Train: 0.062537, Val: 0.021744, Total: 0.057438 (Epoch 30)\n",
      "Epoch   32: Train: 0.066348, Val: 0.016109, Total: 0.060068, LR: 6.32e-05 [WARMUP]\n",
      "          Best: Train: 0.062537, Val: 0.021744, Total: 0.057438 (Epoch 30)\n",
      "Epoch   33: Train: 0.056595, Val: 0.017538, Total: 0.051713, LR: 6.52e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.056595, Val: 0.017538, Total: 0.051713 (Epoch 33)\n",
      "Epoch   34: Train: 0.057449, Val: 0.016296, Total: 0.052305, LR: 6.72e-05 [WARMUP]\n",
      "          Best: Train: 0.056595, Val: 0.017538, Total: 0.051713 (Epoch 33)\n",
      "Epoch   35: Train: 0.052903, Val: 0.035359, Total: 0.050710, LR: 6.92e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.052903, Val: 0.035359, Total: 0.050710 (Epoch 35)\n",
      "Epoch   36: Train: 0.051678, Val: 0.030794, Total: 0.049067, LR: 7.12e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.051678, Val: 0.030794, Total: 0.049067 (Epoch 36)\n",
      "Epoch   37: Train: 0.048192, Val: 0.022612, Total: 0.044994, LR: 7.31e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.048192, Val: 0.022612, Total: 0.044994 (Epoch 37)\n",
      "Epoch   38: Train: 0.049445, Val: 0.025801, Total: 0.046489, LR: 7.51e-05 [WARMUP]\n",
      "          Best: Train: 0.048192, Val: 0.022612, Total: 0.044994 (Epoch 37)\n",
      "Epoch   39: Train: 0.045119, Val: 0.015261, Total: 0.041386, LR: 7.71e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.045119, Val: 0.015261, Total: 0.041386 (Epoch 39)\n",
      "Epoch   40: Train: 0.041383, Val: 0.012530, Total: 0.037776, LR: 7.91e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.041383, Val: 0.012530, Total: 0.037776 (Epoch 40)\n",
      "Epoch   41: Train: 0.034510, Val: 0.015860, Total: 0.032179, LR: 8.10e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.034510, Val: 0.015860, Total: 0.032179 (Epoch 41)\n",
      "Epoch   42: Train: 0.032613, Val: 0.014433, Total: 0.030340, LR: 8.30e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.032613, Val: 0.014433, Total: 0.030340 (Epoch 42)\n",
      "Epoch   43: Train: 0.034562, Val: 0.013492, Total: 0.031928, LR: 8.50e-05 [WARMUP]\n",
      "          Best: Train: 0.032613, Val: 0.014433, Total: 0.030340 (Epoch 42)\n",
      "Epoch   44: Train: 0.033128, Val: 0.014702, Total: 0.030824, LR: 8.70e-05 [WARMUP]\n",
      "          Best: Train: 0.032613, Val: 0.014433, Total: 0.030340 (Epoch 42)\n",
      "Epoch   45: Train: 0.031017, Val: 0.010915, Total: 0.028504, LR: 8.89e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.031017, Val: 0.010915, Total: 0.028504 (Epoch 45)\n",
      "Epoch   46: Train: 0.027748, Val: 0.010328, Total: 0.025570, LR: 9.09e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.027748, Val: 0.010328, Total: 0.025570 (Epoch 46)\n",
      "Epoch   47: Train: 0.025891, Val: 0.011377, Total: 0.024076, LR: 9.29e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.025891, Val: 0.011377, Total: 0.024076 (Epoch 47)\n",
      "Epoch   48: Train: 0.026019, Val: 0.010484, Total: 0.024077, LR: 9.49e-05 [WARMUP]\n",
      "          Best: Train: 0.025891, Val: 0.011377, Total: 0.024076 (Epoch 47)\n",
      "Epoch   49: Train: 0.022914, Val: 0.009899, Total: 0.021287, LR: 9.68e-05 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.022914, Val: 0.009899, Total: 0.021287 (Epoch 49)\n",
      "Epoch   50: Train: 0.023744, Val: 0.008781, Total: 0.021874, LR: 9.88e-05 [WARMUP]\n",
      "          Best: Train: 0.022914, Val: 0.009899, Total: 0.021287 (Epoch 49)\n",
      "Epoch   51: Train: 0.021665, Val: 0.006962, Total: 0.019827, LR: 1.01e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.021665, Val: 0.006962, Total: 0.019827 (Epoch 51)\n",
      "Epoch   52: Train: 0.020899, Val: 0.006584, Total: 0.019109, LR: 1.03e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.020899, Val: 0.006584, Total: 0.019109 (Epoch 52)\n",
      "Epoch   53: Train: 0.021559, Val: 0.003909, Total: 0.019353, LR: 1.05e-04 [WARMUP]\n",
      "          Best: Train: 0.020899, Val: 0.006584, Total: 0.019109 (Epoch 52)\n",
      "Epoch   54: Train: 0.019568, Val: 0.003659, Total: 0.017579, LR: 1.07e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.019568, Val: 0.003659, Total: 0.017579 (Epoch 54)\n",
      "Epoch   55: Train: 0.020057, Val: 0.005297, Total: 0.018212, LR: 1.09e-04 [WARMUP]\n",
      "          Best: Train: 0.019568, Val: 0.003659, Total: 0.017579 (Epoch 54)\n",
      "Epoch   56: Train: 0.017187, Val: 0.003849, Total: 0.015520, LR: 1.11e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.017187, Val: 0.003849, Total: 0.015520 (Epoch 56)\n",
      "Epoch   57: Train: 0.017426, Val: 0.003629, Total: 0.015701, LR: 1.13e-04 [WARMUP]\n",
      "          Best: Train: 0.017187, Val: 0.003849, Total: 0.015520 (Epoch 56)\n",
      "Epoch   58: Train: 0.017640, Val: 0.003651, Total: 0.015891, LR: 1.15e-04 [WARMUP]\n",
      "          Best: Train: 0.017187, Val: 0.003849, Total: 0.015520 (Epoch 56)\n",
      "Epoch   59: Train: 0.016576, Val: 0.003246, Total: 0.014910, LR: 1.17e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.016576, Val: 0.003246, Total: 0.014910 (Epoch 59)\n",
      "Epoch   60: Train: 0.016122, Val: 0.002819, Total: 0.014459, LR: 1.19e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.016122, Val: 0.002819, Total: 0.014459 (Epoch 60)\n",
      "Epoch   61: Train: 0.015370, Val: 0.002716, Total: 0.013788, LR: 1.21e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.015370, Val: 0.002716, Total: 0.013788 (Epoch 61)\n",
      "Epoch   62: Train: 0.013928, Val: 0.002708, Total: 0.012526, LR: 1.23e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.013928, Val: 0.002708, Total: 0.012526 (Epoch 62)\n",
      "Epoch   63: Train: 0.013626, Val: 0.003057, Total: 0.012305, LR: 1.25e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.013626, Val: 0.003057, Total: 0.012305 (Epoch 63)\n",
      "Epoch   64: Train: 0.014499, Val: 0.002471, Total: 0.012996, LR: 1.26e-04 [WARMUP]\n",
      "          Best: Train: 0.013626, Val: 0.003057, Total: 0.012305 (Epoch 63)\n",
      "Epoch   65: Train: 0.013995, Val: 0.002945, Total: 0.012614, LR: 1.28e-04 [WARMUP]\n",
      "          Best: Train: 0.013626, Val: 0.003057, Total: 0.012305 (Epoch 63)\n",
      "Epoch   66: Train: 0.013752, Val: 0.002581, Total: 0.012355, LR: 1.30e-04 [WARMUP]\n",
      "          Best: Train: 0.013626, Val: 0.003057, Total: 0.012305 (Epoch 63)\n",
      "Epoch   67: Train: 0.012223, Val: 0.002501, Total: 0.011008, LR: 1.32e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.012223, Val: 0.002501, Total: 0.011008 (Epoch 67)\n",
      "Epoch   68: Train: 0.011751, Val: 0.002651, Total: 0.010614, LR: 1.34e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.011751, Val: 0.002651, Total: 0.010614 (Epoch 68)\n",
      "Epoch   69: Train: 0.011473, Val: 0.003104, Total: 0.010427, LR: 1.36e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.011473, Val: 0.003104, Total: 0.010427 (Epoch 69)\n",
      "Epoch   70: Train: 0.012093, Val: 0.002513, Total: 0.010895, LR: 1.38e-04 [WARMUP]\n",
      "          Best: Train: 0.011473, Val: 0.003104, Total: 0.010427 (Epoch 69)\n",
      "Epoch   71: Train: 0.010948, Val: 0.002623, Total: 0.009908, LR: 1.40e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010948, Val: 0.002623, Total: 0.009908 (Epoch 71)\n",
      "Epoch   72: Train: 0.010231, Val: 0.003213, Total: 0.009354, LR: 1.42e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010231, Val: 0.003213, Total: 0.009354 (Epoch 72)\n",
      "Epoch   73: Train: 0.010510, Val: 0.003211, Total: 0.009598, LR: 1.44e-04 [WARMUP]\n",
      "          Best: Train: 0.010231, Val: 0.003213, Total: 0.009354 (Epoch 72)\n",
      "Epoch   74: Train: 0.010034, Val: 0.003166, Total: 0.009176, LR: 1.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.010034, Val: 0.003166, Total: 0.009176 (Epoch 74)\n",
      "Epoch   75: Train: 0.010748, Val: 0.003307, Total: 0.009818, LR: 1.48e-04 [WARMUP]\n",
      "          Best: Train: 0.010034, Val: 0.003166, Total: 0.009176 (Epoch 74)\n",
      "Epoch   76: Train: 0.010283, Val: 0.003104, Total: 0.009386, LR: 1.50e-04 [WARMUP]\n",
      "          Best: Train: 0.010034, Val: 0.003166, Total: 0.009176 (Epoch 74)\n",
      "Epoch   77: Train: 0.009890, Val: 0.003175, Total: 0.009051, LR: 1.52e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.009890, Val: 0.003175, Total: 0.009051 (Epoch 77)\n",
      "Epoch   78: Train: 0.009348, Val: 0.003428, Total: 0.008608, LR: 1.54e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.009348, Val: 0.003428, Total: 0.008608 (Epoch 78)\n",
      "Epoch   79: Train: 0.008501, Val: 0.004327, Total: 0.007979, LR: 1.56e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008501, Val: 0.004327, Total: 0.007979 (Epoch 79)\n",
      "Epoch   80: Train: 0.008379, Val: 0.003596, Total: 0.007781, LR: 1.58e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008379, Val: 0.003596, Total: 0.007781 (Epoch 80)\n",
      "Epoch   81: Train: 0.008435, Val: 0.003381, Total: 0.007803, LR: 1.60e-04 [WARMUP]\n",
      "          Best: Train: 0.008379, Val: 0.003596, Total: 0.007781 (Epoch 80)\n",
      "Epoch   82: Train: 0.008368, Val: 0.003521, Total: 0.007762, LR: 1.62e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008368, Val: 0.003521, Total: 0.007762 (Epoch 82)\n",
      "Epoch   83: Train: 0.008302, Val: 0.003322, Total: 0.007679, LR: 1.64e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008302, Val: 0.003322, Total: 0.007679 (Epoch 83)\n",
      "Epoch   84: Train: 0.008256, Val: 0.003327, Total: 0.007640, LR: 1.66e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.008256, Val: 0.003327, Total: 0.007640 (Epoch 84)\n",
      "Epoch   85: Train: 0.007204, Val: 0.003621, Total: 0.006756, LR: 1.68e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.007204, Val: 0.003621, Total: 0.006756 (Epoch 85)\n",
      "Epoch   86: Train: 0.007592, Val: 0.004323, Total: 0.007183, LR: 1.70e-04 [WARMUP]\n",
      "          Best: Train: 0.007204, Val: 0.003621, Total: 0.006756 (Epoch 85)\n",
      "Epoch   87: Train: 0.007671, Val: 0.003298, Total: 0.007124, LR: 1.72e-04 [WARMUP]\n",
      "          Best: Train: 0.007204, Val: 0.003621, Total: 0.006756 (Epoch 85)\n",
      "Epoch   88: Train: 0.006934, Val: 0.003468, Total: 0.006501, LR: 1.74e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006934, Val: 0.003468, Total: 0.006501 (Epoch 88)\n",
      "Epoch   89: Train: 0.007630, Val: 0.003112, Total: 0.007065, LR: 1.76e-04 [WARMUP]\n",
      "          Best: Train: 0.006934, Val: 0.003468, Total: 0.006501 (Epoch 88)\n",
      "Epoch   90: Train: 0.006442, Val: 0.003035, Total: 0.006016, LR: 1.78e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006442, Val: 0.003035, Total: 0.006016 (Epoch 90)\n",
      "Epoch   91: Train: 0.006950, Val: 0.003023, Total: 0.006459, LR: 1.80e-04 [WARMUP]\n",
      "          Best: Train: 0.006442, Val: 0.003035, Total: 0.006016 (Epoch 90)\n",
      "Epoch   92: Train: 0.006728, Val: 0.003337, Total: 0.006304, LR: 1.82e-04 [WARMUP]\n",
      "          Best: Train: 0.006442, Val: 0.003035, Total: 0.006016 (Epoch 90)\n",
      "Epoch   93: Train: 0.006680, Val: 0.002978, Total: 0.006218, LR: 1.84e-04 [WARMUP]\n",
      "          Best: Train: 0.006442, Val: 0.003035, Total: 0.006016 (Epoch 90)\n",
      "Epoch   94: Train: 0.006741, Val: 0.003218, Total: 0.006301, LR: 1.86e-04 [WARMUP]\n",
      "          Best: Train: 0.006442, Val: 0.003035, Total: 0.006016 (Epoch 90)\n",
      "Epoch   95: Train: 0.006277, Val: 0.004093, Total: 0.006004, LR: 1.88e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006277, Val: 0.004093, Total: 0.006004 (Epoch 95)\n",
      "Epoch   96: Train: 0.006057, Val: 0.004210, Total: 0.005827, LR: 1.90e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.006057, Val: 0.004210, Total: 0.005827 (Epoch 96)\n",
      "Epoch   97: Train: 0.005970, Val: 0.003860, Total: 0.005707, LR: 1.92e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005970, Val: 0.003860, Total: 0.005707 (Epoch 97)\n",
      "Epoch   98: Train: 0.005701, Val: 0.003357, Total: 0.005408, LR: 1.94e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005701, Val: 0.003357, Total: 0.005408 (Epoch 98)\n",
      "Epoch   99: Train: 0.005450, Val: 0.003110, Total: 0.005158, LR: 1.96e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005450, Val: 0.003110, Total: 0.005158 (Epoch 99)\n",
      "Epoch  100: Train: 0.005575, Val: 0.002738, Total: 0.005220, LR: 1.98e-04 [WARMUP]\n",
      "          Best: Train: 0.005450, Val: 0.003110, Total: 0.005158 (Epoch 99)\n",
      "Epoch  101: Train: 0.005345, Val: 0.002876, Total: 0.005037, LR: 2.00e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005345, Val: 0.002876, Total: 0.005037 (Epoch 101)\n",
      "Epoch  102: Train: 0.005745, Val: 0.002652, Total: 0.005359, LR: 2.02e-04 [WARMUP]\n",
      "          Best: Train: 0.005345, Val: 0.002876, Total: 0.005037 (Epoch 101)\n",
      "Epoch  103: Train: 0.005695, Val: 0.003751, Total: 0.005452, LR: 2.04e-04 [WARMUP]\n",
      "          Best: Train: 0.005345, Val: 0.002876, Total: 0.005037 (Epoch 101)\n",
      "Epoch  104: Train: 0.005102, Val: 0.003289, Total: 0.004876, LR: 2.06e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.005102, Val: 0.003289, Total: 0.004876 (Epoch 104)\n",
      "Epoch  105: Train: 0.004971, Val: 0.002841, Total: 0.004705, LR: 2.08e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004971, Val: 0.002841, Total: 0.004705 (Epoch 105)\n",
      "Epoch  106: Train: 0.005085, Val: 0.003029, Total: 0.004828, LR: 2.10e-04 [WARMUP]\n",
      "          Best: Train: 0.004971, Val: 0.002841, Total: 0.004705 (Epoch 105)\n",
      "Epoch  107: Train: 0.004784, Val: 0.003081, Total: 0.004571, LR: 2.11e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004784, Val: 0.003081, Total: 0.004571 (Epoch 107)\n",
      "Epoch  108: Train: 0.005033, Val: 0.002382, Total: 0.004701, LR: 2.13e-04 [WARMUP]\n",
      "          Best: Train: 0.004784, Val: 0.003081, Total: 0.004571 (Epoch 107)\n",
      "Epoch  109: Train: 0.004718, Val: 0.002413, Total: 0.004430, LR: 2.15e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004718, Val: 0.002413, Total: 0.004430 (Epoch 109)\n",
      "Epoch  110: Train: 0.005103, Val: 0.002682, Total: 0.004801, LR: 2.17e-04 [WARMUP]\n",
      "          Best: Train: 0.004718, Val: 0.002413, Total: 0.004430 (Epoch 109)\n",
      "Epoch  111: Train: 0.004650, Val: 0.003284, Total: 0.004479, LR: 2.19e-04 [WARMUP]\n",
      "          Best: Train: 0.004718, Val: 0.002413, Total: 0.004430 (Epoch 109)\n",
      "Epoch  112: Train: 0.004578, Val: 0.003899, Total: 0.004493, LR: 2.21e-04 [WARMUP]\n",
      "          Best: Train: 0.004718, Val: 0.002413, Total: 0.004430 (Epoch 109)\n",
      "Epoch  113: Train: 0.004623, Val: 0.003114, Total: 0.004434, LR: 2.23e-04 [WARMUP]\n",
      "          Best: Train: 0.004718, Val: 0.002413, Total: 0.004430 (Epoch 109)\n",
      "Epoch  114: Train: 0.004173, Val: 0.002921, Total: 0.004016, LR: 2.25e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004173, Val: 0.002921, Total: 0.004016 (Epoch 114)\n",
      "Epoch  115: Train: 0.004731, Val: 0.004045, Total: 0.004645, LR: 2.27e-04 [WARMUP]\n",
      "          Best: Train: 0.004173, Val: 0.002921, Total: 0.004016 (Epoch 114)\n",
      "Epoch  116: Train: 0.004549, Val: 0.003618, Total: 0.004433, LR: 2.29e-04 [WARMUP]\n",
      "          Best: Train: 0.004173, Val: 0.002921, Total: 0.004016 (Epoch 114)\n",
      "Epoch  117: Train: 0.004364, Val: 0.003300, Total: 0.004231, LR: 2.31e-04 [WARMUP]\n",
      "          Best: Train: 0.004173, Val: 0.002921, Total: 0.004016 (Epoch 114)\n",
      "Epoch  118: Train: 0.004156, Val: 0.002937, Total: 0.004003, LR: 2.33e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.004156, Val: 0.002937, Total: 0.004003 (Epoch 118)\n",
      "Epoch  119: Train: 0.004228, Val: 0.002582, Total: 0.004022, LR: 2.35e-04 [WARMUP]\n",
      "          Best: Train: 0.004156, Val: 0.002937, Total: 0.004003 (Epoch 118)\n",
      "Epoch  120: Train: 0.004242, Val: 0.002861, Total: 0.004069, LR: 2.37e-04 [WARMUP]\n",
      "          Best: Train: 0.004156, Val: 0.002937, Total: 0.004003 (Epoch 118)\n",
      "Epoch  121: Train: 0.003940, Val: 0.002601, Total: 0.003773, LR: 2.39e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003940, Val: 0.002601, Total: 0.003773 (Epoch 121)\n",
      "Epoch  122: Train: 0.004175, Val: 0.002562, Total: 0.003974, LR: 2.41e-04 [WARMUP]\n",
      "          Best: Train: 0.003940, Val: 0.002601, Total: 0.003773 (Epoch 121)\n",
      "Epoch  123: Train: 0.003932, Val: 0.002687, Total: 0.003777, LR: 2.43e-04 [WARMUP]\n",
      "          Best: Train: 0.003940, Val: 0.002601, Total: 0.003773 (Epoch 121)\n",
      "Epoch  124: Train: 0.004124, Val: 0.003307, Total: 0.004022, LR: 2.45e-04 [WARMUP]\n",
      "          Best: Train: 0.003940, Val: 0.002601, Total: 0.003773 (Epoch 121)\n",
      "Epoch  125: Train: 0.004019, Val: 0.002204, Total: 0.003792, LR: 2.47e-04 [WARMUP]\n",
      "          Best: Train: 0.003940, Val: 0.002601, Total: 0.003773 (Epoch 121)\n",
      "Epoch  126: Train: 0.003618, Val: 0.002430, Total: 0.003470, LR: 2.49e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003618, Val: 0.002430, Total: 0.003470 (Epoch 126)\n",
      "Epoch  127: Train: 0.003585, Val: 0.002718, Total: 0.003477, LR: 2.51e-04 [WARMUP]\n",
      "          Best: Train: 0.003618, Val: 0.002430, Total: 0.003470 (Epoch 126)\n",
      "Epoch  128: Train: 0.003635, Val: 0.002477, Total: 0.003490, LR: 2.53e-04 [WARMUP]\n",
      "          Best: Train: 0.003618, Val: 0.002430, Total: 0.003470 (Epoch 126)\n",
      "Epoch  129: Train: 0.003487, Val: 0.001931, Total: 0.003292, LR: 2.55e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003487, Val: 0.001931, Total: 0.003292 (Epoch 129)\n",
      "Epoch  130: Train: 0.003408, Val: 0.001915, Total: 0.003222, LR: 2.57e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003408, Val: 0.001915, Total: 0.003222 (Epoch 130)\n",
      "Epoch  131: Train: 0.003458, Val: 0.001901, Total: 0.003263, LR: 2.59e-04 [WARMUP]\n",
      "          Best: Train: 0.003408, Val: 0.001915, Total: 0.003222 (Epoch 130)\n",
      "Epoch  132: Train: 0.003649, Val: 0.001984, Total: 0.003441, LR: 2.61e-04 [WARMUP]\n",
      "          Best: Train: 0.003408, Val: 0.001915, Total: 0.003222 (Epoch 130)\n",
      "Epoch  133: Train: 0.003402, Val: 0.003003, Total: 0.003352, LR: 2.63e-04 [WARMUP]\n",
      "          Best: Train: 0.003408, Val: 0.001915, Total: 0.003222 (Epoch 130)\n",
      "Epoch  134: Train: 0.003481, Val: 0.002007, Total: 0.003297, LR: 2.65e-04 [WARMUP]\n",
      "          Best: Train: 0.003408, Val: 0.001915, Total: 0.003222 (Epoch 130)\n",
      "Epoch  135: Train: 0.003331, Val: 0.002298, Total: 0.003202, LR: 2.67e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.003331, Val: 0.002298, Total: 0.003202 (Epoch 135)\n",
      "Epoch  136: Train: 0.002904, Val: 0.002574, Total: 0.002863, LR: 2.69e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002904, Val: 0.002574, Total: 0.002863 (Epoch 136)\n",
      "Epoch  137: Train: 0.003232, Val: 0.002023, Total: 0.003081, LR: 2.71e-04 [WARMUP]\n",
      "          Best: Train: 0.002904, Val: 0.002574, Total: 0.002863 (Epoch 136)\n",
      "Epoch  138: Train: 0.003102, Val: 0.001885, Total: 0.002950, LR: 2.73e-04 [WARMUP]\n",
      "          Best: Train: 0.002904, Val: 0.002574, Total: 0.002863 (Epoch 136)\n",
      "Epoch  139: Train: 0.003125, Val: 0.001896, Total: 0.002971, LR: 2.75e-04 [WARMUP]\n",
      "          Best: Train: 0.002904, Val: 0.002574, Total: 0.002863 (Epoch 136)\n",
      "Epoch  140: Train: 0.002891, Val: 0.001763, Total: 0.002750, LR: 2.77e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002891, Val: 0.001763, Total: 0.002750 (Epoch 140)\n",
      "Epoch  141: Train: 0.003068, Val: 0.002001, Total: 0.002934, LR: 2.79e-04 [WARMUP]\n",
      "          Best: Train: 0.002891, Val: 0.001763, Total: 0.002750 (Epoch 140)\n",
      "Epoch  142: Train: 0.002951, Val: 0.001771, Total: 0.002803, LR: 2.81e-04 [WARMUP]\n",
      "          Best: Train: 0.002891, Val: 0.001763, Total: 0.002750 (Epoch 140)\n",
      "Epoch  143: Train: 0.002626, Val: 0.001884, Total: 0.002533, LR: 2.83e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002626, Val: 0.001884, Total: 0.002533 (Epoch 143)\n",
      "Epoch  144: Train: 0.002636, Val: 0.001773, Total: 0.002528, LR: 2.85e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002636, Val: 0.001773, Total: 0.002528 (Epoch 144)\n",
      "Epoch  145: Train: 0.002605, Val: 0.001745, Total: 0.002498, LR: 2.87e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002605, Val: 0.001745, Total: 0.002498 (Epoch 145)\n",
      "Epoch  146: Train: 0.002721, Val: 0.002206, Total: 0.002657, LR: 2.89e-04 [WARMUP]\n",
      "          Best: Train: 0.002605, Val: 0.001745, Total: 0.002498 (Epoch 145)\n",
      "Epoch  147: Train: 0.002908, Val: 0.001691, Total: 0.002756, LR: 2.91e-04 [WARMUP]\n",
      "          Best: Train: 0.002605, Val: 0.001745, Total: 0.002498 (Epoch 145)\n",
      "Epoch  148: Train: 0.002500, Val: 0.001525, Total: 0.002378, LR: 2.93e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  149: Train: 0.002627, Val: 0.001891, Total: 0.002535, LR: 2.94e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  150: Train: 0.002572, Val: 0.001546, Total: 0.002444, LR: 2.96e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  151: Train: 0.002625, Val: 0.001640, Total: 0.002502, LR: 2.98e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  152: Train: 0.002551, Val: 0.002418, Total: 0.002535, LR: 3.00e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  153: Train: 0.002811, Val: 0.001741, Total: 0.002678, LR: 3.02e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  154: Train: 0.002669, Val: 0.001552, Total: 0.002530, LR: 3.04e-04 [WARMUP]\n",
      "          Best: Train: 0.002500, Val: 0.001525, Total: 0.002378 (Epoch 148)\n",
      "Epoch  155: Train: 0.002362, Val: 0.001610, Total: 0.002268, LR: 3.06e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002362, Val: 0.001610, Total: 0.002268 (Epoch 155)\n",
      "Epoch  156: Train: 0.002369, Val: 0.001544, Total: 0.002266, LR: 3.08e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002369, Val: 0.001544, Total: 0.002266 (Epoch 156)\n",
      "Epoch  157: Train: 0.002357, Val: 0.001541, Total: 0.002255, LR: 3.10e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002357, Val: 0.001541, Total: 0.002255 (Epoch 157)\n",
      "Epoch  158: Train: 0.002312, Val: 0.001401, Total: 0.002198, LR: 3.12e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002312, Val: 0.001401, Total: 0.002198 (Epoch 158)\n",
      "Epoch  159: Train: 0.002276, Val: 0.001449, Total: 0.002172, LR: 3.14e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002276, Val: 0.001449, Total: 0.002172 (Epoch 159)\n",
      "Epoch  160: Train: 0.002285, Val: 0.001606, Total: 0.002200, LR: 3.16e-04 [WARMUP]\n",
      "          Best: Train: 0.002276, Val: 0.001449, Total: 0.002172 (Epoch 159)\n",
      "Epoch  161: Train: 0.002231, Val: 0.001475, Total: 0.002136, LR: 3.18e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002231, Val: 0.001475, Total: 0.002136 (Epoch 161)\n",
      "Epoch  162: Train: 0.002241, Val: 0.001606, Total: 0.002162, LR: 3.20e-04 [WARMUP]\n",
      "          Best: Train: 0.002231, Val: 0.001475, Total: 0.002136 (Epoch 161)\n",
      "Epoch  163: Train: 0.002302, Val: 0.001444, Total: 0.002195, LR: 3.22e-04 [WARMUP]\n",
      "          Best: Train: 0.002231, Val: 0.001475, Total: 0.002136 (Epoch 161)\n",
      "Epoch  164: Train: 0.002187, Val: 0.001499, Total: 0.002101, LR: 3.24e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002187, Val: 0.001499, Total: 0.002101 (Epoch 164)\n",
      "Epoch  165: Train: 0.002152, Val: 0.001579, Total: 0.002080, LR: 3.26e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002152, Val: 0.001579, Total: 0.002080 (Epoch 165)\n",
      "Epoch  166: Train: 0.002134, Val: 0.001875, Total: 0.002102, LR: 3.28e-04 [WARMUP]\n",
      "          Best: Train: 0.002152, Val: 0.001579, Total: 0.002080 (Epoch 165)\n",
      "Epoch  167: Train: 0.002092, Val: 0.001530, Total: 0.002021, LR: 3.30e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.002092, Val: 0.001530, Total: 0.002021 (Epoch 167)\n",
      "Epoch  168: Train: 0.002091, Val: 0.001777, Total: 0.002052, LR: 3.32e-04 [WARMUP]\n",
      "          Best: Train: 0.002092, Val: 0.001530, Total: 0.002021 (Epoch 167)\n",
      "Epoch  169: Train: 0.002118, Val: 0.001623, Total: 0.002056, LR: 3.34e-04 [WARMUP]\n",
      "          Best: Train: 0.002092, Val: 0.001530, Total: 0.002021 (Epoch 167)\n",
      "Epoch  170: Train: 0.001953, Val: 0.001631, Total: 0.001912, LR: 3.36e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001953, Val: 0.001631, Total: 0.001912 (Epoch 170)\n",
      "Epoch  171: Train: 0.001894, Val: 0.001523, Total: 0.001848, LR: 3.38e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001894, Val: 0.001523, Total: 0.001848 (Epoch 171)\n",
      "Epoch  172: Train: 0.002017, Val: 0.001569, Total: 0.001961, LR: 3.40e-04 [WARMUP]\n",
      "          Best: Train: 0.001894, Val: 0.001523, Total: 0.001848 (Epoch 171)\n",
      "Epoch  173: Train: 0.001995, Val: 0.001516, Total: 0.001935, LR: 3.42e-04 [WARMUP]\n",
      "          Best: Train: 0.001894, Val: 0.001523, Total: 0.001848 (Epoch 171)\n",
      "Epoch  174: Train: 0.001958, Val: 0.001551, Total: 0.001907, LR: 3.44e-04 [WARMUP]\n",
      "          Best: Train: 0.001894, Val: 0.001523, Total: 0.001848 (Epoch 171)\n",
      "Epoch  175: Train: 0.001849, Val: 0.001430, Total: 0.001797, LR: 3.46e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001849, Val: 0.001430, Total: 0.001797 (Epoch 175)\n",
      "Epoch  176: Train: 0.001815, Val: 0.001481, Total: 0.001773, LR: 3.48e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001815, Val: 0.001481, Total: 0.001773 (Epoch 176)\n",
      "Epoch  177: Train: 0.001835, Val: 0.001420, Total: 0.001783, LR: 3.50e-04 [WARMUP]\n",
      "          Best: Train: 0.001815, Val: 0.001481, Total: 0.001773 (Epoch 176)\n",
      "Epoch  178: Train: 0.001872, Val: 0.001669, Total: 0.001847, LR: 3.52e-04 [WARMUP]\n",
      "          Best: Train: 0.001815, Val: 0.001481, Total: 0.001773 (Epoch 176)\n",
      "Epoch  179: Train: 0.001873, Val: 0.001542, Total: 0.001832, LR: 3.54e-04 [WARMUP]\n",
      "          Best: Train: 0.001815, Val: 0.001481, Total: 0.001773 (Epoch 176)\n",
      "Epoch  180: Train: 0.001886, Val: 0.001251, Total: 0.001807, LR: 3.56e-04 [WARMUP]\n",
      "          Best: Train: 0.001815, Val: 0.001481, Total: 0.001773 (Epoch 176)\n",
      "Epoch  181: Train: 0.001795, Val: 0.001481, Total: 0.001756, LR: 3.58e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001795, Val: 0.001481, Total: 0.001756 (Epoch 181)\n",
      "Epoch  182: Train: 0.001953, Val: 0.001463, Total: 0.001892, LR: 3.60e-04 [WARMUP]\n",
      "          Best: Train: 0.001795, Val: 0.001481, Total: 0.001756 (Epoch 181)\n",
      "Epoch  183: Train: 0.001898, Val: 0.001218, Total: 0.001813, LR: 3.62e-04 [WARMUP]\n",
      "          Best: Train: 0.001795, Val: 0.001481, Total: 0.001756 (Epoch 181)\n",
      "Epoch  184: Train: 0.001970, Val: 0.001468, Total: 0.001907, LR: 3.64e-04 [WARMUP]\n",
      "          Best: Train: 0.001795, Val: 0.001481, Total: 0.001756 (Epoch 181)\n",
      "Epoch  185: Train: 0.001720, Val: 0.001301, Total: 0.001667, LR: 3.66e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001720, Val: 0.001301, Total: 0.001667 (Epoch 185)\n",
      "Epoch  186: Train: 0.001827, Val: 0.001574, Total: 0.001795, LR: 3.68e-04 [WARMUP]\n",
      "          Best: Train: 0.001720, Val: 0.001301, Total: 0.001667 (Epoch 185)\n",
      "Epoch  187: Train: 0.001970, Val: 0.001272, Total: 0.001883, LR: 3.70e-04 [WARMUP]\n",
      "          Best: Train: 0.001720, Val: 0.001301, Total: 0.001667 (Epoch 185)\n",
      "Epoch  188: Train: 0.001697, Val: 0.001340, Total: 0.001652, LR: 3.72e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001697, Val: 0.001340, Total: 0.001652 (Epoch 188)\n",
      "Epoch  189: Train: 0.001721, Val: 0.001539, Total: 0.001698, LR: 3.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001697, Val: 0.001340, Total: 0.001652 (Epoch 188)\n",
      "Epoch  190: Train: 0.001741, Val: 0.001240, Total: 0.001678, LR: 3.76e-04 [WARMUP]\n",
      "          Best: Train: 0.001697, Val: 0.001340, Total: 0.001652 (Epoch 188)\n",
      "Epoch  191: Train: 0.001601, Val: 0.001432, Total: 0.001580, LR: 3.77e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  192: Train: 0.001650, Val: 0.001486, Total: 0.001629, LR: 3.79e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  193: Train: 0.001816, Val: 0.001494, Total: 0.001776, LR: 3.81e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  194: Train: 0.001617, Val: 0.001554, Total: 0.001610, LR: 3.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  195: Train: 0.001706, Val: 0.001308, Total: 0.001656, LR: 3.85e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  196: Train: 0.001774, Val: 0.001308, Total: 0.001716, LR: 3.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  197: Train: 0.001712, Val: 0.001413, Total: 0.001674, LR: 3.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001601, Val: 0.001432, Total: 0.001580 (Epoch 191)\n",
      "Epoch  198: Train: 0.001547, Val: 0.001274, Total: 0.001513, LR: 3.91e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001547, Val: 0.001274, Total: 0.001513 (Epoch 198)\n",
      "Epoch  199: Train: 0.001637, Val: 0.001525, Total: 0.001623, LR: 3.93e-04 [WARMUP]\n",
      "          Best: Train: 0.001547, Val: 0.001274, Total: 0.001513 (Epoch 198)\n",
      "Epoch  200: Train: 0.001695, Val: 0.001323, Total: 0.001648, LR: 3.95e-04 [WARMUP]\n",
      "          Best: Train: 0.001547, Val: 0.001274, Total: 0.001513 (Epoch 198)\n",
      "Epoch  201: Train: 0.001693, Val: 0.001287, Total: 0.001642, LR: 3.97e-04 [WARMUP]\n",
      "          Best: Train: 0.001547, Val: 0.001274, Total: 0.001513 (Epoch 198)\n",
      "Epoch  202: Train: 0.001643, Val: 0.001335, Total: 0.001605, LR: 3.99e-04 [WARMUP]\n",
      "          Best: Train: 0.001547, Val: 0.001274, Total: 0.001513 (Epoch 198)\n",
      "Epoch  203: Train: 0.001511, Val: 0.001382, Total: 0.001495, LR: 4.01e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001511, Val: 0.001382, Total: 0.001495 (Epoch 203)\n",
      "Epoch  204: Train: 0.001630, Val: 0.001384, Total: 0.001599, LR: 4.03e-04 [WARMUP]\n",
      "          Best: Train: 0.001511, Val: 0.001382, Total: 0.001495 (Epoch 203)\n",
      "Epoch  205: Train: 0.001550, Val: 0.001470, Total: 0.001540, LR: 4.05e-04 [WARMUP]\n",
      "          Best: Train: 0.001511, Val: 0.001382, Total: 0.001495 (Epoch 203)\n",
      "Epoch  206: Train: 0.001651, Val: 0.001413, Total: 0.001622, LR: 4.07e-04 [WARMUP]\n",
      "          Best: Train: 0.001511, Val: 0.001382, Total: 0.001495 (Epoch 203)\n",
      "Epoch  207: Train: 0.001516, Val: 0.001299, Total: 0.001489, LR: 4.09e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001516, Val: 0.001299, Total: 0.001489 (Epoch 207)\n",
      "Epoch  208: Train: 0.001562, Val: 0.001235, Total: 0.001521, LR: 4.11e-04 [WARMUP]\n",
      "          Best: Train: 0.001516, Val: 0.001299, Total: 0.001489 (Epoch 207)\n",
      "Epoch  209: Train: 0.001490, Val: 0.001425, Total: 0.001482, LR: 4.13e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.001425, Total: 0.001482 (Epoch 209)\n",
      "Epoch  210: Train: 0.001628, Val: 0.001369, Total: 0.001596, LR: 4.15e-04 [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.001425, Total: 0.001482 (Epoch 209)\n",
      "Epoch  211: Train: 0.001575, Val: 0.001167, Total: 0.001524, LR: 4.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.001425, Total: 0.001482 (Epoch 209)\n",
      "Epoch  212: Train: 0.001569, Val: 0.001625, Total: 0.001576, LR: 4.19e-04 [WARMUP]\n",
      "          Best: Train: 0.001490, Val: 0.001425, Total: 0.001482 (Epoch 209)\n",
      "Epoch  213: Train: 0.001407, Val: 0.001237, Total: 0.001386, LR: 4.21e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  214: Train: 0.001478, Val: 0.001407, Total: 0.001469, LR: 4.23e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  215: Train: 0.001498, Val: 0.001155, Total: 0.001455, LR: 4.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  216: Train: 0.001626, Val: 0.001610, Total: 0.001624, LR: 4.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  217: Train: 0.001631, Val: 0.002079, Total: 0.001687, LR: 4.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  218: Train: 0.001609, Val: 0.001251, Total: 0.001564, LR: 4.31e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  219: Train: 0.001392, Val: 0.001854, Total: 0.001450, LR: 4.33e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  220: Train: 0.001514, Val: 0.001719, Total: 0.001540, LR: 4.35e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  221: Train: 0.001568, Val: 0.001313, Total: 0.001536, LR: 4.37e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  222: Train: 0.001436, Val: 0.001744, Total: 0.001475, LR: 4.39e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  223: Train: 0.001500, Val: 0.001580, Total: 0.001510, LR: 4.41e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  224: Train: 0.001451, Val: 0.001742, Total: 0.001488, LR: 4.43e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  225: Train: 0.001420, Val: 0.001552, Total: 0.001437, LR: 4.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001407, Val: 0.001237, Total: 0.001386 (Epoch 213)\n",
      "Epoch  226: Train: 0.001391, Val: 0.001309, Total: 0.001381, LR: 4.47e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  227: Train: 0.001438, Val: 0.001565, Total: 0.001454, LR: 4.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  228: Train: 0.001453, Val: 0.001459, Total: 0.001454, LR: 4.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  229: Train: 0.001477, Val: 0.001328, Total: 0.001459, LR: 4.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  230: Train: 0.001439, Val: 0.001492, Total: 0.001446, LR: 4.55e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  231: Train: 0.001398, Val: 0.001405, Total: 0.001399, LR: 4.57e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  232: Train: 0.001423, Val: 0.001352, Total: 0.001414, LR: 4.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  233: Train: 0.001550, Val: 0.001877, Total: 0.001591, LR: 4.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  234: Train: 0.001523, Val: 0.001281, Total: 0.001492, LR: 4.62e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  235: Train: 0.001401, Val: 0.001816, Total: 0.001452, LR: 4.64e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  236: Train: 0.001544, Val: 0.001206, Total: 0.001501, LR: 4.66e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  237: Train: 0.001410, Val: 0.001704, Total: 0.001447, LR: 4.68e-04 [WARMUP]\n",
      "          Best: Train: 0.001391, Val: 0.001309, Total: 0.001381 (Epoch 226)\n",
      "Epoch  238: Train: 0.001349, Val: 0.001312, Total: 0.001344, LR: 4.70e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001349, Val: 0.001312, Total: 0.001344 (Epoch 238)\n",
      "Epoch  239: Train: 0.001316, Val: 0.001395, Total: 0.001326, LR: 4.72e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001316, Val: 0.001395, Total: 0.001326 (Epoch 239)\n",
      "Epoch  240: Train: 0.001409, Val: 0.001478, Total: 0.001418, LR: 4.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001316, Val: 0.001395, Total: 0.001326 (Epoch 239)\n",
      "Epoch  241: Train: 0.001285, Val: 0.001330, Total: 0.001290, LR: 4.76e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001285, Val: 0.001330, Total: 0.001290 (Epoch 241)\n",
      "Epoch  242: Train: 0.001328, Val: 0.001502, Total: 0.001349, LR: 4.78e-04 [WARMUP]\n",
      "          Best: Train: 0.001285, Val: 0.001330, Total: 0.001290 (Epoch 241)\n",
      "Epoch  243: Train: 0.001246, Val: 0.001359, Total: 0.001260, LR: 4.80e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001246, Val: 0.001359, Total: 0.001260 (Epoch 243)\n",
      "Epoch  244: Train: 0.001317, Val: 0.001485, Total: 0.001338, LR: 4.82e-04 [WARMUP]\n",
      "          Best: Train: 0.001246, Val: 0.001359, Total: 0.001260 (Epoch 243)\n",
      "Epoch  245: Train: 0.001358, Val: 0.001418, Total: 0.001366, LR: 4.84e-04 [WARMUP]\n",
      "          Best: Train: 0.001246, Val: 0.001359, Total: 0.001260 (Epoch 243)\n",
      "Epoch  246: Train: 0.001323, Val: 0.001611, Total: 0.001359, LR: 4.86e-04 [WARMUP]\n",
      "          Best: Train: 0.001246, Val: 0.001359, Total: 0.001260 (Epoch 243)\n",
      "Epoch  247: Train: 0.001241, Val: 0.001351, Total: 0.001255, LR: 4.88e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  248: Train: 0.001284, Val: 0.001396, Total: 0.001298, LR: 4.90e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  249: Train: 0.001321, Val: 0.001300, Total: 0.001318, LR: 4.92e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  250: Train: 0.001303, Val: 0.001649, Total: 0.001346, LR: 4.94e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  251: Train: 0.001351, Val: 0.001351, Total: 0.001351, LR: 4.96e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  252: Train: 0.001280, Val: 0.001548, Total: 0.001314, LR: 4.98e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  253: Train: 0.001309, Val: 0.001397, Total: 0.001320, LR: 5.00e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  254: Train: 0.001292, Val: 0.001690, Total: 0.001342, LR: 5.02e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  255: Train: 0.001362, Val: 0.001400, Total: 0.001366, LR: 5.04e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  256: Train: 0.001286, Val: 0.001366, Total: 0.001296, LR: 5.06e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  257: Train: 0.001227, Val: 0.001462, Total: 0.001256, LR: 5.08e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  258: Train: 0.001300, Val: 0.001221, Total: 0.001290, LR: 5.10e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  259: Train: 0.001296, Val: 0.001470, Total: 0.001318, LR: 5.12e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  260: Train: 0.001319, Val: 0.001412, Total: 0.001331, LR: 5.14e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  261: Train: 0.001260, Val: 0.001469, Total: 0.001286, LR: 5.16e-04 [WARMUP]\n",
      "          Best: Train: 0.001241, Val: 0.001351, Total: 0.001255 (Epoch 247)\n",
      "Epoch  262: Train: 0.001221, Val: 0.001268, Total: 0.001227, LR: 5.18e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001221, Val: 0.001268, Total: 0.001227 (Epoch 262)\n",
      "Epoch  263: Train: 0.001204, Val: 0.001294, Total: 0.001215, LR: 5.20e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001204, Val: 0.001294, Total: 0.001215 (Epoch 263)\n",
      "Epoch  264: Train: 0.001197, Val: 0.001258, Total: 0.001205, LR: 5.22e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  265: Train: 0.001276, Val: 0.001374, Total: 0.001289, LR: 5.24e-04 [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  266: Train: 0.001293, Val: 0.001369, Total: 0.001302, LR: 5.26e-04 [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  267: Train: 0.001375, Val: 0.001550, Total: 0.001397, LR: 5.28e-04 [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  268: Train: 0.001206, Val: 0.001396, Total: 0.001230, LR: 5.30e-04 [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  269: Train: 0.001207, Val: 0.001617, Total: 0.001259, LR: 5.32e-04 [WARMUP]\n",
      "          Best: Train: 0.001197, Val: 0.001258, Total: 0.001205 (Epoch 264)\n",
      "Epoch  270: Train: 0.001160, Val: 0.001512, Total: 0.001204, LR: 5.34e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  271: Train: 0.001219, Val: 0.001582, Total: 0.001264, LR: 5.36e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  272: Train: 0.001282, Val: 0.001453, Total: 0.001303, LR: 5.38e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  273: Train: 0.001214, Val: 0.001646, Total: 0.001268, LR: 5.40e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  274: Train: 0.001190, Val: 0.001471, Total: 0.001225, LR: 5.42e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  275: Train: 0.001230, Val: 0.001706, Total: 0.001290, LR: 5.44e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  276: Train: 0.001261, Val: 0.001412, Total: 0.001280, LR: 5.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  277: Train: 0.001320, Val: 0.002277, Total: 0.001440, LR: 5.47e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  278: Train: 0.001264, Val: 0.001575, Total: 0.001303, LR: 5.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  279: Train: 0.001298, Val: 0.001793, Total: 0.001360, LR: 5.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  280: Train: 0.001390, Val: 0.001385, Total: 0.001389, LR: 5.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  281: Train: 0.001390, Val: 0.001636, Total: 0.001421, LR: 5.55e-04 [WARMUP]\n",
      "          Best: Train: 0.001160, Val: 0.001512, Total: 0.001204 (Epoch 270)\n",
      "Epoch  282: Train: 0.001171, Val: 0.001383, Total: 0.001197, LR: 5.57e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  283: Train: 0.001294, Val: 0.001686, Total: 0.001343, LR: 5.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  284: Train: 0.001239, Val: 0.001510, Total: 0.001273, LR: 5.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  285: Train: 0.001264, Val: 0.001890, Total: 0.001343, LR: 5.63e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  286: Train: 0.001163, Val: 0.001458, Total: 0.001200, LR: 5.65e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  287: Train: 0.001200, Val: 0.001604, Total: 0.001251, LR: 5.67e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  288: Train: 0.001218, Val: 0.001558, Total: 0.001261, LR: 5.69e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  289: Train: 0.001239, Val: 0.001619, Total: 0.001287, LR: 5.71e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  290: Train: 0.001201, Val: 0.001500, Total: 0.001238, LR: 5.73e-04 [WARMUP]\n",
      "          Best: Train: 0.001171, Val: 0.001383, Total: 0.001197 (Epoch 282)\n",
      "Epoch  291: Train: 0.001147, Val: 0.001424, Total: 0.001181, LR: 5.75e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001147, Val: 0.001424, Total: 0.001181 (Epoch 291)\n",
      "Epoch  292: Train: 0.001229, Val: 0.001575, Total: 0.001272, LR: 5.77e-04 [WARMUP]\n",
      "          Best: Train: 0.001147, Val: 0.001424, Total: 0.001181 (Epoch 291)\n",
      "Epoch  293: Train: 0.001274, Val: 0.001430, Total: 0.001294, LR: 5.79e-04 [WARMUP]\n",
      "          Best: Train: 0.001147, Val: 0.001424, Total: 0.001181 (Epoch 291)\n",
      "Epoch  294: Train: 0.001161, Val: 0.001325, Total: 0.001181, LR: 5.81e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  295: Train: 0.001268, Val: 0.001408, Total: 0.001285, LR: 5.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  296: Train: 0.001189, Val: 0.001328, Total: 0.001207, LR: 5.85e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  297: Train: 0.001209, Val: 0.001906, Total: 0.001296, LR: 5.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  298: Train: 0.001184, Val: 0.001479, Total: 0.001221, LR: 5.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  299: Train: 0.001202, Val: 0.001715, Total: 0.001266, LR: 5.91e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  300: Train: 0.001248, Val: 0.001408, Total: 0.001268, LR: 5.93e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  301: Train: 0.001190, Val: 0.001748, Total: 0.001259, LR: 5.95e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  302: Train: 0.001179, Val: 0.001578, Total: 0.001229, LR: 5.97e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  303: Train: 0.001264, Val: 0.001743, Total: 0.001324, LR: 5.99e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  304: Train: 0.001183, Val: 0.001329, Total: 0.001202, LR: 6.01e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  305: Train: 0.001170, Val: 0.001870, Total: 0.001257, LR: 6.03e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  306: Train: 0.001247, Val: 0.001312, Total: 0.001255, LR: 6.05e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  307: Train: 0.001173, Val: 0.001597, Total: 0.001226, LR: 6.07e-04 [WARMUP]\n",
      "          Best: Train: 0.001161, Val: 0.001325, Total: 0.001181 (Epoch 294)\n",
      "Epoch  308: Train: 0.001129, Val: 0.001197, Total: 0.001138, LR: 6.09e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001129, Val: 0.001197, Total: 0.001138 (Epoch 308)\n",
      "Epoch  309: Train: 0.001197, Val: 0.001539, Total: 0.001240, LR: 6.11e-04 [WARMUP]\n",
      "          Best: Train: 0.001129, Val: 0.001197, Total: 0.001138 (Epoch 308)\n",
      "Epoch  310: Train: 0.001129, Val: 0.001561, Total: 0.001183, LR: 6.13e-04 [WARMUP]\n",
      "          Best: Train: 0.001129, Val: 0.001197, Total: 0.001138 (Epoch 308)\n",
      "Epoch  311: Train: 0.001086, Val: 0.001493, Total: 0.001137, LR: 6.15e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  312: Train: 0.001146, Val: 0.001471, Total: 0.001187, LR: 6.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  313: Train: 0.001101, Val: 0.001554, Total: 0.001158, LR: 6.19e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  314: Train: 0.001117, Val: 0.001545, Total: 0.001171, LR: 6.21e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  315: Train: 0.001220, Val: 0.001622, Total: 0.001270, LR: 6.23e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  316: Train: 0.001102, Val: 0.001677, Total: 0.001174, LR: 6.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  317: Train: 0.001196, Val: 0.001651, Total: 0.001253, LR: 6.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  318: Train: 0.001094, Val: 0.001556, Total: 0.001151, LR: 6.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  319: Train: 0.001137, Val: 0.001550, Total: 0.001189, LR: 6.30e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  320: Train: 0.001097, Val: 0.001489, Total: 0.001146, LR: 6.32e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  321: Train: 0.001156, Val: 0.001907, Total: 0.001250, LR: 6.34e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  322: Train: 0.001222, Val: 0.001602, Total: 0.001270, LR: 6.36e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  323: Train: 0.001309, Val: 0.001880, Total: 0.001381, LR: 6.38e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  324: Train: 0.001143, Val: 0.001427, Total: 0.001178, LR: 6.40e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  325: Train: 0.001166, Val: 0.001347, Total: 0.001188, LR: 6.42e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  326: Train: 0.001207, Val: 0.001331, Total: 0.001222, LR: 6.44e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  327: Train: 0.001097, Val: 0.001603, Total: 0.001160, LR: 6.46e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  328: Train: 0.001118, Val: 0.001646, Total: 0.001184, LR: 6.48e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  329: Train: 0.001139, Val: 0.001686, Total: 0.001208, LR: 6.50e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  330: Train: 0.001142, Val: 0.001601, Total: 0.001200, LR: 6.52e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  331: Train: 0.001222, Val: 0.001682, Total: 0.001280, LR: 6.54e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  332: Train: 0.001229, Val: 0.001582, Total: 0.001273, LR: 6.56e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  333: Train: 0.001194, Val: 0.001615, Total: 0.001246, LR: 6.58e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  334: Train: 0.001159, Val: 0.001314, Total: 0.001178, LR: 6.60e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  335: Train: 0.001168, Val: 0.001868, Total: 0.001255, LR: 6.62e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  336: Train: 0.001284, Val: 0.001398, Total: 0.001298, LR: 6.64e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  337: Train: 0.001209, Val: 0.002251, Total: 0.001339, LR: 6.66e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  338: Train: 0.001221, Val: 0.001482, Total: 0.001253, LR: 6.68e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  339: Train: 0.001121, Val: 0.001561, Total: 0.001176, LR: 6.70e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  340: Train: 0.001125, Val: 0.001730, Total: 0.001200, LR: 6.72e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  341: Train: 0.001241, Val: 0.001283, Total: 0.001246, LR: 6.74e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  342: Train: 0.001090, Val: 0.001675, Total: 0.001163, LR: 6.76e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  343: Train: 0.001116, Val: 0.001407, Total: 0.001152, LR: 6.78e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  344: Train: 0.001127, Val: 0.001477, Total: 0.001171, LR: 6.80e-04 [WARMUP]\n",
      "          Best: Train: 0.001086, Val: 0.001493, Total: 0.001137 (Epoch 311)\n",
      "Epoch  345: Train: 0.001098, Val: 0.001290, Total: 0.001122, LR: 6.82e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001098, Val: 0.001290, Total: 0.001122 (Epoch 345)\n",
      "Epoch  346: Train: 0.001136, Val: 0.001690, Total: 0.001205, LR: 6.84e-04 [WARMUP]\n",
      "          Best: Train: 0.001098, Val: 0.001290, Total: 0.001122 (Epoch 345)\n",
      "Epoch  347: Train: 0.001157, Val: 0.001498, Total: 0.001200, LR: 6.86e-04 [WARMUP]\n",
      "          Best: Train: 0.001098, Val: 0.001290, Total: 0.001122 (Epoch 345)\n",
      "Epoch  348: Train: 0.001244, Val: 0.001472, Total: 0.001273, LR: 6.88e-04 [WARMUP]\n",
      "          Best: Train: 0.001098, Val: 0.001290, Total: 0.001122 (Epoch 345)\n",
      "Epoch  349: Train: 0.001176, Val: 0.001716, Total: 0.001244, LR: 6.90e-04 [WARMUP]\n",
      "          Best: Train: 0.001098, Val: 0.001290, Total: 0.001122 (Epoch 345)\n",
      "Epoch  350: Train: 0.001072, Val: 0.001299, Total: 0.001100, LR: 6.92e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  351: Train: 0.001071, Val: 0.001449, Total: 0.001118, LR: 6.94e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  352: Train: 0.001107, Val: 0.001428, Total: 0.001147, LR: 6.96e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  353: Train: 0.001164, Val: 0.001573, Total: 0.001215, LR: 6.98e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  354: Train: 0.001096, Val: 0.001341, Total: 0.001127, LR: 7.00e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  355: Train: 0.001059, Val: 0.001400, Total: 0.001102, LR: 7.02e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  356: Train: 0.001091, Val: 0.001387, Total: 0.001128, LR: 7.04e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  357: Train: 0.001031, Val: 0.001637, Total: 0.001106, LR: 7.06e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  358: Train: 0.001090, Val: 0.001542, Total: 0.001146, LR: 7.08e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  359: Train: 0.001148, Val: 0.001470, Total: 0.001188, LR: 7.10e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  360: Train: 0.001202, Val: 0.001576, Total: 0.001249, LR: 7.12e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  361: Train: 0.001103, Val: 0.001276, Total: 0.001124, LR: 7.13e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  362: Train: 0.001075, Val: 0.001790, Total: 0.001164, LR: 7.15e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  363: Train: 0.001099, Val: 0.001562, Total: 0.001157, LR: 7.17e-04 [WARMUP]\n",
      "          Best: Train: 0.001072, Val: 0.001299, Total: 0.001100 (Epoch 350)\n",
      "Epoch  364: Train: 0.001012, Val: 0.001573, Total: 0.001082, LR: 7.19e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  365: Train: 0.001021, Val: 0.001578, Total: 0.001091, LR: 7.21e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  366: Train: 0.001122, Val: 0.001680, Total: 0.001191, LR: 7.23e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  367: Train: 0.001234, Val: 0.001823, Total: 0.001308, LR: 7.25e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  368: Train: 0.001313, Val: 0.002762, Total: 0.001494, LR: 7.27e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  369: Train: 0.001176, Val: 0.001786, Total: 0.001252, LR: 7.29e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  370: Train: 0.001180, Val: 0.001838, Total: 0.001263, LR: 7.31e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  371: Train: 0.001137, Val: 0.001625, Total: 0.001198, LR: 7.33e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  372: Train: 0.001171, Val: 0.001790, Total: 0.001248, LR: 7.35e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  373: Train: 0.001091, Val: 0.001613, Total: 0.001156, LR: 7.37e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  374: Train: 0.001036, Val: 0.001649, Total: 0.001112, LR: 7.39e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  375: Train: 0.001095, Val: 0.001675, Total: 0.001168, LR: 7.41e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  376: Train: 0.001063, Val: 0.001864, Total: 0.001163, LR: 7.43e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  377: Train: 0.001061, Val: 0.001691, Total: 0.001140, LR: 7.45e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  378: Train: 0.001029, Val: 0.001675, Total: 0.001110, LR: 7.47e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  379: Train: 0.001083, Val: 0.001512, Total: 0.001137, LR: 7.49e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  380: Train: 0.001009, Val: 0.001729, Total: 0.001099, LR: 7.51e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  381: Train: 0.001097, Val: 0.001402, Total: 0.001135, LR: 7.53e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  382: Train: 0.001088, Val: 0.001642, Total: 0.001157, LR: 7.55e-04 [WARMUP]\n",
      "          Best: Train: 0.001012, Val: 0.001573, Total: 0.001082 (Epoch 364)\n",
      "Epoch  383: Train: 0.001016, Val: 0.001432, Total: 0.001068, LR: 7.57e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  384: Train: 0.001116, Val: 0.001744, Total: 0.001195, LR: 7.59e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  385: Train: 0.001058, Val: 0.001805, Total: 0.001151, LR: 7.61e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  386: Train: 0.001015, Val: 0.001762, Total: 0.001108, LR: 7.63e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  387: Train: 0.001022, Val: 0.001698, Total: 0.001106, LR: 7.65e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  388: Train: 0.001068, Val: 0.001651, Total: 0.001141, LR: 7.67e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  389: Train: 0.001012, Val: 0.001561, Total: 0.001081, LR: 7.69e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  390: Train: 0.001077, Val: 0.001665, Total: 0.001151, LR: 7.71e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  391: Train: 0.001114, Val: 0.001679, Total: 0.001185, LR: 7.73e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  392: Train: 0.001103, Val: 0.002029, Total: 0.001218, LR: 7.75e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  393: Train: 0.001087, Val: 0.001584, Total: 0.001150, LR: 7.77e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  394: Train: 0.001107, Val: 0.002048, Total: 0.001224, LR: 7.79e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  395: Train: 0.001085, Val: 0.001525, Total: 0.001140, LR: 7.81e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  396: Train: 0.001030, Val: 0.002044, Total: 0.001157, LR: 7.83e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  397: Train: 0.001269, Val: 0.001559, Total: 0.001306, LR: 7.85e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  398: Train: 0.001034, Val: 0.001842, Total: 0.001135, LR: 7.87e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  399: Train: 0.001139, Val: 0.001813, Total: 0.001223, LR: 7.89e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  400: Train: 0.001186, Val: 0.001764, Total: 0.001259, LR: 7.91e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  401: Train: 0.001163, Val: 0.001558, Total: 0.001212, LR: 7.93e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  402: Train: 0.001077, Val: 0.001516, Total: 0.001132, LR: 7.95e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  403: Train: 0.001132, Val: 0.002054, Total: 0.001247, LR: 7.96e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  404: Train: 0.001381, Val: 0.003034, Total: 0.001588, LR: 7.98e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  405: Train: 0.001764, Val: 0.002506, Total: 0.001857, LR: 8.00e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  406: Train: 0.001841, Val: 0.002985, Total: 0.001984, LR: 8.02e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  407: Train: 0.001951, Val: 0.002971, Total: 0.002078, LR: 8.04e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  408: Train: 0.001502, Val: 0.002001, Total: 0.001564, LR: 8.06e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  409: Train: 0.001241, Val: 0.001691, Total: 0.001297, LR: 8.08e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  410: Train: 0.001168, Val: 0.001897, Total: 0.001259, LR: 8.10e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  411: Train: 0.001051, Val: 0.001767, Total: 0.001141, LR: 8.12e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  412: Train: 0.001083, Val: 0.001700, Total: 0.001160, LR: 8.14e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  413: Train: 0.001012, Val: 0.001704, Total: 0.001098, LR: 8.16e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  414: Train: 0.001032, Val: 0.001921, Total: 0.001143, LR: 8.18e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  415: Train: 0.001008, Val: 0.001552, Total: 0.001076, LR: 8.20e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  416: Train: 0.001006, Val: 0.001674, Total: 0.001089, LR: 8.22e-04 [WARMUP]\n",
      "          Best: Train: 0.001016, Val: 0.001432, Total: 0.001068 (Epoch 383)\n",
      "Epoch  417: Train: 0.001007, Val: 0.001462, Total: 0.001063, LR: 8.24e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  418: Train: 0.001014, Val: 0.001545, Total: 0.001080, LR: 8.26e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  419: Train: 0.000986, Val: 0.001636, Total: 0.001067, LR: 8.28e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  420: Train: 0.001014, Val: 0.001467, Total: 0.001071, LR: 8.30e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  421: Train: 0.001031, Val: 0.002432, Total: 0.001206, LR: 8.32e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  422: Train: 0.001069, Val: 0.001679, Total: 0.001146, LR: 8.34e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  423: Train: 0.001016, Val: 0.001775, Total: 0.001111, LR: 8.36e-04 [WARMUP]\n",
      "          Best: Train: 0.001007, Val: 0.001462, Total: 0.001063 (Epoch 417)\n",
      "Epoch  424: Train: 0.000930, Val: 0.001866, Total: 0.001047, LR: 8.38e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  425: Train: 0.001026, Val: 0.001507, Total: 0.001087, LR: 8.40e-04 [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  426: Train: 0.001080, Val: 0.001840, Total: 0.001175, LR: 8.42e-04 [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  427: Train: 0.001024, Val: 0.001459, Total: 0.001079, LR: 8.44e-04 [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  428: Train: 0.000978, Val: 0.001549, Total: 0.001049, LR: 8.46e-04 [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  429: Train: 0.000975, Val: 0.001574, Total: 0.001050, LR: 8.48e-04 [WARMUP]\n",
      "          Best: Train: 0.000930, Val: 0.001866, Total: 0.001047 (Epoch 424)\n",
      "Epoch  430: Train: 0.000957, Val: 0.001646, Total: 0.001043, LR: 8.50e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  431: Train: 0.000987, Val: 0.001561, Total: 0.001059, LR: 8.52e-04 [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  432: Train: 0.001063, Val: 0.001616, Total: 0.001132, LR: 8.54e-04 [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  433: Train: 0.001055, Val: 0.002110, Total: 0.001187, LR: 8.56e-04 [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  434: Train: 0.001150, Val: 0.001814, Total: 0.001233, LR: 8.58e-04 [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  435: Train: 0.001058, Val: 0.001999, Total: 0.001175, LR: 8.60e-04 [WARMUP]\n",
      "          Best: Train: 0.000957, Val: 0.001646, Total: 0.001043 (Epoch 430)\n",
      "Epoch  436: Train: 0.000967, Val: 0.001447, Total: 0.001027, LR: 8.62e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000967, Val: 0.001447, Total: 0.001027 (Epoch 436)\n",
      "Epoch  437: Train: 0.000992, Val: 0.001640, Total: 0.001073, LR: 8.64e-04 [WARMUP]\n",
      "          Best: Train: 0.000967, Val: 0.001447, Total: 0.001027 (Epoch 436)\n",
      "Epoch  438: Train: 0.000965, Val: 0.001531, Total: 0.001036, LR: 8.66e-04 [WARMUP]\n",
      "          Best: Train: 0.000967, Val: 0.001447, Total: 0.001027 (Epoch 436)\n",
      "Epoch  439: Train: 0.000984, Val: 0.001718, Total: 0.001076, LR: 8.68e-04 [WARMUP]\n",
      "          Best: Train: 0.000967, Val: 0.001447, Total: 0.001027 (Epoch 436)\n",
      "Epoch  440: Train: 0.000958, Val: 0.001502, Total: 0.001026, LR: 8.70e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  441: Train: 0.000958, Val: 0.002348, Total: 0.001132, LR: 8.72e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  442: Train: 0.001024, Val: 0.001769, Total: 0.001117, LR: 8.74e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  443: Train: 0.000970, Val: 0.001721, Total: 0.001064, LR: 8.76e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  444: Train: 0.001113, Val: 0.001710, Total: 0.001188, LR: 8.78e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  445: Train: 0.001112, Val: 0.002098, Total: 0.001235, LR: 8.80e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  446: Train: 0.000990, Val: 0.002073, Total: 0.001125, LR: 8.81e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  447: Train: 0.001012, Val: 0.002123, Total: 0.001151, LR: 8.83e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  448: Train: 0.001046, Val: 0.001675, Total: 0.001124, LR: 8.85e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  449: Train: 0.000982, Val: 0.001511, Total: 0.001048, LR: 8.87e-04 [WARMUP]\n",
      "          Best: Train: 0.000958, Val: 0.001502, Total: 0.001026 (Epoch 440)\n",
      "Epoch  450: Train: 0.000947, Val: 0.001576, Total: 0.001026, LR: 8.89e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  451: Train: 0.000995, Val: 0.001875, Total: 0.001105, LR: 8.91e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  452: Train: 0.000980, Val: 0.001940, Total: 0.001100, LR: 8.93e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  453: Train: 0.000966, Val: 0.001782, Total: 0.001068, LR: 8.95e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  454: Train: 0.000979, Val: 0.001765, Total: 0.001077, LR: 8.97e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  455: Train: 0.000925, Val: 0.001916, Total: 0.001049, LR: 8.99e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  456: Train: 0.001029, Val: 0.001928, Total: 0.001141, LR: 9.01e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  457: Train: 0.000966, Val: 0.001701, Total: 0.001058, LR: 9.03e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  458: Train: 0.000947, Val: 0.001975, Total: 0.001075, LR: 9.05e-04 [WARMUP]\n",
      "          Best: Train: 0.000947, Val: 0.001576, Total: 0.001026 (Epoch 450)\n",
      "Epoch  459: Train: 0.000926, Val: 0.001626, Total: 0.001013, LR: 9.07e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000926, Val: 0.001626, Total: 0.001013 (Epoch 459)\n",
      "Epoch  460: Train: 0.000965, Val: 0.001714, Total: 0.001059, LR: 9.09e-04 [WARMUP]\n",
      "          Best: Train: 0.000926, Val: 0.001626, Total: 0.001013 (Epoch 459)\n",
      "Epoch  461: Train: 0.001017, Val: 0.001597, Total: 0.001090, LR: 9.11e-04 [WARMUP]\n",
      "          Best: Train: 0.000926, Val: 0.001626, Total: 0.001013 (Epoch 459)\n",
      "Epoch  462: Train: 0.000896, Val: 0.001792, Total: 0.001008, LR: 9.13e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000896, Val: 0.001792, Total: 0.001008 (Epoch 462)\n",
      "Epoch  463: Train: 0.000900, Val: 0.001674, Total: 0.000997, LR: 9.15e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000900, Val: 0.001674, Total: 0.000997 (Epoch 463)\n",
      "Epoch  464: Train: 0.000853, Val: 0.001704, Total: 0.000959, LR: 9.17e-04 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  465: Train: 0.000972, Val: 0.001681, Total: 0.001061, LR: 9.19e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  466: Train: 0.000886, Val: 0.001754, Total: 0.000995, LR: 9.21e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  467: Train: 0.000914, Val: 0.001800, Total: 0.001025, LR: 9.23e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  468: Train: 0.000952, Val: 0.001419, Total: 0.001011, LR: 9.25e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  469: Train: 0.000916, Val: 0.001575, Total: 0.000998, LR: 9.27e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  470: Train: 0.000944, Val: 0.001477, Total: 0.001011, LR: 9.29e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  471: Train: 0.001086, Val: 0.001642, Total: 0.001155, LR: 9.31e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  472: Train: 0.001042, Val: 0.001774, Total: 0.001134, LR: 9.33e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  473: Train: 0.000993, Val: 0.001487, Total: 0.001055, LR: 9.35e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  474: Train: 0.000966, Val: 0.001447, Total: 0.001026, LR: 9.37e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  475: Train: 0.001053, Val: 0.001812, Total: 0.001148, LR: 9.39e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  476: Train: 0.001004, Val: 0.001662, Total: 0.001086, LR: 9.41e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  477: Train: 0.000971, Val: 0.001683, Total: 0.001060, LR: 9.43e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  478: Train: 0.000977, Val: 0.001483, Total: 0.001040, LR: 9.45e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  479: Train: 0.000983, Val: 0.001650, Total: 0.001067, LR: 9.47e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  480: Train: 0.000943, Val: 0.001521, Total: 0.001015, LR: 9.49e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  481: Train: 0.000900, Val: 0.001699, Total: 0.001000, LR: 9.51e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  482: Train: 0.000991, Val: 0.001567, Total: 0.001063, LR: 9.53e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  483: Train: 0.000864, Val: 0.001986, Total: 0.001004, LR: 9.55e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  484: Train: 0.000887, Val: 0.001669, Total: 0.000984, LR: 9.57e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  485: Train: 0.000917, Val: 0.001844, Total: 0.001033, LR: 9.59e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  486: Train: 0.000961, Val: 0.001560, Total: 0.001036, LR: 9.61e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  487: Train: 0.000967, Val: 0.002005, Total: 0.001097, LR: 9.63e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  488: Train: 0.000901, Val: 0.001806, Total: 0.001014, LR: 9.64e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  489: Train: 0.000992, Val: 0.001463, Total: 0.001051, LR: 9.66e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  490: Train: 0.000981, Val: 0.001725, Total: 0.001074, LR: 9.68e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  491: Train: 0.000940, Val: 0.001448, Total: 0.001003, LR: 9.70e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  492: Train: 0.000959, Val: 0.002031, Total: 0.001093, LR: 9.72e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  493: Train: 0.000948, Val: 0.001815, Total: 0.001056, LR: 9.74e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  494: Train: 0.000906, Val: 0.001649, Total: 0.000999, LR: 9.76e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  495: Train: 0.000932, Val: 0.001582, Total: 0.001014, LR: 9.78e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  496: Train: 0.000923, Val: 0.001723, Total: 0.001023, LR: 9.80e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  497: Train: 0.000963, Val: 0.001463, Total: 0.001026, LR: 9.82e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  498: Train: 0.000939, Val: 0.001833, Total: 0.001050, LR: 9.84e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  499: Train: 0.000917, Val: 0.001772, Total: 0.001024, LR: 9.86e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  500: Train: 0.000908, Val: 0.002482, Total: 0.001105, LR: 9.88e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  501: Train: 0.001032, Val: 0.001583, Total: 0.001101, LR: 9.90e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  502: Train: 0.001028, Val: 0.001583, Total: 0.001097, LR: 9.92e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  503: Train: 0.000967, Val: 0.001666, Total: 0.001054, LR: 9.94e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  504: Train: 0.001005, Val: 0.001729, Total: 0.001096, LR: 9.96e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  505: Train: 0.001003, Val: 0.001520, Total: 0.001068, LR: 9.98e-04 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  506: Train: 0.000984, Val: 0.001823, Total: 0.001089, LR: 1.00e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  507: Train: 0.000958, Val: 0.001457, Total: 0.001020, LR: 1.00e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  508: Train: 0.000900, Val: 0.001657, Total: 0.000995, LR: 1.00e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  509: Train: 0.000889, Val: 0.001571, Total: 0.000974, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  510: Train: 0.000893, Val: 0.001823, Total: 0.001009, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  511: Train: 0.000920, Val: 0.001482, Total: 0.000990, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  512: Train: 0.001068, Val: 0.002125, Total: 0.001200, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  513: Train: 0.001140, Val: 0.001440, Total: 0.001177, LR: 1.01e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  514: Train: 0.001225, Val: 0.002642, Total: 0.001402, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  515: Train: 0.001369, Val: 0.001176, Total: 0.001345, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  516: Train: 0.001115, Val: 0.001321, Total: 0.001140, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  517: Train: 0.001017, Val: 0.001442, Total: 0.001070, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  518: Train: 0.000965, Val: 0.001908, Total: 0.001083, LR: 1.02e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  519: Train: 0.000962, Val: 0.001696, Total: 0.001054, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  520: Train: 0.000892, Val: 0.001789, Total: 0.001004, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  521: Train: 0.000920, Val: 0.001602, Total: 0.001005, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  522: Train: 0.000983, Val: 0.001556, Total: 0.001055, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  523: Train: 0.000923, Val: 0.002178, Total: 0.001080, LR: 1.03e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  524: Train: 0.000951, Val: 0.002063, Total: 0.001090, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  525: Train: 0.000999, Val: 0.002040, Total: 0.001129, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  526: Train: 0.000959, Val: 0.002139, Total: 0.001106, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  527: Train: 0.001175, Val: 0.002144, Total: 0.001296, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  528: Train: 0.001201, Val: 0.001671, Total: 0.001260, LR: 1.04e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  529: Train: 0.001066, Val: 0.001914, Total: 0.001172, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  530: Train: 0.001020, Val: 0.001719, Total: 0.001107, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  531: Train: 0.000970, Val: 0.001760, Total: 0.001068, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  532: Train: 0.000906, Val: 0.001466, Total: 0.000976, LR: 1.05e-03 [WARMUP]\n",
      "          Best: Train: 0.000853, Val: 0.001704, Total: 0.000959 (Epoch 464)\n",
      "Epoch  533: Train: 0.000878, Val: 0.001515, Total: 0.000957, LR: 1.05e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000878, Val: 0.001515, Total: 0.000957 (Epoch 533)\n",
      "Epoch  534: Train: 0.000817, Val: 0.001470, Total: 0.000899, LR: 1.06e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  535: Train: 0.000862, Val: 0.001569, Total: 0.000950, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  536: Train: 0.000934, Val: 0.001525, Total: 0.001008, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  537: Train: 0.000922, Val: 0.001422, Total: 0.000985, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  538: Train: 0.001006, Val: 0.001752, Total: 0.001099, LR: 1.06e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  539: Train: 0.001010, Val: 0.001509, Total: 0.001072, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  540: Train: 0.001024, Val: 0.001729, Total: 0.001112, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  541: Train: 0.000945, Val: 0.001419, Total: 0.001004, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  542: Train: 0.000964, Val: 0.002278, Total: 0.001129, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  543: Train: 0.001112, Val: 0.001596, Total: 0.001173, LR: 1.07e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  544: Train: 0.000949, Val: 0.001831, Total: 0.001059, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  545: Train: 0.000984, Val: 0.001612, Total: 0.001062, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  546: Train: 0.000917, Val: 0.001803, Total: 0.001028, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  547: Train: 0.000931, Val: 0.001949, Total: 0.001058, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  548: Train: 0.000947, Val: 0.001755, Total: 0.001048, LR: 1.08e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  549: Train: 0.000881, Val: 0.002044, Total: 0.001027, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  550: Train: 0.000950, Val: 0.001657, Total: 0.001038, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  551: Train: 0.000914, Val: 0.001882, Total: 0.001035, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  552: Train: 0.000816, Val: 0.001763, Total: 0.000935, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  553: Train: 0.000856, Val: 0.001648, Total: 0.000955, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  554: Train: 0.000918, Val: 0.001235, Total: 0.000958, LR: 1.09e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  555: Train: 0.000977, Val: 0.001767, Total: 0.001076, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  556: Train: 0.000869, Val: 0.001815, Total: 0.000987, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  557: Train: 0.000901, Val: 0.001752, Total: 0.001007, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  558: Train: 0.000870, Val: 0.001660, Total: 0.000969, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  559: Train: 0.000884, Val: 0.001609, Total: 0.000975, LR: 1.10e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  560: Train: 0.000829, Val: 0.001702, Total: 0.000938, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  561: Train: 0.000844, Val: 0.001515, Total: 0.000928, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  562: Train: 0.000857, Val: 0.001606, Total: 0.000951, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  563: Train: 0.000879, Val: 0.001405, Total: 0.000945, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  564: Train: 0.000910, Val: 0.001927, Total: 0.001037, LR: 1.11e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  565: Train: 0.000901, Val: 0.001552, Total: 0.000983, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  566: Train: 0.000892, Val: 0.001457, Total: 0.000963, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  567: Train: 0.000931, Val: 0.001559, Total: 0.001010, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  568: Train: 0.000962, Val: 0.001817, Total: 0.001069, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  569: Train: 0.001041, Val: 0.001705, Total: 0.001124, LR: 1.12e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  570: Train: 0.000938, Val: 0.001549, Total: 0.001015, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  571: Train: 0.000908, Val: 0.001507, Total: 0.000983, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  572: Train: 0.000891, Val: 0.001811, Total: 0.001006, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  573: Train: 0.000936, Val: 0.001460, Total: 0.001001, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  574: Train: 0.000939, Val: 0.001649, Total: 0.001028, LR: 1.13e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  575: Train: 0.000862, Val: 0.001640, Total: 0.000959, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  576: Train: 0.000892, Val: 0.001788, Total: 0.001004, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  577: Train: 0.000832, Val: 0.001737, Total: 0.000945, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  578: Train: 0.000825, Val: 0.001745, Total: 0.000940, LR: 1.14e-03 [WARMUP]\n",
      "          Best: Train: 0.000817, Val: 0.001470, Total: 0.000899 (Epoch 534)\n",
      "Epoch  579: Train: 0.000788, Val: 0.001496, Total: 0.000877, LR: 1.14e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000788, Val: 0.001496, Total: 0.000877 (Epoch 579)\n",
      "Epoch  580: Train: 0.000835, Val: 0.001547, Total: 0.000924, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000788, Val: 0.001496, Total: 0.000877 (Epoch 579)\n",
      "Epoch  581: Train: 0.000836, Val: 0.001568, Total: 0.000928, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000788, Val: 0.001496, Total: 0.000877 (Epoch 579)\n",
      "Epoch  582: Train: 0.000768, Val: 0.001570, Total: 0.000869, LR: 1.15e-03 ★ NEW BEST [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  583: Train: 0.000818, Val: 0.001665, Total: 0.000924, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  584: Train: 0.000826, Val: 0.001506, Total: 0.000911, LR: 1.15e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  585: Train: 0.000905, Val: 0.001501, Total: 0.000980, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  586: Train: 0.000889, Val: 0.001449, Total: 0.000959, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  587: Train: 0.000849, Val: 0.001598, Total: 0.000943, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  588: Train: 0.000900, Val: 0.001800, Total: 0.001013, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  589: Train: 0.000935, Val: 0.001605, Total: 0.001018, LR: 1.16e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  590: Train: 0.000868, Val: 0.001569, Total: 0.000955, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  591: Train: 0.000859, Val: 0.001877, Total: 0.000986, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  592: Train: 0.001072, Val: 0.002060, Total: 0.001196, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  593: Train: 0.001100, Val: 0.001744, Total: 0.001180, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  594: Train: 0.001012, Val: 0.001689, Total: 0.001097, LR: 1.17e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  595: Train: 0.001043, Val: 0.001452, Total: 0.001094, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  596: Train: 0.001029, Val: 0.002063, Total: 0.001159, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  597: Train: 0.001355, Val: 0.002633, Total: 0.001514, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  598: Train: 0.001099, Val: 0.001606, Total: 0.001162, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  599: Train: 0.001186, Val: 0.001377, Total: 0.001210, LR: 1.18e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  600: Train: 0.001047, Val: 0.001568, Total: 0.001112, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  601: Train: 0.001017, Val: 0.002111, Total: 0.001154, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  602: Train: 0.000959, Val: 0.001981, Total: 0.001087, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  603: Train: 0.000900, Val: 0.001920, Total: 0.001028, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  604: Train: 0.001035, Val: 0.001668, Total: 0.001114, LR: 1.19e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  605: Train: 0.000988, Val: 0.001626, Total: 0.001068, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  606: Train: 0.000967, Val: 0.001635, Total: 0.001050, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  607: Train: 0.000923, Val: 0.001627, Total: 0.001011, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  608: Train: 0.000945, Val: 0.001712, Total: 0.001041, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  609: Train: 0.000886, Val: 0.001882, Total: 0.001011, LR: 1.20e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  610: Train: 0.000902, Val: 0.001872, Total: 0.001023, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  611: Train: 0.000954, Val: 0.001993, Total: 0.001084, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  612: Train: 0.000914, Val: 0.002007, Total: 0.001050, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  613: Train: 0.000904, Val: 0.002158, Total: 0.001061, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  614: Train: 0.000993, Val: 0.001677, Total: 0.001078, LR: 1.21e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  615: Train: 0.001058, Val: 0.001718, Total: 0.001141, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  616: Train: 0.001109, Val: 0.002380, Total: 0.001268, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  617: Train: 0.001081, Val: 0.001740, Total: 0.001163, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  618: Train: 0.001002, Val: 0.001754, Total: 0.001096, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  619: Train: 0.000986, Val: 0.002379, Total: 0.001160, LR: 1.22e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  620: Train: 0.001091, Val: 0.002192, Total: 0.001228, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  621: Train: 0.001002, Val: 0.002432, Total: 0.001181, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  622: Train: 0.000989, Val: 0.002095, Total: 0.001127, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  623: Train: 0.000977, Val: 0.002684, Total: 0.001191, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  624: Train: 0.000955, Val: 0.002117, Total: 0.001100, LR: 1.23e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  625: Train: 0.001037, Val: 0.002330, Total: 0.001199, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  626: Train: 0.001041, Val: 0.002564, Total: 0.001232, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  627: Train: 0.001236, Val: 0.003465, Total: 0.001515, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  628: Train: 0.001392, Val: 0.002487, Total: 0.001529, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  629: Train: 0.000982, Val: 0.002649, Total: 0.001191, LR: 1.24e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  630: Train: 0.000952, Val: 0.002332, Total: 0.001124, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  631: Train: 0.001016, Val: 0.002438, Total: 0.001194, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  632: Train: 0.000935, Val: 0.002476, Total: 0.001128, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  633: Train: 0.000981, Val: 0.002059, Total: 0.001116, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  634: Train: 0.000992, Val: 0.001735, Total: 0.001085, LR: 1.25e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  635: Train: 0.000946, Val: 0.001409, Total: 0.001004, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  636: Train: 0.001061, Val: 0.002092, Total: 0.001190, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  637: Train: 0.001163, Val: 0.001960, Total: 0.001263, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  638: Train: 0.001156, Val: 0.002723, Total: 0.001352, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  639: Train: 0.001193, Val: 0.002047, Total: 0.001300, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  640: Train: 0.001137, Val: 0.002361, Total: 0.001290, LR: 1.26e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  641: Train: 0.001151, Val: 0.001989, Total: 0.001256, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  642: Train: 0.000999, Val: 0.002478, Total: 0.001184, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  643: Train: 0.000951, Val: 0.002077, Total: 0.001092, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  644: Train: 0.001058, Val: 0.002525, Total: 0.001241, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  645: Train: 0.001263, Val: 0.002099, Total: 0.001368, LR: 1.27e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  646: Train: 0.001356, Val: 0.002567, Total: 0.001508, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  647: Train: 0.001566, Val: 0.001748, Total: 0.001589, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  648: Train: 0.001324, Val: 0.002748, Total: 0.001502, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  649: Train: 0.001474, Val: 0.001485, Total: 0.001475, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  650: Train: 0.001162, Val: 0.001624, Total: 0.001219, LR: 1.28e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  651: Train: 0.001561, Val: 0.002619, Total: 0.001693, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  652: Train: 0.001490, Val: 0.002333, Total: 0.001595, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  653: Train: 0.002116, Val: 0.002297, Total: 0.002138, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  654: Train: 0.001392, Val: 0.001757, Total: 0.001438, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  655: Train: 0.001359, Val: 0.001845, Total: 0.001420, LR: 1.29e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  656: Train: 0.001241, Val: 0.001738, Total: 0.001303, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  657: Train: 0.001290, Val: 0.002270, Total: 0.001413, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  658: Train: 0.001344, Val: 0.001361, Total: 0.001346, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  659: Train: 0.001398, Val: 0.002140, Total: 0.001490, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  660: Train: 0.001191, Val: 0.001481, Total: 0.001227, LR: 1.30e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  661: Train: 0.001295, Val: 0.001854, Total: 0.001365, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  662: Train: 0.001297, Val: 0.002732, Total: 0.001477, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  663: Train: 0.001411, Val: 0.002023, Total: 0.001488, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  664: Train: 0.001477, Val: 0.003663, Total: 0.001750, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  665: Train: 0.001359, Val: 0.002750, Total: 0.001533, LR: 1.31e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  666: Train: 0.001310, Val: 0.003564, Total: 0.001592, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  667: Train: 0.001393, Val: 0.002002, Total: 0.001469, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  668: Train: 0.001517, Val: 0.001633, Total: 0.001531, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  669: Train: 0.001239, Val: 0.001561, Total: 0.001280, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  670: Train: 0.001214, Val: 0.001895, Total: 0.001299, LR: 1.32e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  671: Train: 0.001427, Val: 0.001707, Total: 0.001462, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  672: Train: 0.001346, Val: 0.001676, Total: 0.001387, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  673: Train: 0.001669, Val: 0.001509, Total: 0.001649, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  674: Train: 0.001254, Val: 0.001492, Total: 0.001283, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  675: Train: 0.001250, Val: 0.001978, Total: 0.001341, LR: 1.33e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  676: Train: 0.001283, Val: 0.001582, Total: 0.001320, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  677: Train: 0.001277, Val: 0.003503, Total: 0.001555, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  678: Train: 0.001349, Val: 0.001397, Total: 0.001355, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  679: Train: 0.001297, Val: 0.001771, Total: 0.001356, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  680: Train: 0.001033, Val: 0.001524, Total: 0.001095, LR: 1.34e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  681: Train: 0.001194, Val: 0.001474, Total: 0.001229, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  682: Train: 0.001122, Val: 0.001668, Total: 0.001191, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  683: Train: 0.001057, Val: 0.002234, Total: 0.001204, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  684: Train: 0.001152, Val: 0.002444, Total: 0.001313, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  685: Train: 0.001153, Val: 0.002550, Total: 0.001327, LR: 1.35e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  686: Train: 0.001241, Val: 0.002689, Total: 0.001422, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  687: Train: 0.001290, Val: 0.001703, Total: 0.001341, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  688: Train: 0.001169, Val: 0.002494, Total: 0.001334, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  689: Train: 0.001132, Val: 0.001734, Total: 0.001208, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  690: Train: 0.001057, Val: 0.001786, Total: 0.001148, LR: 1.36e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  691: Train: 0.000997, Val: 0.001775, Total: 0.001094, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  692: Train: 0.000976, Val: 0.001359, Total: 0.001024, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  693: Train: 0.000923, Val: 0.001999, Total: 0.001057, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  694: Train: 0.001041, Val: 0.001716, Total: 0.001126, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  695: Train: 0.001085, Val: 0.002475, Total: 0.001259, LR: 1.37e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  696: Train: 0.001046, Val: 0.001996, Total: 0.001165, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  697: Train: 0.000972, Val: 0.002195, Total: 0.001125, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  698: Train: 0.001029, Val: 0.001846, Total: 0.001131, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  699: Train: 0.001018, Val: 0.002305, Total: 0.001179, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  700: Train: 0.000978, Val: 0.002085, Total: 0.001116, LR: 1.38e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  701: Train: 0.000981, Val: 0.001914, Total: 0.001098, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  702: Train: 0.000969, Val: 0.001956, Total: 0.001093, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  703: Train: 0.000922, Val: 0.001893, Total: 0.001044, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  704: Train: 0.000911, Val: 0.001910, Total: 0.001036, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  705: Train: 0.000997, Val: 0.001820, Total: 0.001100, LR: 1.39e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  706: Train: 0.000921, Val: 0.001859, Total: 0.001038, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  707: Train: 0.000900, Val: 0.001890, Total: 0.001024, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  708: Train: 0.000908, Val: 0.001803, Total: 0.001020, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  709: Train: 0.000926, Val: 0.002140, Total: 0.001078, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  710: Train: 0.000995, Val: 0.001765, Total: 0.001091, LR: 1.40e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  711: Train: 0.001162, Val: 0.002235, Total: 0.001296, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  712: Train: 0.000975, Val: 0.001747, Total: 0.001071, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  713: Train: 0.000945, Val: 0.001815, Total: 0.001054, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  714: Train: 0.001047, Val: 0.001715, Total: 0.001130, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  715: Train: 0.001043, Val: 0.002581, Total: 0.001235, LR: 1.41e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  716: Train: 0.001010, Val: 0.002101, Total: 0.001146, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  717: Train: 0.001038, Val: 0.002194, Total: 0.001183, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  718: Train: 0.000982, Val: 0.001578, Total: 0.001056, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  719: Train: 0.001098, Val: 0.003177, Total: 0.001358, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  720: Train: 0.001459, Val: 0.006310, Total: 0.002065, LR: 1.42e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  721: Train: 0.002791, Val: 0.003124, Total: 0.002832, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  722: Train: 0.002087, Val: 0.002192, Total: 0.002100, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  723: Train: 0.001550, Val: 0.002164, Total: 0.001627, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  724: Train: 0.001574, Val: 0.001865, Total: 0.001610, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  725: Train: 0.001445, Val: 0.001725, Total: 0.001480, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  726: Train: 0.001200, Val: 0.001987, Total: 0.001299, LR: 1.43e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  727: Train: 0.001453, Val: 0.001434, Total: 0.001450, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  728: Train: 0.001638, Val: 0.002040, Total: 0.001688, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  729: Train: 0.001578, Val: 0.002016, Total: 0.001633, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  730: Train: 0.001444, Val: 0.001547, Total: 0.001457, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  731: Train: 0.001382, Val: 0.001790, Total: 0.001433, LR: 1.44e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  732: Train: 0.001318, Val: 0.001358, Total: 0.001323, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  733: Train: 0.001289, Val: 0.001323, Total: 0.001293, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  734: Train: 0.001204, Val: 0.001406, Total: 0.001229, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  735: Train: 0.001201, Val: 0.001332, Total: 0.001217, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  736: Train: 0.001257, Val: 0.001509, Total: 0.001288, LR: 1.45e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  737: Train: 0.001214, Val: 0.001492, Total: 0.001249, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  738: Train: 0.001231, Val: 0.002189, Total: 0.001351, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  739: Train: 0.001235, Val: 0.001456, Total: 0.001263, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  740: Train: 0.001149, Val: 0.001932, Total: 0.001247, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  741: Train: 0.001200, Val: 0.002039, Total: 0.001305, LR: 1.46e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  742: Train: 0.001315, Val: 0.002062, Total: 0.001408, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  743: Train: 0.001491, Val: 0.001782, Total: 0.001528, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  744: Train: 0.001216, Val: 0.001965, Total: 0.001310, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  745: Train: 0.001167, Val: 0.001972, Total: 0.001268, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  746: Train: 0.001130, Val: 0.002126, Total: 0.001255, LR: 1.47e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  747: Train: 0.001108, Val: 0.002020, Total: 0.001222, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  748: Train: 0.001233, Val: 0.002406, Total: 0.001380, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  749: Train: 0.001132, Val: 0.002193, Total: 0.001265, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  750: Train: 0.001109, Val: 0.002006, Total: 0.001222, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  751: Train: 0.001184, Val: 0.001605, Total: 0.001237, LR: 1.48e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  752: Train: 0.001138, Val: 0.002209, Total: 0.001272, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  753: Train: 0.001076, Val: 0.002030, Total: 0.001195, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  754: Train: 0.001077, Val: 0.002138, Total: 0.001210, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  755: Train: 0.001081, Val: 0.001947, Total: 0.001189, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  756: Train: 0.001095, Val: 0.001861, Total: 0.001191, LR: 1.49e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  757: Train: 0.001100, Val: 0.001907, Total: 0.001201, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  758: Train: 0.001154, Val: 0.001861, Total: 0.001243, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  759: Train: 0.001271, Val: 0.002220, Total: 0.001390, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  760: Train: 0.001306, Val: 0.002004, Total: 0.001393, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  761: Train: 0.001327, Val: 0.002569, Total: 0.001482, LR: 1.50e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  762: Train: 0.001362, Val: 0.002121, Total: 0.001457, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  763: Train: 0.001237, Val: 0.002490, Total: 0.001393, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  764: Train: 0.001199, Val: 0.002023, Total: 0.001302, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  765: Train: 0.001184, Val: 0.002018, Total: 0.001289, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  766: Train: 0.001116, Val: 0.001901, Total: 0.001214, LR: 1.51e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  767: Train: 0.001167, Val: 0.001898, Total: 0.001259, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  768: Train: 0.001075, Val: 0.001900, Total: 0.001178, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  769: Train: 0.001074, Val: 0.001787, Total: 0.001163, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  770: Train: 0.001091, Val: 0.002001, Total: 0.001205, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  771: Train: 0.001022, Val: 0.001859, Total: 0.001127, LR: 1.52e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  772: Train: 0.001114, Val: 0.001871, Total: 0.001209, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  773: Train: 0.001055, Val: 0.001848, Total: 0.001154, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  774: Train: 0.001081, Val: 0.002036, Total: 0.001201, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  775: Train: 0.001030, Val: 0.001905, Total: 0.001139, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  776: Train: 0.001071, Val: 0.001736, Total: 0.001154, LR: 1.53e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  777: Train: 0.001043, Val: 0.001796, Total: 0.001137, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  778: Train: 0.001028, Val: 0.001604, Total: 0.001100, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  779: Train: 0.001055, Val: 0.001562, Total: 0.001118, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  780: Train: 0.001059, Val: 0.001591, Total: 0.001126, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  781: Train: 0.000999, Val: 0.001797, Total: 0.001099, LR: 1.54e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  782: Train: 0.000993, Val: 0.001730, Total: 0.001085, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  783: Train: 0.001013, Val: 0.001852, Total: 0.001118, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  784: Train: 0.001007, Val: 0.001748, Total: 0.001100, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  785: Train: 0.000999, Val: 0.001552, Total: 0.001068, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  786: Train: 0.000990, Val: 0.001556, Total: 0.001061, LR: 1.55e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  787: Train: 0.001018, Val: 0.001865, Total: 0.001123, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  788: Train: 0.001033, Val: 0.001929, Total: 0.001145, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  789: Train: 0.001070, Val: 0.001950, Total: 0.001180, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  790: Train: 0.001082, Val: 0.001816, Total: 0.001174, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  791: Train: 0.001001, Val: 0.001668, Total: 0.001085, LR: 1.56e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  792: Train: 0.001054, Val: 0.001704, Total: 0.001135, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  793: Train: 0.001014, Val: 0.002268, Total: 0.001171, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  794: Train: 0.001031, Val: 0.002027, Total: 0.001156, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  795: Train: 0.001030, Val: 0.002059, Total: 0.001158, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  796: Train: 0.000991, Val: 0.001839, Total: 0.001097, LR: 1.57e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  797: Train: 0.000964, Val: 0.002133, Total: 0.001110, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  798: Train: 0.001026, Val: 0.002375, Total: 0.001195, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  799: Train: 0.001093, Val: 0.002631, Total: 0.001285, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  800: Train: 0.001208, Val: 0.002520, Total: 0.001372, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  801: Train: 0.001152, Val: 0.002507, Total: 0.001321, LR: 1.58e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  802: Train: 0.001132, Val: 0.001781, Total: 0.001214, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  803: Train: 0.001050, Val: 0.002073, Total: 0.001178, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  804: Train: 0.001122, Val: 0.002034, Total: 0.001236, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  805: Train: 0.001027, Val: 0.001860, Total: 0.001131, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  806: Train: 0.001045, Val: 0.001996, Total: 0.001164, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  807: Train: 0.000934, Val: 0.001461, Total: 0.001000, LR: 1.59e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  808: Train: 0.001056, Val: 0.001817, Total: 0.001151, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  809: Train: 0.001004, Val: 0.001825, Total: 0.001107, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  810: Train: 0.000946, Val: 0.001884, Total: 0.001063, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  811: Train: 0.000962, Val: 0.001838, Total: 0.001072, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  812: Train: 0.000946, Val: 0.001842, Total: 0.001058, LR: 1.60e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  813: Train: 0.000943, Val: 0.002137, Total: 0.001093, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  814: Train: 0.000905, Val: 0.002026, Total: 0.001045, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  815: Train: 0.001006, Val: 0.001873, Total: 0.001114, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  816: Train: 0.001032, Val: 0.001971, Total: 0.001149, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  817: Train: 0.001034, Val: 0.001877, Total: 0.001139, LR: 1.61e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  818: Train: 0.001025, Val: 0.002194, Total: 0.001171, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  819: Train: 0.000965, Val: 0.001770, Total: 0.001065, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  820: Train: 0.000938, Val: 0.001814, Total: 0.001047, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  821: Train: 0.000990, Val: 0.001704, Total: 0.001079, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  822: Train: 0.001062, Val: 0.001847, Total: 0.001160, LR: 1.62e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  823: Train: 0.001067, Val: 0.002402, Total: 0.001234, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  824: Train: 0.001142, Val: 0.001712, Total: 0.001213, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  825: Train: 0.001065, Val: 0.002092, Total: 0.001194, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  826: Train: 0.000997, Val: 0.001568, Total: 0.001068, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  827: Train: 0.000980, Val: 0.001903, Total: 0.001095, LR: 1.63e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  828: Train: 0.001040, Val: 0.001695, Total: 0.001121, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  829: Train: 0.000900, Val: 0.001389, Total: 0.000961, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  830: Train: 0.000935, Val: 0.001802, Total: 0.001043, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  831: Train: 0.000932, Val: 0.001728, Total: 0.001032, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  832: Train: 0.000869, Val: 0.001903, Total: 0.000999, LR: 1.64e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  833: Train: 0.000906, Val: 0.001965, Total: 0.001038, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  834: Train: 0.000899, Val: 0.001763, Total: 0.001007, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  835: Train: 0.000857, Val: 0.001872, Total: 0.000984, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  836: Train: 0.000865, Val: 0.001638, Total: 0.000962, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  837: Train: 0.000871, Val: 0.001868, Total: 0.000995, LR: 1.65e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  838: Train: 0.000858, Val: 0.002009, Total: 0.001002, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  839: Train: 0.000872, Val: 0.001728, Total: 0.000979, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  840: Train: 0.000841, Val: 0.001972, Total: 0.000983, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  841: Train: 0.000882, Val: 0.001602, Total: 0.000972, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  842: Train: 0.000941, Val: 0.002110, Total: 0.001087, LR: 1.66e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  843: Train: 0.000933, Val: 0.001490, Total: 0.001003, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  844: Train: 0.000923, Val: 0.001858, Total: 0.001040, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  845: Train: 0.000901, Val: 0.001874, Total: 0.001023, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  846: Train: 0.000837, Val: 0.001839, Total: 0.000962, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  847: Train: 0.000924, Val: 0.001595, Total: 0.001008, LR: 1.67e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  848: Train: 0.000873, Val: 0.001761, Total: 0.000984, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  849: Train: 0.000892, Val: 0.001736, Total: 0.000997, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  850: Train: 0.000861, Val: 0.001762, Total: 0.000973, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  851: Train: 0.000903, Val: 0.001609, Total: 0.000991, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  852: Train: 0.000826, Val: 0.001723, Total: 0.000938, LR: 1.68e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  853: Train: 0.000883, Val: 0.001779, Total: 0.000995, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  854: Train: 0.000879, Val: 0.001546, Total: 0.000962, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  855: Train: 0.000859, Val: 0.001643, Total: 0.000957, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  856: Train: 0.000888, Val: 0.001679, Total: 0.000987, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  857: Train: 0.000855, Val: 0.001665, Total: 0.000957, LR: 1.69e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  858: Train: 0.000882, Val: 0.001758, Total: 0.000992, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  859: Train: 0.000895, Val: 0.001829, Total: 0.001012, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  860: Train: 0.000918, Val: 0.001843, Total: 0.001033, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  861: Train: 0.000843, Val: 0.001728, Total: 0.000953, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  862: Train: 0.000841, Val: 0.001753, Total: 0.000955, LR: 1.70e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  863: Train: 0.000859, Val: 0.001632, Total: 0.000956, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  864: Train: 0.000862, Val: 0.001830, Total: 0.000983, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  865: Train: 0.000860, Val: 0.001612, Total: 0.000954, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  866: Train: 0.000813, Val: 0.001883, Total: 0.000946, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  867: Train: 0.000826, Val: 0.002031, Total: 0.000977, LR: 1.71e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  868: Train: 0.000802, Val: 0.001714, Total: 0.000916, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  869: Train: 0.000890, Val: 0.001735, Total: 0.000996, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  870: Train: 0.000980, Val: 0.002114, Total: 0.001122, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  871: Train: 0.000936, Val: 0.002085, Total: 0.001079, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  872: Train: 0.000904, Val: 0.001582, Total: 0.000989, LR: 1.72e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  873: Train: 0.001014, Val: 0.001938, Total: 0.001130, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  874: Train: 0.000867, Val: 0.001821, Total: 0.000987, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  875: Train: 0.000899, Val: 0.001734, Total: 0.001003, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  876: Train: 0.000862, Val: 0.001727, Total: 0.000970, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  877: Train: 0.000893, Val: 0.001634, Total: 0.000985, LR: 1.73e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  878: Train: 0.000840, Val: 0.001807, Total: 0.000961, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  879: Train: 0.000858, Val: 0.001641, Total: 0.000956, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  880: Train: 0.000849, Val: 0.001878, Total: 0.000978, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  881: Train: 0.000876, Val: 0.001681, Total: 0.000976, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  882: Train: 0.000867, Val: 0.001783, Total: 0.000981, LR: 1.74e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  883: Train: 0.000898, Val: 0.001679, Total: 0.000996, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  884: Train: 0.000845, Val: 0.001782, Total: 0.000962, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  885: Train: 0.000902, Val: 0.001805, Total: 0.001015, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  886: Train: 0.000865, Val: 0.001816, Total: 0.000984, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  887: Train: 0.000857, Val: 0.001682, Total: 0.000960, LR: 1.75e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  888: Train: 0.000857, Val: 0.001762, Total: 0.000970, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  889: Train: 0.000894, Val: 0.001858, Total: 0.001015, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  890: Train: 0.000921, Val: 0.001774, Total: 0.001028, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  891: Train: 0.000880, Val: 0.001848, Total: 0.001001, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  892: Train: 0.000906, Val: 0.001804, Total: 0.001018, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  893: Train: 0.000879, Val: 0.001951, Total: 0.001013, LR: 1.76e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  894: Train: 0.000838, Val: 0.001620, Total: 0.000936, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  895: Train: 0.000910, Val: 0.002041, Total: 0.001052, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  896: Train: 0.000985, Val: 0.001596, Total: 0.001061, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  897: Train: 0.001076, Val: 0.002449, Total: 0.001248, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  898: Train: 0.001114, Val: 0.001670, Total: 0.001184, LR: 1.77e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  899: Train: 0.001050, Val: 0.001823, Total: 0.001146, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  900: Train: 0.001141, Val: 0.002327, Total: 0.001290, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  901: Train: 0.001117, Val: 0.002675, Total: 0.001312, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  902: Train: 0.001366, Val: 0.001958, Total: 0.001440, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  903: Train: 0.001169, Val: 0.002001, Total: 0.001273, LR: 1.78e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  904: Train: 0.001169, Val: 0.001839, Total: 0.001253, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  905: Train: 0.001000, Val: 0.001869, Total: 0.001108, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  906: Train: 0.000973, Val: 0.002691, Total: 0.001188, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  907: Train: 0.000939, Val: 0.002081, Total: 0.001082, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  908: Train: 0.000969, Val: 0.002101, Total: 0.001111, LR: 1.79e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  909: Train: 0.000914, Val: 0.002100, Total: 0.001062, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  910: Train: 0.000908, Val: 0.001969, Total: 0.001040, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  911: Train: 0.000900, Val: 0.002348, Total: 0.001081, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  912: Train: 0.000880, Val: 0.001937, Total: 0.001012, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  913: Train: 0.000953, Val: 0.002115, Total: 0.001098, LR: 1.80e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  914: Train: 0.000953, Val: 0.002155, Total: 0.001104, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  915: Train: 0.000877, Val: 0.002148, Total: 0.001036, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  916: Train: 0.000878, Val: 0.002109, Total: 0.001031, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  917: Train: 0.000868, Val: 0.001969, Total: 0.001006, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  918: Train: 0.000912, Val: 0.002081, Total: 0.001058, LR: 1.81e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  919: Train: 0.000941, Val: 0.002626, Total: 0.001151, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  920: Train: 0.000994, Val: 0.001926, Total: 0.001111, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  921: Train: 0.001067, Val: 0.001793, Total: 0.001158, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  922: Train: 0.001087, Val: 0.001712, Total: 0.001165, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  923: Train: 0.000961, Val: 0.002328, Total: 0.001132, LR: 1.82e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  924: Train: 0.001092, Val: 0.001753, Total: 0.001174, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  925: Train: 0.000988, Val: 0.001833, Total: 0.001094, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  926: Train: 0.001005, Val: 0.002057, Total: 0.001136, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  927: Train: 0.000956, Val: 0.002224, Total: 0.001115, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  928: Train: 0.000893, Val: 0.002242, Total: 0.001062, LR: 1.83e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  929: Train: 0.000922, Val: 0.002191, Total: 0.001080, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  930: Train: 0.000903, Val: 0.002126, Total: 0.001056, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  931: Train: 0.000983, Val: 0.001949, Total: 0.001104, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  932: Train: 0.000973, Val: 0.002377, Total: 0.001148, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  933: Train: 0.000943, Val: 0.002114, Total: 0.001089, LR: 1.84e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  934: Train: 0.000919, Val: 0.001876, Total: 0.001039, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  935: Train: 0.000927, Val: 0.002131, Total: 0.001077, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  936: Train: 0.000975, Val: 0.002095, Total: 0.001115, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  937: Train: 0.000984, Val: 0.002214, Total: 0.001138, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  938: Train: 0.001016, Val: 0.002456, Total: 0.001196, LR: 1.85e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  939: Train: 0.000960, Val: 0.001798, Total: 0.001065, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  940: Train: 0.000987, Val: 0.002218, Total: 0.001141, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  941: Train: 0.000969, Val: 0.001791, Total: 0.001072, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  942: Train: 0.000966, Val: 0.002279, Total: 0.001130, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  943: Train: 0.000938, Val: 0.002111, Total: 0.001085, LR: 1.86e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  944: Train: 0.000929, Val: 0.002137, Total: 0.001080, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  945: Train: 0.000864, Val: 0.001841, Total: 0.000986, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  946: Train: 0.000880, Val: 0.001917, Total: 0.001010, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  947: Train: 0.000939, Val: 0.002674, Total: 0.001156, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  948: Train: 0.000867, Val: 0.002788, Total: 0.001107, LR: 1.87e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  949: Train: 0.000859, Val: 0.002839, Total: 0.001107, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  950: Train: 0.000831, Val: 0.002637, Total: 0.001056, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  951: Train: 0.000873, Val: 0.002512, Total: 0.001078, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  952: Train: 0.000877, Val: 0.002254, Total: 0.001049, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  953: Train: 0.000847, Val: 0.002211, Total: 0.001017, LR: 1.88e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  954: Train: 0.000842, Val: 0.001996, Total: 0.000986, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  955: Train: 0.000934, Val: 0.002034, Total: 0.001071, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  956: Train: 0.000920, Val: 0.001913, Total: 0.001044, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  957: Train: 0.000985, Val: 0.002494, Total: 0.001173, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  958: Train: 0.001138, Val: 0.001938, Total: 0.001238, LR: 1.89e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  959: Train: 0.000916, Val: 0.002212, Total: 0.001078, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  960: Train: 0.000890, Val: 0.002028, Total: 0.001032, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  961: Train: 0.000913, Val: 0.001921, Total: 0.001039, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  962: Train: 0.000904, Val: 0.001827, Total: 0.001020, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  963: Train: 0.000834, Val: 0.001938, Total: 0.000972, LR: 1.90e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  964: Train: 0.000942, Val: 0.002263, Total: 0.001107, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  965: Train: 0.000864, Val: 0.002040, Total: 0.001011, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  966: Train: 0.000830, Val: 0.001886, Total: 0.000962, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  967: Train: 0.000849, Val: 0.001819, Total: 0.000970, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  968: Train: 0.000852, Val: 0.002237, Total: 0.001025, LR: 1.91e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  969: Train: 0.000865, Val: 0.002087, Total: 0.001017, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  970: Train: 0.000820, Val: 0.002304, Total: 0.001005, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  971: Train: 0.000763, Val: 0.002196, Total: 0.000942, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  972: Train: 0.000785, Val: 0.002060, Total: 0.000945, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  973: Train: 0.000796, Val: 0.002058, Total: 0.000954, LR: 1.92e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  974: Train: 0.000793, Val: 0.002335, Total: 0.000986, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  975: Train: 0.000769, Val: 0.002093, Total: 0.000935, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  976: Train: 0.000744, Val: 0.002023, Total: 0.000903, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  977: Train: 0.000754, Val: 0.002193, Total: 0.000934, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  978: Train: 0.000740, Val: 0.002215, Total: 0.000925, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  979: Train: 0.000796, Val: 0.002111, Total: 0.000961, LR: 1.93e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  980: Train: 0.000813, Val: 0.002387, Total: 0.001010, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  981: Train: 0.000854, Val: 0.002182, Total: 0.001020, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  982: Train: 0.000841, Val: 0.001945, Total: 0.000979, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  983: Train: 0.000821, Val: 0.002032, Total: 0.000973, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  984: Train: 0.000848, Val: 0.002141, Total: 0.001010, LR: 1.94e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  985: Train: 0.000822, Val: 0.002023, Total: 0.000972, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  986: Train: 0.000847, Val: 0.002072, Total: 0.001001, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  987: Train: 0.000888, Val: 0.002023, Total: 0.001030, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  988: Train: 0.000808, Val: 0.002005, Total: 0.000958, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  989: Train: 0.000792, Val: 0.002086, Total: 0.000954, LR: 1.95e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  990: Train: 0.000791, Val: 0.002168, Total: 0.000963, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  991: Train: 0.000811, Val: 0.002004, Total: 0.000960, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  992: Train: 0.000803, Val: 0.001980, Total: 0.000950, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  993: Train: 0.001115, Val: 0.001966, Total: 0.001221, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  994: Train: 0.001364, Val: 0.002090, Total: 0.001454, LR: 1.96e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  995: Train: 0.001005, Val: 0.002787, Total: 0.001228, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  996: Train: 0.001011, Val: 0.001797, Total: 0.001109, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  997: Train: 0.001076, Val: 0.001866, Total: 0.001174, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  998: Train: 0.001107, Val: 0.003479, Total: 0.001403, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch  999: Train: 0.001366, Val: 0.002487, Total: 0.001507, LR: 1.97e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1000: Train: 0.001182, Val: 0.002470, Total: 0.001343, LR: 1.98e-03 [WARMUP]\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1001: Train: 0.001240, Val: 0.001404, Total: 0.001260, LR: 1.98e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1002: Train: 0.001111, Val: 0.002811, Total: 0.001324, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1003: Train: 0.001176, Val: 0.002503, Total: 0.001342, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1004: Train: 0.001038, Val: 0.002395, Total: 0.001207, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1005: Train: 0.001079, Val: 0.002421, Total: 0.001247, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1006: Train: 0.001084, Val: 0.002573, Total: 0.001270, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1007: Train: 0.001174, Val: 0.001654, Total: 0.001234, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1008: Train: 0.001136, Val: 0.001761, Total: 0.001214, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1009: Train: 0.001078, Val: 0.002502, Total: 0.001256, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1010: Train: 0.000971, Val: 0.002903, Total: 0.001212, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1011: Train: 0.000989, Val: 0.002200, Total: 0.001141, LR: 1.97e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1012: Train: 0.001068, Val: 0.002498, Total: 0.001247, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1013: Train: 0.001050, Val: 0.001493, Total: 0.001105, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1014: Train: 0.001140, Val: 0.002603, Total: 0.001323, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1015: Train: 0.001033, Val: 0.002734, Total: 0.001245, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1016: Train: 0.001002, Val: 0.002339, Total: 0.001169, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1017: Train: 0.001029, Val: 0.002416, Total: 0.001202, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1018: Train: 0.000954, Val: 0.002009, Total: 0.001086, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1019: Train: 0.000935, Val: 0.002023, Total: 0.001071, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1020: Train: 0.000920, Val: 0.001942, Total: 0.001048, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1021: Train: 0.000896, Val: 0.002087, Total: 0.001045, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1022: Train: 0.000851, Val: 0.001903, Total: 0.000982, LR: 1.96e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1023: Train: 0.000814, Val: 0.001995, Total: 0.000962, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1024: Train: 0.000907, Val: 0.002067, Total: 0.001052, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1025: Train: 0.000890, Val: 0.002251, Total: 0.001060, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1026: Train: 0.000924, Val: 0.002134, Total: 0.001076, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1027: Train: 0.000985, Val: 0.002241, Total: 0.001142, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1028: Train: 0.000994, Val: 0.001803, Total: 0.001095, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1029: Train: 0.001008, Val: 0.002372, Total: 0.001178, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1030: Train: 0.000905, Val: 0.001850, Total: 0.001023, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1031: Train: 0.000912, Val: 0.001939, Total: 0.001040, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1032: Train: 0.001047, Val: 0.001810, Total: 0.001142, LR: 1.95e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1033: Train: 0.001056, Val: 0.002100, Total: 0.001186, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1034: Train: 0.000946, Val: 0.002387, Total: 0.001126, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1035: Train: 0.000923, Val: 0.001828, Total: 0.001037, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1036: Train: 0.000958, Val: 0.002403, Total: 0.001138, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1037: Train: 0.000962, Val: 0.002002, Total: 0.001092, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1038: Train: 0.000972, Val: 0.002331, Total: 0.001142, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1039: Train: 0.000903, Val: 0.002067, Total: 0.001049, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1040: Train: 0.000837, Val: 0.001845, Total: 0.000963, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1041: Train: 0.000821, Val: 0.002232, Total: 0.000998, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1042: Train: 0.000846, Val: 0.002143, Total: 0.001008, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1043: Train: 0.000913, Val: 0.002126, Total: 0.001065, LR: 1.94e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1044: Train: 0.000918, Val: 0.002000, Total: 0.001054, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1045: Train: 0.000939, Val: 0.002023, Total: 0.001075, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1046: Train: 0.000888, Val: 0.002015, Total: 0.001029, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1047: Train: 0.000939, Val: 0.002274, Total: 0.001106, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1048: Train: 0.000946, Val: 0.001730, Total: 0.001044, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1049: Train: 0.000866, Val: 0.002009, Total: 0.001009, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1050: Train: 0.000928, Val: 0.001817, Total: 0.001039, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1051: Train: 0.001001, Val: 0.001633, Total: 0.001080, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1052: Train: 0.000926, Val: 0.002162, Total: 0.001080, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1053: Train: 0.000961, Val: 0.002260, Total: 0.001123, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1054: Train: 0.001008, Val: 0.002271, Total: 0.001166, LR: 1.93e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1055: Train: 0.000992, Val: 0.002324, Total: 0.001159, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1056: Train: 0.002201, Val: 0.002982, Total: 0.002299, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1057: Train: 0.002487, Val: 0.002422, Total: 0.002479, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1058: Train: 0.001843, Val: 0.002687, Total: 0.001949, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1059: Train: 0.002018, Val: 0.002347, Total: 0.002059, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1060: Train: 0.001845, Val: 0.002581, Total: 0.001937, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1061: Train: 0.001589, Val: 0.002100, Total: 0.001653, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1062: Train: 0.001412, Val: 0.002222, Total: 0.001513, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1063: Train: 0.001228, Val: 0.002348, Total: 0.001368, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1064: Train: 0.001058, Val: 0.001937, Total: 0.001168, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1065: Train: 0.001329, Val: 0.002336, Total: 0.001455, LR: 1.92e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1066: Train: 0.001321, Val: 0.001857, Total: 0.001388, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1067: Train: 0.001093, Val: 0.002183, Total: 0.001229, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1068: Train: 0.001259, Val: 0.002129, Total: 0.001368, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1069: Train: 0.001112, Val: 0.002253, Total: 0.001255, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1070: Train: 0.001061, Val: 0.002415, Total: 0.001230, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1071: Train: 0.000980, Val: 0.002104, Total: 0.001120, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1072: Train: 0.000948, Val: 0.001795, Total: 0.001054, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1073: Train: 0.000869, Val: 0.002098, Total: 0.001022, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1074: Train: 0.000884, Val: 0.002272, Total: 0.001057, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1075: Train: 0.000938, Val: 0.002413, Total: 0.001123, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1076: Train: 0.000931, Val: 0.001734, Total: 0.001031, LR: 1.91e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1077: Train: 0.000890, Val: 0.002093, Total: 0.001041, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1078: Train: 0.000906, Val: 0.001582, Total: 0.000991, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1079: Train: 0.000992, Val: 0.001692, Total: 0.001080, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1080: Train: 0.000958, Val: 0.002310, Total: 0.001127, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1081: Train: 0.000950, Val: 0.002851, Total: 0.001187, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1082: Train: 0.001014, Val: 0.002667, Total: 0.001221, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1083: Train: 0.000969, Val: 0.002395, Total: 0.001147, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1084: Train: 0.000991, Val: 0.002611, Total: 0.001194, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1085: Train: 0.000896, Val: 0.002645, Total: 0.001114, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1086: Train: 0.000895, Val: 0.002645, Total: 0.001114, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1087: Train: 0.001002, Val: 0.002741, Total: 0.001219, LR: 1.90e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1088: Train: 0.000875, Val: 0.002700, Total: 0.001103, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1089: Train: 0.000895, Val: 0.002706, Total: 0.001121, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1090: Train: 0.000928, Val: 0.002474, Total: 0.001121, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1091: Train: 0.001003, Val: 0.002299, Total: 0.001165, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1092: Train: 0.000926, Val: 0.002648, Total: 0.001142, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1093: Train: 0.000913, Val: 0.002741, Total: 0.001141, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1094: Train: 0.000849, Val: 0.002564, Total: 0.001063, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1095: Train: 0.000889, Val: 0.002170, Total: 0.001049, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1096: Train: 0.000837, Val: 0.002286, Total: 0.001018, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1097: Train: 0.000827, Val: 0.002448, Total: 0.001030, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1098: Train: 0.000840, Val: 0.002157, Total: 0.001005, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1099: Train: 0.000831, Val: 0.002496, Total: 0.001039, LR: 1.89e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1100: Train: 0.000852, Val: 0.002445, Total: 0.001051, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1101: Train: 0.000856, Val: 0.002229, Total: 0.001028, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1102: Train: 0.000863, Val: 0.002202, Total: 0.001031, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1103: Train: 0.000831, Val: 0.002387, Total: 0.001026, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1104: Train: 0.000861, Val: 0.002245, Total: 0.001034, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1105: Train: 0.000824, Val: 0.002446, Total: 0.001027, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1106: Train: 0.000830, Val: 0.002326, Total: 0.001017, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1107: Train: 0.000824, Val: 0.002175, Total: 0.000993, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1108: Train: 0.000778, Val: 0.002276, Total: 0.000965, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1109: Train: 0.000780, Val: 0.002308, Total: 0.000971, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1110: Train: 0.000817, Val: 0.002260, Total: 0.000997, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1111: Train: 0.000777, Val: 0.002308, Total: 0.000969, LR: 1.88e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1112: Train: 0.000803, Val: 0.002234, Total: 0.000981, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1113: Train: 0.000824, Val: 0.002293, Total: 0.001007, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1114: Train: 0.000850, Val: 0.001999, Total: 0.000993, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1115: Train: 0.000856, Val: 0.002387, Total: 0.001048, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1116: Train: 0.000840, Val: 0.002232, Total: 0.001014, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1117: Train: 0.000879, Val: 0.002307, Total: 0.001058, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1118: Train: 0.000890, Val: 0.002124, Total: 0.001044, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1119: Train: 0.000894, Val: 0.002438, Total: 0.001087, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1120: Train: 0.000866, Val: 0.002407, Total: 0.001058, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1121: Train: 0.000852, Val: 0.002556, Total: 0.001065, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1122: Train: 0.000816, Val: 0.002275, Total: 0.000999, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1123: Train: 0.000888, Val: 0.002591, Total: 0.001100, LR: 1.87e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1124: Train: 0.000828, Val: 0.002459, Total: 0.001032, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1125: Train: 0.000840, Val: 0.002203, Total: 0.001010, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1126: Train: 0.000823, Val: 0.002233, Total: 0.000999, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1127: Train: 0.000839, Val: 0.002556, Total: 0.001054, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1128: Train: 0.000818, Val: 0.002256, Total: 0.000998, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1129: Train: 0.000806, Val: 0.002241, Total: 0.000985, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1130: Train: 0.000855, Val: 0.002206, Total: 0.001024, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1131: Train: 0.000786, Val: 0.002074, Total: 0.000947, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1132: Train: 0.000784, Val: 0.002119, Total: 0.000951, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1133: Train: 0.000799, Val: 0.002123, Total: 0.000964, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1134: Train: 0.000771, Val: 0.002160, Total: 0.000945, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1135: Train: 0.000802, Val: 0.002035, Total: 0.000956, LR: 1.86e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1136: Train: 0.000763, Val: 0.002185, Total: 0.000941, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1137: Train: 0.000753, Val: 0.002101, Total: 0.000921, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1138: Train: 0.000816, Val: 0.002152, Total: 0.000983, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1139: Train: 0.000801, Val: 0.001848, Total: 0.000932, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1140: Train: 0.000753, Val: 0.002227, Total: 0.000937, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1141: Train: 0.000765, Val: 0.002087, Total: 0.000930, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1142: Train: 0.000786, Val: 0.002158, Total: 0.000958, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1143: Train: 0.000815, Val: 0.001957, Total: 0.000958, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1144: Train: 0.000771, Val: 0.002121, Total: 0.000940, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1145: Train: 0.000798, Val: 0.002092, Total: 0.000960, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1146: Train: 0.000785, Val: 0.002050, Total: 0.000943, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1147: Train: 0.000795, Val: 0.002149, Total: 0.000965, LR: 1.85e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1148: Train: 0.000840, Val: 0.002093, Total: 0.000997, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1149: Train: 0.000959, Val: 0.002049, Total: 0.001096, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1150: Train: 0.000956, Val: 0.002375, Total: 0.001133, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1151: Train: 0.000918, Val: 0.002082, Total: 0.001064, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1152: Train: 0.000851, Val: 0.001883, Total: 0.000980, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1153: Train: 0.000884, Val: 0.002098, Total: 0.001035, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1154: Train: 0.000815, Val: 0.001896, Total: 0.000950, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1155: Train: 0.000843, Val: 0.002326, Total: 0.001028, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1156: Train: 0.000809, Val: 0.002045, Total: 0.000963, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1157: Train: 0.000819, Val: 0.002066, Total: 0.000975, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1158: Train: 0.000861, Val: 0.002026, Total: 0.001007, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1159: Train: 0.000865, Val: 0.001946, Total: 0.001000, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1160: Train: 0.000862, Val: 0.002220, Total: 0.001031, LR: 1.84e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1161: Train: 0.000897, Val: 0.002144, Total: 0.001053, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1162: Train: 0.000830, Val: 0.002341, Total: 0.001019, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1163: Train: 0.000816, Val: 0.002016, Total: 0.000966, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1164: Train: 0.000844, Val: 0.002330, Total: 0.001029, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1165: Train: 0.000886, Val: 0.001901, Total: 0.001013, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1166: Train: 0.000804, Val: 0.002124, Total: 0.000969, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1167: Train: 0.000781, Val: 0.002259, Total: 0.000965, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1168: Train: 0.000800, Val: 0.002129, Total: 0.000966, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1169: Train: 0.000796, Val: 0.002226, Total: 0.000974, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1170: Train: 0.000802, Val: 0.001960, Total: 0.000947, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1171: Train: 0.000809, Val: 0.002500, Total: 0.001020, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1172: Train: 0.000753, Val: 0.001960, Total: 0.000904, LR: 1.83e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1173: Train: 0.000739, Val: 0.002087, Total: 0.000908, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1174: Train: 0.000752, Val: 0.002066, Total: 0.000916, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1175: Train: 0.000753, Val: 0.002094, Total: 0.000920, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1176: Train: 0.000766, Val: 0.002017, Total: 0.000923, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1177: Train: 0.000794, Val: 0.001869, Total: 0.000929, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1178: Train: 0.000769, Val: 0.002093, Total: 0.000935, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1179: Train: 0.000754, Val: 0.001804, Total: 0.000885, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1180: Train: 0.000782, Val: 0.002143, Total: 0.000952, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1181: Train: 0.000761, Val: 0.001998, Total: 0.000915, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1182: Train: 0.000758, Val: 0.001917, Total: 0.000902, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1183: Train: 0.000749, Val: 0.002111, Total: 0.000920, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1184: Train: 0.000734, Val: 0.001915, Total: 0.000881, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1185: Train: 0.000754, Val: 0.002030, Total: 0.000913, LR: 1.82e-03\n",
      "          Best: Train: 0.000768, Val: 0.001570, Total: 0.000869 (Epoch 582)\n",
      "Epoch 1186: Train: 0.000722, Val: 0.001818, Total: 0.000859, LR: 1.81e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1187: Train: 0.000749, Val: 0.001834, Total: 0.000884, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1188: Train: 0.000800, Val: 0.002098, Total: 0.000963, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1189: Train: 0.000777, Val: 0.002020, Total: 0.000932, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1190: Train: 0.000745, Val: 0.001787, Total: 0.000876, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1191: Train: 0.000766, Val: 0.002033, Total: 0.000924, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1192: Train: 0.000768, Val: 0.002041, Total: 0.000927, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1193: Train: 0.000728, Val: 0.002035, Total: 0.000891, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1194: Train: 0.000780, Val: 0.002151, Total: 0.000951, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1195: Train: 0.000753, Val: 0.002111, Total: 0.000923, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1196: Train: 0.000733, Val: 0.001974, Total: 0.000888, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1197: Train: 0.000745, Val: 0.002091, Total: 0.000914, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1198: Train: 0.000775, Val: 0.002093, Total: 0.000940, LR: 1.81e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1199: Train: 0.000759, Val: 0.001958, Total: 0.000909, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1200: Train: 0.000765, Val: 0.002143, Total: 0.000937, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1201: Train: 0.000730, Val: 0.002090, Total: 0.000900, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1202: Train: 0.000709, Val: 0.002039, Total: 0.000876, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1203: Train: 0.000727, Val: 0.002075, Total: 0.000895, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1204: Train: 0.000716, Val: 0.002048, Total: 0.000882, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1205: Train: 0.000712, Val: 0.002165, Total: 0.000894, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1206: Train: 0.000731, Val: 0.002136, Total: 0.000906, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1207: Train: 0.000701, Val: 0.002036, Total: 0.000868, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1208: Train: 0.000738, Val: 0.002078, Total: 0.000906, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1209: Train: 0.000755, Val: 0.002078, Total: 0.000920, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1210: Train: 0.000727, Val: 0.002136, Total: 0.000903, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1211: Train: 0.000726, Val: 0.002097, Total: 0.000897, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1212: Train: 0.000754, Val: 0.001817, Total: 0.000887, LR: 1.80e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1213: Train: 0.000738, Val: 0.002237, Total: 0.000925, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1214: Train: 0.000738, Val: 0.002060, Total: 0.000903, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1215: Train: 0.000770, Val: 0.001961, Total: 0.000919, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1216: Train: 0.000785, Val: 0.001917, Total: 0.000927, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1217: Train: 0.000733, Val: 0.001997, Total: 0.000891, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1218: Train: 0.000709, Val: 0.001988, Total: 0.000869, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1219: Train: 0.000745, Val: 0.002002, Total: 0.000902, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1220: Train: 0.000743, Val: 0.002060, Total: 0.000908, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1221: Train: 0.000725, Val: 0.001891, Total: 0.000871, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1222: Train: 0.000798, Val: 0.002131, Total: 0.000965, LR: 1.79e-03\n",
      "          Best: Train: 0.000722, Val: 0.001818, Total: 0.000859 (Epoch 1186)\n",
      "Epoch 1223: Train: 0.000717, Val: 0.001825, Total: 0.000856, LR: 1.79e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1224: Train: 0.000750, Val: 0.001983, Total: 0.000904, LR: 1.79e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1225: Train: 0.000730, Val: 0.001956, Total: 0.000883, LR: 1.79e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1226: Train: 0.000739, Val: 0.001864, Total: 0.000879, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1227: Train: 0.000736, Val: 0.002208, Total: 0.000920, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1228: Train: 0.000794, Val: 0.001688, Total: 0.000906, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1229: Train: 0.000778, Val: 0.002389, Total: 0.000979, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1230: Train: 0.000787, Val: 0.001938, Total: 0.000931, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1231: Train: 0.000765, Val: 0.002206, Total: 0.000945, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1232: Train: 0.000777, Val: 0.001996, Total: 0.000929, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1233: Train: 0.000726, Val: 0.001891, Total: 0.000872, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1234: Train: 0.000759, Val: 0.002053, Total: 0.000921, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1235: Train: 0.000795, Val: 0.001941, Total: 0.000939, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1236: Train: 0.000722, Val: 0.002069, Total: 0.000890, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1237: Train: 0.000748, Val: 0.001966, Total: 0.000900, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1238: Train: 0.000751, Val: 0.002281, Total: 0.000942, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1239: Train: 0.000764, Val: 0.002095, Total: 0.000930, LR: 1.78e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1240: Train: 0.000758, Val: 0.001941, Total: 0.000906, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1241: Train: 0.000715, Val: 0.001854, Total: 0.000857, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1242: Train: 0.000738, Val: 0.001719, Total: 0.000860, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1243: Train: 0.000726, Val: 0.002224, Total: 0.000913, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1244: Train: 0.000738, Val: 0.001785, Total: 0.000869, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1245: Train: 0.000740, Val: 0.001871, Total: 0.000882, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1246: Train: 0.000784, Val: 0.001957, Total: 0.000931, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1247: Train: 0.000745, Val: 0.001876, Total: 0.000886, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1248: Train: 0.000744, Val: 0.001953, Total: 0.000895, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1249: Train: 0.000764, Val: 0.002096, Total: 0.000930, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1250: Train: 0.000742, Val: 0.001958, Total: 0.000894, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1251: Train: 0.000773, Val: 0.001928, Total: 0.000918, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1252: Train: 0.000825, Val: 0.001890, Total: 0.000958, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1253: Train: 0.000789, Val: 0.002035, Total: 0.000945, LR: 1.77e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1254: Train: 0.000775, Val: 0.002014, Total: 0.000930, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1255: Train: 0.000768, Val: 0.001969, Total: 0.000918, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1256: Train: 0.000739, Val: 0.001942, Total: 0.000890, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1257: Train: 0.000715, Val: 0.002006, Total: 0.000876, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1258: Train: 0.000768, Val: 0.002088, Total: 0.000933, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1259: Train: 0.000729, Val: 0.001976, Total: 0.000885, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1260: Train: 0.000719, Val: 0.002010, Total: 0.000880, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1261: Train: 0.000766, Val: 0.001890, Total: 0.000906, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1262: Train: 0.000743, Val: 0.002158, Total: 0.000920, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1263: Train: 0.000713, Val: 0.002018, Total: 0.000876, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1264: Train: 0.000747, Val: 0.002002, Total: 0.000904, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1265: Train: 0.000745, Val: 0.002039, Total: 0.000906, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1266: Train: 0.000713, Val: 0.001980, Total: 0.000871, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1267: Train: 0.000735, Val: 0.002106, Total: 0.000906, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1268: Train: 0.000740, Val: 0.002078, Total: 0.000907, LR: 1.76e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1269: Train: 0.000740, Val: 0.001935, Total: 0.000890, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1270: Train: 0.000730, Val: 0.001972, Total: 0.000885, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1271: Train: 0.000737, Val: 0.001915, Total: 0.000884, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1272: Train: 0.000783, Val: 0.002114, Total: 0.000949, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1273: Train: 0.000762, Val: 0.001993, Total: 0.000916, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1274: Train: 0.000759, Val: 0.002024, Total: 0.000917, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1275: Train: 0.000767, Val: 0.002016, Total: 0.000923, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1276: Train: 0.000808, Val: 0.002312, Total: 0.000996, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1277: Train: 0.000781, Val: 0.001988, Total: 0.000932, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1278: Train: 0.000859, Val: 0.002411, Total: 0.001053, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1279: Train: 0.000885, Val: 0.002002, Total: 0.001024, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1280: Train: 0.000759, Val: 0.001825, Total: 0.000892, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1281: Train: 0.000750, Val: 0.002251, Total: 0.000937, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1282: Train: 0.000725, Val: 0.001871, Total: 0.000868, LR: 1.75e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1283: Train: 0.000799, Val: 0.002204, Total: 0.000974, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1284: Train: 0.000762, Val: 0.001818, Total: 0.000894, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1285: Train: 0.000741, Val: 0.001951, Total: 0.000893, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1286: Train: 0.000750, Val: 0.002044, Total: 0.000912, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1287: Train: 0.000715, Val: 0.002140, Total: 0.000893, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1288: Train: 0.000722, Val: 0.002141, Total: 0.000899, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1289: Train: 0.000701, Val: 0.001955, Total: 0.000858, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1290: Train: 0.000752, Val: 0.002026, Total: 0.000911, LR: 1.74e-03\n",
      "          Best: Train: 0.000717, Val: 0.001825, Total: 0.000856 (Epoch 1223)\n",
      "Epoch 1291: Train: 0.000698, Val: 0.001925, Total: 0.000851, LR: 1.74e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000698, Val: 0.001925, Total: 0.000851 (Epoch 1291)\n",
      "Epoch 1292: Train: 0.000694, Val: 0.002109, Total: 0.000871, LR: 1.74e-03\n",
      "          Best: Train: 0.000698, Val: 0.001925, Total: 0.000851 (Epoch 1291)\n",
      "Epoch 1293: Train: 0.000711, Val: 0.001950, Total: 0.000866, LR: 1.74e-03\n",
      "          Best: Train: 0.000698, Val: 0.001925, Total: 0.000851 (Epoch 1291)\n",
      "Epoch 1294: Train: 0.000757, Val: 0.002121, Total: 0.000927, LR: 1.74e-03\n",
      "          Best: Train: 0.000698, Val: 0.001925, Total: 0.000851 (Epoch 1291)\n",
      "Epoch 1295: Train: 0.000694, Val: 0.001937, Total: 0.000850, LR: 1.74e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000694, Val: 0.001937, Total: 0.000850 (Epoch 1295)\n",
      "Epoch 1296: Train: 0.000753, Val: 0.002053, Total: 0.000916, LR: 1.74e-03\n",
      "          Best: Train: 0.000694, Val: 0.001937, Total: 0.000850 (Epoch 1295)\n",
      "Epoch 1297: Train: 0.000723, Val: 0.002023, Total: 0.000885, LR: 1.74e-03\n",
      "          Best: Train: 0.000694, Val: 0.001937, Total: 0.000850 (Epoch 1295)\n",
      "Epoch 1298: Train: 0.000708, Val: 0.002043, Total: 0.000875, LR: 1.73e-03\n",
      "          Best: Train: 0.000694, Val: 0.001937, Total: 0.000850 (Epoch 1295)\n",
      "Epoch 1299: Train: 0.000697, Val: 0.001869, Total: 0.000843, LR: 1.73e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1300: Train: 0.000714, Val: 0.001956, Total: 0.000869, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1301: Train: 0.000740, Val: 0.002028, Total: 0.000901, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1302: Train: 0.000733, Val: 0.001814, Total: 0.000868, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1303: Train: 0.000762, Val: 0.001939, Total: 0.000909, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1304: Train: 0.000760, Val: 0.001831, Total: 0.000894, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1305: Train: 0.000740, Val: 0.002095, Total: 0.000909, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1306: Train: 0.000762, Val: 0.001991, Total: 0.000915, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1307: Train: 0.000746, Val: 0.002146, Total: 0.000921, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1308: Train: 0.000756, Val: 0.001977, Total: 0.000909, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1309: Train: 0.000752, Val: 0.002073, Total: 0.000917, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1310: Train: 0.000728, Val: 0.001936, Total: 0.000879, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1311: Train: 0.000719, Val: 0.002239, Total: 0.000909, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1312: Train: 0.000730, Val: 0.002073, Total: 0.000898, LR: 1.73e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1313: Train: 0.000764, Val: 0.002254, Total: 0.000950, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1314: Train: 0.000779, Val: 0.002253, Total: 0.000963, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1315: Train: 0.000763, Val: 0.001969, Total: 0.000914, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1316: Train: 0.000834, Val: 0.001814, Total: 0.000957, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1317: Train: 0.000793, Val: 0.002221, Total: 0.000972, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1318: Train: 0.000791, Val: 0.002152, Total: 0.000961, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1319: Train: 0.000854, Val: 0.001831, Total: 0.000976, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1320: Train: 0.000749, Val: 0.002172, Total: 0.000927, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1321: Train: 0.000757, Val: 0.001817, Total: 0.000890, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1322: Train: 0.000775, Val: 0.002093, Total: 0.000940, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1323: Train: 0.000863, Val: 0.001991, Total: 0.001004, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1324: Train: 0.000795, Val: 0.001822, Total: 0.000924, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1325: Train: 0.000750, Val: 0.001908, Total: 0.000894, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1326: Train: 0.000747, Val: 0.002167, Total: 0.000924, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1327: Train: 0.000781, Val: 0.002065, Total: 0.000941, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1328: Train: 0.000743, Val: 0.001782, Total: 0.000873, LR: 1.72e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1329: Train: 0.000744, Val: 0.002047, Total: 0.000907, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1330: Train: 0.000744, Val: 0.002147, Total: 0.000919, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1331: Train: 0.000746, Val: 0.001984, Total: 0.000901, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1332: Train: 0.000733, Val: 0.001857, Total: 0.000874, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1333: Train: 0.000788, Val: 0.001817, Total: 0.000917, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1334: Train: 0.000731, Val: 0.001954, Total: 0.000884, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1335: Train: 0.000771, Val: 0.002137, Total: 0.000941, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1336: Train: 0.000748, Val: 0.001922, Total: 0.000895, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1337: Train: 0.000712, Val: 0.001874, Total: 0.000858, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1338: Train: 0.000751, Val: 0.002011, Total: 0.000909, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1339: Train: 0.000738, Val: 0.001954, Total: 0.000890, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1340: Train: 0.000742, Val: 0.001900, Total: 0.000886, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1341: Train: 0.000703, Val: 0.002044, Total: 0.000870, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1342: Train: 0.000704, Val: 0.001893, Total: 0.000853, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1343: Train: 0.000729, Val: 0.001788, Total: 0.000862, LR: 1.71e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1344: Train: 0.000746, Val: 0.002090, Total: 0.000914, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1345: Train: 0.000719, Val: 0.001887, Total: 0.000865, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1346: Train: 0.000731, Val: 0.001788, Total: 0.000863, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1347: Train: 0.000749, Val: 0.002177, Total: 0.000927, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1348: Train: 0.000740, Val: 0.001932, Total: 0.000889, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1349: Train: 0.000737, Val: 0.001967, Total: 0.000891, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1350: Train: 0.000739, Val: 0.002040, Total: 0.000901, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1351: Train: 0.000771, Val: 0.001910, Total: 0.000914, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1352: Train: 0.000765, Val: 0.001837, Total: 0.000899, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1353: Train: 0.000760, Val: 0.002039, Total: 0.000920, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1354: Train: 0.000764, Val: 0.001879, Total: 0.000903, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1355: Train: 0.000732, Val: 0.002039, Total: 0.000895, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1356: Train: 0.000777, Val: 0.002177, Total: 0.000952, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1357: Train: 0.000747, Val: 0.002139, Total: 0.000921, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1358: Train: 0.000792, Val: 0.002242, Total: 0.000974, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1359: Train: 0.000727, Val: 0.001864, Total: 0.000869, LR: 1.70e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1360: Train: 0.000743, Val: 0.002279, Total: 0.000935, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1361: Train: 0.000823, Val: 0.001852, Total: 0.000952, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1362: Train: 0.000806, Val: 0.001913, Total: 0.000944, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1363: Train: 0.000749, Val: 0.001893, Total: 0.000892, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1364: Train: 0.000782, Val: 0.001918, Total: 0.000924, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1365: Train: 0.000737, Val: 0.001789, Total: 0.000869, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1366: Train: 0.000777, Val: 0.002241, Total: 0.000960, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1367: Train: 0.000821, Val: 0.001902, Total: 0.000956, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1368: Train: 0.000903, Val: 0.002280, Total: 0.001075, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1369: Train: 0.001041, Val: 0.002046, Total: 0.001166, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1370: Train: 0.001069, Val: 0.001984, Total: 0.001183, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1371: Train: 0.001031, Val: 0.002325, Total: 0.001193, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1372: Train: 0.001155, Val: 0.001662, Total: 0.001218, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1373: Train: 0.001221, Val: 0.001527, Total: 0.001259, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1374: Train: 0.001063, Val: 0.003122, Total: 0.001321, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1375: Train: 0.001351, Val: 0.002549, Total: 0.001501, LR: 1.69e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1376: Train: 0.001487, Val: 0.003050, Total: 0.001683, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1377: Train: 0.001710, Val: 0.002326, Total: 0.001787, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1378: Train: 0.001750, Val: 0.002023, Total: 0.001784, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1379: Train: 0.001871, Val: 0.005260, Total: 0.002295, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1380: Train: 0.005257, Val: 0.003314, Total: 0.005014, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1381: Train: 0.003264, Val: 0.004297, Total: 0.003393, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1382: Train: 0.003160, Val: 0.001724, Total: 0.002980, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1383: Train: 0.003349, Val: 0.002143, Total: 0.003199, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1384: Train: 0.003049, Val: 0.001915, Total: 0.002907, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1385: Train: 0.002941, Val: 0.003683, Total: 0.003033, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1386: Train: 0.002433, Val: 0.004996, Total: 0.002753, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1387: Train: 0.002112, Val: 0.004723, Total: 0.002439, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1388: Train: 0.002251, Val: 0.004417, Total: 0.002521, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1389: Train: 0.002787, Val: 0.004136, Total: 0.002956, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1390: Train: 0.004275, Val: 0.003146, Total: 0.004134, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1391: Train: 0.004121, Val: 0.003267, Total: 0.004015, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1392: Train: 0.002764, Val: 0.003531, Total: 0.002860, LR: 1.68e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1393: Train: 0.002081, Val: 0.004514, Total: 0.002385, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1394: Train: 0.001964, Val: 0.004448, Total: 0.002274, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1395: Train: 0.001900, Val: 0.004057, Total: 0.002169, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1396: Train: 0.002006, Val: 0.001914, Total: 0.001994, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1397: Train: 0.002079, Val: 0.002192, Total: 0.002093, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1398: Train: 0.002229, Val: 0.003512, Total: 0.002389, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1399: Train: 0.002027, Val: 0.003640, Total: 0.002228, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1400: Train: 0.001881, Val: 0.003082, Total: 0.002031, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1401: Train: 0.001918, Val: 0.002332, Total: 0.001970, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1402: Train: 0.001909, Val: 0.002164, Total: 0.001940, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1403: Train: 0.002034, Val: 0.001944, Total: 0.002023, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1404: Train: 0.001976, Val: 0.001872, Total: 0.001963, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1405: Train: 0.002074, Val: 0.001949, Total: 0.002058, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1406: Train: 0.001890, Val: 0.002111, Total: 0.001918, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1407: Train: 0.001693, Val: 0.001883, Total: 0.001717, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1408: Train: 0.001821, Val: 0.002065, Total: 0.001852, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1409: Train: 0.001644, Val: 0.002027, Total: 0.001692, LR: 1.67e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1410: Train: 0.001812, Val: 0.001938, Total: 0.001827, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1411: Train: 0.001710, Val: 0.002074, Total: 0.001756, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1412: Train: 0.001654, Val: 0.002527, Total: 0.001764, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1413: Train: 0.001852, Val: 0.002422, Total: 0.001923, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1414: Train: 0.002533, Val: 0.001854, Total: 0.002448, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1415: Train: 0.001946, Val: 0.001742, Total: 0.001920, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1416: Train: 0.002102, Val: 0.002992, Total: 0.002213, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1417: Train: 0.002050, Val: 0.003534, Total: 0.002235, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1418: Train: 0.002158, Val: 0.002976, Total: 0.002260, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1419: Train: 0.001868, Val: 0.003520, Total: 0.002075, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1420: Train: 0.001679, Val: 0.003296, Total: 0.001881, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1421: Train: 0.001715, Val: 0.002037, Total: 0.001755, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1422: Train: 0.001747, Val: 0.001848, Total: 0.001760, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1423: Train: 0.001738, Val: 0.001761, Total: 0.001741, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1424: Train: 0.001557, Val: 0.001862, Total: 0.001595, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1425: Train: 0.001588, Val: 0.001775, Total: 0.001611, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1426: Train: 0.001596, Val: 0.001769, Total: 0.001617, LR: 1.66e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1427: Train: 0.001586, Val: 0.001833, Total: 0.001617, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1428: Train: 0.001670, Val: 0.001686, Total: 0.001672, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1429: Train: 0.001665, Val: 0.001763, Total: 0.001677, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1430: Train: 0.001567, Val: 0.001879, Total: 0.001606, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1431: Train: 0.001671, Val: 0.001832, Total: 0.001691, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1432: Train: 0.001702, Val: 0.001723, Total: 0.001704, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1433: Train: 0.001563, Val: 0.001772, Total: 0.001589, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1434: Train: 0.001617, Val: 0.001816, Total: 0.001642, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1435: Train: 0.001562, Val: 0.001810, Total: 0.001593, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1436: Train: 0.001493, Val: 0.001828, Total: 0.001535, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1437: Train: 0.001518, Val: 0.001982, Total: 0.001576, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1438: Train: 0.001504, Val: 0.001797, Total: 0.001541, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1439: Train: 0.001466, Val: 0.001818, Total: 0.001510, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1440: Train: 0.001436, Val: 0.001923, Total: 0.001497, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1441: Train: 0.001472, Val: 0.001923, Total: 0.001528, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1442: Train: 0.001446, Val: 0.001958, Total: 0.001510, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1443: Train: 0.001416, Val: 0.002200, Total: 0.001514, LR: 1.65e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1444: Train: 0.001524, Val: 0.001781, Total: 0.001556, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1445: Train: 0.001430, Val: 0.002465, Total: 0.001559, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1446: Train: 0.001506, Val: 0.002029, Total: 0.001572, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1447: Train: 0.001401, Val: 0.002002, Total: 0.001476, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1448: Train: 0.001427, Val: 0.002121, Total: 0.001514, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1449: Train: 0.001433, Val: 0.001976, Total: 0.001501, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1450: Train: 0.001430, Val: 0.001798, Total: 0.001476, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1451: Train: 0.001450, Val: 0.001979, Total: 0.001516, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1452: Train: 0.001426, Val: 0.001854, Total: 0.001479, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1453: Train: 0.001354, Val: 0.001972, Total: 0.001431, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1454: Train: 0.001638, Val: 0.002509, Total: 0.001747, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1455: Train: 0.001428, Val: 0.001961, Total: 0.001495, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1456: Train: 0.001750, Val: 0.002317, Total: 0.001821, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1457: Train: 0.001613, Val: 0.002421, Total: 0.001714, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1458: Train: 0.001467, Val: 0.002010, Total: 0.001535, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1459: Train: 0.001489, Val: 0.003429, Total: 0.001732, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1460: Train: 0.001421, Val: 0.003058, Total: 0.001626, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1461: Train: 0.001344, Val: 0.003472, Total: 0.001610, LR: 1.64e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1462: Train: 0.001391, Val: 0.002946, Total: 0.001586, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1463: Train: 0.001445, Val: 0.002982, Total: 0.001637, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1464: Train: 0.001442, Val: 0.003076, Total: 0.001646, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1465: Train: 0.001361, Val: 0.002976, Total: 0.001563, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1466: Train: 0.001281, Val: 0.002936, Total: 0.001488, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1467: Train: 0.001336, Val: 0.002778, Total: 0.001516, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1468: Train: 0.001245, Val: 0.002928, Total: 0.001455, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1469: Train: 0.001402, Val: 0.003023, Total: 0.001604, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1470: Train: 0.001512, Val: 0.003744, Total: 0.001791, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1471: Train: 0.001753, Val: 0.003100, Total: 0.001921, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1472: Train: 0.001849, Val: 0.003277, Total: 0.002027, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1473: Train: 0.001954, Val: 0.002860, Total: 0.002068, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1474: Train: 0.001597, Val: 0.001419, Total: 0.001575, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1475: Train: 0.001674, Val: 0.001560, Total: 0.001660, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1476: Train: 0.001508, Val: 0.001521, Total: 0.001509, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1477: Train: 0.001552, Val: 0.001419, Total: 0.001536, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1478: Train: 0.001466, Val: 0.002133, Total: 0.001550, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1479: Train: 0.001439, Val: 0.001497, Total: 0.001446, LR: 1.63e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1480: Train: 0.001554, Val: 0.001574, Total: 0.001557, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1481: Train: 0.001672, Val: 0.001544, Total: 0.001656, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1482: Train: 0.001287, Val: 0.001897, Total: 0.001363, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1483: Train: 0.001307, Val: 0.001581, Total: 0.001341, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1484: Train: 0.001285, Val: 0.001562, Total: 0.001319, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1485: Train: 0.001207, Val: 0.001552, Total: 0.001250, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1486: Train: 0.001299, Val: 0.001524, Total: 0.001327, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1487: Train: 0.001264, Val: 0.001798, Total: 0.001331, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1488: Train: 0.001378, Val: 0.001453, Total: 0.001388, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1489: Train: 0.001445, Val: 0.001888, Total: 0.001500, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1490: Train: 0.001354, Val: 0.001542, Total: 0.001378, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1491: Train: 0.001209, Val: 0.001674, Total: 0.001267, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1492: Train: 0.001175, Val: 0.001841, Total: 0.001259, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1493: Train: 0.001170, Val: 0.002189, Total: 0.001298, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1494: Train: 0.001180, Val: 0.001776, Total: 0.001255, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1495: Train: 0.001253, Val: 0.001999, Total: 0.001346, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1496: Train: 0.001188, Val: 0.001567, Total: 0.001236, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1497: Train: 0.001189, Val: 0.001595, Total: 0.001240, LR: 1.62e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1498: Train: 0.001175, Val: 0.001493, Total: 0.001215, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1499: Train: 0.001129, Val: 0.001709, Total: 0.001202, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1500: Train: 0.001178, Val: 0.001589, Total: 0.001229, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1501: Train: 0.001200, Val: 0.001475, Total: 0.001235, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1502: Train: 0.001232, Val: 0.001799, Total: 0.001303, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1503: Train: 0.001214, Val: 0.001669, Total: 0.001271, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1504: Train: 0.001264, Val: 0.001608, Total: 0.001307, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1505: Train: 0.001171, Val: 0.002185, Total: 0.001298, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1506: Train: 0.001442, Val: 0.001681, Total: 0.001472, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1507: Train: 0.001549, Val: 0.001482, Total: 0.001541, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1508: Train: 0.001893, Val: 0.002048, Total: 0.001913, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1509: Train: 0.002872, Val: 0.001596, Total: 0.002713, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1510: Train: 0.002893, Val: 0.001648, Total: 0.002737, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1511: Train: 0.002641, Val: 0.002591, Total: 0.002635, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1512: Train: 0.002367, Val: 0.001931, Total: 0.002312, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1513: Train: 0.001803, Val: 0.001701, Total: 0.001790, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1514: Train: 0.001524, Val: 0.001761, Total: 0.001554, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1515: Train: 0.001464, Val: 0.002151, Total: 0.001550, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1516: Train: 0.001520, Val: 0.001677, Total: 0.001540, LR: 1.61e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1517: Train: 0.001548, Val: 0.001475, Total: 0.001539, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1518: Train: 0.001360, Val: 0.001410, Total: 0.001366, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1519: Train: 0.001506, Val: 0.001420, Total: 0.001495, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1520: Train: 0.001410, Val: 0.001692, Total: 0.001445, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1521: Train: 0.001411, Val: 0.001862, Total: 0.001467, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1522: Train: 0.001214, Val: 0.001828, Total: 0.001291, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1523: Train: 0.001334, Val: 0.001802, Total: 0.001392, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1524: Train: 0.001257, Val: 0.001875, Total: 0.001334, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1525: Train: 0.001360, Val: 0.001801, Total: 0.001415, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1526: Train: 0.001313, Val: 0.001835, Total: 0.001378, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1527: Train: 0.001308, Val: 0.001885, Total: 0.001380, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1528: Train: 0.001312, Val: 0.002181, Total: 0.001420, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1529: Train: 0.001346, Val: 0.001684, Total: 0.001389, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1530: Train: 0.001258, Val: 0.001776, Total: 0.001323, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1531: Train: 0.001285, Val: 0.002031, Total: 0.001378, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1532: Train: 0.001277, Val: 0.001864, Total: 0.001350, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1533: Train: 0.001334, Val: 0.002231, Total: 0.001446, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1534: Train: 0.001298, Val: 0.001552, Total: 0.001330, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1535: Train: 0.001277, Val: 0.002306, Total: 0.001406, LR: 1.60e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1536: Train: 0.001222, Val: 0.001664, Total: 0.001277, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1537: Train: 0.001367, Val: 0.001852, Total: 0.001427, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1538: Train: 0.001141, Val: 0.001846, Total: 0.001229, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1539: Train: 0.001133, Val: 0.001763, Total: 0.001212, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1540: Train: 0.001060, Val: 0.001870, Total: 0.001161, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1541: Train: 0.001070, Val: 0.001720, Total: 0.001151, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1542: Train: 0.001032, Val: 0.001787, Total: 0.001127, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1543: Train: 0.001025, Val: 0.001737, Total: 0.001114, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1544: Train: 0.001002, Val: 0.001734, Total: 0.001093, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1545: Train: 0.000991, Val: 0.001781, Total: 0.001090, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1546: Train: 0.001229, Val: 0.001982, Total: 0.001323, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1547: Train: 0.001060, Val: 0.001970, Total: 0.001173, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1548: Train: 0.001093, Val: 0.001724, Total: 0.001172, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1549: Train: 0.001035, Val: 0.001687, Total: 0.001116, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1550: Train: 0.000958, Val: 0.001782, Total: 0.001061, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1551: Train: 0.001082, Val: 0.001617, Total: 0.001149, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1552: Train: 0.001080, Val: 0.001934, Total: 0.001187, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1553: Train: 0.001103, Val: 0.001790, Total: 0.001189, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1554: Train: 0.001406, Val: 0.001881, Total: 0.001465, LR: 1.59e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1555: Train: 0.001152, Val: 0.002084, Total: 0.001268, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1556: Train: 0.001061, Val: 0.001938, Total: 0.001171, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1557: Train: 0.001039, Val: 0.001549, Total: 0.001103, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1558: Train: 0.001038, Val: 0.001529, Total: 0.001100, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1559: Train: 0.001028, Val: 0.001595, Total: 0.001098, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1560: Train: 0.000939, Val: 0.002001, Total: 0.001072, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1561: Train: 0.000965, Val: 0.001785, Total: 0.001067, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1562: Train: 0.001038, Val: 0.001905, Total: 0.001146, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1563: Train: 0.000990, Val: 0.001842, Total: 0.001097, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1564: Train: 0.001019, Val: 0.001922, Total: 0.001132, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1565: Train: 0.000961, Val: 0.001877, Total: 0.001076, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1566: Train: 0.000968, Val: 0.001893, Total: 0.001084, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1567: Train: 0.000984, Val: 0.001736, Total: 0.001078, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1568: Train: 0.001087, Val: 0.001967, Total: 0.001197, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1569: Train: 0.001020, Val: 0.001831, Total: 0.001121, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1570: Train: 0.001078, Val: 0.002062, Total: 0.001201, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1571: Train: 0.001056, Val: 0.002729, Total: 0.001265, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1572: Train: 0.000992, Val: 0.002854, Total: 0.001225, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1573: Train: 0.000972, Val: 0.002800, Total: 0.001201, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1574: Train: 0.001041, Val: 0.002859, Total: 0.001268, LR: 1.58e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1575: Train: 0.000972, Val: 0.002803, Total: 0.001201, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1576: Train: 0.000996, Val: 0.002713, Total: 0.001211, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1577: Train: 0.000991, Val: 0.002607, Total: 0.001193, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1578: Train: 0.000967, Val: 0.002572, Total: 0.001167, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1579: Train: 0.000976, Val: 0.002690, Total: 0.001190, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1580: Train: 0.001006, Val: 0.002449, Total: 0.001187, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1581: Train: 0.001002, Val: 0.002480, Total: 0.001187, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1582: Train: 0.001029, Val: 0.002527, Total: 0.001216, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1583: Train: 0.001002, Val: 0.002433, Total: 0.001181, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1584: Train: 0.000980, Val: 0.002542, Total: 0.001175, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1585: Train: 0.001017, Val: 0.002590, Total: 0.001213, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1586: Train: 0.000961, Val: 0.002511, Total: 0.001154, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1587: Train: 0.000994, Val: 0.001999, Total: 0.001119, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1588: Train: 0.000940, Val: 0.001738, Total: 0.001040, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1589: Train: 0.000970, Val: 0.001580, Total: 0.001046, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1590: Train: 0.000973, Val: 0.001802, Total: 0.001077, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1591: Train: 0.000926, Val: 0.001549, Total: 0.001004, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1592: Train: 0.000901, Val: 0.001806, Total: 0.001014, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1593: Train: 0.000970, Val: 0.001981, Total: 0.001097, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1594: Train: 0.000978, Val: 0.001753, Total: 0.001075, LR: 1.57e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1595: Train: 0.000908, Val: 0.001891, Total: 0.001031, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1596: Train: 0.000966, Val: 0.001998, Total: 0.001095, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1597: Train: 0.000901, Val: 0.001774, Total: 0.001011, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1598: Train: 0.000932, Val: 0.001901, Total: 0.001053, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1599: Train: 0.000980, Val: 0.001767, Total: 0.001078, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1600: Train: 0.000880, Val: 0.001835, Total: 0.000999, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1601: Train: 0.000908, Val: 0.001953, Total: 0.001039, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1602: Train: 0.000942, Val: 0.001791, Total: 0.001048, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1603: Train: 0.000941, Val: 0.001788, Total: 0.001047, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1604: Train: 0.000939, Val: 0.001899, Total: 0.001059, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1605: Train: 0.000911, Val: 0.001675, Total: 0.001007, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1606: Train: 0.000922, Val: 0.001736, Total: 0.001023, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1607: Train: 0.000888, Val: 0.001676, Total: 0.000987, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1608: Train: 0.000971, Val: 0.001755, Total: 0.001069, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1609: Train: 0.000960, Val: 0.001908, Total: 0.001079, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1610: Train: 0.000931, Val: 0.001773, Total: 0.001036, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1611: Train: 0.000914, Val: 0.001780, Total: 0.001022, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1612: Train: 0.000905, Val: 0.001779, Total: 0.001015, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1613: Train: 0.000950, Val: 0.001769, Total: 0.001053, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1614: Train: 0.000971, Val: 0.001930, Total: 0.001091, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1615: Train: 0.000948, Val: 0.002038, Total: 0.001084, LR: 1.56e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1616: Train: 0.000914, Val: 0.001863, Total: 0.001033, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1617: Train: 0.000966, Val: 0.001912, Total: 0.001084, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1618: Train: 0.000975, Val: 0.001874, Total: 0.001087, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1619: Train: 0.000969, Val: 0.001780, Total: 0.001071, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1620: Train: 0.000899, Val: 0.001713, Total: 0.001001, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1621: Train: 0.000888, Val: 0.001738, Total: 0.000994, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1622: Train: 0.000881, Val: 0.001972, Total: 0.001018, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1623: Train: 0.000895, Val: 0.001827, Total: 0.001011, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1624: Train: 0.000912, Val: 0.001890, Total: 0.001034, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1625: Train: 0.000943, Val: 0.001837, Total: 0.001055, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1626: Train: 0.000990, Val: 0.001775, Total: 0.001088, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1627: Train: 0.000976, Val: 0.001757, Total: 0.001073, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1628: Train: 0.000930, Val: 0.001785, Total: 0.001037, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1629: Train: 0.000935, Val: 0.001746, Total: 0.001036, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1630: Train: 0.000927, Val: 0.001756, Total: 0.001031, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1631: Train: 0.000897, Val: 0.001762, Total: 0.001005, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1632: Train: 0.000965, Val: 0.001881, Total: 0.001079, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1633: Train: 0.000932, Val: 0.001818, Total: 0.001043, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1634: Train: 0.000984, Val: 0.001947, Total: 0.001105, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1635: Train: 0.001027, Val: 0.001857, Total: 0.001131, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1636: Train: 0.001048, Val: 0.001903, Total: 0.001155, LR: 1.55e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1637: Train: 0.001019, Val: 0.001799, Total: 0.001116, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1638: Train: 0.001054, Val: 0.001921, Total: 0.001163, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1639: Train: 0.001150, Val: 0.001961, Total: 0.001251, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1640: Train: 0.001107, Val: 0.001770, Total: 0.001190, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1641: Train: 0.001050, Val: 0.001947, Total: 0.001162, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1642: Train: 0.000939, Val: 0.001830, Total: 0.001051, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1643: Train: 0.000914, Val: 0.001867, Total: 0.001033, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1644: Train: 0.000995, Val: 0.002033, Total: 0.001125, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1645: Train: 0.000931, Val: 0.001771, Total: 0.001036, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1646: Train: 0.000876, Val: 0.001842, Total: 0.000996, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1647: Train: 0.000938, Val: 0.001799, Total: 0.001046, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1648: Train: 0.000940, Val: 0.001854, Total: 0.001054, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1649: Train: 0.000875, Val: 0.001823, Total: 0.000994, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1650: Train: 0.000957, Val: 0.001817, Total: 0.001064, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1651: Train: 0.000875, Val: 0.001932, Total: 0.001007, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1652: Train: 0.000925, Val: 0.001829, Total: 0.001038, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1653: Train: 0.000885, Val: 0.001722, Total: 0.000989, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1654: Train: 0.000870, Val: 0.001817, Total: 0.000989, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1655: Train: 0.000901, Val: 0.001804, Total: 0.001014, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1656: Train: 0.000847, Val: 0.001746, Total: 0.000960, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1657: Train: 0.000843, Val: 0.001781, Total: 0.000961, LR: 1.54e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1658: Train: 0.000916, Val: 0.001872, Total: 0.001036, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1659: Train: 0.000875, Val: 0.001940, Total: 0.001008, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1660: Train: 0.000874, Val: 0.001908, Total: 0.001003, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1661: Train: 0.000885, Val: 0.001879, Total: 0.001010, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1662: Train: 0.000860, Val: 0.001854, Total: 0.000985, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1663: Train: 0.000953, Val: 0.001866, Total: 0.001067, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1664: Train: 0.000903, Val: 0.001890, Total: 0.001026, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1665: Train: 0.000951, Val: 0.001985, Total: 0.001081, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1666: Train: 0.000925, Val: 0.001784, Total: 0.001032, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1667: Train: 0.000958, Val: 0.001935, Total: 0.001081, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1668: Train: 0.001002, Val: 0.001992, Total: 0.001126, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1669: Train: 0.001147, Val: 0.002569, Total: 0.001325, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1670: Train: 0.001001, Val: 0.001807, Total: 0.001102, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1671: Train: 0.001046, Val: 0.001830, Total: 0.001144, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1672: Train: 0.000930, Val: 0.002149, Total: 0.001082, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1673: Train: 0.000934, Val: 0.002059, Total: 0.001074, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1674: Train: 0.000920, Val: 0.002220, Total: 0.001082, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1675: Train: 0.000968, Val: 0.001888, Total: 0.001083, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1676: Train: 0.000947, Val: 0.001992, Total: 0.001077, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1677: Train: 0.000959, Val: 0.001766, Total: 0.001060, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1678: Train: 0.000939, Val: 0.001617, Total: 0.001024, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1679: Train: 0.001077, Val: 0.001453, Total: 0.001124, LR: 1.53e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1680: Train: 0.000905, Val: 0.001645, Total: 0.000997, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1681: Train: 0.000881, Val: 0.002091, Total: 0.001032, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1682: Train: 0.000999, Val: 0.002156, Total: 0.001143, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1683: Train: 0.000951, Val: 0.001880, Total: 0.001067, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1684: Train: 0.000954, Val: 0.001752, Total: 0.001054, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1685: Train: 0.000965, Val: 0.002014, Total: 0.001096, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1686: Train: 0.000975, Val: 0.001884, Total: 0.001089, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1687: Train: 0.001000, Val: 0.001996, Total: 0.001124, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1688: Train: 0.001040, Val: 0.001987, Total: 0.001158, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1689: Train: 0.000987, Val: 0.001820, Total: 0.001091, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1690: Train: 0.000931, Val: 0.001860, Total: 0.001048, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1691: Train: 0.000969, Val: 0.001752, Total: 0.001067, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1692: Train: 0.000953, Val: 0.001808, Total: 0.001060, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1693: Train: 0.000917, Val: 0.001780, Total: 0.001025, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1694: Train: 0.000889, Val: 0.001761, Total: 0.000998, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1695: Train: 0.000896, Val: 0.001742, Total: 0.001002, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1696: Train: 0.000903, Val: 0.001822, Total: 0.001018, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1697: Train: 0.000966, Val: 0.002049, Total: 0.001101, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1698: Train: 0.000909, Val: 0.001928, Total: 0.001036, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1699: Train: 0.000899, Val: 0.002012, Total: 0.001038, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1700: Train: 0.000885, Val: 0.001808, Total: 0.001000, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1701: Train: 0.000887, Val: 0.001785, Total: 0.000999, LR: 1.52e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1702: Train: 0.000875, Val: 0.001846, Total: 0.000996, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1703: Train: 0.000864, Val: 0.001796, Total: 0.000981, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1704: Train: 0.000873, Val: 0.001749, Total: 0.000982, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1705: Train: 0.000866, Val: 0.001742, Total: 0.000975, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1706: Train: 0.000839, Val: 0.001845, Total: 0.000965, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1707: Train: 0.000869, Val: 0.001706, Total: 0.000974, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1708: Train: 0.000863, Val: 0.001864, Total: 0.000988, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1709: Train: 0.001050, Val: 0.002115, Total: 0.001183, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1710: Train: 0.001160, Val: 0.001751, Total: 0.001234, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1711: Train: 0.001175, Val: 0.001913, Total: 0.001267, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1712: Train: 0.001048, Val: 0.001899, Total: 0.001154, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1713: Train: 0.001023, Val: 0.002121, Total: 0.001160, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1714: Train: 0.000988, Val: 0.001962, Total: 0.001110, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1715: Train: 0.001199, Val: 0.002014, Total: 0.001301, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1716: Train: 0.001054, Val: 0.001978, Total: 0.001169, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1717: Train: 0.001009, Val: 0.001716, Total: 0.001097, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1718: Train: 0.000956, Val: 0.001931, Total: 0.001078, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1719: Train: 0.000924, Val: 0.002051, Total: 0.001065, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1720: Train: 0.000974, Val: 0.001892, Total: 0.001089, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1721: Train: 0.000928, Val: 0.001972, Total: 0.001058, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1722: Train: 0.000909, Val: 0.001783, Total: 0.001018, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1723: Train: 0.000958, Val: 0.001882, Total: 0.001073, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1724: Train: 0.000946, Val: 0.001762, Total: 0.001048, LR: 1.51e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1725: Train: 0.000985, Val: 0.001902, Total: 0.001100, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1726: Train: 0.001062, Val: 0.001802, Total: 0.001154, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1727: Train: 0.000937, Val: 0.001728, Total: 0.001036, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1728: Train: 0.000959, Val: 0.001960, Total: 0.001084, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1729: Train: 0.000935, Val: 0.001745, Total: 0.001036, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1730: Train: 0.000935, Val: 0.001996, Total: 0.001068, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1731: Train: 0.000880, Val: 0.001927, Total: 0.001011, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1732: Train: 0.000926, Val: 0.001857, Total: 0.001042, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1733: Train: 0.000874, Val: 0.001917, Total: 0.001004, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1734: Train: 0.000920, Val: 0.001801, Total: 0.001030, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1735: Train: 0.000853, Val: 0.001820, Total: 0.000974, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1736: Train: 0.000926, Val: 0.001883, Total: 0.001046, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1737: Train: 0.000905, Val: 0.001836, Total: 0.001022, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1738: Train: 0.000915, Val: 0.001888, Total: 0.001037, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1739: Train: 0.000927, Val: 0.001917, Total: 0.001051, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1740: Train: 0.000901, Val: 0.001882, Total: 0.001023, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1741: Train: 0.000870, Val: 0.001948, Total: 0.001005, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1742: Train: 0.000925, Val: 0.001727, Total: 0.001025, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1743: Train: 0.000887, Val: 0.001694, Total: 0.000988, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1744: Train: 0.000885, Val: 0.001731, Total: 0.000991, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1745: Train: 0.000875, Val: 0.001802, Total: 0.000991, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1746: Train: 0.000963, Val: 0.001899, Total: 0.001080, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1747: Train: 0.000922, Val: 0.001624, Total: 0.001010, LR: 1.50e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1748: Train: 0.000898, Val: 0.001761, Total: 0.001006, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1749: Train: 0.000954, Val: 0.001694, Total: 0.001047, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1750: Train: 0.000861, Val: 0.001761, Total: 0.000973, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1751: Train: 0.000871, Val: 0.001886, Total: 0.000998, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1752: Train: 0.000856, Val: 0.001601, Total: 0.000949, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1753: Train: 0.000922, Val: 0.001734, Total: 0.001024, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1754: Train: 0.000891, Val: 0.001830, Total: 0.001008, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1755: Train: 0.000880, Val: 0.002057, Total: 0.001027, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1756: Train: 0.000896, Val: 0.001808, Total: 0.001010, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1757: Train: 0.000854, Val: 0.001515, Total: 0.000936, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1758: Train: 0.000870, Val: 0.001656, Total: 0.000968, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1759: Train: 0.000877, Val: 0.001673, Total: 0.000976, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1760: Train: 0.000930, Val: 0.001571, Total: 0.001010, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1761: Train: 0.000921, Val: 0.001713, Total: 0.001020, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1762: Train: 0.000893, Val: 0.001623, Total: 0.000984, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1763: Train: 0.000881, Val: 0.001569, Total: 0.000967, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1764: Train: 0.000879, Val: 0.001942, Total: 0.001012, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1765: Train: 0.000843, Val: 0.001721, Total: 0.000952, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1766: Train: 0.000884, Val: 0.001533, Total: 0.000965, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1767: Train: 0.000831, Val: 0.001680, Total: 0.000937, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1768: Train: 0.000840, Val: 0.001714, Total: 0.000949, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1769: Train: 0.000889, Val: 0.001725, Total: 0.000993, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1770: Train: 0.000886, Val: 0.001488, Total: 0.000962, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1771: Train: 0.000873, Val: 0.001862, Total: 0.000996, LR: 1.49e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1772: Train: 0.000912, Val: 0.001556, Total: 0.000993, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1773: Train: 0.000956, Val: 0.001794, Total: 0.001061, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1774: Train: 0.000998, Val: 0.001871, Total: 0.001107, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1775: Train: 0.000898, Val: 0.001489, Total: 0.000972, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1776: Train: 0.000850, Val: 0.001707, Total: 0.000957, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1777: Train: 0.000920, Val: 0.001753, Total: 0.001024, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1778: Train: 0.000856, Val: 0.001973, Total: 0.000995, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1779: Train: 0.000894, Val: 0.001643, Total: 0.000988, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1780: Train: 0.000943, Val: 0.001343, Total: 0.000993, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1781: Train: 0.000896, Val: 0.001648, Total: 0.000990, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1782: Train: 0.000795, Val: 0.001573, Total: 0.000892, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1783: Train: 0.000929, Val: 0.001611, Total: 0.001014, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1784: Train: 0.000926, Val: 0.001597, Total: 0.001010, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1785: Train: 0.000866, Val: 0.001914, Total: 0.000997, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1786: Train: 0.000916, Val: 0.001796, Total: 0.001026, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1787: Train: 0.000843, Val: 0.001725, Total: 0.000954, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1788: Train: 0.000874, Val: 0.001722, Total: 0.000980, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1789: Train: 0.000913, Val: 0.001691, Total: 0.001010, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1790: Train: 0.000877, Val: 0.001714, Total: 0.000982, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1791: Train: 0.000869, Val: 0.001732, Total: 0.000977, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1792: Train: 0.000873, Val: 0.001742, Total: 0.000981, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1793: Train: 0.000897, Val: 0.001607, Total: 0.000985, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1794: Train: 0.000878, Val: 0.001589, Total: 0.000967, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1795: Train: 0.000837, Val: 0.001678, Total: 0.000942, LR: 1.48e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1796: Train: 0.000881, Val: 0.001616, Total: 0.000973, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1797: Train: 0.000895, Val: 0.001678, Total: 0.000993, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1798: Train: 0.000857, Val: 0.001683, Total: 0.000960, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1799: Train: 0.000871, Val: 0.001639, Total: 0.000967, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1800: Train: 0.000896, Val: 0.001606, Total: 0.000985, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1801: Train: 0.000892, Val: 0.002072, Total: 0.001039, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1802: Train: 0.000819, Val: 0.002001, Total: 0.000967, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1803: Train: 0.000879, Val: 0.001642, Total: 0.000975, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1804: Train: 0.000892, Val: 0.001501, Total: 0.000968, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1805: Train: 0.000874, Val: 0.001561, Total: 0.000959, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1806: Train: 0.000905, Val: 0.001611, Total: 0.000993, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1807: Train: 0.000861, Val: 0.001733, Total: 0.000970, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1808: Train: 0.000862, Val: 0.001738, Total: 0.000971, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1809: Train: 0.000846, Val: 0.001595, Total: 0.000940, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1810: Train: 0.000870, Val: 0.001662, Total: 0.000969, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1811: Train: 0.000878, Val: 0.001588, Total: 0.000966, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1812: Train: 0.000834, Val: 0.001634, Total: 0.000934, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1813: Train: 0.000846, Val: 0.001635, Total: 0.000944, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1814: Train: 0.000878, Val: 0.001690, Total: 0.000980, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1815: Train: 0.000880, Val: 0.001705, Total: 0.000983, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1816: Train: 0.000856, Val: 0.001600, Total: 0.000949, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1817: Train: 0.000815, Val: 0.001627, Total: 0.000917, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1818: Train: 0.000837, Val: 0.001602, Total: 0.000933, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1819: Train: 0.000833, Val: 0.001532, Total: 0.000920, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1820: Train: 0.000855, Val: 0.001616, Total: 0.000950, LR: 1.47e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1821: Train: 0.000859, Val: 0.001626, Total: 0.000954, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1822: Train: 0.000870, Val: 0.001606, Total: 0.000962, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1823: Train: 0.000898, Val: 0.001756, Total: 0.001005, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1824: Train: 0.000852, Val: 0.001597, Total: 0.000945, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1825: Train: 0.000875, Val: 0.001656, Total: 0.000972, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1826: Train: 0.000844, Val: 0.001636, Total: 0.000943, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1827: Train: 0.000887, Val: 0.001579, Total: 0.000974, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1828: Train: 0.000851, Val: 0.001604, Total: 0.000945, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1829: Train: 0.000866, Val: 0.001625, Total: 0.000961, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1830: Train: 0.000870, Val: 0.001681, Total: 0.000971, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1831: Train: 0.000866, Val: 0.001628, Total: 0.000961, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1832: Train: 0.000863, Val: 0.001535, Total: 0.000947, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1833: Train: 0.000826, Val: 0.001650, Total: 0.000929, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1834: Train: 0.000841, Val: 0.001656, Total: 0.000943, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1835: Train: 0.000827, Val: 0.001605, Total: 0.000924, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1836: Train: 0.000864, Val: 0.001622, Total: 0.000959, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1837: Train: 0.000829, Val: 0.001610, Total: 0.000927, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1838: Train: 0.000889, Val: 0.001581, Total: 0.000976, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1839: Train: 0.000850, Val: 0.001663, Total: 0.000951, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1840: Train: 0.000821, Val: 0.001620, Total: 0.000921, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1841: Train: 0.000871, Val: 0.001572, Total: 0.000958, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1842: Train: 0.000864, Val: 0.001650, Total: 0.000962, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1843: Train: 0.000864, Val: 0.001616, Total: 0.000958, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1844: Train: 0.000862, Val: 0.001610, Total: 0.000956, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1845: Train: 0.000853, Val: 0.001595, Total: 0.000945, LR: 1.46e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1846: Train: 0.000832, Val: 0.001727, Total: 0.000944, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1847: Train: 0.000823, Val: 0.001750, Total: 0.000939, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1848: Train: 0.000857, Val: 0.001633, Total: 0.000954, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1849: Train: 0.000872, Val: 0.001633, Total: 0.000967, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1850: Train: 0.000846, Val: 0.001562, Total: 0.000935, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1851: Train: 0.000798, Val: 0.001686, Total: 0.000909, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1852: Train: 0.000853, Val: 0.001550, Total: 0.000940, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1853: Train: 0.000896, Val: 0.001771, Total: 0.001005, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1854: Train: 0.001049, Val: 0.001458, Total: 0.001100, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1855: Train: 0.001066, Val: 0.001747, Total: 0.001151, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1856: Train: 0.001049, Val: 0.001791, Total: 0.001142, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1857: Train: 0.001020, Val: 0.001647, Total: 0.001099, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1858: Train: 0.000843, Val: 0.001799, Total: 0.000962, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1859: Train: 0.000999, Val: 0.001320, Total: 0.001039, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1860: Train: 0.000930, Val: 0.002329, Total: 0.001105, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1861: Train: 0.000916, Val: 0.002032, Total: 0.001056, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1862: Train: 0.000990, Val: 0.001958, Total: 0.001111, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1863: Train: 0.000900, Val: 0.002008, Total: 0.001039, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1864: Train: 0.000959, Val: 0.001632, Total: 0.001043, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1865: Train: 0.000969, Val: 0.001880, Total: 0.001083, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1866: Train: 0.000999, Val: 0.001665, Total: 0.001082, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1867: Train: 0.000968, Val: 0.001813, Total: 0.001074, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1868: Train: 0.001011, Val: 0.001631, Total: 0.001089, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1869: Train: 0.000978, Val: 0.001490, Total: 0.001042, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1870: Train: 0.000953, Val: 0.001726, Total: 0.001050, LR: 1.45e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1871: Train: 0.000994, Val: 0.002039, Total: 0.001124, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1872: Train: 0.001085, Val: 0.001682, Total: 0.001159, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1873: Train: 0.001125, Val: 0.001998, Total: 0.001235, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1874: Train: 0.001050, Val: 0.002338, Total: 0.001211, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1875: Train: 0.001084, Val: 0.002132, Total: 0.001215, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1876: Train: 0.001103, Val: 0.001987, Total: 0.001213, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1877: Train: 0.000958, Val: 0.001600, Total: 0.001038, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1878: Train: 0.000944, Val: 0.001882, Total: 0.001061, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1879: Train: 0.000932, Val: 0.001759, Total: 0.001036, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1880: Train: 0.001034, Val: 0.001690, Total: 0.001116, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1881: Train: 0.000903, Val: 0.001772, Total: 0.001012, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1882: Train: 0.000933, Val: 0.001716, Total: 0.001030, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1883: Train: 0.000883, Val: 0.001767, Total: 0.000994, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1884: Train: 0.000917, Val: 0.001889, Total: 0.001038, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1885: Train: 0.000939, Val: 0.001955, Total: 0.001066, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1886: Train: 0.000884, Val: 0.002101, Total: 0.001036, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1887: Train: 0.000865, Val: 0.002002, Total: 0.001007, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1888: Train: 0.000831, Val: 0.002095, Total: 0.000989, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1889: Train: 0.000788, Val: 0.002039, Total: 0.000944, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1890: Train: 0.000838, Val: 0.002096, Total: 0.000995, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1891: Train: 0.000857, Val: 0.002102, Total: 0.001012, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1892: Train: 0.000892, Val: 0.002119, Total: 0.001045, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1893: Train: 0.000853, Val: 0.002065, Total: 0.001004, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1894: Train: 0.000900, Val: 0.001919, Total: 0.001027, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1895: Train: 0.000840, Val: 0.001710, Total: 0.000949, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1896: Train: 0.000825, Val: 0.001764, Total: 0.000942, LR: 1.44e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1897: Train: 0.000835, Val: 0.001671, Total: 0.000939, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1898: Train: 0.000833, Val: 0.001558, Total: 0.000923, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1899: Train: 0.000835, Val: 0.001565, Total: 0.000927, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1900: Train: 0.000782, Val: 0.001894, Total: 0.000921, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1901: Train: 0.000821, Val: 0.001670, Total: 0.000927, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1902: Train: 0.000819, Val: 0.001837, Total: 0.000947, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1903: Train: 0.000824, Val: 0.001667, Total: 0.000929, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1904: Train: 0.000787, Val: 0.001789, Total: 0.000913, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1905: Train: 0.000778, Val: 0.001861, Total: 0.000913, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1906: Train: 0.000848, Val: 0.001466, Total: 0.000925, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1907: Train: 0.000771, Val: 0.001646, Total: 0.000880, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1908: Train: 0.000842, Val: 0.001607, Total: 0.000937, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1909: Train: 0.000756, Val: 0.001772, Total: 0.000883, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1910: Train: 0.000762, Val: 0.001809, Total: 0.000893, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1911: Train: 0.000780, Val: 0.001728, Total: 0.000899, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1912: Train: 0.000793, Val: 0.001714, Total: 0.000908, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1913: Train: 0.000799, Val: 0.001781, Total: 0.000921, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1914: Train: 0.000799, Val: 0.001611, Total: 0.000901, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1915: Train: 0.000800, Val: 0.001808, Total: 0.000926, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1916: Train: 0.000844, Val: 0.001513, Total: 0.000928, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1917: Train: 0.000816, Val: 0.001708, Total: 0.000927, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1918: Train: 0.000825, Val: 0.001819, Total: 0.000950, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1919: Train: 0.000782, Val: 0.001641, Total: 0.000890, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1920: Train: 0.000833, Val: 0.001686, Total: 0.000940, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1921: Train: 0.000826, Val: 0.001727, Total: 0.000938, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1922: Train: 0.000790, Val: 0.001800, Total: 0.000917, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1923: Train: 0.000776, Val: 0.001825, Total: 0.000907, LR: 1.43e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1924: Train: 0.000788, Val: 0.001809, Total: 0.000916, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1925: Train: 0.000776, Val: 0.001570, Total: 0.000875, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1926: Train: 0.000783, Val: 0.001627, Total: 0.000889, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1927: Train: 0.000818, Val: 0.001818, Total: 0.000943, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1928: Train: 0.000773, Val: 0.001725, Total: 0.000892, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1929: Train: 0.000766, Val: 0.001836, Total: 0.000900, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1930: Train: 0.000740, Val: 0.001700, Total: 0.000860, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1931: Train: 0.000780, Val: 0.001673, Total: 0.000892, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1932: Train: 0.000735, Val: 0.001672, Total: 0.000852, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1933: Train: 0.000771, Val: 0.001677, Total: 0.000884, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1934: Train: 0.000825, Val: 0.001579, Total: 0.000919, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1935: Train: 0.000769, Val: 0.001723, Total: 0.000889, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1936: Train: 0.000772, Val: 0.001575, Total: 0.000873, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1937: Train: 0.000792, Val: 0.001720, Total: 0.000908, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1938: Train: 0.000842, Val: 0.001760, Total: 0.000957, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1939: Train: 0.000877, Val: 0.001583, Total: 0.000965, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1940: Train: 0.000802, Val: 0.001735, Total: 0.000918, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1941: Train: 0.000759, Val: 0.001793, Total: 0.000888, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1942: Train: 0.000769, Val: 0.001727, Total: 0.000889, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1943: Train: 0.000750, Val: 0.001651, Total: 0.000863, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1944: Train: 0.000772, Val: 0.001687, Total: 0.000886, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1945: Train: 0.000760, Val: 0.001640, Total: 0.000870, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1946: Train: 0.000756, Val: 0.001683, Total: 0.000872, LR: 1.42e-03\n",
      "          Best: Train: 0.000697, Val: 0.001869, Total: 0.000843 (Epoch 1299)\n",
      "Epoch 1947: Train: 0.000736, Val: 0.001590, Total: 0.000843, LR: 1.42e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000736, Val: 0.001590, Total: 0.000843 (Epoch 1947)\n",
      "Epoch 1948: Train: 0.000732, Val: 0.001675, Total: 0.000850, LR: 1.42e-03\n",
      "          Best: Train: 0.000736, Val: 0.001590, Total: 0.000843 (Epoch 1947)\n",
      "Epoch 1949: Train: 0.000776, Val: 0.001658, Total: 0.000886, LR: 1.42e-03\n",
      "          Best: Train: 0.000736, Val: 0.001590, Total: 0.000843 (Epoch 1947)\n",
      "Epoch 1950: Train: 0.000741, Val: 0.001567, Total: 0.000844, LR: 1.42e-03\n",
      "          Best: Train: 0.000736, Val: 0.001590, Total: 0.000843 (Epoch 1947)\n",
      "Epoch 1951: Train: 0.000716, Val: 0.001622, Total: 0.000829, LR: 1.41e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000716, Val: 0.001622, Total: 0.000829 (Epoch 1951)\n",
      "Epoch 1952: Train: 0.000762, Val: 0.001651, Total: 0.000873, LR: 1.41e-03\n",
      "          Best: Train: 0.000716, Val: 0.001622, Total: 0.000829 (Epoch 1951)\n",
      "Epoch 1953: Train: 0.000800, Val: 0.001654, Total: 0.000907, LR: 1.41e-03\n",
      "          Best: Train: 0.000716, Val: 0.001622, Total: 0.000829 (Epoch 1951)\n",
      "Epoch 1954: Train: 0.000706, Val: 0.001541, Total: 0.000811, LR: 1.41e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1955: Train: 0.000776, Val: 0.001668, Total: 0.000888, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1956: Train: 0.000771, Val: 0.001585, Total: 0.000872, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1957: Train: 0.000789, Val: 0.001747, Total: 0.000909, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1958: Train: 0.000758, Val: 0.001490, Total: 0.000850, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1959: Train: 0.000779, Val: 0.001772, Total: 0.000903, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1960: Train: 0.000769, Val: 0.001900, Total: 0.000911, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1961: Train: 0.000743, Val: 0.001958, Total: 0.000895, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1962: Train: 0.000742, Val: 0.001956, Total: 0.000894, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1963: Train: 0.000771, Val: 0.001982, Total: 0.000922, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1964: Train: 0.000775, Val: 0.001967, Total: 0.000924, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1965: Train: 0.000727, Val: 0.002072, Total: 0.000895, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1966: Train: 0.000723, Val: 0.001903, Total: 0.000871, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1967: Train: 0.000800, Val: 0.001867, Total: 0.000933, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1968: Train: 0.000762, Val: 0.001934, Total: 0.000908, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1969: Train: 0.000735, Val: 0.001726, Total: 0.000859, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1970: Train: 0.000771, Val: 0.001729, Total: 0.000890, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1971: Train: 0.000758, Val: 0.001930, Total: 0.000904, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1972: Train: 0.000735, Val: 0.002065, Total: 0.000901, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1973: Train: 0.000761, Val: 0.001939, Total: 0.000908, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1974: Train: 0.000770, Val: 0.001883, Total: 0.000909, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1975: Train: 0.000782, Val: 0.001731, Total: 0.000901, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1976: Train: 0.000750, Val: 0.001561, Total: 0.000851, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1977: Train: 0.000774, Val: 0.001611, Total: 0.000879, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1978: Train: 0.000778, Val: 0.001571, Total: 0.000877, LR: 1.41e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1979: Train: 0.000762, Val: 0.001636, Total: 0.000872, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1980: Train: 0.000792, Val: 0.002055, Total: 0.000950, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1981: Train: 0.000890, Val: 0.002033, Total: 0.001033, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1982: Train: 0.000953, Val: 0.001951, Total: 0.001078, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1983: Train: 0.000923, Val: 0.002011, Total: 0.001059, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1984: Train: 0.000944, Val: 0.001755, Total: 0.001045, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1985: Train: 0.000916, Val: 0.001925, Total: 0.001042, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1986: Train: 0.000889, Val: 0.001535, Total: 0.000970, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1987: Train: 0.000871, Val: 0.001729, Total: 0.000978, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1988: Train: 0.000846, Val: 0.001758, Total: 0.000960, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1989: Train: 0.000880, Val: 0.001799, Total: 0.000995, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1990: Train: 0.000893, Val: 0.001852, Total: 0.001013, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1991: Train: 0.001020, Val: 0.002169, Total: 0.001164, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1992: Train: 0.001056, Val: 0.002416, Total: 0.001226, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1993: Train: 0.000925, Val: 0.001636, Total: 0.001014, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1994: Train: 0.000986, Val: 0.001810, Total: 0.001089, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1995: Train: 0.000960, Val: 0.001633, Total: 0.001044, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1996: Train: 0.000887, Val: 0.001817, Total: 0.001003, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1997: Train: 0.000840, Val: 0.001666, Total: 0.000943, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1998: Train: 0.000861, Val: 0.001710, Total: 0.000967, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 1999: Train: 0.000867, Val: 0.001668, Total: 0.000967, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2000: Train: 0.000872, Val: 0.001836, Total: 0.000993, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2001: Train: 0.000858, Val: 0.001894, Total: 0.000987, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2002: Train: 0.000870, Val: 0.001805, Total: 0.000987, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2003: Train: 0.000860, Val: 0.001795, Total: 0.000977, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2004: Train: 0.000848, Val: 0.001800, Total: 0.000967, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2005: Train: 0.000782, Val: 0.001796, Total: 0.000908, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2006: Train: 0.000798, Val: 0.001638, Total: 0.000903, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2007: Train: 0.000867, Val: 0.001814, Total: 0.000985, LR: 1.40e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2008: Train: 0.000789, Val: 0.001791, Total: 0.000914, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2009: Train: 0.000758, Val: 0.001869, Total: 0.000897, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2010: Train: 0.000806, Val: 0.001810, Total: 0.000932, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2011: Train: 0.000781, Val: 0.001804, Total: 0.000909, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2012: Train: 0.000770, Val: 0.001694, Total: 0.000885, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2013: Train: 0.000759, Val: 0.001775, Total: 0.000886, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2014: Train: 0.000744, Val: 0.001776, Total: 0.000873, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2015: Train: 0.000807, Val: 0.001685, Total: 0.000917, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2016: Train: 0.000762, Val: 0.001752, Total: 0.000886, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2017: Train: 0.000807, Val: 0.001764, Total: 0.000927, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2018: Train: 0.000766, Val: 0.001734, Total: 0.000887, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2019: Train: 0.000806, Val: 0.001853, Total: 0.000937, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2020: Train: 0.000759, Val: 0.001702, Total: 0.000877, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2021: Train: 0.000733, Val: 0.001677, Total: 0.000851, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2022: Train: 0.000824, Val: 0.001865, Total: 0.000954, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2023: Train: 0.000854, Val: 0.001675, Total: 0.000956, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2024: Train: 0.000854, Val: 0.001809, Total: 0.000973, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2025: Train: 0.000786, Val: 0.001827, Total: 0.000917, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2026: Train: 0.000766, Val: 0.001736, Total: 0.000887, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2027: Train: 0.000757, Val: 0.001776, Total: 0.000884, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2028: Train: 0.000742, Val: 0.001766, Total: 0.000870, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2029: Train: 0.000756, Val: 0.001729, Total: 0.000877, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2030: Train: 0.000799, Val: 0.001819, Total: 0.000926, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2031: Train: 0.000750, Val: 0.001620, Total: 0.000859, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2032: Train: 0.000785, Val: 0.001948, Total: 0.000930, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2033: Train: 0.000829, Val: 0.001735, Total: 0.000942, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2034: Train: 0.000798, Val: 0.002361, Total: 0.000993, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2035: Train: 0.000786, Val: 0.002103, Total: 0.000951, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2036: Train: 0.000787, Val: 0.001898, Total: 0.000925, LR: 1.39e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2037: Train: 0.000788, Val: 0.001826, Total: 0.000918, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2038: Train: 0.000810, Val: 0.001694, Total: 0.000921, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2039: Train: 0.000761, Val: 0.001825, Total: 0.000894, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2040: Train: 0.000765, Val: 0.001905, Total: 0.000907, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2041: Train: 0.000782, Val: 0.001646, Total: 0.000890, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2042: Train: 0.000772, Val: 0.001530, Total: 0.000867, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2043: Train: 0.000759, Val: 0.001616, Total: 0.000866, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2044: Train: 0.000737, Val: 0.001735, Total: 0.000861, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2045: Train: 0.000754, Val: 0.001598, Total: 0.000859, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2046: Train: 0.000773, Val: 0.001573, Total: 0.000873, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2047: Train: 0.000775, Val: 0.001852, Total: 0.000910, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2048: Train: 0.000772, Val: 0.001685, Total: 0.000886, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2049: Train: 0.000816, Val: 0.001666, Total: 0.000922, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2050: Train: 0.000752, Val: 0.001658, Total: 0.000865, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2051: Train: 0.000754, Val: 0.001752, Total: 0.000879, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2052: Train: 0.000762, Val: 0.001657, Total: 0.000874, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2053: Train: 0.000740, Val: 0.001609, Total: 0.000848, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2054: Train: 0.000763, Val: 0.001753, Total: 0.000887, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2055: Train: 0.000756, Val: 0.001728, Total: 0.000878, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2056: Train: 0.000802, Val: 0.001620, Total: 0.000904, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2057: Train: 0.000757, Val: 0.001593, Total: 0.000861, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2058: Train: 0.000734, Val: 0.001652, Total: 0.000849, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2059: Train: 0.000727, Val: 0.001604, Total: 0.000837, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2060: Train: 0.000746, Val: 0.001537, Total: 0.000845, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2061: Train: 0.000727, Val: 0.001638, Total: 0.000841, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2062: Train: 0.000714, Val: 0.001549, Total: 0.000818, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2063: Train: 0.000742, Val: 0.001608, Total: 0.000850, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2064: Train: 0.000759, Val: 0.001625, Total: 0.000867, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2065: Train: 0.000723, Val: 0.001554, Total: 0.000827, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2066: Train: 0.000769, Val: 0.001561, Total: 0.000868, LR: 1.38e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2067: Train: 0.000741, Val: 0.001557, Total: 0.000843, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2068: Train: 0.000764, Val: 0.001779, Total: 0.000891, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2069: Train: 0.000762, Val: 0.001699, Total: 0.000879, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2070: Train: 0.000810, Val: 0.001526, Total: 0.000899, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2071: Train: 0.000762, Val: 0.001619, Total: 0.000869, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2072: Train: 0.000736, Val: 0.001562, Total: 0.000839, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2073: Train: 0.000741, Val: 0.001736, Total: 0.000865, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2074: Train: 0.000740, Val: 0.001744, Total: 0.000866, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2075: Train: 0.000780, Val: 0.001683, Total: 0.000893, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2076: Train: 0.000770, Val: 0.001633, Total: 0.000878, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2077: Train: 0.000793, Val: 0.001687, Total: 0.000905, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2078: Train: 0.000755, Val: 0.001428, Total: 0.000839, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2079: Train: 0.000798, Val: 0.001586, Total: 0.000897, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2080: Train: 0.000781, Val: 0.001717, Total: 0.000898, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2081: Train: 0.000763, Val: 0.001604, Total: 0.000868, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2082: Train: 0.000735, Val: 0.001577, Total: 0.000840, LR: 1.37e-03\n",
      "          Best: Train: 0.000706, Val: 0.001541, Total: 0.000811 (Epoch 1954)\n",
      "Epoch 2083: Train: 0.000713, Val: 0.001476, Total: 0.000808, LR: 1.37e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2084: Train: 0.000712, Val: 0.001624, Total: 0.000826, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2085: Train: 0.000749, Val: 0.001504, Total: 0.000843, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2086: Train: 0.000741, Val: 0.001650, Total: 0.000855, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2087: Train: 0.000718, Val: 0.001519, Total: 0.000818, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2088: Train: 0.000729, Val: 0.001556, Total: 0.000833, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2089: Train: 0.000739, Val: 0.001555, Total: 0.000841, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2090: Train: 0.000740, Val: 0.001485, Total: 0.000833, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2091: Train: 0.000750, Val: 0.001635, Total: 0.000860, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2092: Train: 0.000719, Val: 0.001488, Total: 0.000816, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2093: Train: 0.000785, Val: 0.001553, Total: 0.000881, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2094: Train: 0.000759, Val: 0.001547, Total: 0.000857, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2095: Train: 0.000767, Val: 0.001740, Total: 0.000889, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2096: Train: 0.000849, Val: 0.001922, Total: 0.000983, LR: 1.37e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2097: Train: 0.000850, Val: 0.002051, Total: 0.001000, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2098: Train: 0.000836, Val: 0.001777, Total: 0.000953, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2099: Train: 0.000794, Val: 0.001707, Total: 0.000908, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2100: Train: 0.000802, Val: 0.001960, Total: 0.000947, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2101: Train: 0.000789, Val: 0.001809, Total: 0.000917, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2102: Train: 0.000845, Val: 0.001849, Total: 0.000971, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2103: Train: 0.000778, Val: 0.001778, Total: 0.000903, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2104: Train: 0.000732, Val: 0.001790, Total: 0.000864, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2105: Train: 0.000806, Val: 0.001892, Total: 0.000942, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2106: Train: 0.000747, Val: 0.001696, Total: 0.000865, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2107: Train: 0.000757, Val: 0.001622, Total: 0.000865, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2108: Train: 0.000779, Val: 0.001834, Total: 0.000911, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2109: Train: 0.000771, Val: 0.001732, Total: 0.000891, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2110: Train: 0.000806, Val: 0.002121, Total: 0.000970, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2111: Train: 0.000777, Val: 0.001830, Total: 0.000908, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2112: Train: 0.000762, Val: 0.001620, Total: 0.000869, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2113: Train: 0.000769, Val: 0.001954, Total: 0.000917, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2114: Train: 0.000760, Val: 0.001729, Total: 0.000882, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2115: Train: 0.000782, Val: 0.001956, Total: 0.000929, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2116: Train: 0.000744, Val: 0.001714, Total: 0.000866, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2117: Train: 0.000761, Val: 0.001772, Total: 0.000887, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2118: Train: 0.000760, Val: 0.001685, Total: 0.000876, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2119: Train: 0.000783, Val: 0.001708, Total: 0.000899, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2120: Train: 0.000806, Val: 0.002033, Total: 0.000959, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2121: Train: 0.000786, Val: 0.001795, Total: 0.000912, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2122: Train: 0.000740, Val: 0.001741, Total: 0.000865, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2123: Train: 0.000740, Val: 0.001816, Total: 0.000875, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2124: Train: 0.000745, Val: 0.001819, Total: 0.000879, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2125: Train: 0.000758, Val: 0.001735, Total: 0.000880, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2126: Train: 0.000750, Val: 0.001780, Total: 0.000879, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2127: Train: 0.000795, Val: 0.001842, Total: 0.000926, LR: 1.36e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2128: Train: 0.000782, Val: 0.001585, Total: 0.000883, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2129: Train: 0.000803, Val: 0.001636, Total: 0.000907, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2130: Train: 0.000787, Val: 0.001753, Total: 0.000908, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2131: Train: 0.000723, Val: 0.001870, Total: 0.000867, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2132: Train: 0.000744, Val: 0.001631, Total: 0.000855, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2133: Train: 0.000733, Val: 0.001603, Total: 0.000842, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2134: Train: 0.000759, Val: 0.001931, Total: 0.000906, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2135: Train: 0.000725, Val: 0.001705, Total: 0.000848, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2136: Train: 0.000754, Val: 0.001719, Total: 0.000875, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2137: Train: 0.000714, Val: 0.001640, Total: 0.000830, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2138: Train: 0.000759, Val: 0.001731, Total: 0.000880, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2139: Train: 0.000731, Val: 0.001568, Total: 0.000835, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2140: Train: 0.000729, Val: 0.001627, Total: 0.000841, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2141: Train: 0.000712, Val: 0.001623, Total: 0.000826, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2142: Train: 0.000739, Val: 0.001535, Total: 0.000838, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2143: Train: 0.000706, Val: 0.001702, Total: 0.000831, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2144: Train: 0.000779, Val: 0.001744, Total: 0.000899, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2145: Train: 0.000742, Val: 0.001666, Total: 0.000857, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2146: Train: 0.000725, Val: 0.001632, Total: 0.000838, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2147: Train: 0.000726, Val: 0.001745, Total: 0.000853, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2148: Train: 0.000780, Val: 0.001784, Total: 0.000906, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2149: Train: 0.000752, Val: 0.001880, Total: 0.000893, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2150: Train: 0.000753, Val: 0.001732, Total: 0.000875, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2151: Train: 0.000744, Val: 0.001828, Total: 0.000880, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2152: Train: 0.000748, Val: 0.001593, Total: 0.000854, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2153: Train: 0.000778, Val: 0.001694, Total: 0.000892, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2154: Train: 0.000780, Val: 0.001634, Total: 0.000886, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2155: Train: 0.000736, Val: 0.001681, Total: 0.000854, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2156: Train: 0.000756, Val: 0.001726, Total: 0.000877, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2157: Train: 0.000729, Val: 0.001659, Total: 0.000845, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2158: Train: 0.000743, Val: 0.001722, Total: 0.000866, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2159: Train: 0.000734, Val: 0.001597, Total: 0.000842, LR: 1.35e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2160: Train: 0.000749, Val: 0.001439, Total: 0.000835, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2161: Train: 0.000730, Val: 0.001549, Total: 0.000832, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2162: Train: 0.000734, Val: 0.001588, Total: 0.000841, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2163: Train: 0.000773, Val: 0.001536, Total: 0.000869, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2164: Train: 0.000742, Val: 0.001742, Total: 0.000867, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2165: Train: 0.000706, Val: 0.001590, Total: 0.000816, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2166: Train: 0.000744, Val: 0.001717, Total: 0.000865, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2167: Train: 0.000719, Val: 0.001598, Total: 0.000829, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2168: Train: 0.000753, Val: 0.001626, Total: 0.000862, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2169: Train: 0.000732, Val: 0.001582, Total: 0.000838, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2170: Train: 0.000724, Val: 0.001584, Total: 0.000831, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2171: Train: 0.000765, Val: 0.001572, Total: 0.000866, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2172: Train: 0.000771, Val: 0.001728, Total: 0.000891, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2173: Train: 0.000723, Val: 0.001598, Total: 0.000832, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2174: Train: 0.000709, Val: 0.001650, Total: 0.000827, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2175: Train: 0.000713, Val: 0.001664, Total: 0.000832, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2176: Train: 0.000706, Val: 0.001579, Total: 0.000815, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2177: Train: 0.000728, Val: 0.001575, Total: 0.000834, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2178: Train: 0.000732, Val: 0.001653, Total: 0.000847, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2179: Train: 0.000728, Val: 0.001688, Total: 0.000848, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2180: Train: 0.000786, Val: 0.001532, Total: 0.000879, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2181: Train: 0.000749, Val: 0.001669, Total: 0.000864, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2182: Train: 0.000754, Val: 0.001613, Total: 0.000862, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2183: Train: 0.000783, Val: 0.001661, Total: 0.000893, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2184: Train: 0.000745, Val: 0.001565, Total: 0.000847, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2185: Train: 0.000736, Val: 0.001689, Total: 0.000856, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2186: Train: 0.000728, Val: 0.001566, Total: 0.000833, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2187: Train: 0.000739, Val: 0.001530, Total: 0.000838, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2188: Train: 0.000717, Val: 0.001502, Total: 0.000815, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2189: Train: 0.000711, Val: 0.001583, Total: 0.000820, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2190: Train: 0.000735, Val: 0.001788, Total: 0.000866, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2191: Train: 0.000739, Val: 0.001459, Total: 0.000829, LR: 1.34e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2192: Train: 0.000769, Val: 0.001657, Total: 0.000880, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2193: Train: 0.000708, Val: 0.001696, Total: 0.000832, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2194: Train: 0.000720, Val: 0.001705, Total: 0.000843, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2195: Train: 0.000702, Val: 0.001580, Total: 0.000812, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2196: Train: 0.000729, Val: 0.001586, Total: 0.000836, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2197: Train: 0.000753, Val: 0.001654, Total: 0.000865, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2198: Train: 0.000728, Val: 0.001625, Total: 0.000840, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2199: Train: 0.000705, Val: 0.001693, Total: 0.000829, LR: 1.33e-03\n",
      "          Best: Train: 0.000713, Val: 0.001476, Total: 0.000808 (Epoch 2083)\n",
      "Epoch 2200: Train: 0.000696, Val: 0.001585, Total: 0.000807, LR: 1.33e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000696, Val: 0.001585, Total: 0.000807 (Epoch 2200)\n",
      "Epoch 2201: Train: 0.000682, Val: 0.001507, Total: 0.000786, LR: 1.33e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2202: Train: 0.000716, Val: 0.001667, Total: 0.000835, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2203: Train: 0.000736, Val: 0.001510, Total: 0.000833, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2204: Train: 0.000753, Val: 0.001779, Total: 0.000881, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2205: Train: 0.000746, Val: 0.001603, Total: 0.000853, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2206: Train: 0.000711, Val: 0.001709, Total: 0.000836, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2207: Train: 0.000737, Val: 0.001529, Total: 0.000836, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2208: Train: 0.000776, Val: 0.001788, Total: 0.000902, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2209: Train: 0.000773, Val: 0.001957, Total: 0.000921, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2210: Train: 0.000955, Val: 0.001900, Total: 0.001073, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2211: Train: 0.000824, Val: 0.001639, Total: 0.000926, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2212: Train: 0.000861, Val: 0.001830, Total: 0.000982, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2213: Train: 0.000847, Val: 0.001723, Total: 0.000956, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2214: Train: 0.000763, Val: 0.001657, Total: 0.000875, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2215: Train: 0.000792, Val: 0.001679, Total: 0.000903, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2216: Train: 0.000772, Val: 0.001664, Total: 0.000884, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2217: Train: 0.000762, Val: 0.001914, Total: 0.000906, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2218: Train: 0.000773, Val: 0.001631, Total: 0.000880, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2219: Train: 0.000774, Val: 0.001579, Total: 0.000874, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2220: Train: 0.000819, Val: 0.001566, Total: 0.000913, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2221: Train: 0.000842, Val: 0.001829, Total: 0.000965, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2222: Train: 0.000898, Val: 0.001581, Total: 0.000983, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2223: Train: 0.000809, Val: 0.001495, Total: 0.000895, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2224: Train: 0.000854, Val: 0.001724, Total: 0.000963, LR: 1.33e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2225: Train: 0.001094, Val: 0.001569, Total: 0.001153, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2226: Train: 0.000955, Val: 0.002290, Total: 0.001122, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2227: Train: 0.001553, Val: 0.002359, Total: 0.001654, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2228: Train: 0.001300, Val: 0.002501, Total: 0.001450, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2229: Train: 0.001129, Val: 0.001516, Total: 0.001177, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2230: Train: 0.001214, Val: 0.001667, Total: 0.001271, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2231: Train: 0.001317, Val: 0.002544, Total: 0.001470, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2232: Train: 0.001241, Val: 0.002593, Total: 0.001410, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2233: Train: 0.001366, Val: 0.002615, Total: 0.001523, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2234: Train: 0.001790, Val: 0.002375, Total: 0.001863, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2235: Train: 0.002338, Val: 0.003007, Total: 0.002422, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2236: Train: 0.002464, Val: 0.002728, Total: 0.002497, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2237: Train: 0.003474, Val: 0.003070, Total: 0.003424, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2238: Train: 0.002518, Val: 0.003279, Total: 0.002614, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2239: Train: 0.002139, Val: 0.003316, Total: 0.002286, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2240: Train: 0.002523, Val: 0.003129, Total: 0.002598, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2241: Train: 0.002201, Val: 0.003134, Total: 0.002318, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2242: Train: 0.002199, Val: 0.003176, Total: 0.002321, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2243: Train: 0.001939, Val: 0.003029, Total: 0.002075, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2244: Train: 0.001924, Val: 0.002909, Total: 0.002047, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2245: Train: 0.001819, Val: 0.002625, Total: 0.001920, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2246: Train: 0.001876, Val: 0.002781, Total: 0.001989, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2247: Train: 0.001600, Val: 0.003757, Total: 0.001869, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2248: Train: 0.001937, Val: 0.002032, Total: 0.001949, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2249: Train: 0.001601, Val: 0.002115, Total: 0.001665, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2250: Train: 0.001709, Val: 0.001932, Total: 0.001737, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2251: Train: 0.001399, Val: 0.001466, Total: 0.001407, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2252: Train: 0.001310, Val: 0.001422, Total: 0.001324, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2253: Train: 0.001313, Val: 0.001548, Total: 0.001342, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2254: Train: 0.001496, Val: 0.002563, Total: 0.001629, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2255: Train: 0.002401, Val: 0.002072, Total: 0.002360, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2256: Train: 0.001440, Val: 0.001957, Total: 0.001504, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2257: Train: 0.001414, Val: 0.002295, Total: 0.001524, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2258: Train: 0.001250, Val: 0.001843, Total: 0.001324, LR: 1.32e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2259: Train: 0.001295, Val: 0.001582, Total: 0.001331, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2260: Train: 0.001166, Val: 0.002409, Total: 0.001321, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2261: Train: 0.001141, Val: 0.001910, Total: 0.001237, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2262: Train: 0.001146, Val: 0.002253, Total: 0.001284, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2263: Train: 0.001182, Val: 0.002164, Total: 0.001305, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2264: Train: 0.001073, Val: 0.002131, Total: 0.001205, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2265: Train: 0.001061, Val: 0.001935, Total: 0.001170, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2266: Train: 0.001064, Val: 0.001805, Total: 0.001157, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2267: Train: 0.001010, Val: 0.001770, Total: 0.001105, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2268: Train: 0.001038, Val: 0.001815, Total: 0.001136, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2269: Train: 0.001007, Val: 0.001696, Total: 0.001093, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2270: Train: 0.001016, Val: 0.001518, Total: 0.001079, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2271: Train: 0.001033, Val: 0.001398, Total: 0.001079, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2272: Train: 0.001028, Val: 0.001565, Total: 0.001095, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2273: Train: 0.000935, Val: 0.001509, Total: 0.001007, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2274: Train: 0.000918, Val: 0.001945, Total: 0.001046, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2275: Train: 0.000903, Val: 0.001956, Total: 0.001034, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2276: Train: 0.000921, Val: 0.001674, Total: 0.001015, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2277: Train: 0.000924, Val: 0.001874, Total: 0.001042, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2278: Train: 0.000941, Val: 0.001849, Total: 0.001054, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2279: Train: 0.000930, Val: 0.001695, Total: 0.001026, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2280: Train: 0.000861, Val: 0.001826, Total: 0.000982, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2281: Train: 0.000853, Val: 0.001917, Total: 0.000986, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2282: Train: 0.000864, Val: 0.001652, Total: 0.000963, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2283: Train: 0.000837, Val: 0.001754, Total: 0.000951, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2284: Train: 0.000804, Val: 0.001670, Total: 0.000912, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2285: Train: 0.000840, Val: 0.001489, Total: 0.000921, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2286: Train: 0.000826, Val: 0.001730, Total: 0.000939, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2287: Train: 0.000805, Val: 0.002075, Total: 0.000964, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2288: Train: 0.000803, Val: 0.001925, Total: 0.000943, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2289: Train: 0.000855, Val: 0.001855, Total: 0.000980, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2290: Train: 0.000815, Val: 0.001731, Total: 0.000929, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2291: Train: 0.000872, Val: 0.002093, Total: 0.001024, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2292: Train: 0.000857, Val: 0.002095, Total: 0.001012, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2293: Train: 0.000829, Val: 0.002011, Total: 0.000977, LR: 1.31e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2294: Train: 0.000881, Val: 0.001989, Total: 0.001020, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2295: Train: 0.000817, Val: 0.002045, Total: 0.000970, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2296: Train: 0.000862, Val: 0.001928, Total: 0.000995, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2297: Train: 0.000820, Val: 0.001889, Total: 0.000954, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2298: Train: 0.000788, Val: 0.001791, Total: 0.000913, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2299: Train: 0.000809, Val: 0.001946, Total: 0.000951, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2300: Train: 0.000809, Val: 0.001790, Total: 0.000931, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2301: Train: 0.000840, Val: 0.001684, Total: 0.000946, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2302: Train: 0.000805, Val: 0.002016, Total: 0.000956, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2303: Train: 0.000821, Val: 0.002045, Total: 0.000974, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2304: Train: 0.000834, Val: 0.001788, Total: 0.000954, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2305: Train: 0.000812, Val: 0.001877, Total: 0.000945, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2306: Train: 0.000810, Val: 0.001943, Total: 0.000951, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2307: Train: 0.000840, Val: 0.001758, Total: 0.000955, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2308: Train: 0.000792, Val: 0.001809, Total: 0.000919, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2309: Train: 0.000791, Val: 0.001789, Total: 0.000916, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2310: Train: 0.000774, Val: 0.001767, Total: 0.000898, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2311: Train: 0.000751, Val: 0.001769, Total: 0.000879, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2312: Train: 0.000777, Val: 0.001892, Total: 0.000917, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2313: Train: 0.000764, Val: 0.001805, Total: 0.000894, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2314: Train: 0.000748, Val: 0.001806, Total: 0.000880, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2315: Train: 0.000811, Val: 0.001934, Total: 0.000951, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2316: Train: 0.000808, Val: 0.001818, Total: 0.000934, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2317: Train: 0.000782, Val: 0.001861, Total: 0.000917, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2318: Train: 0.000757, Val: 0.001669, Total: 0.000871, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2319: Train: 0.000796, Val: 0.001755, Total: 0.000916, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2320: Train: 0.000785, Val: 0.001704, Total: 0.000900, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2321: Train: 0.000777, Val: 0.001700, Total: 0.000892, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2322: Train: 0.000805, Val: 0.001861, Total: 0.000937, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2323: Train: 0.000787, Val: 0.001782, Total: 0.000911, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2324: Train: 0.000796, Val: 0.001686, Total: 0.000907, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2325: Train: 0.000788, Val: 0.001729, Total: 0.000906, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2326: Train: 0.000798, Val: 0.001826, Total: 0.000926, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2327: Train: 0.000776, Val: 0.001814, Total: 0.000906, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2328: Train: 0.000812, Val: 0.001766, Total: 0.000931, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2329: Train: 0.000807, Val: 0.001695, Total: 0.000918, LR: 1.30e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2330: Train: 0.000802, Val: 0.001976, Total: 0.000949, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2331: Train: 0.000761, Val: 0.001957, Total: 0.000911, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2332: Train: 0.000735, Val: 0.001788, Total: 0.000867, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2333: Train: 0.000742, Val: 0.001840, Total: 0.000879, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2334: Train: 0.000791, Val: 0.001786, Total: 0.000915, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2335: Train: 0.000749, Val: 0.001787, Total: 0.000879, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2336: Train: 0.000740, Val: 0.001786, Total: 0.000871, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2337: Train: 0.000748, Val: 0.001743, Total: 0.000873, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2338: Train: 0.000736, Val: 0.001823, Total: 0.000872, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2339: Train: 0.000779, Val: 0.001750, Total: 0.000900, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2340: Train: 0.000756, Val: 0.001832, Total: 0.000890, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2341: Train: 0.000768, Val: 0.001858, Total: 0.000904, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2342: Train: 0.000721, Val: 0.001792, Total: 0.000855, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2343: Train: 0.000733, Val: 0.001781, Total: 0.000864, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2344: Train: 0.000807, Val: 0.001820, Total: 0.000934, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2345: Train: 0.000742, Val: 0.001772, Total: 0.000871, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2346: Train: 0.000766, Val: 0.001743, Total: 0.000888, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2347: Train: 0.000773, Val: 0.001764, Total: 0.000897, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2348: Train: 0.000766, Val: 0.001678, Total: 0.000880, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2349: Train: 0.000739, Val: 0.001777, Total: 0.000868, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2350: Train: 0.000746, Val: 0.001728, Total: 0.000868, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2351: Train: 0.000748, Val: 0.001707, Total: 0.000868, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2352: Train: 0.000747, Val: 0.001710, Total: 0.000867, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2353: Train: 0.000741, Val: 0.001632, Total: 0.000852, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2354: Train: 0.000744, Val: 0.001609, Total: 0.000853, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2355: Train: 0.000749, Val: 0.001849, Total: 0.000886, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2356: Train: 0.000791, Val: 0.001842, Total: 0.000922, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2357: Train: 0.000816, Val: 0.001474, Total: 0.000898, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2358: Train: 0.000817, Val: 0.001659, Total: 0.000922, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2359: Train: 0.000768, Val: 0.001543, Total: 0.000865, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2360: Train: 0.000760, Val: 0.001604, Total: 0.000866, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2361: Train: 0.000767, Val: 0.001515, Total: 0.000860, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2362: Train: 0.000781, Val: 0.001536, Total: 0.000876, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2363: Train: 0.000844, Val: 0.001656, Total: 0.000946, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2364: Train: 0.000804, Val: 0.001653, Total: 0.000910, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2365: Train: 0.000792, Val: 0.001680, Total: 0.000903, LR: 1.29e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2366: Train: 0.000813, Val: 0.001713, Total: 0.000925, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2367: Train: 0.000756, Val: 0.001730, Total: 0.000878, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2368: Train: 0.000822, Val: 0.001784, Total: 0.000942, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2369: Train: 0.000862, Val: 0.001712, Total: 0.000968, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2370: Train: 0.000839, Val: 0.001721, Total: 0.000949, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2371: Train: 0.000876, Val: 0.001823, Total: 0.000995, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2372: Train: 0.000813, Val: 0.001805, Total: 0.000937, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2373: Train: 0.000777, Val: 0.001625, Total: 0.000883, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2374: Train: 0.000814, Val: 0.001619, Total: 0.000914, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2375: Train: 0.000851, Val: 0.001833, Total: 0.000974, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2376: Train: 0.000751, Val: 0.001797, Total: 0.000881, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2377: Train: 0.000788, Val: 0.001815, Total: 0.000916, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2378: Train: 0.000734, Val: 0.001665, Total: 0.000851, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2379: Train: 0.000760, Val: 0.001571, Total: 0.000862, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2380: Train: 0.000756, Val: 0.001572, Total: 0.000858, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2381: Train: 0.000761, Val: 0.001688, Total: 0.000877, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2382: Train: 0.000733, Val: 0.001678, Total: 0.000851, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2383: Train: 0.000788, Val: 0.001683, Total: 0.000899, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2384: Train: 0.000744, Val: 0.001733, Total: 0.000868, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2385: Train: 0.000733, Val: 0.001719, Total: 0.000856, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2386: Train: 0.000746, Val: 0.001769, Total: 0.000874, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2387: Train: 0.000758, Val: 0.001702, Total: 0.000876, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2388: Train: 0.000799, Val: 0.001698, Total: 0.000912, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2389: Train: 0.000752, Val: 0.001726, Total: 0.000874, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2390: Train: 0.000725, Val: 0.001788, Total: 0.000858, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2391: Train: 0.000736, Val: 0.001745, Total: 0.000862, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2392: Train: 0.000776, Val: 0.001711, Total: 0.000893, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2393: Train: 0.000754, Val: 0.001777, Total: 0.000882, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2394: Train: 0.000777, Val: 0.001783, Total: 0.000903, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2395: Train: 0.000745, Val: 0.001664, Total: 0.000860, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2396: Train: 0.000777, Val: 0.001600, Total: 0.000880, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2397: Train: 0.000736, Val: 0.001674, Total: 0.000853, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2398: Train: 0.000731, Val: 0.001789, Total: 0.000864, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2399: Train: 0.000778, Val: 0.001600, Total: 0.000881, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2400: Train: 0.000745, Val: 0.001685, Total: 0.000863, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2401: Train: 0.000760, Val: 0.001728, Total: 0.000881, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2402: Train: 0.000745, Val: 0.001647, Total: 0.000857, LR: 1.28e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2403: Train: 0.000741, Val: 0.001672, Total: 0.000857, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2404: Train: 0.000760, Val: 0.001824, Total: 0.000893, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2405: Train: 0.000728, Val: 0.001662, Total: 0.000845, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2406: Train: 0.000793, Val: 0.002005, Total: 0.000945, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2407: Train: 0.000823, Val: 0.001916, Total: 0.000959, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2408: Train: 0.000788, Val: 0.001842, Total: 0.000920, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2409: Train: 0.000764, Val: 0.001639, Total: 0.000874, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2410: Train: 0.000857, Val: 0.001630, Total: 0.000954, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2411: Train: 0.000818, Val: 0.001698, Total: 0.000928, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2412: Train: 0.000840, Val: 0.001715, Total: 0.000949, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2413: Train: 0.000765, Val: 0.001637, Total: 0.000874, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2414: Train: 0.000830, Val: 0.001650, Total: 0.000932, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2415: Train: 0.000782, Val: 0.001698, Total: 0.000897, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2416: Train: 0.000812, Val: 0.001634, Total: 0.000915, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2417: Train: 0.000805, Val: 0.001653, Total: 0.000911, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2418: Train: 0.000792, Val: 0.001598, Total: 0.000893, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2419: Train: 0.000808, Val: 0.001756, Total: 0.000927, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2420: Train: 0.000776, Val: 0.001705, Total: 0.000892, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2421: Train: 0.000744, Val: 0.001547, Total: 0.000844, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2422: Train: 0.000768, Val: 0.001717, Total: 0.000886, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2423: Train: 0.000723, Val: 0.001606, Total: 0.000833, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2424: Train: 0.000760, Val: 0.001581, Total: 0.000863, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2425: Train: 0.000812, Val: 0.001774, Total: 0.000932, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2426: Train: 0.000792, Val: 0.001700, Total: 0.000905, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2427: Train: 0.000771, Val: 0.001403, Total: 0.000850, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2428: Train: 0.000780, Val: 0.001834, Total: 0.000911, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2429: Train: 0.000790, Val: 0.001705, Total: 0.000904, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2430: Train: 0.000794, Val: 0.001684, Total: 0.000905, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2431: Train: 0.000778, Val: 0.001688, Total: 0.000891, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2432: Train: 0.000774, Val: 0.001453, Total: 0.000858, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2433: Train: 0.000744, Val: 0.001741, Total: 0.000869, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2434: Train: 0.000777, Val: 0.001640, Total: 0.000885, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2435: Train: 0.000788, Val: 0.001736, Total: 0.000906, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2436: Train: 0.000743, Val: 0.001791, Total: 0.000874, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2437: Train: 0.000802, Val: 0.001636, Total: 0.000906, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2438: Train: 0.000764, Val: 0.001705, Total: 0.000882, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2439: Train: 0.000743, Val: 0.001790, Total: 0.000874, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2440: Train: 0.000744, Val: 0.001766, Total: 0.000872, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2441: Train: 0.000743, Val: 0.001728, Total: 0.000866, LR: 1.27e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2442: Train: 0.000766, Val: 0.001632, Total: 0.000874, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2443: Train: 0.000731, Val: 0.001662, Total: 0.000847, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2444: Train: 0.000726, Val: 0.001638, Total: 0.000840, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2445: Train: 0.000744, Val: 0.001641, Total: 0.000856, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2446: Train: 0.000711, Val: 0.001666, Total: 0.000830, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2447: Train: 0.000747, Val: 0.001658, Total: 0.000861, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2448: Train: 0.000753, Val: 0.001631, Total: 0.000863, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2449: Train: 0.000747, Val: 0.001618, Total: 0.000855, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2450: Train: 0.000745, Val: 0.001729, Total: 0.000868, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2451: Train: 0.000743, Val: 0.001602, Total: 0.000851, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2452: Train: 0.000801, Val: 0.001679, Total: 0.000911, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2453: Train: 0.000709, Val: 0.001754, Total: 0.000840, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2454: Train: 0.000707, Val: 0.001689, Total: 0.000830, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2455: Train: 0.000709, Val: 0.001694, Total: 0.000832, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2456: Train: 0.000735, Val: 0.001690, Total: 0.000855, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2457: Train: 0.000724, Val: 0.001753, Total: 0.000853, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2458: Train: 0.000771, Val: 0.001493, Total: 0.000861, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2459: Train: 0.000789, Val: 0.001677, Total: 0.000900, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2460: Train: 0.000782, Val: 0.001752, Total: 0.000903, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2461: Train: 0.000758, Val: 0.001363, Total: 0.000834, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2462: Train: 0.000739, Val: 0.001699, Total: 0.000859, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2463: Train: 0.000773, Val: 0.001798, Total: 0.000901, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2464: Train: 0.000756, Val: 0.001697, Total: 0.000874, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2465: Train: 0.000716, Val: 0.001636, Total: 0.000831, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2466: Train: 0.000739, Val: 0.001683, Total: 0.000857, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2467: Train: 0.000730, Val: 0.001643, Total: 0.000844, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2468: Train: 0.000745, Val: 0.001669, Total: 0.000861, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2469: Train: 0.000731, Val: 0.001675, Total: 0.000849, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2470: Train: 0.000701, Val: 0.001672, Total: 0.000822, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2471: Train: 0.000730, Val: 0.001696, Total: 0.000851, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2472: Train: 0.000755, Val: 0.001643, Total: 0.000866, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2473: Train: 0.000709, Val: 0.001671, Total: 0.000829, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2474: Train: 0.000747, Val: 0.001588, Total: 0.000852, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2475: Train: 0.000732, Val: 0.001643, Total: 0.000846, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2476: Train: 0.000734, Val: 0.001722, Total: 0.000858, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2477: Train: 0.000733, Val: 0.001656, Total: 0.000849, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2478: Train: 0.000710, Val: 0.001657, Total: 0.000828, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2479: Train: 0.000742, Val: 0.001658, Total: 0.000857, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2480: Train: 0.000715, Val: 0.001660, Total: 0.000833, LR: 1.26e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2481: Train: 0.000732, Val: 0.001528, Total: 0.000831, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2482: Train: 0.000735, Val: 0.001614, Total: 0.000845, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2483: Train: 0.000761, Val: 0.001660, Total: 0.000873, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2484: Train: 0.000817, Val: 0.001613, Total: 0.000917, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2485: Train: 0.000759, Val: 0.001649, Total: 0.000870, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2486: Train: 0.000746, Val: 0.001674, Total: 0.000862, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2487: Train: 0.000708, Val: 0.001586, Total: 0.000818, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2488: Train: 0.000749, Val: 0.001599, Total: 0.000855, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2489: Train: 0.000715, Val: 0.001667, Total: 0.000834, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2490: Train: 0.000722, Val: 0.001644, Total: 0.000837, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2491: Train: 0.000716, Val: 0.001562, Total: 0.000821, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2492: Train: 0.000748, Val: 0.001605, Total: 0.000855, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2493: Train: 0.000705, Val: 0.001597, Total: 0.000817, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2494: Train: 0.000733, Val: 0.001606, Total: 0.000842, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2495: Train: 0.000747, Val: 0.001684, Total: 0.000864, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2496: Train: 0.000771, Val: 0.001609, Total: 0.000876, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2497: Train: 0.000730, Val: 0.001632, Total: 0.000843, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2498: Train: 0.000751, Val: 0.001651, Total: 0.000863, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2499: Train: 0.000774, Val: 0.001547, Total: 0.000870, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2500: Train: 0.000751, Val: 0.001659, Total: 0.000865, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2501: Train: 0.000735, Val: 0.001584, Total: 0.000841, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2502: Train: 0.000704, Val: 0.001557, Total: 0.000810, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2503: Train: 0.000738, Val: 0.001786, Total: 0.000869, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2504: Train: 0.000733, Val: 0.001734, Total: 0.000858, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2505: Train: 0.000777, Val: 0.001803, Total: 0.000905, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2506: Train: 0.000750, Val: 0.001694, Total: 0.000868, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2507: Train: 0.000769, Val: 0.001626, Total: 0.000876, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2508: Train: 0.000715, Val: 0.001723, Total: 0.000841, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2509: Train: 0.000738, Val: 0.001620, Total: 0.000848, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2510: Train: 0.000705, Val: 0.001745, Total: 0.000835, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2511: Train: 0.000722, Val: 0.001706, Total: 0.000845, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2512: Train: 0.000716, Val: 0.001617, Total: 0.000829, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2513: Train: 0.000719, Val: 0.001644, Total: 0.000835, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2514: Train: 0.000799, Val: 0.001714, Total: 0.000914, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2515: Train: 0.000746, Val: 0.001530, Total: 0.000844, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2516: Train: 0.000732, Val: 0.001658, Total: 0.000847, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2517: Train: 0.000713, Val: 0.001510, Total: 0.000813, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2518: Train: 0.000727, Val: 0.001618, Total: 0.000838, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2519: Train: 0.000735, Val: 0.001705, Total: 0.000856, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2520: Train: 0.000738, Val: 0.001626, Total: 0.000849, LR: 1.25e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2521: Train: 0.000784, Val: 0.001538, Total: 0.000878, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2522: Train: 0.000757, Val: 0.001600, Total: 0.000863, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2523: Train: 0.000779, Val: 0.001584, Total: 0.000880, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2524: Train: 0.000724, Val: 0.001554, Total: 0.000827, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2525: Train: 0.000728, Val: 0.001640, Total: 0.000842, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2526: Train: 0.000713, Val: 0.001643, Total: 0.000830, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2527: Train: 0.000744, Val: 0.001533, Total: 0.000842, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2528: Train: 0.000713, Val: 0.001573, Total: 0.000821, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2529: Train: 0.000725, Val: 0.001538, Total: 0.000827, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2530: Train: 0.000747, Val: 0.001577, Total: 0.000851, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2531: Train: 0.000722, Val: 0.001561, Total: 0.000827, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2532: Train: 0.000713, Val: 0.001581, Total: 0.000822, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2533: Train: 0.000720, Val: 0.001558, Total: 0.000824, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2534: Train: 0.000728, Val: 0.001669, Total: 0.000846, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2535: Train: 0.000746, Val: 0.001559, Total: 0.000847, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2536: Train: 0.000750, Val: 0.001509, Total: 0.000845, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2537: Train: 0.000772, Val: 0.001741, Total: 0.000893, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2538: Train: 0.000766, Val: 0.001543, Total: 0.000863, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2539: Train: 0.000776, Val: 0.001779, Total: 0.000901, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2540: Train: 0.000776, Val: 0.001494, Total: 0.000866, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2541: Train: 0.000778, Val: 0.001617, Total: 0.000883, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2542: Train: 0.000783, Val: 0.001830, Total: 0.000914, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2543: Train: 0.000731, Val: 0.001555, Total: 0.000834, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2544: Train: 0.000751, Val: 0.001649, Total: 0.000863, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2545: Train: 0.000737, Val: 0.001745, Total: 0.000863, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2546: Train: 0.000724, Val: 0.001699, Total: 0.000846, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2547: Train: 0.000714, Val: 0.001723, Total: 0.000840, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2548: Train: 0.000789, Val: 0.001652, Total: 0.000897, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2549: Train: 0.000742, Val: 0.001581, Total: 0.000847, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2550: Train: 0.000757, Val: 0.001590, Total: 0.000861, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2551: Train: 0.000739, Val: 0.001618, Total: 0.000849, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2552: Train: 0.000706, Val: 0.001578, Total: 0.000815, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2553: Train: 0.000736, Val: 0.001606, Total: 0.000844, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2554: Train: 0.000730, Val: 0.001621, Total: 0.000841, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2555: Train: 0.000729, Val: 0.001589, Total: 0.000836, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2556: Train: 0.000738, Val: 0.001610, Total: 0.000847, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2557: Train: 0.000705, Val: 0.001638, Total: 0.000821, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2558: Train: 0.000704, Val: 0.001570, Total: 0.000812, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2559: Train: 0.000726, Val: 0.001617, Total: 0.000838, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2560: Train: 0.000726, Val: 0.001710, Total: 0.000849, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2561: Train: 0.000737, Val: 0.001553, Total: 0.000839, LR: 1.24e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2562: Train: 0.000726, Val: 0.001587, Total: 0.000834, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2563: Train: 0.000700, Val: 0.001516, Total: 0.000802, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2564: Train: 0.000750, Val: 0.001527, Total: 0.000847, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2565: Train: 0.000735, Val: 0.001652, Total: 0.000850, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2566: Train: 0.000742, Val: 0.001590, Total: 0.000848, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2567: Train: 0.000727, Val: 0.001699, Total: 0.000849, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2568: Train: 0.000734, Val: 0.001681, Total: 0.000853, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2569: Train: 0.000707, Val: 0.001499, Total: 0.000806, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2570: Train: 0.000727, Val: 0.001594, Total: 0.000835, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2571: Train: 0.000738, Val: 0.001596, Total: 0.000845, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2572: Train: 0.000742, Val: 0.001496, Total: 0.000836, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2573: Train: 0.000733, Val: 0.001632, Total: 0.000846, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2574: Train: 0.000756, Val: 0.001630, Total: 0.000865, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2575: Train: 0.000769, Val: 0.001744, Total: 0.000891, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2576: Train: 0.000912, Val: 0.001740, Total: 0.001016, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2577: Train: 0.001025, Val: 0.001690, Total: 0.001108, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2578: Train: 0.001040, Val: 0.001557, Total: 0.001105, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2579: Train: 0.000920, Val: 0.001733, Total: 0.001022, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2580: Train: 0.000779, Val: 0.001619, Total: 0.000884, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2581: Train: 0.000765, Val: 0.001521, Total: 0.000859, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2582: Train: 0.000742, Val: 0.001332, Total: 0.000816, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2583: Train: 0.000744, Val: 0.001631, Total: 0.000855, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2584: Train: 0.000742, Val: 0.001653, Total: 0.000856, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2585: Train: 0.000736, Val: 0.001615, Total: 0.000846, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2586: Train: 0.000736, Val: 0.001605, Total: 0.000845, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2587: Train: 0.000764, Val: 0.001560, Total: 0.000864, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2588: Train: 0.000717, Val: 0.001573, Total: 0.000824, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2589: Train: 0.000721, Val: 0.001586, Total: 0.000829, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2590: Train: 0.000741, Val: 0.001560, Total: 0.000843, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2591: Train: 0.000726, Val: 0.001562, Total: 0.000831, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2592: Train: 0.000723, Val: 0.001540, Total: 0.000825, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2593: Train: 0.000723, Val: 0.001708, Total: 0.000846, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2594: Train: 0.000711, Val: 0.001659, Total: 0.000829, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2595: Train: 0.000724, Val: 0.001652, Total: 0.000840, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2596: Train: 0.000730, Val: 0.001544, Total: 0.000832, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2597: Train: 0.000721, Val: 0.001577, Total: 0.000828, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2598: Train: 0.000720, Val: 0.001708, Total: 0.000843, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2599: Train: 0.000751, Val: 0.001480, Total: 0.000842, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2600: Train: 0.000774, Val: 0.001975, Total: 0.000924, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2601: Train: 0.000755, Val: 0.001825, Total: 0.000889, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2602: Train: 0.000724, Val: 0.001786, Total: 0.000857, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2603: Train: 0.000761, Val: 0.001617, Total: 0.000868, LR: 1.23e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2604: Train: 0.000730, Val: 0.001633, Total: 0.000843, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2605: Train: 0.000740, Val: 0.001615, Total: 0.000849, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2606: Train: 0.000717, Val: 0.001639, Total: 0.000832, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2607: Train: 0.000694, Val: 0.001673, Total: 0.000816, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2608: Train: 0.000713, Val: 0.001719, Total: 0.000839, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2609: Train: 0.000715, Val: 0.001655, Total: 0.000832, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2610: Train: 0.000735, Val: 0.001649, Total: 0.000849, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2611: Train: 0.000714, Val: 0.001526, Total: 0.000815, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2612: Train: 0.000750, Val: 0.001754, Total: 0.000875, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2613: Train: 0.000736, Val: 0.001678, Total: 0.000854, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2614: Train: 0.000737, Val: 0.001590, Total: 0.000844, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2615: Train: 0.000693, Val: 0.001637, Total: 0.000811, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2616: Train: 0.000709, Val: 0.001712, Total: 0.000834, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2617: Train: 0.000706, Val: 0.001590, Total: 0.000817, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2618: Train: 0.000720, Val: 0.001567, Total: 0.000825, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2619: Train: 0.000715, Val: 0.001613, Total: 0.000827, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2620: Train: 0.000708, Val: 0.001669, Total: 0.000828, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2621: Train: 0.000725, Val: 0.001551, Total: 0.000828, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2622: Train: 0.000748, Val: 0.001664, Total: 0.000862, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2623: Train: 0.000699, Val: 0.001687, Total: 0.000822, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2624: Train: 0.000732, Val: 0.001567, Total: 0.000836, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2625: Train: 0.000736, Val: 0.001675, Total: 0.000854, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2626: Train: 0.000787, Val: 0.001424, Total: 0.000867, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2627: Train: 0.000771, Val: 0.001762, Total: 0.000895, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2628: Train: 0.000803, Val: 0.001812, Total: 0.000930, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2629: Train: 0.000739, Val: 0.001519, Total: 0.000836, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2630: Train: 0.000748, Val: 0.001693, Total: 0.000866, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2631: Train: 0.000700, Val: 0.001566, Total: 0.000809, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2632: Train: 0.000703, Val: 0.001585, Total: 0.000813, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2633: Train: 0.000734, Val: 0.001613, Total: 0.000844, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2634: Train: 0.000719, Val: 0.001586, Total: 0.000828, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2635: Train: 0.000707, Val: 0.001605, Total: 0.000819, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2636: Train: 0.000732, Val: 0.001665, Total: 0.000849, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2637: Train: 0.000734, Val: 0.001641, Total: 0.000847, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2638: Train: 0.000736, Val: 0.001636, Total: 0.000848, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2639: Train: 0.000720, Val: 0.001558, Total: 0.000824, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2640: Train: 0.000703, Val: 0.001704, Total: 0.000828, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2641: Train: 0.000719, Val: 0.001520, Total: 0.000819, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2642: Train: 0.000720, Val: 0.001671, Total: 0.000839, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2643: Train: 0.000742, Val: 0.001483, Total: 0.000834, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2644: Train: 0.000744, Val: 0.001826, Total: 0.000879, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2645: Train: 0.000783, Val: 0.001222, Total: 0.000838, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2646: Train: 0.000748, Val: 0.001325, Total: 0.000820, LR: 1.22e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2647: Train: 0.000767, Val: 0.002101, Total: 0.000934, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2648: Train: 0.000743, Val: 0.001715, Total: 0.000864, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2649: Train: 0.000761, Val: 0.001587, Total: 0.000865, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2650: Train: 0.000710, Val: 0.001603, Total: 0.000821, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2651: Train: 0.000776, Val: 0.001665, Total: 0.000887, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2652: Train: 0.000738, Val: 0.001651, Total: 0.000852, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2653: Train: 0.000718, Val: 0.001602, Total: 0.000829, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2654: Train: 0.000706, Val: 0.001604, Total: 0.000818, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2655: Train: 0.000727, Val: 0.001663, Total: 0.000844, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2656: Train: 0.000686, Val: 0.001663, Total: 0.000808, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2657: Train: 0.000706, Val: 0.001675, Total: 0.000827, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2658: Train: 0.000693, Val: 0.001498, Total: 0.000793, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2659: Train: 0.000776, Val: 0.001578, Total: 0.000877, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2660: Train: 0.000741, Val: 0.001618, Total: 0.000851, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2661: Train: 0.000996, Val: 0.002031, Total: 0.001125, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2662: Train: 0.001074, Val: 0.002108, Total: 0.001203, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2663: Train: 0.001156, Val: 0.001746, Total: 0.001230, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2664: Train: 0.001001, Val: 0.001824, Total: 0.001103, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2665: Train: 0.000934, Val: 0.001852, Total: 0.001049, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2666: Train: 0.000892, Val: 0.002030, Total: 0.001034, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2667: Train: 0.000979, Val: 0.002377, Total: 0.001154, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2668: Train: 0.000953, Val: 0.001698, Total: 0.001046, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2669: Train: 0.000885, Val: 0.001573, Total: 0.000971, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2670: Train: 0.000921, Val: 0.001341, Total: 0.000974, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2671: Train: 0.000832, Val: 0.002138, Total: 0.000995, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2672: Train: 0.000831, Val: 0.002249, Total: 0.001008, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2673: Train: 0.000880, Val: 0.002048, Total: 0.001026, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2674: Train: 0.000897, Val: 0.001808, Total: 0.001011, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2675: Train: 0.001049, Val: 0.002713, Total: 0.001257, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2676: Train: 0.000987, Val: 0.002649, Total: 0.001195, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2677: Train: 0.002421, Val: 0.002816, Total: 0.002470, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2678: Train: 0.001416, Val: 0.002280, Total: 0.001524, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2679: Train: 0.001257, Val: 0.003029, Total: 0.001479, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2680: Train: 0.001220, Val: 0.002738, Total: 0.001410, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2681: Train: 0.001299, Val: 0.003298, Total: 0.001549, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2682: Train: 0.001051, Val: 0.002877, Total: 0.001280, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2683: Train: 0.001332, Val: 0.003514, Total: 0.001605, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2684: Train: 0.001279, Val: 0.002578, Total: 0.001441, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2685: Train: 0.001145, Val: 0.003161, Total: 0.001397, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2686: Train: 0.001326, Val: 0.002263, Total: 0.001443, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2687: Train: 0.001096, Val: 0.002835, Total: 0.001313, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2688: Train: 0.001023, Val: 0.002682, Total: 0.001230, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2689: Train: 0.000935, Val: 0.002427, Total: 0.001122, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2690: Train: 0.000940, Val: 0.001939, Total: 0.001065, LR: 1.21e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2691: Train: 0.000939, Val: 0.001458, Total: 0.001004, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2692: Train: 0.000913, Val: 0.001509, Total: 0.000987, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2693: Train: 0.000948, Val: 0.001577, Total: 0.001027, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2694: Train: 0.000865, Val: 0.001612, Total: 0.000959, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2695: Train: 0.000838, Val: 0.001591, Total: 0.000932, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2696: Train: 0.000866, Val: 0.001831, Total: 0.000986, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2697: Train: 0.000836, Val: 0.001797, Total: 0.000956, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2698: Train: 0.000879, Val: 0.001728, Total: 0.000985, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2699: Train: 0.000958, Val: 0.002007, Total: 0.001089, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2700: Train: 0.000833, Val: 0.001307, Total: 0.000892, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2701: Train: 0.000864, Val: 0.001417, Total: 0.000933, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2702: Train: 0.000839, Val: 0.001707, Total: 0.000947, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2703: Train: 0.000915, Val: 0.001784, Total: 0.001024, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2704: Train: 0.000924, Val: 0.001414, Total: 0.000986, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2705: Train: 0.000842, Val: 0.002377, Total: 0.001034, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2706: Train: 0.000818, Val: 0.002366, Total: 0.001011, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2707: Train: 0.000821, Val: 0.002348, Total: 0.001012, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2708: Train: 0.000824, Val: 0.002359, Total: 0.001016, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2709: Train: 0.000820, Val: 0.001537, Total: 0.000910, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2710: Train: 0.000827, Val: 0.001474, Total: 0.000908, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2711: Train: 0.000826, Val: 0.001749, Total: 0.000941, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2712: Train: 0.000841, Val: 0.001940, Total: 0.000978, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2713: Train: 0.000789, Val: 0.001746, Total: 0.000909, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2714: Train: 0.000782, Val: 0.001601, Total: 0.000884, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2715: Train: 0.000779, Val: 0.001665, Total: 0.000890, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2716: Train: 0.000764, Val: 0.001960, Total: 0.000914, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2717: Train: 0.000772, Val: 0.001982, Total: 0.000923, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2718: Train: 0.000779, Val: 0.002131, Total: 0.000948, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2719: Train: 0.000784, Val: 0.002023, Total: 0.000939, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2720: Train: 0.000753, Val: 0.001952, Total: 0.000903, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2721: Train: 0.000760, Val: 0.001866, Total: 0.000899, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2722: Train: 0.000766, Val: 0.001889, Total: 0.000907, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2723: Train: 0.000748, Val: 0.001968, Total: 0.000900, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2724: Train: 0.000772, Val: 0.001942, Total: 0.000918, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2725: Train: 0.000736, Val: 0.001993, Total: 0.000893, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2726: Train: 0.000824, Val: 0.001829, Total: 0.000949, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2727: Train: 0.000767, Val: 0.001853, Total: 0.000903, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2728: Train: 0.000793, Val: 0.001792, Total: 0.000918, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2729: Train: 0.000800, Val: 0.001669, Total: 0.000909, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2730: Train: 0.000756, Val: 0.001669, Total: 0.000870, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2731: Train: 0.000746, Val: 0.001628, Total: 0.000856, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2732: Train: 0.000779, Val: 0.001605, Total: 0.000882, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2733: Train: 0.000755, Val: 0.001552, Total: 0.000855, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2734: Train: 0.000817, Val: 0.001535, Total: 0.000906, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2735: Train: 0.000780, Val: 0.001705, Total: 0.000896, LR: 1.20e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2736: Train: 0.000739, Val: 0.001695, Total: 0.000859, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2737: Train: 0.000752, Val: 0.001636, Total: 0.000862, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2738: Train: 0.000784, Val: 0.001570, Total: 0.000883, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2739: Train: 0.000744, Val: 0.001579, Total: 0.000848, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2740: Train: 0.000726, Val: 0.001584, Total: 0.000833, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2741: Train: 0.000724, Val: 0.001538, Total: 0.000825, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2742: Train: 0.000737, Val: 0.001543, Total: 0.000838, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2743: Train: 0.000741, Val: 0.001530, Total: 0.000839, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2744: Train: 0.000733, Val: 0.001590, Total: 0.000840, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2745: Train: 0.000731, Val: 0.001488, Total: 0.000826, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2746: Train: 0.000735, Val: 0.001499, Total: 0.000830, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2747: Train: 0.000757, Val: 0.001638, Total: 0.000867, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2748: Train: 0.000757, Val: 0.001537, Total: 0.000854, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2749: Train: 0.000764, Val: 0.001598, Total: 0.000868, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2750: Train: 0.000715, Val: 0.001638, Total: 0.000830, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2751: Train: 0.000795, Val: 0.001548, Total: 0.000889, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2752: Train: 0.000726, Val: 0.001785, Total: 0.000859, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2753: Train: 0.000770, Val: 0.001769, Total: 0.000895, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2754: Train: 0.000748, Val: 0.001680, Total: 0.000864, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2755: Train: 0.000762, Val: 0.001621, Total: 0.000870, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2756: Train: 0.000746, Val: 0.001658, Total: 0.000860, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2757: Train: 0.000759, Val: 0.001630, Total: 0.000868, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2758: Train: 0.000738, Val: 0.001603, Total: 0.000846, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2759: Train: 0.000736, Val: 0.001648, Total: 0.000850, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2760: Train: 0.000767, Val: 0.001504, Total: 0.000859, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2761: Train: 0.000743, Val: 0.001602, Total: 0.000850, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2762: Train: 0.000787, Val: 0.001719, Total: 0.000904, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2763: Train: 0.000748, Val: 0.001633, Total: 0.000858, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2764: Train: 0.000766, Val: 0.001591, Total: 0.000869, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2765: Train: 0.000745, Val: 0.001540, Total: 0.000845, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2766: Train: 0.000767, Val: 0.001590, Total: 0.000870, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2767: Train: 0.000749, Val: 0.001618, Total: 0.000858, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2768: Train: 0.000777, Val: 0.001536, Total: 0.000872, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2769: Train: 0.000740, Val: 0.001593, Total: 0.000847, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2770: Train: 0.000756, Val: 0.001604, Total: 0.000862, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2771: Train: 0.000797, Val: 0.001558, Total: 0.000892, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2772: Train: 0.000727, Val: 0.001598, Total: 0.000836, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2773: Train: 0.000722, Val: 0.001521, Total: 0.000822, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2774: Train: 0.000717, Val: 0.001550, Total: 0.000821, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2775: Train: 0.000725, Val: 0.001670, Total: 0.000843, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2776: Train: 0.000764, Val: 0.001531, Total: 0.000860, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2777: Train: 0.000719, Val: 0.001437, Total: 0.000809, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2778: Train: 0.000746, Val: 0.001488, Total: 0.000839, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2779: Train: 0.000723, Val: 0.001570, Total: 0.000829, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2780: Train: 0.000731, Val: 0.001516, Total: 0.000830, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2781: Train: 0.000754, Val: 0.001521, Total: 0.000850, LR: 1.19e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2782: Train: 0.000787, Val: 0.001594, Total: 0.000888, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2783: Train: 0.000816, Val: 0.001597, Total: 0.000913, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2784: Train: 0.000818, Val: 0.001502, Total: 0.000903, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2785: Train: 0.000800, Val: 0.001549, Total: 0.000894, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2786: Train: 0.000806, Val: 0.001679, Total: 0.000915, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2787: Train: 0.000743, Val: 0.001572, Total: 0.000847, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2788: Train: 0.000794, Val: 0.001635, Total: 0.000899, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2789: Train: 0.000763, Val: 0.001541, Total: 0.000860, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2790: Train: 0.000789, Val: 0.001423, Total: 0.000868, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2791: Train: 0.000861, Val: 0.001766, Total: 0.000974, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2792: Train: 0.000819, Val: 0.001532, Total: 0.000908, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2793: Train: 0.000805, Val: 0.001600, Total: 0.000905, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2794: Train: 0.000727, Val: 0.001693, Total: 0.000848, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2795: Train: 0.000717, Val: 0.001561, Total: 0.000822, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2796: Train: 0.000761, Val: 0.001509, Total: 0.000855, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2797: Train: 0.000739, Val: 0.001596, Total: 0.000847, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2798: Train: 0.000721, Val: 0.001539, Total: 0.000823, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2799: Train: 0.000697, Val: 0.001509, Total: 0.000799, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2800: Train: 0.000704, Val: 0.001543, Total: 0.000809, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2801: Train: 0.000735, Val: 0.001617, Total: 0.000845, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2802: Train: 0.000711, Val: 0.001534, Total: 0.000814, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2803: Train: 0.000740, Val: 0.001424, Total: 0.000825, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2804: Train: 0.000728, Val: 0.001466, Total: 0.000820, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2805: Train: 0.000738, Val: 0.001528, Total: 0.000836, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2806: Train: 0.000754, Val: 0.001589, Total: 0.000859, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2807: Train: 0.000744, Val: 0.001446, Total: 0.000831, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2808: Train: 0.000732, Val: 0.001474, Total: 0.000825, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2809: Train: 0.000710, Val: 0.001521, Total: 0.000811, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2810: Train: 0.000727, Val: 0.001390, Total: 0.000810, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2811: Train: 0.000708, Val: 0.001534, Total: 0.000811, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2812: Train: 0.000715, Val: 0.001518, Total: 0.000816, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2813: Train: 0.000757, Val: 0.001467, Total: 0.000846, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2814: Train: 0.000729, Val: 0.001372, Total: 0.000810, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2815: Train: 0.000711, Val: 0.001368, Total: 0.000793, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2816: Train: 0.000727, Val: 0.001504, Total: 0.000824, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2817: Train: 0.000745, Val: 0.001546, Total: 0.000845, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2818: Train: 0.000699, Val: 0.001595, Total: 0.000811, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2819: Train: 0.000711, Val: 0.001609, Total: 0.000823, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2820: Train: 0.000712, Val: 0.001528, Total: 0.000814, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2821: Train: 0.000758, Val: 0.001569, Total: 0.000859, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2822: Train: 0.000733, Val: 0.001532, Total: 0.000833, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2823: Train: 0.000755, Val: 0.001521, Total: 0.000851, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2824: Train: 0.000698, Val: 0.001514, Total: 0.000800, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2825: Train: 0.000723, Val: 0.001543, Total: 0.000826, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2826: Train: 0.000676, Val: 0.001564, Total: 0.000787, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2827: Train: 0.000691, Val: 0.001545, Total: 0.000798, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2828: Train: 0.000720, Val: 0.001560, Total: 0.000825, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2829: Train: 0.000736, Val: 0.001473, Total: 0.000828, LR: 1.18e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2830: Train: 0.000738, Val: 0.001620, Total: 0.000848, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2831: Train: 0.000776, Val: 0.001527, Total: 0.000870, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2832: Train: 0.000715, Val: 0.001585, Total: 0.000824, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2833: Train: 0.000737, Val: 0.001572, Total: 0.000841, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2834: Train: 0.000710, Val: 0.001463, Total: 0.000804, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2835: Train: 0.000727, Val: 0.001583, Total: 0.000834, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2836: Train: 0.000718, Val: 0.001594, Total: 0.000827, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2837: Train: 0.000694, Val: 0.001495, Total: 0.000794, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2838: Train: 0.000712, Val: 0.001520, Total: 0.000813, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2839: Train: 0.000722, Val: 0.001548, Total: 0.000825, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2840: Train: 0.000734, Val: 0.001525, Total: 0.000833, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2841: Train: 0.000727, Val: 0.001441, Total: 0.000816, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2842: Train: 0.000722, Val: 0.001518, Total: 0.000821, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2843: Train: 0.000714, Val: 0.001513, Total: 0.000814, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2844: Train: 0.000696, Val: 0.001585, Total: 0.000807, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2845: Train: 0.000753, Val: 0.001515, Total: 0.000848, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2846: Train: 0.000722, Val: 0.001511, Total: 0.000821, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2847: Train: 0.000761, Val: 0.001487, Total: 0.000852, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2848: Train: 0.000712, Val: 0.001664, Total: 0.000831, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2849: Train: 0.000751, Val: 0.001622, Total: 0.000860, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2850: Train: 0.000766, Val: 0.001342, Total: 0.000838, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2851: Train: 0.000724, Val: 0.001531, Total: 0.000824, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2852: Train: 0.000761, Val: 0.001594, Total: 0.000865, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2853: Train: 0.000756, Val: 0.001609, Total: 0.000863, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2854: Train: 0.000713, Val: 0.001581, Total: 0.000821, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2855: Train: 0.000701, Val: 0.001499, Total: 0.000801, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2856: Train: 0.000762, Val: 0.001527, Total: 0.000858, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2857: Train: 0.000742, Val: 0.001620, Total: 0.000852, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2858: Train: 0.000708, Val: 0.001624, Total: 0.000823, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2859: Train: 0.000725, Val: 0.001608, Total: 0.000836, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2860: Train: 0.000721, Val: 0.001623, Total: 0.000834, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2861: Train: 0.000706, Val: 0.001556, Total: 0.000813, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2862: Train: 0.000732, Val: 0.001625, Total: 0.000843, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2863: Train: 0.000718, Val: 0.001545, Total: 0.000822, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2864: Train: 0.000704, Val: 0.001558, Total: 0.000811, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2865: Train: 0.000719, Val: 0.001579, Total: 0.000827, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2866: Train: 0.000732, Val: 0.001554, Total: 0.000835, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2867: Train: 0.000719, Val: 0.001486, Total: 0.000815, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2868: Train: 0.000702, Val: 0.001559, Total: 0.000809, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2869: Train: 0.000714, Val: 0.001515, Total: 0.000814, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2870: Train: 0.000712, Val: 0.001538, Total: 0.000815, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2871: Train: 0.000740, Val: 0.001491, Total: 0.000834, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2872: Train: 0.000727, Val: 0.001500, Total: 0.000823, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2873: Train: 0.000686, Val: 0.001551, Total: 0.000794, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2874: Train: 0.000718, Val: 0.001515, Total: 0.000818, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2875: Train: 0.000711, Val: 0.001560, Total: 0.000817, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2876: Train: 0.000705, Val: 0.001520, Total: 0.000807, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2877: Train: 0.000694, Val: 0.001574, Total: 0.000804, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2878: Train: 0.000691, Val: 0.001526, Total: 0.000796, LR: 1.17e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2879: Train: 0.000756, Val: 0.001526, Total: 0.000852, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2880: Train: 0.000730, Val: 0.001510, Total: 0.000827, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2881: Train: 0.000694, Val: 0.001587, Total: 0.000806, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2882: Train: 0.000736, Val: 0.001496, Total: 0.000831, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2883: Train: 0.000699, Val: 0.001582, Total: 0.000810, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2884: Train: 0.000719, Val: 0.001522, Total: 0.000820, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2885: Train: 0.000697, Val: 0.001489, Total: 0.000796, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2886: Train: 0.000732, Val: 0.001569, Total: 0.000837, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2887: Train: 0.000690, Val: 0.001576, Total: 0.000801, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2888: Train: 0.000691, Val: 0.001585, Total: 0.000803, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2889: Train: 0.000719, Val: 0.001493, Total: 0.000815, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2890: Train: 0.000689, Val: 0.001483, Total: 0.000789, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2891: Train: 0.000702, Val: 0.001561, Total: 0.000810, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2892: Train: 0.000722, Val: 0.001560, Total: 0.000827, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2893: Train: 0.000697, Val: 0.001469, Total: 0.000794, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2894: Train: 0.000682, Val: 0.001522, Total: 0.000787, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2895: Train: 0.000714, Val: 0.001525, Total: 0.000815, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2896: Train: 0.000687, Val: 0.001562, Total: 0.000796, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2897: Train: 0.000738, Val: 0.001557, Total: 0.000840, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2898: Train: 0.000731, Val: 0.001561, Total: 0.000835, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2899: Train: 0.000756, Val: 0.001702, Total: 0.000874, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2900: Train: 0.000732, Val: 0.001492, Total: 0.000827, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2901: Train: 0.000713, Val: 0.001522, Total: 0.000814, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2902: Train: 0.000713, Val: 0.001560, Total: 0.000819, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2903: Train: 0.000714, Val: 0.001515, Total: 0.000814, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2904: Train: 0.000761, Val: 0.001557, Total: 0.000861, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2905: Train: 0.000714, Val: 0.001584, Total: 0.000823, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2906: Train: 0.000737, Val: 0.001460, Total: 0.000828, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2907: Train: 0.000684, Val: 0.001545, Total: 0.000792, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2908: Train: 0.000741, Val: 0.001598, Total: 0.000848, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2909: Train: 0.000709, Val: 0.001548, Total: 0.000814, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2910: Train: 0.000690, Val: 0.001572, Total: 0.000800, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2911: Train: 0.000750, Val: 0.001486, Total: 0.000842, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2912: Train: 0.000731, Val: 0.001533, Total: 0.000831, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2913: Train: 0.000726, Val: 0.001543, Total: 0.000828, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2914: Train: 0.000699, Val: 0.001505, Total: 0.000800, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2915: Train: 0.000724, Val: 0.001501, Total: 0.000821, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2916: Train: 0.000694, Val: 0.001543, Total: 0.000800, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2917: Train: 0.000704, Val: 0.001471, Total: 0.000800, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2918: Train: 0.000694, Val: 0.001501, Total: 0.000795, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2919: Train: 0.000742, Val: 0.001612, Total: 0.000851, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2920: Train: 0.000729, Val: 0.001444, Total: 0.000818, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2921: Train: 0.000722, Val: 0.001489, Total: 0.000818, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2922: Train: 0.000772, Val: 0.001422, Total: 0.000853, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2923: Train: 0.000751, Val: 0.001553, Total: 0.000851, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2924: Train: 0.000745, Val: 0.001536, Total: 0.000844, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2925: Train: 0.000764, Val: 0.001446, Total: 0.000849, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2926: Train: 0.000765, Val: 0.001432, Total: 0.000849, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2927: Train: 0.000725, Val: 0.001545, Total: 0.000828, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2928: Train: 0.000713, Val: 0.001517, Total: 0.000814, LR: 1.16e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2929: Train: 0.000721, Val: 0.001504, Total: 0.000819, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2930: Train: 0.000721, Val: 0.001482, Total: 0.000816, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2931: Train: 0.000745, Val: 0.001430, Total: 0.000831, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2932: Train: 0.000712, Val: 0.001466, Total: 0.000806, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2933: Train: 0.000690, Val: 0.001459, Total: 0.000786, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2934: Train: 0.000720, Val: 0.001493, Total: 0.000817, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2935: Train: 0.000724, Val: 0.001474, Total: 0.000818, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2936: Train: 0.000718, Val: 0.001446, Total: 0.000809, LR: 1.15e-03\n",
      "          Best: Train: 0.000682, Val: 0.001507, Total: 0.000786 (Epoch 2201)\n",
      "Epoch 2937: Train: 0.000680, Val: 0.001452, Total: 0.000777, LR: 1.15e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2938: Train: 0.000731, Val: 0.001518, Total: 0.000830, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2939: Train: 0.000699, Val: 0.001419, Total: 0.000789, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2940: Train: 0.000777, Val: 0.001547, Total: 0.000873, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2941: Train: 0.000733, Val: 0.001413, Total: 0.000818, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2942: Train: 0.000695, Val: 0.001441, Total: 0.000788, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2943: Train: 0.000739, Val: 0.001490, Total: 0.000833, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2944: Train: 0.000740, Val: 0.001383, Total: 0.000820, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2945: Train: 0.000721, Val: 0.001530, Total: 0.000822, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2946: Train: 0.000740, Val: 0.001471, Total: 0.000831, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2947: Train: 0.000711, Val: 0.001603, Total: 0.000823, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2948: Train: 0.000717, Val: 0.001443, Total: 0.000808, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2949: Train: 0.000717, Val: 0.001424, Total: 0.000805, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2950: Train: 0.000711, Val: 0.001579, Total: 0.000820, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2951: Train: 0.000706, Val: 0.001510, Total: 0.000806, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2952: Train: 0.000701, Val: 0.001464, Total: 0.000796, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2953: Train: 0.000717, Val: 0.001618, Total: 0.000829, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2954: Train: 0.000702, Val: 0.001396, Total: 0.000789, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2955: Train: 0.000724, Val: 0.001531, Total: 0.000825, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2956: Train: 0.000719, Val: 0.001756, Total: 0.000849, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2957: Train: 0.000717, Val: 0.001516, Total: 0.000817, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2958: Train: 0.000679, Val: 0.001474, Total: 0.000779, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2959: Train: 0.000726, Val: 0.001628, Total: 0.000839, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2960: Train: 0.000708, Val: 0.001485, Total: 0.000806, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2961: Train: 0.000752, Val: 0.001469, Total: 0.000842, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2962: Train: 0.000747, Val: 0.001505, Total: 0.000842, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2963: Train: 0.000726, Val: 0.001460, Total: 0.000817, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2964: Train: 0.000766, Val: 0.001552, Total: 0.000865, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2965: Train: 0.000711, Val: 0.001604, Total: 0.000822, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2966: Train: 0.000713, Val: 0.001417, Total: 0.000801, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2967: Train: 0.000757, Val: 0.001568, Total: 0.000859, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2968: Train: 0.000722, Val: 0.001816, Total: 0.000859, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2969: Train: 0.000722, Val: 0.001593, Total: 0.000831, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2970: Train: 0.000724, Val: 0.001507, Total: 0.000822, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2971: Train: 0.000707, Val: 0.001548, Total: 0.000812, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2972: Train: 0.000703, Val: 0.001581, Total: 0.000813, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2973: Train: 0.000726, Val: 0.001556, Total: 0.000830, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2974: Train: 0.000746, Val: 0.001668, Total: 0.000861, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2975: Train: 0.000743, Val: 0.001496, Total: 0.000837, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2976: Train: 0.000696, Val: 0.001531, Total: 0.000800, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2977: Train: 0.000702, Val: 0.001496, Total: 0.000802, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2978: Train: 0.000706, Val: 0.001524, Total: 0.000808, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2979: Train: 0.000719, Val: 0.001601, Total: 0.000829, LR: 1.15e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2980: Train: 0.000731, Val: 0.001464, Total: 0.000823, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2981: Train: 0.000696, Val: 0.001554, Total: 0.000803, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2982: Train: 0.000740, Val: 0.001564, Total: 0.000843, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2983: Train: 0.000689, Val: 0.001480, Total: 0.000788, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2984: Train: 0.000734, Val: 0.001541, Total: 0.000835, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2985: Train: 0.000702, Val: 0.001458, Total: 0.000797, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2986: Train: 0.000706, Val: 0.001502, Total: 0.000806, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2987: Train: 0.000671, Val: 0.001598, Total: 0.000787, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2988: Train: 0.000714, Val: 0.001482, Total: 0.000810, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2989: Train: 0.000707, Val: 0.001452, Total: 0.000800, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2990: Train: 0.000717, Val: 0.001564, Total: 0.000823, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2991: Train: 0.000722, Val: 0.001565, Total: 0.000827, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2992: Train: 0.000727, Val: 0.001530, Total: 0.000828, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2993: Train: 0.000719, Val: 0.001542, Total: 0.000822, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2994: Train: 0.000747, Val: 0.001506, Total: 0.000841, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2995: Train: 0.000762, Val: 0.001489, Total: 0.000853, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2996: Train: 0.000699, Val: 0.001496, Total: 0.000798, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2997: Train: 0.000699, Val: 0.001491, Total: 0.000798, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2998: Train: 0.000724, Val: 0.001527, Total: 0.000825, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 2999: Train: 0.000692, Val: 0.001545, Total: 0.000799, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3000: Train: 0.000703, Val: 0.001455, Total: 0.000797, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3001: Train: 0.000747, Val: 0.001545, Total: 0.000847, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3002: Train: 0.000687, Val: 0.001527, Total: 0.000792, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3003: Train: 0.000715, Val: 0.001461, Total: 0.000808, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3004: Train: 0.000704, Val: 0.001538, Total: 0.000808, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3005: Train: 0.000696, Val: 0.001504, Total: 0.000797, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3006: Train: 0.000716, Val: 0.001471, Total: 0.000810, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3007: Train: 0.000724, Val: 0.001562, Total: 0.000829, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3008: Train: 0.000709, Val: 0.001403, Total: 0.000796, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3009: Train: 0.000723, Val: 0.001615, Total: 0.000834, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3010: Train: 0.000716, Val: 0.001411, Total: 0.000803, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3011: Train: 0.000741, Val: 0.001622, Total: 0.000851, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3012: Train: 0.000723, Val: 0.001708, Total: 0.000846, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3013: Train: 0.000691, Val: 0.001499, Total: 0.000792, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3014: Train: 0.000723, Val: 0.001549, Total: 0.000826, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3015: Train: 0.000736, Val: 0.001604, Total: 0.000844, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3016: Train: 0.000699, Val: 0.001528, Total: 0.000802, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3017: Train: 0.000734, Val: 0.001645, Total: 0.000848, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3018: Train: 0.000706, Val: 0.001556, Total: 0.000812, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3019: Train: 0.000752, Val: 0.001592, Total: 0.000857, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3020: Train: 0.000708, Val: 0.001436, Total: 0.000799, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3021: Train: 0.000728, Val: 0.001568, Total: 0.000833, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3022: Train: 0.000704, Val: 0.001581, Total: 0.000814, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3023: Train: 0.000681, Val: 0.001545, Total: 0.000789, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3024: Train: 0.000700, Val: 0.001680, Total: 0.000822, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3025: Train: 0.000704, Val: 0.001532, Total: 0.000807, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3026: Train: 0.000718, Val: 0.001596, Total: 0.000827, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3027: Train: 0.000689, Val: 0.001588, Total: 0.000801, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3028: Train: 0.000704, Val: 0.001512, Total: 0.000805, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3029: Train: 0.000710, Val: 0.001573, Total: 0.000818, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3030: Train: 0.000692, Val: 0.001506, Total: 0.000794, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3031: Train: 0.000703, Val: 0.001548, Total: 0.000809, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3032: Train: 0.000690, Val: 0.001531, Total: 0.000795, LR: 1.14e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3033: Train: 0.000710, Val: 0.001485, Total: 0.000807, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3034: Train: 0.000713, Val: 0.001639, Total: 0.000829, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3035: Train: 0.000726, Val: 0.001529, Total: 0.000826, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3036: Train: 0.000701, Val: 0.001508, Total: 0.000802, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3037: Train: 0.000689, Val: 0.001536, Total: 0.000795, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3038: Train: 0.000716, Val: 0.001519, Total: 0.000817, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3039: Train: 0.000701, Val: 0.001487, Total: 0.000799, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3040: Train: 0.000695, Val: 0.001530, Total: 0.000800, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3041: Train: 0.000738, Val: 0.001516, Total: 0.000835, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3042: Train: 0.000699, Val: 0.001541, Total: 0.000804, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3043: Train: 0.000717, Val: 0.001560, Total: 0.000822, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3044: Train: 0.000710, Val: 0.001790, Total: 0.000845, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3045: Train: 0.000765, Val: 0.001538, Total: 0.000862, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3046: Train: 0.000755, Val: 0.001402, Total: 0.000835, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3047: Train: 0.000704, Val: 0.001467, Total: 0.000799, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3048: Train: 0.000709, Val: 0.001561, Total: 0.000816, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3049: Train: 0.000712, Val: 0.001575, Total: 0.000820, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3050: Train: 0.000701, Val: 0.001579, Total: 0.000811, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3051: Train: 0.000744, Val: 0.001572, Total: 0.000847, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3052: Train: 0.000688, Val: 0.001557, Total: 0.000797, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3053: Train: 0.000707, Val: 0.001561, Total: 0.000814, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3054: Train: 0.000737, Val: 0.001581, Total: 0.000843, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3055: Train: 0.000744, Val: 0.001509, Total: 0.000840, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3056: Train: 0.000712, Val: 0.001507, Total: 0.000812, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3057: Train: 0.000692, Val: 0.001536, Total: 0.000797, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3058: Train: 0.000716, Val: 0.001566, Total: 0.000822, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3059: Train: 0.000736, Val: 0.001579, Total: 0.000841, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3060: Train: 0.000728, Val: 0.001517, Total: 0.000826, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3061: Train: 0.000707, Val: 0.001598, Total: 0.000818, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3062: Train: 0.000699, Val: 0.001546, Total: 0.000805, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3063: Train: 0.000709, Val: 0.001522, Total: 0.000811, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3064: Train: 0.000722, Val: 0.001543, Total: 0.000825, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3065: Train: 0.000758, Val: 0.001533, Total: 0.000855, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3066: Train: 0.000711, Val: 0.001510, Total: 0.000811, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3067: Train: 0.000743, Val: 0.001534, Total: 0.000842, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3068: Train: 0.000693, Val: 0.001512, Total: 0.000795, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3069: Train: 0.000693, Val: 0.001477, Total: 0.000791, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3070: Train: 0.000743, Val: 0.001505, Total: 0.000838, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3071: Train: 0.000702, Val: 0.001503, Total: 0.000802, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3072: Train: 0.000686, Val: 0.001600, Total: 0.000800, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3073: Train: 0.000726, Val: 0.001530, Total: 0.000826, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3074: Train: 0.000721, Val: 0.001543, Total: 0.000823, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3075: Train: 0.000751, Val: 0.001554, Total: 0.000852, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3076: Train: 0.000741, Val: 0.001429, Total: 0.000827, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3077: Train: 0.000697, Val: 0.001491, Total: 0.000796, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3078: Train: 0.000711, Val: 0.001477, Total: 0.000807, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3079: Train: 0.000718, Val: 0.001557, Total: 0.000823, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3080: Train: 0.000688, Val: 0.001588, Total: 0.000801, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3081: Train: 0.000693, Val: 0.001518, Total: 0.000796, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3082: Train: 0.000703, Val: 0.001614, Total: 0.000817, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3083: Train: 0.000765, Val: 0.001556, Total: 0.000864, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3084: Train: 0.000746, Val: 0.001641, Total: 0.000858, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3085: Train: 0.000738, Val: 0.001440, Total: 0.000826, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3086: Train: 0.000711, Val: 0.001551, Total: 0.000816, LR: 1.13e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3087: Train: 0.000755, Val: 0.001548, Total: 0.000855, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3088: Train: 0.000755, Val: 0.001492, Total: 0.000847, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3089: Train: 0.000742, Val: 0.001594, Total: 0.000849, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3090: Train: 0.000709, Val: 0.001513, Total: 0.000810, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3091: Train: 0.000682, Val: 0.001453, Total: 0.000779, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3092: Train: 0.000690, Val: 0.001564, Total: 0.000799, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3093: Train: 0.000710, Val: 0.001496, Total: 0.000808, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3094: Train: 0.000697, Val: 0.001641, Total: 0.000815, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3095: Train: 0.000695, Val: 0.001490, Total: 0.000794, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3096: Train: 0.000712, Val: 0.001443, Total: 0.000804, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3097: Train: 0.000678, Val: 0.001551, Total: 0.000787, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3098: Train: 0.000707, Val: 0.001499, Total: 0.000806, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3099: Train: 0.000706, Val: 0.001508, Total: 0.000806, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3100: Train: 0.000703, Val: 0.001464, Total: 0.000798, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3101: Train: 0.000735, Val: 0.001817, Total: 0.000870, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3102: Train: 0.000778, Val: 0.001791, Total: 0.000905, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3103: Train: 0.000770, Val: 0.002214, Total: 0.000950, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3104: Train: 0.000762, Val: 0.002113, Total: 0.000931, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3105: Train: 0.000729, Val: 0.001970, Total: 0.000884, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3106: Train: 0.000733, Val: 0.001636, Total: 0.000846, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3107: Train: 0.000684, Val: 0.001525, Total: 0.000789, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3108: Train: 0.000696, Val: 0.001575, Total: 0.000806, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3109: Train: 0.000713, Val: 0.001572, Total: 0.000821, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3110: Train: 0.000694, Val: 0.001444, Total: 0.000788, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3111: Train: 0.000687, Val: 0.001554, Total: 0.000795, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3112: Train: 0.000747, Val: 0.001512, Total: 0.000843, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3113: Train: 0.000699, Val: 0.001546, Total: 0.000805, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3114: Train: 0.000706, Val: 0.001596, Total: 0.000817, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3115: Train: 0.000695, Val: 0.001514, Total: 0.000798, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3116: Train: 0.000717, Val: 0.001668, Total: 0.000836, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3117: Train: 0.000737, Val: 0.001577, Total: 0.000842, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3118: Train: 0.000694, Val: 0.001565, Total: 0.000803, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3119: Train: 0.000729, Val: 0.001647, Total: 0.000844, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3120: Train: 0.000730, Val: 0.001539, Total: 0.000831, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3121: Train: 0.000681, Val: 0.001578, Total: 0.000793, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3122: Train: 0.000702, Val: 0.001533, Total: 0.000806, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3123: Train: 0.000724, Val: 0.001636, Total: 0.000838, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3124: Train: 0.000725, Val: 0.001520, Total: 0.000825, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3125: Train: 0.000733, Val: 0.001580, Total: 0.000839, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3126: Train: 0.000703, Val: 0.001531, Total: 0.000807, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3127: Train: 0.000686, Val: 0.001562, Total: 0.000795, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3128: Train: 0.000719, Val: 0.001584, Total: 0.000827, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3129: Train: 0.000728, Val: 0.001580, Total: 0.000834, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3130: Train: 0.000726, Val: 0.001535, Total: 0.000827, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3131: Train: 0.000717, Val: 0.001593, Total: 0.000826, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3132: Train: 0.000711, Val: 0.001508, Total: 0.000811, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3133: Train: 0.000691, Val: 0.001524, Total: 0.000795, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3134: Train: 0.000685, Val: 0.001470, Total: 0.000783, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3135: Train: 0.000688, Val: 0.001647, Total: 0.000808, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3136: Train: 0.000709, Val: 0.001798, Total: 0.000845, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3137: Train: 0.000721, Val: 0.001676, Total: 0.000841, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3138: Train: 0.000698, Val: 0.001618, Total: 0.000813, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3139: Train: 0.000720, Val: 0.001500, Total: 0.000818, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3140: Train: 0.000707, Val: 0.001620, Total: 0.000821, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3141: Train: 0.000708, Val: 0.001492, Total: 0.000806, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3142: Train: 0.000703, Val: 0.001639, Total: 0.000820, LR: 1.12e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3143: Train: 0.000691, Val: 0.001589, Total: 0.000803, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3144: Train: 0.000740, Val: 0.001697, Total: 0.000860, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3145: Train: 0.000766, Val: 0.001485, Total: 0.000856, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3146: Train: 0.000696, Val: 0.001657, Total: 0.000816, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3147: Train: 0.000746, Val: 0.001514, Total: 0.000842, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3148: Train: 0.000673, Val: 0.001639, Total: 0.000794, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3149: Train: 0.000742, Val: 0.001630, Total: 0.000853, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3150: Train: 0.000739, Val: 0.001502, Total: 0.000834, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3151: Train: 0.000713, Val: 0.001728, Total: 0.000840, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3152: Train: 0.000730, Val: 0.001501, Total: 0.000826, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3153: Train: 0.000828, Val: 0.001764, Total: 0.000945, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3154: Train: 0.000827, Val: 0.001567, Total: 0.000920, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3155: Train: 0.000769, Val: 0.001425, Total: 0.000851, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3156: Train: 0.000768, Val: 0.001915, Total: 0.000911, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3157: Train: 0.000815, Val: 0.001366, Total: 0.000884, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3158: Train: 0.000832, Val: 0.001487, Total: 0.000914, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3159: Train: 0.000760, Val: 0.001900, Total: 0.000903, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3160: Train: 0.000752, Val: 0.001616, Total: 0.000860, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3161: Train: 0.000751, Val: 0.001552, Total: 0.000851, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3162: Train: 0.000716, Val: 0.001543, Total: 0.000820, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3163: Train: 0.000716, Val: 0.001458, Total: 0.000809, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3164: Train: 0.000738, Val: 0.001693, Total: 0.000857, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3165: Train: 0.000720, Val: 0.001597, Total: 0.000829, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3166: Train: 0.000730, Val: 0.001459, Total: 0.000821, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3167: Train: 0.000727, Val: 0.001565, Total: 0.000831, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3168: Train: 0.000726, Val: 0.001548, Total: 0.000828, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3169: Train: 0.000727, Val: 0.001547, Total: 0.000829, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3170: Train: 0.000703, Val: 0.001533, Total: 0.000807, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3171: Train: 0.000709, Val: 0.001554, Total: 0.000815, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3172: Train: 0.000713, Val: 0.001570, Total: 0.000820, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3173: Train: 0.000698, Val: 0.001481, Total: 0.000796, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3174: Train: 0.000718, Val: 0.001508, Total: 0.000816, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3175: Train: 0.000689, Val: 0.001518, Total: 0.000792, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3176: Train: 0.000742, Val: 0.001503, Total: 0.000837, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3177: Train: 0.000704, Val: 0.001600, Total: 0.000816, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3178: Train: 0.000685, Val: 0.001594, Total: 0.000799, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3179: Train: 0.000697, Val: 0.001539, Total: 0.000803, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3180: Train: 0.000741, Val: 0.001528, Total: 0.000839, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3181: Train: 0.000702, Val: 0.001573, Total: 0.000811, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3182: Train: 0.000712, Val: 0.001567, Total: 0.000819, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3183: Train: 0.000749, Val: 0.001521, Total: 0.000846, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3184: Train: 0.000684, Val: 0.001543, Total: 0.000791, LR: 1.11e-03\n",
      "          Best: Train: 0.000680, Val: 0.001452, Total: 0.000777 (Epoch 2937)\n",
      "Epoch 3185: Train: 0.000667, Val: 0.001538, Total: 0.000776, LR: 1.11e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3186: Train: 0.000713, Val: 0.001436, Total: 0.000803, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3187: Train: 0.000701, Val: 0.001483, Total: 0.000798, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3188: Train: 0.000688, Val: 0.001523, Total: 0.000793, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3189: Train: 0.000704, Val: 0.001524, Total: 0.000807, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3190: Train: 0.000686, Val: 0.001488, Total: 0.000786, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3191: Train: 0.000708, Val: 0.001542, Total: 0.000812, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3192: Train: 0.000702, Val: 0.001566, Total: 0.000810, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3193: Train: 0.000696, Val: 0.001519, Total: 0.000799, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3194: Train: 0.000722, Val: 0.001501, Total: 0.000819, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3195: Train: 0.000682, Val: 0.001555, Total: 0.000791, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3196: Train: 0.000712, Val: 0.001604, Total: 0.000823, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3197: Train: 0.000718, Val: 0.001525, Total: 0.000818, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3198: Train: 0.000692, Val: 0.001539, Total: 0.000798, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3199: Train: 0.000713, Val: 0.001481, Total: 0.000809, LR: 1.11e-03\n",
      "          Best: Train: 0.000667, Val: 0.001538, Total: 0.000776 (Epoch 3185)\n",
      "Epoch 3200: Train: 0.000661, Val: 0.001551, Total: 0.000772, LR: 1.10e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3201: Train: 0.000748, Val: 0.001543, Total: 0.000847, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3202: Train: 0.000708, Val: 0.001460, Total: 0.000802, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3203: Train: 0.000724, Val: 0.001573, Total: 0.000830, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3204: Train: 0.000743, Val: 0.001486, Total: 0.000836, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3205: Train: 0.000728, Val: 0.001546, Total: 0.000830, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3206: Train: 0.000724, Val: 0.001604, Total: 0.000834, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3207: Train: 0.000718, Val: 0.001645, Total: 0.000834, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3208: Train: 0.000784, Val: 0.001782, Total: 0.000909, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3209: Train: 0.000835, Val: 0.001700, Total: 0.000943, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3210: Train: 0.000752, Val: 0.001766, Total: 0.000879, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3211: Train: 0.000882, Val: 0.001730, Total: 0.000988, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3212: Train: 0.000857, Val: 0.001801, Total: 0.000975, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3213: Train: 0.000785, Val: 0.001751, Total: 0.000906, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3214: Train: 0.000795, Val: 0.001777, Total: 0.000918, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3215: Train: 0.000798, Val: 0.001716, Total: 0.000913, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3216: Train: 0.000945, Val: 0.001925, Total: 0.001067, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3217: Train: 0.000858, Val: 0.001928, Total: 0.000992, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3218: Train: 0.000851, Val: 0.001742, Total: 0.000962, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3219: Train: 0.000836, Val: 0.001560, Total: 0.000927, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3220: Train: 0.000810, Val: 0.001606, Total: 0.000910, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3221: Train: 0.000788, Val: 0.001697, Total: 0.000902, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3222: Train: 0.000743, Val: 0.001722, Total: 0.000866, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3223: Train: 0.000751, Val: 0.001680, Total: 0.000867, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3224: Train: 0.000740, Val: 0.001730, Total: 0.000864, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3225: Train: 0.000756, Val: 0.001669, Total: 0.000870, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3226: Train: 0.000730, Val: 0.001665, Total: 0.000847, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3227: Train: 0.000747, Val: 0.001601, Total: 0.000854, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3228: Train: 0.000700, Val: 0.001622, Total: 0.000815, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3229: Train: 0.000701, Val: 0.001570, Total: 0.000810, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3230: Train: 0.000698, Val: 0.001548, Total: 0.000804, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3231: Train: 0.000735, Val: 0.001601, Total: 0.000843, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3232: Train: 0.000706, Val: 0.001553, Total: 0.000812, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3233: Train: 0.000726, Val: 0.001628, Total: 0.000839, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3234: Train: 0.000719, Val: 0.001544, Total: 0.000822, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3235: Train: 0.000703, Val: 0.001459, Total: 0.000797, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3236: Train: 0.000729, Val: 0.001591, Total: 0.000837, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3237: Train: 0.000698, Val: 0.001635, Total: 0.000815, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3238: Train: 0.000749, Val: 0.001576, Total: 0.000852, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3239: Train: 0.000716, Val: 0.001607, Total: 0.000827, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3240: Train: 0.000709, Val: 0.001590, Total: 0.000819, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3241: Train: 0.000689, Val: 0.001507, Total: 0.000791, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3242: Train: 0.000699, Val: 0.001603, Total: 0.000812, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3243: Train: 0.000673, Val: 0.001515, Total: 0.000778, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3244: Train: 0.000690, Val: 0.001530, Total: 0.000795, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3245: Train: 0.000677, Val: 0.001507, Total: 0.000781, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3246: Train: 0.000704, Val: 0.001457, Total: 0.000798, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3247: Train: 0.000707, Val: 0.001568, Total: 0.000814, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3248: Train: 0.000686, Val: 0.001496, Total: 0.000788, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3249: Train: 0.000699, Val: 0.001518, Total: 0.000801, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3250: Train: 0.000706, Val: 0.001558, Total: 0.000812, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3251: Train: 0.000745, Val: 0.001494, Total: 0.000838, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3252: Train: 0.000694, Val: 0.001596, Total: 0.000807, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3253: Train: 0.000726, Val: 0.001524, Total: 0.000826, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3254: Train: 0.000699, Val: 0.001501, Total: 0.000800, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3255: Train: 0.000714, Val: 0.001603, Total: 0.000825, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3256: Train: 0.000725, Val: 0.001547, Total: 0.000828, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3257: Train: 0.000688, Val: 0.001543, Total: 0.000795, LR: 1.10e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3258: Train: 0.000709, Val: 0.001474, Total: 0.000804, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3259: Train: 0.000694, Val: 0.001525, Total: 0.000798, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3260: Train: 0.000741, Val: 0.001538, Total: 0.000840, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3261: Train: 0.000701, Val: 0.001551, Total: 0.000807, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3262: Train: 0.000705, Val: 0.001480, Total: 0.000802, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3263: Train: 0.000686, Val: 0.001549, Total: 0.000794, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3264: Train: 0.000695, Val: 0.001483, Total: 0.000794, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3265: Train: 0.000689, Val: 0.001489, Total: 0.000789, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3266: Train: 0.000729, Val: 0.001573, Total: 0.000834, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3267: Train: 0.000710, Val: 0.001483, Total: 0.000807, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3268: Train: 0.000733, Val: 0.001518, Total: 0.000831, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3269: Train: 0.000683, Val: 0.001471, Total: 0.000782, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3270: Train: 0.000714, Val: 0.001555, Total: 0.000819, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3271: Train: 0.000693, Val: 0.001501, Total: 0.000794, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3272: Train: 0.000680, Val: 0.001515, Total: 0.000785, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3273: Train: 0.000708, Val: 0.001486, Total: 0.000805, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3274: Train: 0.000699, Val: 0.001551, Total: 0.000805, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3275: Train: 0.000693, Val: 0.001554, Total: 0.000800, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3276: Train: 0.000730, Val: 0.001424, Total: 0.000816, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3277: Train: 0.000721, Val: 0.001652, Total: 0.000837, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3278: Train: 0.000711, Val: 0.001488, Total: 0.000809, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3279: Train: 0.000716, Val: 0.001500, Total: 0.000814, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3280: Train: 0.000713, Val: 0.001554, Total: 0.000818, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3281: Train: 0.000716, Val: 0.001536, Total: 0.000819, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3282: Train: 0.000735, Val: 0.001596, Total: 0.000843, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3283: Train: 0.000693, Val: 0.001577, Total: 0.000803, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3284: Train: 0.000730, Val: 0.001350, Total: 0.000807, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3285: Train: 0.000718, Val: 0.001541, Total: 0.000821, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3286: Train: 0.000737, Val: 0.001522, Total: 0.000835, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3287: Train: 0.000707, Val: 0.001437, Total: 0.000798, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3288: Train: 0.000712, Val: 0.001561, Total: 0.000818, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3289: Train: 0.000707, Val: 0.001437, Total: 0.000798, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3290: Train: 0.000728, Val: 0.001454, Total: 0.000818, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3291: Train: 0.000692, Val: 0.001551, Total: 0.000800, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3292: Train: 0.000726, Val: 0.001507, Total: 0.000823, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3293: Train: 0.000698, Val: 0.001444, Total: 0.000791, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3294: Train: 0.000709, Val: 0.001522, Total: 0.000811, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3295: Train: 0.000717, Val: 0.001479, Total: 0.000812, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3296: Train: 0.000713, Val: 0.001527, Total: 0.000815, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3297: Train: 0.000674, Val: 0.001465, Total: 0.000773, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3298: Train: 0.000687, Val: 0.001492, Total: 0.000788, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3299: Train: 0.000721, Val: 0.001585, Total: 0.000829, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3300: Train: 0.000715, Val: 0.001429, Total: 0.000804, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3301: Train: 0.000715, Val: 0.001626, Total: 0.000829, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3302: Train: 0.000716, Val: 0.001497, Total: 0.000814, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3303: Train: 0.000694, Val: 0.001447, Total: 0.000788, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3304: Train: 0.000677, Val: 0.001600, Total: 0.000792, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3305: Train: 0.000712, Val: 0.001490, Total: 0.000809, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3306: Train: 0.000725, Val: 0.001512, Total: 0.000823, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3307: Train: 0.000714, Val: 0.001643, Total: 0.000830, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3308: Train: 0.000720, Val: 0.001533, Total: 0.000821, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3309: Train: 0.000693, Val: 0.001581, Total: 0.000804, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3310: Train: 0.000722, Val: 0.001547, Total: 0.000825, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3311: Train: 0.000716, Val: 0.001498, Total: 0.000814, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3312: Train: 0.000689, Val: 0.001453, Total: 0.000784, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3313: Train: 0.000683, Val: 0.001470, Total: 0.000782, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3314: Train: 0.000704, Val: 0.001463, Total: 0.000799, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3315: Train: 0.000740, Val: 0.001549, Total: 0.000841, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3316: Train: 0.000734, Val: 0.001523, Total: 0.000832, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3317: Train: 0.000701, Val: 0.001403, Total: 0.000788, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3318: Train: 0.000710, Val: 0.001524, Total: 0.000812, LR: 1.09e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3319: Train: 0.000696, Val: 0.001452, Total: 0.000790, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3320: Train: 0.000719, Val: 0.001501, Total: 0.000816, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3321: Train: 0.000707, Val: 0.001561, Total: 0.000814, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3322: Train: 0.000681, Val: 0.001475, Total: 0.000780, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3323: Train: 0.000699, Val: 0.001429, Total: 0.000791, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3324: Train: 0.000706, Val: 0.001457, Total: 0.000800, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3325: Train: 0.000709, Val: 0.001463, Total: 0.000803, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3326: Train: 0.000731, Val: 0.001502, Total: 0.000828, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3327: Train: 0.000716, Val: 0.001418, Total: 0.000803, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3328: Train: 0.000728, Val: 0.001430, Total: 0.000816, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3329: Train: 0.000693, Val: 0.001646, Total: 0.000812, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3330: Train: 0.000672, Val: 0.001499, Total: 0.000776, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3331: Train: 0.000717, Val: 0.001455, Total: 0.000809, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3332: Train: 0.000713, Val: 0.001537, Total: 0.000816, LR: 1.08e-03\n",
      "          Best: Train: 0.000661, Val: 0.001551, Total: 0.000772 (Epoch 3200)\n",
      "Epoch 3333: Train: 0.000667, Val: 0.001398, Total: 0.000759, LR: 1.08e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3334: Train: 0.000722, Val: 0.001539, Total: 0.000824, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3335: Train: 0.000685, Val: 0.001522, Total: 0.000790, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3336: Train: 0.000680, Val: 0.001479, Total: 0.000780, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3337: Train: 0.000675, Val: 0.001511, Total: 0.000780, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3338: Train: 0.000695, Val: 0.001440, Total: 0.000788, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3339: Train: 0.000676, Val: 0.001544, Total: 0.000785, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3340: Train: 0.000713, Val: 0.001570, Total: 0.000820, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3341: Train: 0.000758, Val: 0.001639, Total: 0.000868, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3342: Train: 0.000702, Val: 0.001472, Total: 0.000798, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3343: Train: 0.000688, Val: 0.001503, Total: 0.000790, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3344: Train: 0.000693, Val: 0.001578, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3345: Train: 0.000738, Val: 0.001582, Total: 0.000844, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3346: Train: 0.000701, Val: 0.001472, Total: 0.000797, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3347: Train: 0.000698, Val: 0.001512, Total: 0.000800, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3348: Train: 0.000676, Val: 0.001610, Total: 0.000793, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3349: Train: 0.000693, Val: 0.001511, Total: 0.000795, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3350: Train: 0.000709, Val: 0.001476, Total: 0.000805, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3351: Train: 0.000686, Val: 0.001627, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3352: Train: 0.000687, Val: 0.001618, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3353: Train: 0.000694, Val: 0.001493, Total: 0.000794, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3354: Train: 0.000713, Val: 0.001526, Total: 0.000814, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3355: Train: 0.000692, Val: 0.001419, Total: 0.000783, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3356: Train: 0.000706, Val: 0.001502, Total: 0.000805, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3357: Train: 0.000695, Val: 0.001499, Total: 0.000795, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3358: Train: 0.000708, Val: 0.001475, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3359: Train: 0.000683, Val: 0.001631, Total: 0.000801, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3360: Train: 0.000711, Val: 0.001652, Total: 0.000829, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3361: Train: 0.000700, Val: 0.001440, Total: 0.000793, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3362: Train: 0.000719, Val: 0.001651, Total: 0.000836, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3363: Train: 0.000700, Val: 0.001533, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3364: Train: 0.000701, Val: 0.001499, Total: 0.000801, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3365: Train: 0.000726, Val: 0.001471, Total: 0.000819, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3366: Train: 0.000697, Val: 0.001552, Total: 0.000804, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3367: Train: 0.000668, Val: 0.001481, Total: 0.000770, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3368: Train: 0.000701, Val: 0.001461, Total: 0.000796, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3369: Train: 0.000682, Val: 0.001517, Total: 0.000786, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3370: Train: 0.000742, Val: 0.001519, Total: 0.000839, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3371: Train: 0.000714, Val: 0.001471, Total: 0.000809, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3372: Train: 0.000699, Val: 0.001468, Total: 0.000795, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3373: Train: 0.000681, Val: 0.001511, Total: 0.000785, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3374: Train: 0.000692, Val: 0.001449, Total: 0.000787, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3375: Train: 0.000724, Val: 0.001466, Total: 0.000817, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3376: Train: 0.000682, Val: 0.001525, Total: 0.000787, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3377: Train: 0.000697, Val: 0.001523, Total: 0.000800, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3378: Train: 0.000708, Val: 0.001433, Total: 0.000799, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3379: Train: 0.000699, Val: 0.001518, Total: 0.000802, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3380: Train: 0.000702, Val: 0.001526, Total: 0.000805, LR: 1.08e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3381: Train: 0.000690, Val: 0.001406, Total: 0.000779, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3382: Train: 0.000675, Val: 0.001482, Total: 0.000776, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3383: Train: 0.000715, Val: 0.001513, Total: 0.000815, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3384: Train: 0.000680, Val: 0.001435, Total: 0.000774, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3385: Train: 0.000716, Val: 0.001595, Total: 0.000826, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3386: Train: 0.000690, Val: 0.001494, Total: 0.000791, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3387: Train: 0.000692, Val: 0.001496, Total: 0.000792, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3388: Train: 0.000689, Val: 0.001559, Total: 0.000798, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3389: Train: 0.000733, Val: 0.001514, Total: 0.000830, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3390: Train: 0.000687, Val: 0.001584, Total: 0.000799, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3391: Train: 0.000714, Val: 0.001506, Total: 0.000813, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3392: Train: 0.000691, Val: 0.001426, Total: 0.000783, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3393: Train: 0.000691, Val: 0.001544, Total: 0.000798, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3394: Train: 0.000707, Val: 0.001569, Total: 0.000815, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3395: Train: 0.000673, Val: 0.001510, Total: 0.000778, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3396: Train: 0.000722, Val: 0.001511, Total: 0.000821, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3397: Train: 0.000701, Val: 0.001472, Total: 0.000797, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3398: Train: 0.000754, Val: 0.001560, Total: 0.000855, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3399: Train: 0.000790, Val: 0.001550, Total: 0.000885, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3400: Train: 0.000758, Val: 0.001423, Total: 0.000841, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3401: Train: 0.000721, Val: 0.001644, Total: 0.000836, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3402: Train: 0.000727, Val: 0.001441, Total: 0.000816, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3403: Train: 0.000711, Val: 0.001608, Total: 0.000823, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3404: Train: 0.000694, Val: 0.001511, Total: 0.000796, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3405: Train: 0.000751, Val: 0.001602, Total: 0.000857, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3406: Train: 0.000714, Val: 0.001666, Total: 0.000833, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3407: Train: 0.000762, Val: 0.001493, Total: 0.000853, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3408: Train: 0.000740, Val: 0.001572, Total: 0.000844, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3409: Train: 0.000698, Val: 0.001630, Total: 0.000815, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3410: Train: 0.000733, Val: 0.001401, Total: 0.000816, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3411: Train: 0.000776, Val: 0.001670, Total: 0.000888, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3412: Train: 0.000745, Val: 0.001786, Total: 0.000875, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3413: Train: 0.000798, Val: 0.001554, Total: 0.000892, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3414: Train: 0.000854, Val: 0.001722, Total: 0.000962, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3415: Train: 0.000758, Val: 0.001731, Total: 0.000880, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3416: Train: 0.000798, Val: 0.001659, Total: 0.000906, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3417: Train: 0.000762, Val: 0.001557, Total: 0.000862, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3418: Train: 0.000753, Val: 0.001661, Total: 0.000867, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3419: Train: 0.000763, Val: 0.001682, Total: 0.000878, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3420: Train: 0.000800, Val: 0.001725, Total: 0.000916, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3421: Train: 0.000804, Val: 0.001633, Total: 0.000908, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3422: Train: 0.000780, Val: 0.001768, Total: 0.000903, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3423: Train: 0.000832, Val: 0.001931, Total: 0.000969, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3424: Train: 0.000938, Val: 0.001775, Total: 0.001043, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3425: Train: 0.000853, Val: 0.001943, Total: 0.000989, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3426: Train: 0.000800, Val: 0.001657, Total: 0.000907, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3427: Train: 0.000777, Val: 0.001892, Total: 0.000916, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3428: Train: 0.000750, Val: 0.001704, Total: 0.000870, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3429: Train: 0.000742, Val: 0.001759, Total: 0.000869, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3430: Train: 0.000704, Val: 0.001725, Total: 0.000832, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3431: Train: 0.000743, Val: 0.001594, Total: 0.000850, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3432: Train: 0.000733, Val: 0.001668, Total: 0.000850, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3433: Train: 0.000720, Val: 0.001664, Total: 0.000838, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3434: Train: 0.000702, Val: 0.001685, Total: 0.000825, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3435: Train: 0.000721, Val: 0.001645, Total: 0.000836, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3436: Train: 0.000744, Val: 0.001707, Total: 0.000864, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3437: Train: 0.000737, Val: 0.001530, Total: 0.000836, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3438: Train: 0.000718, Val: 0.001248, Total: 0.000785, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3439: Train: 0.000767, Val: 0.001299, Total: 0.000833, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3440: Train: 0.000720, Val: 0.001224, Total: 0.000783, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3441: Train: 0.000754, Val: 0.001338, Total: 0.000827, LR: 1.07e-03\n",
      "          Best: Train: 0.000667, Val: 0.001398, Total: 0.000759 (Epoch 3333)\n",
      "Epoch 3442: Train: 0.000665, Val: 0.001366, Total: 0.000752, LR: 1.07e-03 ★ NEW BEST\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3443: Train: 0.000718, Val: 0.001627, Total: 0.000831, LR: 1.07e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3444: Train: 0.000728, Val: 0.001665, Total: 0.000845, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3445: Train: 0.000703, Val: 0.001619, Total: 0.000817, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3446: Train: 0.000708, Val: 0.001570, Total: 0.000815, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3447: Train: 0.000723, Val: 0.001530, Total: 0.000824, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3448: Train: 0.000686, Val: 0.001599, Total: 0.000800, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3449: Train: 0.000714, Val: 0.001597, Total: 0.000825, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3450: Train: 0.000701, Val: 0.001538, Total: 0.000806, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3451: Train: 0.000700, Val: 0.001568, Total: 0.000808, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3452: Train: 0.000699, Val: 0.001592, Total: 0.000810, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3453: Train: 0.000707, Val: 0.001589, Total: 0.000818, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3454: Train: 0.000708, Val: 0.001520, Total: 0.000810, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3455: Train: 0.000727, Val: 0.001585, Total: 0.000834, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3456: Train: 0.000711, Val: 0.001636, Total: 0.000827, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3457: Train: 0.000698, Val: 0.001614, Total: 0.000813, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3458: Train: 0.000713, Val: 0.001623, Total: 0.000827, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3459: Train: 0.000693, Val: 0.001639, Total: 0.000811, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3460: Train: 0.000703, Val: 0.001479, Total: 0.000800, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3461: Train: 0.000719, Val: 0.001682, Total: 0.000839, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3462: Train: 0.000711, Val: 0.001648, Total: 0.000828, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3463: Train: 0.000675, Val: 0.001601, Total: 0.000791, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3464: Train: 0.000691, Val: 0.001650, Total: 0.000811, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3465: Train: 0.000693, Val: 0.001650, Total: 0.000812, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3466: Train: 0.000677, Val: 0.001601, Total: 0.000792, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3467: Train: 0.000705, Val: 0.001528, Total: 0.000808, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3468: Train: 0.000680, Val: 0.001616, Total: 0.000797, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3469: Train: 0.000696, Val: 0.001563, Total: 0.000804, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3470: Train: 0.000699, Val: 0.001542, Total: 0.000804, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3471: Train: 0.000726, Val: 0.001788, Total: 0.000859, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3472: Train: 0.000765, Val: 0.001585, Total: 0.000868, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3473: Train: 0.000751, Val: 0.001727, Total: 0.000873, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3474: Train: 0.000740, Val: 0.001852, Total: 0.000879, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3475: Train: 0.000759, Val: 0.001793, Total: 0.000889, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3476: Train: 0.000720, Val: 0.001639, Total: 0.000835, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3477: Train: 0.000716, Val: 0.001593, Total: 0.000826, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3478: Train: 0.000704, Val: 0.001666, Total: 0.000825, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3479: Train: 0.000708, Val: 0.001534, Total: 0.000811, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3480: Train: 0.000714, Val: 0.001671, Total: 0.000833, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3481: Train: 0.000733, Val: 0.001530, Total: 0.000833, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3482: Train: 0.000735, Val: 0.001479, Total: 0.000828, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3483: Train: 0.000671, Val: 0.001576, Total: 0.000784, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3484: Train: 0.000733, Val: 0.001514, Total: 0.000830, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3485: Train: 0.000736, Val: 0.001489, Total: 0.000830, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3486: Train: 0.000692, Val: 0.001550, Total: 0.000799, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3487: Train: 0.000676, Val: 0.001606, Total: 0.000792, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3488: Train: 0.000711, Val: 0.001606, Total: 0.000823, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3489: Train: 0.000741, Val: 0.001645, Total: 0.000854, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3490: Train: 0.000697, Val: 0.001638, Total: 0.000815, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3491: Train: 0.000704, Val: 0.001548, Total: 0.000810, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3492: Train: 0.000708, Val: 0.001572, Total: 0.000816, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3493: Train: 0.000663, Val: 0.001598, Total: 0.000780, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3494: Train: 0.000721, Val: 0.001642, Total: 0.000836, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3495: Train: 0.000685, Val: 0.001546, Total: 0.000793, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3496: Train: 0.000678, Val: 0.001601, Total: 0.000793, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3497: Train: 0.000688, Val: 0.001508, Total: 0.000790, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3498: Train: 0.000693, Val: 0.001547, Total: 0.000800, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3499: Train: 0.000754, Val: 0.001633, Total: 0.000864, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3500: Train: 0.000719, Val: 0.001514, Total: 0.000818, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3501: Train: 0.000718, Val: 0.001608, Total: 0.000829, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3502: Train: 0.000701, Val: 0.001616, Total: 0.000815, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3503: Train: 0.000693, Val: 0.001622, Total: 0.000809, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3504: Train: 0.000703, Val: 0.001626, Total: 0.000818, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3505: Train: 0.000714, Val: 0.001606, Total: 0.000825, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3506: Train: 0.000746, Val: 0.001557, Total: 0.000848, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3507: Train: 0.000719, Val: 0.001517, Total: 0.000819, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3508: Train: 0.000698, Val: 0.001683, Total: 0.000821, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3509: Train: 0.000719, Val: 0.001611, Total: 0.000831, LR: 1.06e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3510: Train: 0.000685, Val: 0.001618, Total: 0.000802, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3511: Train: 0.000689, Val: 0.001544, Total: 0.000796, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3512: Train: 0.000700, Val: 0.001663, Total: 0.000820, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3513: Train: 0.000703, Val: 0.001526, Total: 0.000806, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3514: Train: 0.000769, Val: 0.001652, Total: 0.000879, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3515: Train: 0.000761, Val: 0.001557, Total: 0.000861, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3516: Train: 0.000702, Val: 0.001541, Total: 0.000807, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3517: Train: 0.000695, Val: 0.001561, Total: 0.000803, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3518: Train: 0.000695, Val: 0.001586, Total: 0.000807, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3519: Train: 0.000708, Val: 0.001525, Total: 0.000810, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3520: Train: 0.000691, Val: 0.001605, Total: 0.000806, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3521: Train: 0.000709, Val: 0.001545, Total: 0.000813, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3522: Train: 0.000681, Val: 0.001557, Total: 0.000790, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3523: Train: 0.000663, Val: 0.001544, Total: 0.000773, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3524: Train: 0.000708, Val: 0.001488, Total: 0.000806, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3525: Train: 0.000707, Val: 0.001673, Total: 0.000828, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3526: Train: 0.000669, Val: 0.001619, Total: 0.000787, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3527: Train: 0.000707, Val: 0.001610, Total: 0.000820, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3528: Train: 0.000850, Val: 0.001715, Total: 0.000958, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3529: Train: 0.000801, Val: 0.001778, Total: 0.000923, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3530: Train: 0.000711, Val: 0.001572, Total: 0.000819, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3531: Train: 0.000803, Val: 0.001725, Total: 0.000918, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3532: Train: 0.000817, Val: 0.001778, Total: 0.000937, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3533: Train: 0.000822, Val: 0.001954, Total: 0.000964, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3534: Train: 0.000877, Val: 0.002162, Total: 0.001037, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3535: Train: 0.000959, Val: 0.002747, Total: 0.001183, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3536: Train: 0.000870, Val: 0.002304, Total: 0.001049, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3537: Train: 0.000869, Val: 0.002254, Total: 0.001042, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3538: Train: 0.000832, Val: 0.002183, Total: 0.001001, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3539: Train: 0.000775, Val: 0.002146, Total: 0.000946, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3540: Train: 0.000728, Val: 0.002314, Total: 0.000926, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3541: Train: 0.000770, Val: 0.002166, Total: 0.000945, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3542: Train: 0.000748, Val: 0.002102, Total: 0.000918, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3543: Train: 0.000730, Val: 0.001969, Total: 0.000884, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3544: Train: 0.000720, Val: 0.001936, Total: 0.000872, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3545: Train: 0.000743, Val: 0.001879, Total: 0.000885, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3546: Train: 0.000742, Val: 0.001992, Total: 0.000898, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3547: Train: 0.000722, Val: 0.001974, Total: 0.000879, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3548: Train: 0.000738, Val: 0.001836, Total: 0.000875, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3549: Train: 0.000689, Val: 0.001861, Total: 0.000836, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3550: Train: 0.000790, Val: 0.001618, Total: 0.000894, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3551: Train: 0.000689, Val: 0.001554, Total: 0.000798, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3552: Train: 0.000693, Val: 0.001623, Total: 0.000809, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3553: Train: 0.000758, Val: 0.001603, Total: 0.000864, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3554: Train: 0.000705, Val: 0.001587, Total: 0.000815, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3555: Train: 0.000733, Val: 0.002065, Total: 0.000899, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3556: Train: 0.000735, Val: 0.002026, Total: 0.000896, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3557: Train: 0.000738, Val: 0.001980, Total: 0.000893, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3558: Train: 0.000734, Val: 0.001976, Total: 0.000889, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3559: Train: 0.000727, Val: 0.001855, Total: 0.000868, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3560: Train: 0.000739, Val: 0.001830, Total: 0.000875, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3561: Train: 0.000764, Val: 0.001942, Total: 0.000911, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3562: Train: 0.000720, Val: 0.001899, Total: 0.000868, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3563: Train: 0.000706, Val: 0.001778, Total: 0.000840, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3564: Train: 0.000683, Val: 0.001809, Total: 0.000824, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3565: Train: 0.000745, Val: 0.001722, Total: 0.000867, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3566: Train: 0.000712, Val: 0.001771, Total: 0.000844, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3567: Train: 0.000687, Val: 0.001680, Total: 0.000811, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3568: Train: 0.000731, Val: 0.001606, Total: 0.000840, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3569: Train: 0.000693, Val: 0.001631, Total: 0.000810, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3570: Train: 0.000688, Val: 0.001597, Total: 0.000802, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3571: Train: 0.000703, Val: 0.001541, Total: 0.000808, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3572: Train: 0.000739, Val: 0.001584, Total: 0.000844, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3573: Train: 0.000721, Val: 0.001581, Total: 0.000829, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3574: Train: 0.000730, Val: 0.001564, Total: 0.000834, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3575: Train: 0.000696, Val: 0.001641, Total: 0.000814, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3576: Train: 0.000705, Val: 0.001529, Total: 0.000808, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3577: Train: 0.000745, Val: 0.001609, Total: 0.000853, LR: 1.05e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3578: Train: 0.000743, Val: 0.001633, Total: 0.000854, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3579: Train: 0.000714, Val: 0.001536, Total: 0.000817, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3580: Train: 0.000686, Val: 0.001661, Total: 0.000808, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3581: Train: 0.000690, Val: 0.001552, Total: 0.000798, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3582: Train: 0.000715, Val: 0.001522, Total: 0.000816, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3583: Train: 0.000715, Val: 0.001579, Total: 0.000823, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3584: Train: 0.000689, Val: 0.001548, Total: 0.000796, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3585: Train: 0.000662, Val: 0.001574, Total: 0.000776, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3586: Train: 0.000726, Val: 0.001504, Total: 0.000823, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3587: Train: 0.000718, Val: 0.001540, Total: 0.000821, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3588: Train: 0.000704, Val: 0.001560, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3589: Train: 0.000691, Val: 0.001510, Total: 0.000793, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3590: Train: 0.000697, Val: 0.001505, Total: 0.000798, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3591: Train: 0.000702, Val: 0.001520, Total: 0.000804, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3592: Train: 0.000712, Val: 0.001560, Total: 0.000818, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3593: Train: 0.000703, Val: 0.001565, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3594: Train: 0.000684, Val: 0.001555, Total: 0.000792, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3595: Train: 0.000691, Val: 0.001474, Total: 0.000789, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3596: Train: 0.000702, Val: 0.001535, Total: 0.000806, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3597: Train: 0.000750, Val: 0.001574, Total: 0.000853, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3598: Train: 0.000711, Val: 0.001562, Total: 0.000817, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3599: Train: 0.000691, Val: 0.001659, Total: 0.000812, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3600: Train: 0.000706, Val: 0.001558, Total: 0.000812, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3601: Train: 0.000694, Val: 0.001549, Total: 0.000801, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3602: Train: 0.000694, Val: 0.001528, Total: 0.000798, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3603: Train: 0.000697, Val: 0.001478, Total: 0.000795, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3604: Train: 0.000701, Val: 0.001579, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3605: Train: 0.000697, Val: 0.001597, Total: 0.000809, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3606: Train: 0.000734, Val: 0.001520, Total: 0.000832, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3607: Train: 0.000700, Val: 0.001561, Total: 0.000808, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3608: Train: 0.000700, Val: 0.001533, Total: 0.000804, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3609: Train: 0.000679, Val: 0.001517, Total: 0.000784, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3610: Train: 0.000661, Val: 0.001595, Total: 0.000778, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3611: Train: 0.000694, Val: 0.001551, Total: 0.000801, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3612: Train: 0.000691, Val: 0.001532, Total: 0.000796, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3613: Train: 0.000697, Val: 0.001540, Total: 0.000802, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3614: Train: 0.000691, Val: 0.001514, Total: 0.000794, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3615: Train: 0.000684, Val: 0.001592, Total: 0.000798, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3616: Train: 0.000752, Val: 0.001647, Total: 0.000864, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3617: Train: 0.000701, Val: 0.001509, Total: 0.000802, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3618: Train: 0.000707, Val: 0.001567, Total: 0.000815, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3619: Train: 0.000702, Val: 0.001599, Total: 0.000814, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3620: Train: 0.000706, Val: 0.001574, Total: 0.000815, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3621: Train: 0.000713, Val: 0.001483, Total: 0.000809, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3622: Train: 0.000664, Val: 0.001512, Total: 0.000770, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3623: Train: 0.000699, Val: 0.001538, Total: 0.000804, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3624: Train: 0.000724, Val: 0.001625, Total: 0.000837, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3625: Train: 0.000723, Val: 0.001528, Total: 0.000824, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3626: Train: 0.000715, Val: 0.001592, Total: 0.000825, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3627: Train: 0.000696, Val: 0.001622, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3628: Train: 0.000728, Val: 0.001521, Total: 0.000827, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3629: Train: 0.000701, Val: 0.001666, Total: 0.000822, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3630: Train: 0.000703, Val: 0.001528, Total: 0.000806, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3631: Train: 0.000694, Val: 0.001507, Total: 0.000796, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3632: Train: 0.000722, Val: 0.001516, Total: 0.000821, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3633: Train: 0.000701, Val: 0.001620, Total: 0.000816, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3634: Train: 0.000708, Val: 0.001508, Total: 0.000808, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3635: Train: 0.000741, Val: 0.001562, Total: 0.000844, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3636: Train: 0.000744, Val: 0.001509, Total: 0.000840, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3637: Train: 0.000711, Val: 0.001554, Total: 0.000816, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3638: Train: 0.000690, Val: 0.001606, Total: 0.000805, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3639: Train: 0.000703, Val: 0.001466, Total: 0.000798, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3640: Train: 0.000681, Val: 0.001511, Total: 0.000785, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3641: Train: 0.000677, Val: 0.001534, Total: 0.000784, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3642: Train: 0.000704, Val: 0.001561, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3643: Train: 0.000694, Val: 0.001630, Total: 0.000811, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3644: Train: 0.000720, Val: 0.001441, Total: 0.000810, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3645: Train: 0.000706, Val: 0.001554, Total: 0.000812, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3646: Train: 0.000722, Val: 0.001583, Total: 0.000830, LR: 1.04e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3647: Train: 0.000708, Val: 0.001553, Total: 0.000813, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3648: Train: 0.000671, Val: 0.001523, Total: 0.000778, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3649: Train: 0.000676, Val: 0.001587, Total: 0.000789, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3650: Train: 0.000700, Val: 0.001588, Total: 0.000811, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3651: Train: 0.000731, Val: 0.001536, Total: 0.000831, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3652: Train: 0.000680, Val: 0.001565, Total: 0.000791, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3653: Train: 0.000695, Val: 0.001581, Total: 0.000806, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3654: Train: 0.000675, Val: 0.001597, Total: 0.000790, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3655: Train: 0.000678, Val: 0.001621, Total: 0.000796, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3656: Train: 0.000704, Val: 0.001596, Total: 0.000816, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3657: Train: 0.000677, Val: 0.001558, Total: 0.000788, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3658: Train: 0.000710, Val: 0.001586, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3659: Train: 0.000692, Val: 0.001541, Total: 0.000798, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3660: Train: 0.000691, Val: 0.001584, Total: 0.000803, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3661: Train: 0.000730, Val: 0.001710, Total: 0.000853, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3662: Train: 0.000709, Val: 0.001594, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3663: Train: 0.000676, Val: 0.001555, Total: 0.000786, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3664: Train: 0.000711, Val: 0.001676, Total: 0.000831, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3665: Train: 0.000689, Val: 0.001616, Total: 0.000805, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3666: Train: 0.000710, Val: 0.001583, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3667: Train: 0.000676, Val: 0.001572, Total: 0.000788, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3668: Train: 0.000688, Val: 0.001625, Total: 0.000805, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3669: Train: 0.000689, Val: 0.001598, Total: 0.000803, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3670: Train: 0.000724, Val: 0.001520, Total: 0.000823, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3671: Train: 0.000675, Val: 0.001505, Total: 0.000779, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3672: Train: 0.000717, Val: 0.001586, Total: 0.000825, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3673: Train: 0.000707, Val: 0.001531, Total: 0.000810, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3674: Train: 0.000701, Val: 0.001675, Total: 0.000823, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3675: Train: 0.000733, Val: 0.001548, Total: 0.000835, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3676: Train: 0.000739, Val: 0.001583, Total: 0.000845, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3677: Train: 0.000760, Val: 0.001655, Total: 0.000872, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3678: Train: 0.000942, Val: 0.001931, Total: 0.001066, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3679: Train: 0.000877, Val: 0.001563, Total: 0.000963, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3680: Train: 0.000895, Val: 0.001741, Total: 0.001001, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3681: Train: 0.000837, Val: 0.001779, Total: 0.000955, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3682: Train: 0.000872, Val: 0.001845, Total: 0.000994, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3683: Train: 0.000836, Val: 0.001971, Total: 0.000978, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3684: Train: 0.000826, Val: 0.001670, Total: 0.000931, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3685: Train: 0.000805, Val: 0.001637, Total: 0.000909, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3686: Train: 0.000816, Val: 0.001531, Total: 0.000905, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3687: Train: 0.000750, Val: 0.001664, Total: 0.000864, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3688: Train: 0.000723, Val: 0.001701, Total: 0.000845, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3689: Train: 0.000752, Val: 0.001649, Total: 0.000864, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3690: Train: 0.000701, Val: 0.001635, Total: 0.000818, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3691: Train: 0.000729, Val: 0.001574, Total: 0.000834, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3692: Train: 0.000728, Val: 0.001613, Total: 0.000839, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3693: Train: 0.000699, Val: 0.001528, Total: 0.000803, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3694: Train: 0.000736, Val: 0.001682, Total: 0.000854, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3695: Train: 0.000705, Val: 0.001537, Total: 0.000809, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3696: Train: 0.000703, Val: 0.001551, Total: 0.000809, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3697: Train: 0.000708, Val: 0.001545, Total: 0.000812, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3698: Train: 0.000718, Val: 0.001398, Total: 0.000803, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3699: Train: 0.000698, Val: 0.001578, Total: 0.000808, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3700: Train: 0.000740, Val: 0.001671, Total: 0.000857, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3701: Train: 0.000691, Val: 0.001716, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3702: Train: 0.000704, Val: 0.001604, Total: 0.000817, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3703: Train: 0.000702, Val: 0.001625, Total: 0.000818, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3704: Train: 0.000688, Val: 0.001643, Total: 0.000807, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3705: Train: 0.000724, Val: 0.001544, Total: 0.000827, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3706: Train: 0.000685, Val: 0.001548, Total: 0.000793, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3707: Train: 0.000701, Val: 0.001507, Total: 0.000802, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3708: Train: 0.000717, Val: 0.001605, Total: 0.000828, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3709: Train: 0.000721, Val: 0.001542, Total: 0.000823, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3710: Train: 0.000703, Val: 0.001529, Total: 0.000806, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3711: Train: 0.000722, Val: 0.001559, Total: 0.000827, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3712: Train: 0.000724, Val: 0.001490, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3713: Train: 0.000721, Val: 0.001593, Total: 0.000830, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3714: Train: 0.000720, Val: 0.001584, Total: 0.000828, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3715: Train: 0.000722, Val: 0.001495, Total: 0.000819, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3716: Train: 0.000694, Val: 0.001487, Total: 0.000793, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3717: Train: 0.000692, Val: 0.001542, Total: 0.000799, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3718: Train: 0.000679, Val: 0.001507, Total: 0.000782, LR: 1.03e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3719: Train: 0.000697, Val: 0.001532, Total: 0.000801, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3720: Train: 0.000706, Val: 0.001541, Total: 0.000810, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3721: Train: 0.000676, Val: 0.001535, Total: 0.000783, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3722: Train: 0.000703, Val: 0.001592, Total: 0.000814, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3723: Train: 0.000698, Val: 0.001472, Total: 0.000795, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3724: Train: 0.000684, Val: 0.001540, Total: 0.000791, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3725: Train: 0.000704, Val: 0.001533, Total: 0.000808, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3726: Train: 0.000709, Val: 0.001489, Total: 0.000807, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3727: Train: 0.000694, Val: 0.001575, Total: 0.000804, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3728: Train: 0.000711, Val: 0.001475, Total: 0.000806, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3729: Train: 0.000678, Val: 0.001511, Total: 0.000782, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3730: Train: 0.000671, Val: 0.001541, Total: 0.000780, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3731: Train: 0.000687, Val: 0.001512, Total: 0.000790, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3732: Train: 0.000674, Val: 0.001550, Total: 0.000784, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3733: Train: 0.000736, Val: 0.001498, Total: 0.000831, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3734: Train: 0.000677, Val: 0.001543, Total: 0.000785, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3735: Train: 0.000746, Val: 0.001556, Total: 0.000848, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3736: Train: 0.000732, Val: 0.001535, Total: 0.000833, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3737: Train: 0.000672, Val: 0.001453, Total: 0.000769, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3738: Train: 0.000682, Val: 0.001551, Total: 0.000791, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3739: Train: 0.000706, Val: 0.001511, Total: 0.000806, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3740: Train: 0.000682, Val: 0.001432, Total: 0.000776, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3741: Train: 0.000672, Val: 0.001505, Total: 0.000776, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3742: Train: 0.000683, Val: 0.001467, Total: 0.000781, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3743: Train: 0.000681, Val: 0.001534, Total: 0.000788, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3744: Train: 0.000689, Val: 0.001543, Total: 0.000795, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3745: Train: 0.000699, Val: 0.001477, Total: 0.000796, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3746: Train: 0.000738, Val: 0.001488, Total: 0.000832, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3747: Train: 0.000671, Val: 0.001471, Total: 0.000771, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3748: Train: 0.000697, Val: 0.001505, Total: 0.000798, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3749: Train: 0.000700, Val: 0.001604, Total: 0.000813, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3750: Train: 0.000738, Val: 0.001525, Total: 0.000837, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3751: Train: 0.000721, Val: 0.001595, Total: 0.000830, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3752: Train: 0.000702, Val: 0.001518, Total: 0.000804, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3753: Train: 0.000673, Val: 0.001488, Total: 0.000775, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3754: Train: 0.000714, Val: 0.001619, Total: 0.000827, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3755: Train: 0.000672, Val: 0.001514, Total: 0.000778, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3756: Train: 0.000735, Val: 0.001462, Total: 0.000826, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3757: Train: 0.000732, Val: 0.001587, Total: 0.000839, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3758: Train: 0.000673, Val: 0.001460, Total: 0.000772, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3759: Train: 0.000697, Val: 0.001445, Total: 0.000790, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3760: Train: 0.000691, Val: 0.001517, Total: 0.000794, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3761: Train: 0.000687, Val: 0.001494, Total: 0.000788, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3762: Train: 0.000665, Val: 0.001488, Total: 0.000768, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3763: Train: 0.000711, Val: 0.001579, Total: 0.000820, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3764: Train: 0.000700, Val: 0.001495, Total: 0.000799, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3765: Train: 0.000699, Val: 0.001458, Total: 0.000794, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3766: Train: 0.000705, Val: 0.001566, Total: 0.000813, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3767: Train: 0.000698, Val: 0.001538, Total: 0.000803, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3768: Train: 0.000710, Val: 0.001463, Total: 0.000804, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3769: Train: 0.000677, Val: 0.001563, Total: 0.000788, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3770: Train: 0.000699, Val: 0.001525, Total: 0.000803, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3771: Train: 0.000687, Val: 0.001565, Total: 0.000797, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3772: Train: 0.000672, Val: 0.001518, Total: 0.000778, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3773: Train: 0.000722, Val: 0.001515, Total: 0.000821, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3774: Train: 0.000701, Val: 0.001496, Total: 0.000801, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3775: Train: 0.000691, Val: 0.001510, Total: 0.000793, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3776: Train: 0.000679, Val: 0.001564, Total: 0.000790, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3777: Train: 0.000683, Val: 0.001497, Total: 0.000785, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3778: Train: 0.000673, Val: 0.001498, Total: 0.000776, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3779: Train: 0.000693, Val: 0.001543, Total: 0.000799, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3780: Train: 0.000692, Val: 0.001479, Total: 0.000790, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3781: Train: 0.000719, Val: 0.001470, Total: 0.000813, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3782: Train: 0.000697, Val: 0.001555, Total: 0.000804, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3783: Train: 0.000709, Val: 0.001489, Total: 0.000806, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3784: Train: 0.000674, Val: 0.001537, Total: 0.000782, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3785: Train: 0.000665, Val: 0.001473, Total: 0.000766, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3786: Train: 0.000675, Val: 0.001495, Total: 0.000777, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3787: Train: 0.000669, Val: 0.001506, Total: 0.000774, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3788: Train: 0.000679, Val: 0.001479, Total: 0.000779, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3789: Train: 0.000676, Val: 0.001492, Total: 0.000778, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3790: Train: 0.000699, Val: 0.001504, Total: 0.000799, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3791: Train: 0.000685, Val: 0.001488, Total: 0.000785, LR: 1.02e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3792: Train: 0.000670, Val: 0.001545, Total: 0.000779, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3793: Train: 0.000692, Val: 0.001471, Total: 0.000789, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3794: Train: 0.000695, Val: 0.001541, Total: 0.000801, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3795: Train: 0.000718, Val: 0.001515, Total: 0.000817, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3796: Train: 0.000688, Val: 0.001467, Total: 0.000785, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3797: Train: 0.000675, Val: 0.001536, Total: 0.000782, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3798: Train: 0.000721, Val: 0.001485, Total: 0.000816, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3799: Train: 0.000700, Val: 0.001511, Total: 0.000801, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3800: Train: 0.000709, Val: 0.001517, Total: 0.000810, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3801: Train: 0.000671, Val: 0.001471, Total: 0.000771, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3802: Train: 0.000701, Val: 0.001449, Total: 0.000795, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3803: Train: 0.000682, Val: 0.001488, Total: 0.000783, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3804: Train: 0.000689, Val: 0.001498, Total: 0.000790, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3805: Train: 0.000705, Val: 0.001437, Total: 0.000796, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3806: Train: 0.000674, Val: 0.001605, Total: 0.000791, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3807: Train: 0.000689, Val: 0.001433, Total: 0.000782, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3808: Train: 0.000698, Val: 0.001573, Total: 0.000807, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3809: Train: 0.000732, Val: 0.001464, Total: 0.000823, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3810: Train: 0.000668, Val: 0.001472, Total: 0.000769, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3811: Train: 0.000702, Val: 0.001472, Total: 0.000798, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3812: Train: 0.000696, Val: 0.001472, Total: 0.000793, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3813: Train: 0.000693, Val: 0.001536, Total: 0.000799, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3814: Train: 0.000698, Val: 0.001405, Total: 0.000786, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3815: Train: 0.000738, Val: 0.001599, Total: 0.000845, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3816: Train: 0.000736, Val: 0.001607, Total: 0.000845, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3817: Train: 0.000698, Val: 0.001455, Total: 0.000793, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3818: Train: 0.000703, Val: 0.001578, Total: 0.000812, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3819: Train: 0.000712, Val: 0.001569, Total: 0.000819, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3820: Train: 0.000714, Val: 0.001500, Total: 0.000813, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3821: Train: 0.000712, Val: 0.001499, Total: 0.000810, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3822: Train: 0.000653, Val: 0.001476, Total: 0.000756, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3823: Train: 0.000702, Val: 0.001512, Total: 0.000803, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3824: Train: 0.000683, Val: 0.001519, Total: 0.000788, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3825: Train: 0.000707, Val: 0.001476, Total: 0.000803, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3826: Train: 0.000689, Val: 0.001524, Total: 0.000794, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3827: Train: 0.000698, Val: 0.001442, Total: 0.000791, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3828: Train: 0.000700, Val: 0.001509, Total: 0.000801, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3829: Train: 0.000690, Val: 0.001664, Total: 0.000812, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3830: Train: 0.000673, Val: 0.001438, Total: 0.000769, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3831: Train: 0.000720, Val: 0.001522, Total: 0.000820, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3832: Train: 0.000678, Val: 0.001507, Total: 0.000782, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3833: Train: 0.000694, Val: 0.001576, Total: 0.000804, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3834: Train: 0.000694, Val: 0.001493, Total: 0.000794, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3835: Train: 0.000675, Val: 0.001412, Total: 0.000767, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3836: Train: 0.000723, Val: 0.001530, Total: 0.000824, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3837: Train: 0.000693, Val: 0.001499, Total: 0.000794, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3838: Train: 0.000688, Val: 0.001475, Total: 0.000787, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3839: Train: 0.000713, Val: 0.001455, Total: 0.000806, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3840: Train: 0.000674, Val: 0.001469, Total: 0.000774, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3841: Train: 0.000715, Val: 0.001550, Total: 0.000819, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3842: Train: 0.000692, Val: 0.001497, Total: 0.000793, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3843: Train: 0.000672, Val: 0.001407, Total: 0.000764, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3844: Train: 0.000712, Val: 0.001546, Total: 0.000817, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3845: Train: 0.000676, Val: 0.001535, Total: 0.000784, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3846: Train: 0.000711, Val: 0.001508, Total: 0.000810, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3847: Train: 0.000678, Val: 0.001530, Total: 0.000784, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3848: Train: 0.000705, Val: 0.001520, Total: 0.000807, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3849: Train: 0.000668, Val: 0.001470, Total: 0.000769, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3850: Train: 0.000688, Val: 0.001528, Total: 0.000793, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3851: Train: 0.000678, Val: 0.001507, Total: 0.000781, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3852: Train: 0.000706, Val: 0.001470, Total: 0.000802, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3853: Train: 0.000705, Val: 0.001464, Total: 0.000800, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3854: Train: 0.000718, Val: 0.001511, Total: 0.000817, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3855: Train: 0.000680, Val: 0.001442, Total: 0.000776, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3856: Train: 0.000692, Val: 0.001516, Total: 0.000795, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3857: Train: 0.000698, Val: 0.001526, Total: 0.000802, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3858: Train: 0.000682, Val: 0.001442, Total: 0.000777, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3859: Train: 0.000673, Val: 0.001475, Total: 0.000773, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3860: Train: 0.000689, Val: 0.001494, Total: 0.000790, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3861: Train: 0.000715, Val: 0.001433, Total: 0.000805, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3862: Train: 0.000708, Val: 0.001477, Total: 0.000804, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3863: Train: 0.000684, Val: 0.001521, Total: 0.000789, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3864: Train: 0.000727, Val: 0.001450, Total: 0.000817, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3865: Train: 0.000737, Val: 0.001511, Total: 0.000834, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3866: Train: 0.000687, Val: 0.001547, Total: 0.000794, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3867: Train: 0.000682, Val: 0.001473, Total: 0.000781, LR: 1.01e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3868: Train: 0.000677, Val: 0.001519, Total: 0.000782, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3869: Train: 0.000685, Val: 0.001437, Total: 0.000779, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3870: Train: 0.000691, Val: 0.001530, Total: 0.000796, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3871: Train: 0.000664, Val: 0.001533, Total: 0.000773, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3872: Train: 0.000691, Val: 0.001406, Total: 0.000780, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3873: Train: 0.000687, Val: 0.001501, Total: 0.000788, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3874: Train: 0.000661, Val: 0.001465, Total: 0.000761, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3875: Train: 0.000673, Val: 0.001501, Total: 0.000776, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3876: Train: 0.000696, Val: 0.001486, Total: 0.000795, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3877: Train: 0.000667, Val: 0.001433, Total: 0.000763, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3878: Train: 0.000692, Val: 0.001530, Total: 0.000797, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3879: Train: 0.000685, Val: 0.001492, Total: 0.000786, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3880: Train: 0.000732, Val: 0.001418, Total: 0.000818, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3881: Train: 0.000736, Val: 0.001565, Total: 0.000840, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3882: Train: 0.000773, Val: 0.001449, Total: 0.000858, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3883: Train: 0.000685, Val: 0.001490, Total: 0.000785, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3884: Train: 0.000669, Val: 0.001529, Total: 0.000777, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3885: Train: 0.000693, Val: 0.001489, Total: 0.000793, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3886: Train: 0.000758, Val: 0.001518, Total: 0.000853, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3887: Train: 0.000726, Val: 0.001536, Total: 0.000828, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3888: Train: 0.000734, Val: 0.001433, Total: 0.000821, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3889: Train: 0.000678, Val: 0.001600, Total: 0.000793, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3890: Train: 0.000697, Val: 0.001508, Total: 0.000798, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3891: Train: 0.000700, Val: 0.001458, Total: 0.000795, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3892: Train: 0.000683, Val: 0.001503, Total: 0.000785, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3893: Train: 0.000672, Val: 0.001522, Total: 0.000778, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3894: Train: 0.000692, Val: 0.001491, Total: 0.000792, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3895: Train: 0.000656, Val: 0.001540, Total: 0.000766, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3896: Train: 0.000673, Val: 0.001520, Total: 0.000779, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3897: Train: 0.000687, Val: 0.001490, Total: 0.000788, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3898: Train: 0.000717, Val: 0.001503, Total: 0.000816, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3899: Train: 0.000711, Val: 0.001590, Total: 0.000821, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3900: Train: 0.000716, Val: 0.001543, Total: 0.000819, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3901: Train: 0.000712, Val: 0.001583, Total: 0.000821, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3902: Train: 0.000710, Val: 0.001537, Total: 0.000813, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3903: Train: 0.000705, Val: 0.001525, Total: 0.000807, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3904: Train: 0.000735, Val: 0.001566, Total: 0.000839, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3905: Train: 0.000703, Val: 0.001484, Total: 0.000801, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3906: Train: 0.000677, Val: 0.001558, Total: 0.000787, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3907: Train: 0.000702, Val: 0.001550, Total: 0.000808, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3908: Train: 0.000720, Val: 0.001592, Total: 0.000829, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3909: Train: 0.000704, Val: 0.001483, Total: 0.000801, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3910: Train: 0.000724, Val: 0.001534, Total: 0.000825, LR: 1.00e-03\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3911: Train: 0.000711, Val: 0.001482, Total: 0.000807, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3912: Train: 0.000685, Val: 0.001525, Total: 0.000790, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3913: Train: 0.000698, Val: 0.001502, Total: 0.000798, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3914: Train: 0.000704, Val: 0.001511, Total: 0.000805, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3915: Train: 0.000708, Val: 0.001471, Total: 0.000803, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3916: Train: 0.000703, Val: 0.001517, Total: 0.000805, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3917: Train: 0.000677, Val: 0.001475, Total: 0.000777, LR: 9.99e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3918: Train: 0.000710, Val: 0.001527, Total: 0.000812, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3919: Train: 0.000722, Val: 0.001514, Total: 0.000821, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3920: Train: 0.000674, Val: 0.001474, Total: 0.000774, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3921: Train: 0.000682, Val: 0.001493, Total: 0.000783, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3922: Train: 0.000685, Val: 0.001469, Total: 0.000783, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3923: Train: 0.000658, Val: 0.001480, Total: 0.000761, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3924: Train: 0.000695, Val: 0.001497, Total: 0.000795, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3925: Train: 0.000667, Val: 0.001410, Total: 0.000760, LR: 9.98e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3926: Train: 0.000682, Val: 0.001518, Total: 0.000786, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3927: Train: 0.000701, Val: 0.001521, Total: 0.000804, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3928: Train: 0.000683, Val: 0.001463, Total: 0.000781, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3929: Train: 0.000672, Val: 0.001495, Total: 0.000775, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3930: Train: 0.000715, Val: 0.001500, Total: 0.000813, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3931: Train: 0.000654, Val: 0.001513, Total: 0.000761, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3932: Train: 0.000677, Val: 0.001497, Total: 0.000780, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3933: Train: 0.000659, Val: 0.001520, Total: 0.000766, LR: 9.97e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3934: Train: 0.000704, Val: 0.001497, Total: 0.000803, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3935: Train: 0.000700, Val: 0.001501, Total: 0.000800, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3936: Train: 0.000695, Val: 0.001533, Total: 0.000799, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3937: Train: 0.000686, Val: 0.001466, Total: 0.000784, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3938: Train: 0.000764, Val: 0.001128, Total: 0.000810, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3939: Train: 0.000772, Val: 0.001256, Total: 0.000833, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3940: Train: 0.000764, Val: 0.001169, Total: 0.000815, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3941: Train: 0.000806, Val: 0.001191, Total: 0.000854, LR: 9.96e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3942: Train: 0.000964, Val: 0.001102, Total: 0.000981, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3943: Train: 0.000858, Val: 0.001328, Total: 0.000917, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3944: Train: 0.000888, Val: 0.001715, Total: 0.000992, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3945: Train: 0.000912, Val: 0.001463, Total: 0.000981, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3946: Train: 0.000907, Val: 0.001321, Total: 0.000959, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3947: Train: 0.000995, Val: 0.001344, Total: 0.001039, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3948: Train: 0.000993, Val: 0.001294, Total: 0.001030, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3949: Train: 0.000855, Val: 0.001429, Total: 0.000927, LR: 9.95e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3950: Train: 0.001063, Val: 0.001823, Total: 0.001158, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3951: Train: 0.000935, Val: 0.001358, Total: 0.000988, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3952: Train: 0.000957, Val: 0.001281, Total: 0.000997, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3953: Train: 0.002247, Val: 0.002105, Total: 0.002229, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3954: Train: 0.001620, Val: 0.001652, Total: 0.001624, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3955: Train: 0.001159, Val: 0.002159, Total: 0.001284, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3956: Train: 0.001186, Val: 0.002371, Total: 0.001334, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3957: Train: 0.001129, Val: 0.001943, Total: 0.001231, LR: 9.94e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3958: Train: 0.001083, Val: 0.002311, Total: 0.001237, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3959: Train: 0.001011, Val: 0.001803, Total: 0.001110, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3960: Train: 0.000957, Val: 0.002185, Total: 0.001110, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3961: Train: 0.000862, Val: 0.002402, Total: 0.001055, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3962: Train: 0.000878, Val: 0.002004, Total: 0.001019, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3963: Train: 0.000821, Val: 0.002374, Total: 0.001015, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3964: Train: 0.001041, Val: 0.001851, Total: 0.001143, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3965: Train: 0.000854, Val: 0.001504, Total: 0.000935, LR: 9.93e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3966: Train: 0.000949, Val: 0.001781, Total: 0.001053, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3967: Train: 0.000939, Val: 0.001901, Total: 0.001059, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3968: Train: 0.000888, Val: 0.001764, Total: 0.000997, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3969: Train: 0.000818, Val: 0.001563, Total: 0.000911, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3970: Train: 0.000906, Val: 0.001436, Total: 0.000973, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3971: Train: 0.000824, Val: 0.002261, Total: 0.001004, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3972: Train: 0.000833, Val: 0.001641, Total: 0.000934, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3973: Train: 0.000848, Val: 0.001566, Total: 0.000938, LR: 9.92e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3974: Train: 0.000886, Val: 0.001376, Total: 0.000948, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3975: Train: 0.000808, Val: 0.001791, Total: 0.000931, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3976: Train: 0.000856, Val: 0.001767, Total: 0.000970, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3977: Train: 0.000835, Val: 0.001520, Total: 0.000920, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3978: Train: 0.000780, Val: 0.001548, Total: 0.000876, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3979: Train: 0.000803, Val: 0.001512, Total: 0.000891, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3980: Train: 0.000759, Val: 0.001460, Total: 0.000846, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3981: Train: 0.000765, Val: 0.001490, Total: 0.000856, LR: 9.91e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3982: Train: 0.000719, Val: 0.001504, Total: 0.000817, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3983: Train: 0.000722, Val: 0.001495, Total: 0.000819, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3984: Train: 0.000778, Val: 0.001573, Total: 0.000877, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3985: Train: 0.000734, Val: 0.001578, Total: 0.000840, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3986: Train: 0.000713, Val: 0.001495, Total: 0.000811, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3987: Train: 0.000712, Val: 0.001470, Total: 0.000807, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3988: Train: 0.000736, Val: 0.001486, Total: 0.000830, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3989: Train: 0.000720, Val: 0.001480, Total: 0.000815, LR: 9.90e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3990: Train: 0.000728, Val: 0.001519, Total: 0.000827, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3991: Train: 0.000719, Val: 0.001508, Total: 0.000818, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3992: Train: 0.000738, Val: 0.001470, Total: 0.000829, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3993: Train: 0.000679, Val: 0.001479, Total: 0.000779, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3994: Train: 0.000727, Val: 0.001492, Total: 0.000822, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3995: Train: 0.000737, Val: 0.001485, Total: 0.000830, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3996: Train: 0.000747, Val: 0.001490, Total: 0.000839, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3997: Train: 0.000717, Val: 0.001543, Total: 0.000820, LR: 9.89e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3998: Train: 0.000766, Val: 0.001489, Total: 0.000857, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 3999: Train: 0.000708, Val: 0.001482, Total: 0.000805, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4000: Train: 0.000700, Val: 0.001568, Total: 0.000808, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4001: Train: 0.000699, Val: 0.001632, Total: 0.000816, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4002: Train: 0.000710, Val: 0.001482, Total: 0.000806, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4003: Train: 0.000714, Val: 0.001408, Total: 0.000800, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4004: Train: 0.000717, Val: 0.001520, Total: 0.000817, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4005: Train: 0.000718, Val: 0.001503, Total: 0.000816, LR: 9.88e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4006: Train: 0.000680, Val: 0.001447, Total: 0.000776, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4007: Train: 0.000709, Val: 0.001454, Total: 0.000802, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4008: Train: 0.000703, Val: 0.001338, Total: 0.000782, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4009: Train: 0.000743, Val: 0.001256, Total: 0.000807, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4010: Train: 0.000701, Val: 0.001492, Total: 0.000800, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4011: Train: 0.000715, Val: 0.001518, Total: 0.000815, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4012: Train: 0.000702, Val: 0.001480, Total: 0.000799, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4013: Train: 0.000693, Val: 0.001491, Total: 0.000792, LR: 9.87e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4014: Train: 0.000694, Val: 0.001576, Total: 0.000804, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4015: Train: 0.000745, Val: 0.001551, Total: 0.000846, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4016: Train: 0.000713, Val: 0.001471, Total: 0.000808, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4017: Train: 0.000737, Val: 0.001450, Total: 0.000826, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4018: Train: 0.000709, Val: 0.001501, Total: 0.000808, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4019: Train: 0.000674, Val: 0.001503, Total: 0.000777, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4020: Train: 0.000734, Val: 0.001511, Total: 0.000831, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4021: Train: 0.000709, Val: 0.001506, Total: 0.000809, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4022: Train: 0.000692, Val: 0.001566, Total: 0.000801, LR: 9.86e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4023: Train: 0.000704, Val: 0.001540, Total: 0.000808, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4024: Train: 0.000680, Val: 0.001516, Total: 0.000785, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4025: Train: 0.000692, Val: 0.001497, Total: 0.000792, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4026: Train: 0.000697, Val: 0.001559, Total: 0.000804, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4027: Train: 0.000711, Val: 0.001579, Total: 0.000819, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4028: Train: 0.000696, Val: 0.001563, Total: 0.000804, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4029: Train: 0.000714, Val: 0.001512, Total: 0.000814, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4030: Train: 0.000729, Val: 0.001519, Total: 0.000828, LR: 9.85e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4031: Train: 0.000710, Val: 0.001486, Total: 0.000807, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4032: Train: 0.000698, Val: 0.001466, Total: 0.000794, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4033: Train: 0.000690, Val: 0.001517, Total: 0.000794, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4034: Train: 0.000685, Val: 0.001450, Total: 0.000780, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4035: Train: 0.000677, Val: 0.001428, Total: 0.000771, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4036: Train: 0.000699, Val: 0.001533, Total: 0.000803, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4037: Train: 0.000692, Val: 0.001517, Total: 0.000795, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4038: Train: 0.000680, Val: 0.001463, Total: 0.000778, LR: 9.84e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4039: Train: 0.000710, Val: 0.001478, Total: 0.000806, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4040: Train: 0.000696, Val: 0.001532, Total: 0.000800, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4041: Train: 0.000687, Val: 0.001501, Total: 0.000789, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4042: Train: 0.000708, Val: 0.001453, Total: 0.000801, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4043: Train: 0.000721, Val: 0.001462, Total: 0.000814, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4044: Train: 0.000761, Val: 0.001524, Total: 0.000856, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4045: Train: 0.000717, Val: 0.001399, Total: 0.000802, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4046: Train: 0.000698, Val: 0.001460, Total: 0.000793, LR: 9.83e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4047: Train: 0.000704, Val: 0.001483, Total: 0.000802, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4048: Train: 0.000709, Val: 0.001414, Total: 0.000797, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4049: Train: 0.000713, Val: 0.001440, Total: 0.000804, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4050: Train: 0.000684, Val: 0.001479, Total: 0.000783, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4051: Train: 0.000713, Val: 0.001395, Total: 0.000798, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4052: Train: 0.000725, Val: 0.001439, Total: 0.000814, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4053: Train: 0.000687, Val: 0.001508, Total: 0.000789, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4054: Train: 0.000671, Val: 0.001456, Total: 0.000769, LR: 9.82e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4055: Train: 0.000706, Val: 0.001446, Total: 0.000799, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4056: Train: 0.000763, Val: 0.001503, Total: 0.000856, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4057: Train: 0.000667, Val: 0.001530, Total: 0.000775, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4058: Train: 0.000714, Val: 0.001383, Total: 0.000798, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4059: Train: 0.000738, Val: 0.001390, Total: 0.000820, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4060: Train: 0.000698, Val: 0.001459, Total: 0.000793, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4061: Train: 0.000710, Val: 0.001510, Total: 0.000810, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4062: Train: 0.000701, Val: 0.001468, Total: 0.000797, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4063: Train: 0.000686, Val: 0.001423, Total: 0.000778, LR: 9.81e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4064: Train: 0.000693, Val: 0.001464, Total: 0.000790, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4065: Train: 0.000714, Val: 0.001473, Total: 0.000809, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4066: Train: 0.000704, Val: 0.001492, Total: 0.000803, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4067: Train: 0.000729, Val: 0.001507, Total: 0.000826, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4068: Train: 0.000712, Val: 0.001497, Total: 0.000810, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4069: Train: 0.000694, Val: 0.001503, Total: 0.000795, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4070: Train: 0.000704, Val: 0.001489, Total: 0.000802, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4071: Train: 0.000708, Val: 0.001444, Total: 0.000800, LR: 9.80e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4072: Train: 0.000708, Val: 0.001536, Total: 0.000812, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4073: Train: 0.000700, Val: 0.001460, Total: 0.000795, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4074: Train: 0.000680, Val: 0.001447, Total: 0.000776, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4075: Train: 0.000679, Val: 0.001492, Total: 0.000780, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4076: Train: 0.000720, Val: 0.001512, Total: 0.000819, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4077: Train: 0.000706, Val: 0.001466, Total: 0.000801, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4078: Train: 0.000676, Val: 0.001491, Total: 0.000778, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4079: Train: 0.000694, Val: 0.001471, Total: 0.000791, LR: 9.79e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4080: Train: 0.000701, Val: 0.001512, Total: 0.000802, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4081: Train: 0.000704, Val: 0.001551, Total: 0.000810, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4082: Train: 0.000699, Val: 0.001480, Total: 0.000797, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4083: Train: 0.000712, Val: 0.001509, Total: 0.000812, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4084: Train: 0.000714, Val: 0.001506, Total: 0.000813, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4085: Train: 0.000708, Val: 0.001396, Total: 0.000794, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4086: Train: 0.000688, Val: 0.001532, Total: 0.000793, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4087: Train: 0.000682, Val: 0.001528, Total: 0.000788, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4088: Train: 0.000698, Val: 0.001444, Total: 0.000791, LR: 9.78e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4089: Train: 0.000670, Val: 0.001458, Total: 0.000768, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4090: Train: 0.000723, Val: 0.001562, Total: 0.000828, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4091: Train: 0.000720, Val: 0.001483, Total: 0.000815, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4092: Train: 0.000690, Val: 0.001464, Total: 0.000787, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4093: Train: 0.000711, Val: 0.001513, Total: 0.000811, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4094: Train: 0.000720, Val: 0.001531, Total: 0.000822, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4095: Train: 0.000723, Val: 0.001531, Total: 0.000824, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4096: Train: 0.000698, Val: 0.001499, Total: 0.000798, LR: 9.77e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4097: Train: 0.000682, Val: 0.001482, Total: 0.000782, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4098: Train: 0.000722, Val: 0.001556, Total: 0.000826, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4099: Train: 0.000701, Val: 0.001523, Total: 0.000804, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4100: Train: 0.000723, Val: 0.001515, Total: 0.000822, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4101: Train: 0.000694, Val: 0.001468, Total: 0.000791, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4102: Train: 0.000716, Val: 0.001479, Total: 0.000812, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4103: Train: 0.000665, Val: 0.001493, Total: 0.000769, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4104: Train: 0.000692, Val: 0.001496, Total: 0.000792, LR: 9.76e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4105: Train: 0.000669, Val: 0.001478, Total: 0.000770, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4106: Train: 0.000688, Val: 0.001493, Total: 0.000788, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4107: Train: 0.000742, Val: 0.001561, Total: 0.000845, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4108: Train: 0.000670, Val: 0.001499, Total: 0.000774, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4109: Train: 0.000692, Val: 0.001479, Total: 0.000790, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4110: Train: 0.000675, Val: 0.001462, Total: 0.000774, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4111: Train: 0.000687, Val: 0.001468, Total: 0.000784, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4112: Train: 0.000737, Val: 0.001490, Total: 0.000831, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4113: Train: 0.000743, Val: 0.001489, Total: 0.000836, LR: 9.75e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4114: Train: 0.000695, Val: 0.001524, Total: 0.000799, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4115: Train: 0.000738, Val: 0.001481, Total: 0.000830, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4116: Train: 0.000685, Val: 0.001471, Total: 0.000784, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4117: Train: 0.000702, Val: 0.001522, Total: 0.000805, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4118: Train: 0.000700, Val: 0.001537, Total: 0.000805, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4119: Train: 0.000688, Val: 0.001526, Total: 0.000793, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4120: Train: 0.000703, Val: 0.001479, Total: 0.000800, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4121: Train: 0.000701, Val: 0.001452, Total: 0.000795, LR: 9.74e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4122: Train: 0.000706, Val: 0.001454, Total: 0.000800, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4123: Train: 0.000733, Val: 0.001511, Total: 0.000831, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4124: Train: 0.000700, Val: 0.001516, Total: 0.000802, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4125: Train: 0.000671, Val: 0.001470, Total: 0.000771, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4126: Train: 0.000664, Val: 0.001472, Total: 0.000765, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4127: Train: 0.000673, Val: 0.001538, Total: 0.000781, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4128: Train: 0.000687, Val: 0.001466, Total: 0.000784, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4129: Train: 0.000688, Val: 0.001452, Total: 0.000783, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4130: Train: 0.000691, Val: 0.001581, Total: 0.000802, LR: 9.73e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4131: Train: 0.000703, Val: 0.001506, Total: 0.000803, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4132: Train: 0.000691, Val: 0.001415, Total: 0.000782, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4133: Train: 0.000664, Val: 0.001508, Total: 0.000769, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4134: Train: 0.000699, Val: 0.001552, Total: 0.000805, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4135: Train: 0.000714, Val: 0.001497, Total: 0.000812, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4136: Train: 0.000713, Val: 0.001497, Total: 0.000811, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4137: Train: 0.000713, Val: 0.001547, Total: 0.000818, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4138: Train: 0.000694, Val: 0.001485, Total: 0.000793, LR: 9.72e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4139: Train: 0.000693, Val: 0.001431, Total: 0.000785, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4140: Train: 0.000678, Val: 0.001470, Total: 0.000777, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4141: Train: 0.000726, Val: 0.001475, Total: 0.000819, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4142: Train: 0.000707, Val: 0.001554, Total: 0.000813, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4143: Train: 0.000656, Val: 0.001651, Total: 0.000781, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4144: Train: 0.000721, Val: 0.001575, Total: 0.000828, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4145: Train: 0.000717, Val: 0.001426, Total: 0.000806, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4146: Train: 0.000709, Val: 0.001473, Total: 0.000805, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4147: Train: 0.000683, Val: 0.001536, Total: 0.000790, LR: 9.71e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4148: Train: 0.000675, Val: 0.001449, Total: 0.000771, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4149: Train: 0.000693, Val: 0.001514, Total: 0.000796, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4150: Train: 0.000688, Val: 0.001523, Total: 0.000792, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4151: Train: 0.000670, Val: 0.001448, Total: 0.000767, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4152: Train: 0.000691, Val: 0.001468, Total: 0.000788, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4153: Train: 0.000688, Val: 0.001477, Total: 0.000786, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4154: Train: 0.000675, Val: 0.001470, Total: 0.000774, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4155: Train: 0.000730, Val: 0.001457, Total: 0.000821, LR: 9.70e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4156: Train: 0.000717, Val: 0.001481, Total: 0.000813, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4157: Train: 0.000660, Val: 0.001469, Total: 0.000761, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4158: Train: 0.000675, Val: 0.001481, Total: 0.000776, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4159: Train: 0.000687, Val: 0.001511, Total: 0.000790, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4160: Train: 0.000683, Val: 0.001450, Total: 0.000779, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4161: Train: 0.000700, Val: 0.001403, Total: 0.000788, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4162: Train: 0.000691, Val: 0.001514, Total: 0.000794, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4163: Train: 0.000676, Val: 0.001472, Total: 0.000776, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4164: Train: 0.000693, Val: 0.001477, Total: 0.000791, LR: 9.69e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4165: Train: 0.000685, Val: 0.001512, Total: 0.000789, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4166: Train: 0.000664, Val: 0.001471, Total: 0.000765, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4167: Train: 0.000687, Val: 0.001455, Total: 0.000783, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4168: Train: 0.000710, Val: 0.001540, Total: 0.000814, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4169: Train: 0.000683, Val: 0.001479, Total: 0.000783, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4170: Train: 0.000704, Val: 0.001517, Total: 0.000805, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4171: Train: 0.000699, Val: 0.001477, Total: 0.000796, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4172: Train: 0.000705, Val: 0.001386, Total: 0.000790, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4173: Train: 0.000684, Val: 0.001421, Total: 0.000776, LR: 9.68e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4174: Train: 0.000685, Val: 0.001420, Total: 0.000777, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4175: Train: 0.000684, Val: 0.001383, Total: 0.000771, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4176: Train: 0.000711, Val: 0.001412, Total: 0.000799, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4177: Train: 0.000700, Val: 0.001417, Total: 0.000790, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4178: Train: 0.000683, Val: 0.001474, Total: 0.000782, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4179: Train: 0.000678, Val: 0.001411, Total: 0.000769, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4180: Train: 0.000673, Val: 0.001424, Total: 0.000767, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4181: Train: 0.000690, Val: 0.001487, Total: 0.000790, LR: 9.67e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4182: Train: 0.000724, Val: 0.001263, Total: 0.000791, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4183: Train: 0.000731, Val: 0.001187, Total: 0.000788, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4184: Train: 0.000682, Val: 0.001253, Total: 0.000753, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4185: Train: 0.000696, Val: 0.001252, Total: 0.000766, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4186: Train: 0.000688, Val: 0.001255, Total: 0.000759, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4187: Train: 0.000690, Val: 0.001302, Total: 0.000766, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4188: Train: 0.000706, Val: 0.001347, Total: 0.000786, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4189: Train: 0.000679, Val: 0.001455, Total: 0.000776, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4190: Train: 0.000722, Val: 0.001423, Total: 0.000810, LR: 9.66e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4191: Train: 0.000684, Val: 0.001397, Total: 0.000773, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4192: Train: 0.000691, Val: 0.001511, Total: 0.000794, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4193: Train: 0.000692, Val: 0.001426, Total: 0.000784, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4194: Train: 0.000744, Val: 0.001484, Total: 0.000836, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4195: Train: 0.000750, Val: 0.001551, Total: 0.000850, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4196: Train: 0.000719, Val: 0.001490, Total: 0.000815, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4197: Train: 0.000733, Val: 0.001477, Total: 0.000826, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4198: Train: 0.000730, Val: 0.001520, Total: 0.000829, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4199: Train: 0.000682, Val: 0.001463, Total: 0.000779, LR: 9.65e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4200: Train: 0.000707, Val: 0.001464, Total: 0.000802, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4201: Train: 0.000733, Val: 0.001523, Total: 0.000832, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4202: Train: 0.000728, Val: 0.001473, Total: 0.000822, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4203: Train: 0.000693, Val: 0.001461, Total: 0.000789, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4204: Train: 0.000681, Val: 0.001501, Total: 0.000784, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4205: Train: 0.000696, Val: 0.001477, Total: 0.000794, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4206: Train: 0.000685, Val: 0.001469, Total: 0.000783, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4207: Train: 0.000682, Val: 0.001512, Total: 0.000786, LR: 9.64e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4208: Train: 0.000739, Val: 0.001441, Total: 0.000827, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4209: Train: 0.000686, Val: 0.001575, Total: 0.000797, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4210: Train: 0.000689, Val: 0.001539, Total: 0.000795, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4211: Train: 0.000699, Val: 0.001506, Total: 0.000800, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4212: Train: 0.000714, Val: 0.001493, Total: 0.000811, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4213: Train: 0.000699, Val: 0.001570, Total: 0.000808, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4214: Train: 0.000655, Val: 0.001474, Total: 0.000757, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4215: Train: 0.000730, Val: 0.001472, Total: 0.000823, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4216: Train: 0.000702, Val: 0.001518, Total: 0.000804, LR: 9.63e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4217: Train: 0.000724, Val: 0.001526, Total: 0.000824, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4218: Train: 0.000696, Val: 0.001490, Total: 0.000795, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4219: Train: 0.000677, Val: 0.001441, Total: 0.000773, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4220: Train: 0.000684, Val: 0.001577, Total: 0.000796, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4221: Train: 0.000693, Val: 0.001484, Total: 0.000792, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4222: Train: 0.000687, Val: 0.001448, Total: 0.000782, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4223: Train: 0.000706, Val: 0.001534, Total: 0.000810, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4224: Train: 0.000682, Val: 0.001507, Total: 0.000785, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4225: Train: 0.000687, Val: 0.001493, Total: 0.000787, LR: 9.62e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4226: Train: 0.000669, Val: 0.001472, Total: 0.000770, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4227: Train: 0.000674, Val: 0.001438, Total: 0.000770, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4228: Train: 0.000687, Val: 0.001589, Total: 0.000800, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4229: Train: 0.000711, Val: 0.001493, Total: 0.000809, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4230: Train: 0.000669, Val: 0.001493, Total: 0.000772, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4231: Train: 0.000675, Val: 0.001540, Total: 0.000783, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4232: Train: 0.000670, Val: 0.001466, Total: 0.000770, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4233: Train: 0.000684, Val: 0.001475, Total: 0.000783, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4234: Train: 0.000679, Val: 0.001488, Total: 0.000780, LR: 9.61e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4235: Train: 0.000718, Val: 0.001484, Total: 0.000814, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4236: Train: 0.000701, Val: 0.001500, Total: 0.000801, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4237: Train: 0.000696, Val: 0.001462, Total: 0.000792, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4238: Train: 0.000718, Val: 0.001511, Total: 0.000817, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4239: Train: 0.000683, Val: 0.001552, Total: 0.000791, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4240: Train: 0.000701, Val: 0.001501, Total: 0.000801, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4241: Train: 0.000673, Val: 0.001519, Total: 0.000779, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4242: Train: 0.000678, Val: 0.001537, Total: 0.000786, LR: 9.60e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4243: Train: 0.000677, Val: 0.001505, Total: 0.000781, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4244: Train: 0.000674, Val: 0.001506, Total: 0.000778, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4245: Train: 0.000695, Val: 0.001447, Total: 0.000789, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4246: Train: 0.000680, Val: 0.001529, Total: 0.000786, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4247: Train: 0.000702, Val: 0.001452, Total: 0.000796, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4248: Train: 0.000706, Val: 0.001411, Total: 0.000794, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4249: Train: 0.000716, Val: 0.001564, Total: 0.000822, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4250: Train: 0.000743, Val: 0.001543, Total: 0.000843, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4251: Train: 0.000718, Val: 0.001354, Total: 0.000797, LR: 9.59e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4252: Train: 0.000714, Val: 0.001640, Total: 0.000830, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4253: Train: 0.000797, Val: 0.001551, Total: 0.000891, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4254: Train: 0.000714, Val: 0.001332, Total: 0.000791, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4255: Train: 0.000733, Val: 0.001661, Total: 0.000849, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4256: Train: 0.000799, Val: 0.001524, Total: 0.000890, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4257: Train: 0.000706, Val: 0.001315, Total: 0.000782, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4258: Train: 0.000878, Val: 0.001807, Total: 0.000994, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4259: Train: 0.000933, Val: 0.001658, Total: 0.001023, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4260: Train: 0.000839, Val: 0.001194, Total: 0.000883, LR: 9.58e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4261: Train: 0.000805, Val: 0.001940, Total: 0.000947, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4262: Train: 0.000734, Val: 0.002034, Total: 0.000896, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4263: Train: 0.000772, Val: 0.001738, Total: 0.000892, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4264: Train: 0.000717, Val: 0.001601, Total: 0.000828, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4265: Train: 0.000746, Val: 0.001615, Total: 0.000854, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4266: Train: 0.000664, Val: 0.001555, Total: 0.000776, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4267: Train: 0.000684, Val: 0.001546, Total: 0.000792, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4268: Train: 0.000688, Val: 0.001603, Total: 0.000802, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4269: Train: 0.000710, Val: 0.001497, Total: 0.000808, LR: 9.57e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4270: Train: 0.000717, Val: 0.001446, Total: 0.000808, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4271: Train: 0.000711, Val: 0.001555, Total: 0.000816, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4272: Train: 0.000669, Val: 0.001492, Total: 0.000772, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4273: Train: 0.000674, Val: 0.001449, Total: 0.000771, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4274: Train: 0.000696, Val: 0.001506, Total: 0.000797, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4275: Train: 0.000682, Val: 0.001495, Total: 0.000784, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4276: Train: 0.000687, Val: 0.001451, Total: 0.000782, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4277: Train: 0.000658, Val: 0.001502, Total: 0.000764, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4278: Train: 0.000654, Val: 0.001525, Total: 0.000763, LR: 9.56e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4279: Train: 0.000679, Val: 0.001510, Total: 0.000783, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4280: Train: 0.000682, Val: 0.001455, Total: 0.000779, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4281: Train: 0.000661, Val: 0.001507, Total: 0.000767, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4282: Train: 0.000669, Val: 0.001513, Total: 0.000775, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4283: Train: 0.000668, Val: 0.001535, Total: 0.000777, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4284: Train: 0.000690, Val: 0.001523, Total: 0.000794, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4285: Train: 0.000681, Val: 0.001504, Total: 0.000784, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4286: Train: 0.000700, Val: 0.001515, Total: 0.000802, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4287: Train: 0.000689, Val: 0.001498, Total: 0.000790, LR: 9.55e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4288: Train: 0.000695, Val: 0.001540, Total: 0.000801, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4289: Train: 0.000737, Val: 0.001556, Total: 0.000839, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4290: Train: 0.000698, Val: 0.001539, Total: 0.000803, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4291: Train: 0.000705, Val: 0.001555, Total: 0.000811, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4292: Train: 0.000671, Val: 0.001580, Total: 0.000785, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4293: Train: 0.000686, Val: 0.001513, Total: 0.000789, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4294: Train: 0.000698, Val: 0.001488, Total: 0.000797, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4295: Train: 0.000708, Val: 0.001546, Total: 0.000813, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4296: Train: 0.000695, Val: 0.001545, Total: 0.000801, LR: 9.54e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4297: Train: 0.000715, Val: 0.001525, Total: 0.000816, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4298: Train: 0.000695, Val: 0.001513, Total: 0.000797, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4299: Train: 0.000720, Val: 0.001546, Total: 0.000823, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4300: Train: 0.000702, Val: 0.001552, Total: 0.000809, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4301: Train: 0.000691, Val: 0.001535, Total: 0.000797, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4302: Train: 0.000657, Val: 0.001528, Total: 0.000766, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4303: Train: 0.000706, Val: 0.001559, Total: 0.000813, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4304: Train: 0.000720, Val: 0.001502, Total: 0.000817, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4305: Train: 0.000668, Val: 0.001561, Total: 0.000780, LR: 9.53e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4306: Train: 0.000715, Val: 0.001538, Total: 0.000818, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4307: Train: 0.000734, Val: 0.001530, Total: 0.000834, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4308: Train: 0.000683, Val: 0.001563, Total: 0.000793, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4309: Train: 0.000698, Val: 0.001491, Total: 0.000797, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4310: Train: 0.000731, Val: 0.001491, Total: 0.000826, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4311: Train: 0.000741, Val: 0.001508, Total: 0.000837, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4312: Train: 0.000720, Val: 0.001516, Total: 0.000819, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4313: Train: 0.000713, Val: 0.001490, Total: 0.000810, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4314: Train: 0.000729, Val: 0.001533, Total: 0.000829, LR: 9.52e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4315: Train: 0.000681, Val: 0.001518, Total: 0.000785, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4316: Train: 0.000687, Val: 0.001485, Total: 0.000786, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4317: Train: 0.000702, Val: 0.001506, Total: 0.000803, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4318: Train: 0.000666, Val: 0.001508, Total: 0.000771, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4319: Train: 0.000688, Val: 0.001581, Total: 0.000800, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4320: Train: 0.000724, Val: 0.001509, Total: 0.000822, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4321: Train: 0.000696, Val: 0.001567, Total: 0.000805, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4322: Train: 0.000689, Val: 0.001509, Total: 0.000791, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4323: Train: 0.000683, Val: 0.001526, Total: 0.000789, LR: 9.51e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4324: Train: 0.000715, Val: 0.001524, Total: 0.000816, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4325: Train: 0.000697, Val: 0.001448, Total: 0.000791, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4326: Train: 0.000677, Val: 0.001485, Total: 0.000778, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4327: Train: 0.000710, Val: 0.001500, Total: 0.000809, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4328: Train: 0.000656, Val: 0.001511, Total: 0.000763, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4329: Train: 0.000677, Val: 0.001454, Total: 0.000774, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4330: Train: 0.000686, Val: 0.001511, Total: 0.000789, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4331: Train: 0.000675, Val: 0.001517, Total: 0.000780, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4332: Train: 0.000686, Val: 0.001489, Total: 0.000786, LR: 9.50e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4333: Train: 0.000670, Val: 0.001467, Total: 0.000770, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4334: Train: 0.000670, Val: 0.001536, Total: 0.000778, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4335: Train: 0.000686, Val: 0.001533, Total: 0.000792, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4336: Train: 0.000714, Val: 0.001501, Total: 0.000812, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4337: Train: 0.000711, Val: 0.001476, Total: 0.000806, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4338: Train: 0.000710, Val: 0.001487, Total: 0.000807, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4339: Train: 0.000693, Val: 0.001558, Total: 0.000801, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4340: Train: 0.000709, Val: 0.001490, Total: 0.000807, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4341: Train: 0.000742, Val: 0.001451, Total: 0.000831, LR: 9.49e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4342: Train: 0.000685, Val: 0.001496, Total: 0.000787, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4343: Train: 0.000697, Val: 0.001482, Total: 0.000795, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4344: Train: 0.000677, Val: 0.001523, Total: 0.000782, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4345: Train: 0.000696, Val: 0.001497, Total: 0.000796, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4346: Train: 0.000692, Val: 0.001508, Total: 0.000794, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4347: Train: 0.000702, Val: 0.001514, Total: 0.000804, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4348: Train: 0.000687, Val: 0.001561, Total: 0.000796, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4349: Train: 0.000699, Val: 0.001529, Total: 0.000803, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4350: Train: 0.000713, Val: 0.001586, Total: 0.000822, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4351: Train: 0.000723, Val: 0.001539, Total: 0.000825, LR: 9.48e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4352: Train: 0.000687, Val: 0.001495, Total: 0.000788, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4353: Train: 0.000700, Val: 0.001576, Total: 0.000810, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4354: Train: 0.000689, Val: 0.001495, Total: 0.000789, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4355: Train: 0.000681, Val: 0.001505, Total: 0.000784, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4356: Train: 0.000662, Val: 0.001493, Total: 0.000766, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4357: Train: 0.000675, Val: 0.001577, Total: 0.000788, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4358: Train: 0.000717, Val: 0.001510, Total: 0.000816, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4359: Train: 0.000718, Val: 0.001479, Total: 0.000814, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4360: Train: 0.000698, Val: 0.001577, Total: 0.000808, LR: 9.47e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4361: Train: 0.000711, Val: 0.001559, Total: 0.000817, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4362: Train: 0.000687, Val: 0.001486, Total: 0.000787, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4363: Train: 0.000673, Val: 0.001558, Total: 0.000783, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4364: Train: 0.000689, Val: 0.001516, Total: 0.000792, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4365: Train: 0.000688, Val: 0.001501, Total: 0.000790, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4366: Train: 0.000728, Val: 0.001518, Total: 0.000826, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4367: Train: 0.000677, Val: 0.001513, Total: 0.000782, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4368: Train: 0.000678, Val: 0.001547, Total: 0.000786, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4369: Train: 0.000703, Val: 0.001556, Total: 0.000809, LR: 9.46e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4370: Train: 0.000695, Val: 0.001472, Total: 0.000792, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4371: Train: 0.000656, Val: 0.001494, Total: 0.000761, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4372: Train: 0.000672, Val: 0.001491, Total: 0.000774, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4373: Train: 0.000687, Val: 0.001518, Total: 0.000791, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4374: Train: 0.000689, Val: 0.001525, Total: 0.000793, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4375: Train: 0.000680, Val: 0.001463, Total: 0.000778, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4376: Train: 0.000685, Val: 0.001483, Total: 0.000785, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4377: Train: 0.000670, Val: 0.001533, Total: 0.000778, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4378: Train: 0.000706, Val: 0.001572, Total: 0.000815, LR: 9.45e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4379: Train: 0.000725, Val: 0.001511, Total: 0.000823, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4380: Train: 0.000670, Val: 0.001539, Total: 0.000779, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4381: Train: 0.000692, Val: 0.001568, Total: 0.000801, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4382: Train: 0.000703, Val: 0.001511, Total: 0.000804, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4383: Train: 0.000694, Val: 0.001565, Total: 0.000803, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4384: Train: 0.000690, Val: 0.001568, Total: 0.000800, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4385: Train: 0.000682, Val: 0.001546, Total: 0.000790, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4386: Train: 0.000663, Val: 0.001492, Total: 0.000767, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4387: Train: 0.000670, Val: 0.001525, Total: 0.000777, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4388: Train: 0.000712, Val: 0.001514, Total: 0.000812, LR: 9.44e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4389: Train: 0.000660, Val: 0.001455, Total: 0.000759, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4390: Train: 0.000683, Val: 0.001546, Total: 0.000791, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4391: Train: 0.000669, Val: 0.001537, Total: 0.000778, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4392: Train: 0.000675, Val: 0.001509, Total: 0.000779, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4393: Train: 0.000678, Val: 0.001595, Total: 0.000792, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4394: Train: 0.000704, Val: 0.001507, Total: 0.000805, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4395: Train: 0.000667, Val: 0.001512, Total: 0.000772, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4396: Train: 0.000666, Val: 0.001545, Total: 0.000776, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4397: Train: 0.000655, Val: 0.001497, Total: 0.000760, LR: 9.43e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4398: Train: 0.000694, Val: 0.001494, Total: 0.000794, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4399: Train: 0.000681, Val: 0.001569, Total: 0.000792, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4400: Train: 0.000736, Val: 0.001473, Total: 0.000828, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4401: Train: 0.000732, Val: 0.001494, Total: 0.000827, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4402: Train: 0.000686, Val: 0.001653, Total: 0.000807, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4403: Train: 0.000666, Val: 0.001529, Total: 0.000774, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4404: Train: 0.000672, Val: 0.001524, Total: 0.000778, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4405: Train: 0.000674, Val: 0.001547, Total: 0.000783, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4406: Train: 0.000686, Val: 0.001488, Total: 0.000786, LR: 9.42e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4407: Train: 0.000683, Val: 0.001550, Total: 0.000792, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4408: Train: 0.000677, Val: 0.001587, Total: 0.000790, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4409: Train: 0.000694, Val: 0.001461, Total: 0.000789, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4410: Train: 0.000659, Val: 0.001481, Total: 0.000761, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4411: Train: 0.000676, Val: 0.001521, Total: 0.000782, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4412: Train: 0.000690, Val: 0.001544, Total: 0.000797, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4413: Train: 0.000698, Val: 0.001529, Total: 0.000802, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4414: Train: 0.000701, Val: 0.001472, Total: 0.000797, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4415: Train: 0.000676, Val: 0.001509, Total: 0.000780, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4416: Train: 0.000658, Val: 0.001508, Total: 0.000764, LR: 9.41e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4417: Train: 0.000667, Val: 0.001540, Total: 0.000776, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4418: Train: 0.000677, Val: 0.001456, Total: 0.000774, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4419: Train: 0.000679, Val: 0.001541, Total: 0.000787, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4420: Train: 0.000682, Val: 0.001566, Total: 0.000792, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4421: Train: 0.000730, Val: 0.001533, Total: 0.000831, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4422: Train: 0.000678, Val: 0.001501, Total: 0.000781, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4423: Train: 0.000689, Val: 0.001555, Total: 0.000797, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4424: Train: 0.000670, Val: 0.001485, Total: 0.000772, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4425: Train: 0.000672, Val: 0.001567, Total: 0.000784, LR: 9.40e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4426: Train: 0.000699, Val: 0.001547, Total: 0.000805, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4427: Train: 0.000720, Val: 0.001547, Total: 0.000823, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4428: Train: 0.000672, Val: 0.001532, Total: 0.000780, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4429: Train: 0.000671, Val: 0.001564, Total: 0.000783, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4430: Train: 0.000668, Val: 0.001476, Total: 0.000769, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4431: Train: 0.000724, Val: 0.001552, Total: 0.000828, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4432: Train: 0.000690, Val: 0.001526, Total: 0.000794, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4433: Train: 0.000715, Val: 0.001591, Total: 0.000825, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4434: Train: 0.000706, Val: 0.001521, Total: 0.000808, LR: 9.39e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4435: Train: 0.000675, Val: 0.001580, Total: 0.000788, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4436: Train: 0.000681, Val: 0.001483, Total: 0.000781, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4437: Train: 0.000706, Val: 0.001523, Total: 0.000808, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4438: Train: 0.000723, Val: 0.001469, Total: 0.000816, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4439: Train: 0.000703, Val: 0.001490, Total: 0.000801, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4440: Train: 0.000684, Val: 0.001457, Total: 0.000781, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4441: Train: 0.000716, Val: 0.001560, Total: 0.000822, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Epoch 4442: Train: 0.000696, Val: 0.001528, Total: 0.000800, LR: 9.38e-04\n",
      "          Best: Train: 0.000665, Val: 0.001366, Total: 0.000752 (Epoch 3442)\n",
      "Early stopping at epoch 4442\n",
      "\n",
      "Training completed!\n",
      "============================================================\n",
      "Best Performance (Epoch 3442):\n",
      "  Best Total Loss:  0.000752\n",
      "  Best Train Loss:  0.000665\n",
      "  Best Val Loss:    0.001366\n",
      "============================================================\n",
      "Final Performance (Epoch 4442):\n",
      "  Final Total Loss: 0.000800\n",
      "  Final Train Loss: 0.000696\n",
      "  Final Val Loss:   0.001528\n",
      "  Final LR:         9.38e-04\n",
      "============================================================\n",
      "Warmup completed at epoch 1000 with peak LR: 1.98e-03\n"
     ]
    }
   ],
   "source": [
    "# Training loop with Noam scheduler (epoch-based) - based on train_single_fold function\n",
    "print(\"Starting training with Noam scheduler (epoch-based)...\")\n",
    "\n",
    "# 실제 데이터셋 크기 기반 동적 가중치 계산\n",
    "train_samples = len(train_loader.dataset)\n",
    "val_samples = len(val_loader.dataset)\n",
    "total_samples = train_samples + val_samples\n",
    "\n",
    "train_weight = train_samples / total_samples\n",
    "val_weight = val_samples / total_samples\n",
    "\n",
    "print(f\"데이터 분포 - Train: {train_samples}({train_weight:.3f}), Val: {val_samples}({val_weight:.3f})\")\n",
    "\n",
    "best_total_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "total_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 에포크 시작 시 학습률 업데이트\n",
    "    current_lr = scheduler.step_epoch()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "    \n",
    "    for input_seq, seq_lengths in train_loader:\n",
    "        try:\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_lengths = seq_lengths.to(device)\n",
    "            \n",
    "            # Teacher forcing 데이터 준비 (전류 제외한 input, 전류 포함한 target)\n",
    "            inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs, target_seq_lengths)\n",
    "            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 그래디언트 클리핑\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Training batch error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if train_batches == 0:\n",
    "        print(\"No valid training batches\")\n",
    "        break\n",
    "    \n",
    "    train_loss = train_loss / train_batches\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_seq, seq_lengths in val_loader:\n",
    "            try:\n",
    "                input_seq = input_seq.to(device)\n",
    "                seq_lengths = seq_lengths.to(device)\n",
    "                \n",
    "                inputs, targets, target_seq_lengths = prepare_teacher_forcing_data(input_seq, seq_lengths)\n",
    "                predictions = model(inputs, target_seq_lengths)\n",
    "                loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Validation batch error: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if val_batches == 0:\n",
    "        print(\"No valid validation batches\")\n",
    "        break\n",
    "    \n",
    "    val_loss = val_loss / val_batches\n",
    "    \n",
    "    # Total loss 계산 (실제 데이터 분포 기반 동적 가중치)\n",
    "    total_loss = train_weight * train_loss + val_weight * val_loss\n",
    "    \n",
    "    # 기록 저장\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    total_losses.append(total_loss)\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Early stopping (total_loss 기준)\n",
    "    if total_loss < best_total_loss:\n",
    "        best_total_loss = total_loss\n",
    "        best_train_loss = train_loss\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        # 베스트 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_bmed_noam_model.pth')\n",
    "        best_status = \" ★ NEW BEST\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        best_status = \"\"\n",
    "    \n",
    "    # Warmup 구간 표시\n",
    "    if epoch + 1 <= warmup_epochs:\n",
    "        warmup_status = \" [WARMUP]\"\n",
    "    else:\n",
    "        warmup_status = \"\"\n",
    "    \n",
    "    # 매 에포크마다 로깅 - best 성능 정보 포함\n",
    "    print(f\"Epoch {epoch+1:4d}: Train: {train_loss:.6f}, Val: {val_loss:.6f}, Total: {total_loss:.6f}, LR: {current_lr:.2e}{best_status}{warmup_status}\")\n",
    "    \n",
    "    # Best 성능 정보 추가 표시 (매 에포크)\n",
    "    if epoch == 0:\n",
    "        print(f\"          Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f} (Epoch {best_epoch})\")\n",
    "    elif total_loss < best_total_loss:\n",
    "        print(f\"          ✓ Updated Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f}\")\n",
    "    else:\n",
    "        print(f\"          Best: Train: {best_train_loss:.6f}, Val: {best_val_loss:.6f}, Total: {best_total_loss:.6f} (Epoch {best_epoch})\")\n",
    "    \n",
    "    # Early stopping 체크 (total_loss 기준)\n",
    "    if epoch >= min_epochs and patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Best Performance (Epoch {best_epoch}):\")\n",
    "print(f\"  Best Total Loss:  {best_total_loss:.6f}\")\n",
    "print(f\"  Best Train Loss:  {best_train_loss:.6f}\")\n",
    "print(f\"  Best Val Loss:    {best_val_loss:.6f}\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Final Performance (Epoch {len(train_losses)}):\")\n",
    "print(f\"  Final Total Loss: {total_losses[-1]:.6f}\")\n",
    "print(f\"  Final Train Loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"  Final Val Loss:   {val_losses[-1]:.6f}\")\n",
    "print(f\"  Final LR:         {current_lr:.2e}\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Warmup completed at epoch {warmup_epochs} with peak LR: {max(learning_rates):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1m06cppxd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Statistics ===\n",
      "Total epochs: 4442\n",
      "Best total loss: 0.000752\n",
      "Final train loss: 0.000696\n",
      "Final validation loss: 0.001528\n",
      "Final total loss: 0.000800\n",
      "Initial learning rate: 1.98e-06\n",
      "Final learning rate: 9.38e-04\n",
      "Max learning rate: 1.98e-03\n",
      "Min learning rate: 1.98e-06\n",
      "\n",
      "=== Noam Scheduler Analysis ===\n",
      "Model size (hidden_size): 256\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoamScheduler' object has no attribute 'warmup_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Noam Scheduler Analysis ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel size (hidden_size): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler.model_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarmup steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFactor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler.factor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m warmup_lr = scheduler.factor * (scheduler.model_size ** (-\u001b[32m0.5\u001b[39m) * scheduler.warmup_steps ** (-\u001b[32m0.5\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoamScheduler' object has no attribute 'warmup_steps'"
     ]
    }
   ],
   "source": [
    "# 학습 결과 시각화 - total_loss 포함\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. 손실 함수 변화 (train, val, total)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "axes[0, 0].plot(epochs, train_losses, label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(epochs, val_losses, label='Validation Loss', alpha=0.7)\n",
    "axes[0, 0].plot(epochs, total_losses, label='Total Loss (Weighted)', alpha=0.7, linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training, Validation, and Total Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 학습률 변화 (Noam scheduler)\n",
    "axes[0, 1].plot(epochs, learning_rates, label='Learning Rate', color='orange', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Learning Rate')\n",
    "axes[0, 1].set_title('Noam Scheduler Learning Rate')\n",
    "axes[0, 1].set_yscale('log')  # 로그 스케일로 표시\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 학습률과 Total 손실의 관계\n",
    "scatter = axes[1, 0].scatter(learning_rates, total_losses, alpha=0.6, c=epochs, cmap='viridis', s=30)\n",
    "axes[1, 0].set_xlabel('Learning Rate')\n",
    "axes[1, 0].set_ylabel('Total Loss')\n",
    "axes[1, 0].set_title('Learning Rate vs Total Loss')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter, ax=axes[1, 0])\n",
    "cbar1.set_label('Epoch')\n",
    "\n",
    "# 4. Train vs Validation Loss 산점도\n",
    "scatter2 = axes[1, 1].scatter(train_losses, val_losses, alpha=0.6, c=epochs, cmap='plasma', s=30)\n",
    "axes[1, 1].set_xlabel('Train Loss')\n",
    "axes[1, 1].set_ylabel('Validation Loss')\n",
    "axes[1, 1].set_title('Train vs Validation Loss')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "# 대각선 추가 (perfect correlation)\n",
    "min_loss = min(min(train_losses), min(val_losses))\n",
    "max_loss = max(max(train_losses), max(val_losses))\n",
    "axes[1, 1].plot([min_loss, max_loss], [min_loss, max_loss], 'r--', alpha=0.5, label='Perfect Correlation')\n",
    "axes[1, 1].legend()\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1, 1])\n",
    "cbar2.set_label('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 학습 통계 출력\n",
    "print(\"\\n=== Training Statistics ===\")\n",
    "print(f\"Total epochs: {len(train_losses)}\")\n",
    "print(f\"Best total loss: {best_total_loss:.6f}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.6f}\")\n",
    "print(f\"Final total loss: {total_losses[-1]:.6f}\")\n",
    "print(f\"Initial learning rate: {learning_rates[0]:.2e}\")\n",
    "print(f\"Final learning rate: {learning_rates[-1]:.2e}\")\n",
    "print(f\"Max learning rate: {max(learning_rates):.2e}\")\n",
    "print(f\"Min learning rate: {min(learning_rates):.2e}\")\n",
    "\n",
    "# Noam scheduler 특성 분석\n",
    "print(f\"\\n=== Noam Scheduler Analysis ===\")\n",
    "print(f\"Model size (hidden_size): {scheduler.model_size}\")\n",
    "print(f\"Warmup steps: {scheduler.warmup_steps}\")\n",
    "print(f\"Factor: {scheduler.factor}\")\n",
    "warmup_lr = scheduler.factor * (scheduler.model_size ** (-0.5) * scheduler.warmup_steps ** (-0.5))\n",
    "print(f\"Peak learning rate at warmup: {warmup_lr:.2e}\")\n",
    "\n",
    "# 데이터 분포 가중치 정보\n",
    "print(f\"\\n=== Data Distribution Weights ===\")\n",
    "print(f\"Train samples: {train_samples} (weight: {train_weight:.3f})\")\n",
    "print(f\"Validation samples: {val_samples} (weight: {val_weight:.3f})\")\n",
    "print(f\"Total loss formula: {train_weight:.3f} * train_loss + {val_weight:.3f} * val_loss\")\n",
    "\n",
    "# 최고 성능 에포크 찾기\n",
    "best_epoch = total_losses.index(min(total_losses)) + 1\n",
    "print(f\"\\n=== Best Performance ===\")\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "print(f\"Best total loss: {min(total_losses):.6f}\")\n",
    "print(f\"Train loss at best epoch: {train_losses[best_epoch-1]:.6f}\")\n",
    "print(f\"Val loss at best epoch: {val_losses[best_epoch-1]:.6f}\")\n",
    "print(f\"Learning rate at best epoch: {learning_rates[best_epoch-1]:.2e}\")\n",
    "\n",
    "# 모델 저장 정보\n",
    "print(f\"\\n=== Model Saved ===\")\n",
    "print(f\"Best model saved as: best_bmed_noam_model.pth\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
