{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbe9d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import optuna\n",
    "np.random.seed(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "306f65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    \"\"\"\n",
    "    Set the device to GPU if available, otherwise use CPU.\n",
    "\n",
    "    Returns:\n",
    "        device (torch.device): The device to use for training.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15c611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    \"\"\"\n",
    "    Load the data from the csv file and normalize the data.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the csv file.\n",
    "\n",
    "    Returns:\n",
    "        ndf (pd.DataFrame): The normalized data.\n",
    "        exp_num_list (list): List of experiment numbers in order.\n",
    "    \"\"\"\n",
    "    # raw data\n",
    "    df = pd.read_csv(name) \n",
    "\n",
    "    # normalized data\n",
    "    ndf = pd.DataFrame() \n",
    "\n",
    "    # the range of min-max normalization for each feature\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CBLA': {'min':0, 'max': df['CBLA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CAK': {'min':0, 'max': df['CAK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "    \n",
    "    # add experiment number and time\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t'] \n",
    "\n",
    "    # min-max normalization\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']: # min-max normalization\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "\n",
    "    # Get the unique experiment numbers in order\n",
    "    exp_num_list = sorted(ndf['exp'].unique())\n",
    "\n",
    "    return ndf, exp_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4bdecd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_const(ndf):\n",
    "    \"\"\"\n",
    "    Set the data sequences.\n",
    "\n",
    "    Args:\n",
    "        ndf (pd.DataFrame): The normalized data.\n",
    "\n",
    "    Returns:\n",
    "        sequences (list): The sequences of the data.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "    \n",
    "    # get the sequences of the data for each experiment\n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        sequences.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43e19a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Pad the sequences.\n",
    "\n",
    "    Args:\n",
    "        sequences (list): The sequences of the data.\n",
    "\n",
    "    Returns:\n",
    "        padded_sequences (torch.Tensor): The padded sequences.\n",
    "    \"\"\"\n",
    "    max_seq_len = max([len(seq) for seq in sequences])\n",
    "    seq_len = [len(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=-1)\n",
    "    \n",
    "    return padded_sequences, seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84d4489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    \"\"\"\n",
    "    Generate the dataset.\n",
    "\n",
    "    Args:\n",
    "        pad_seq (torch.Tensor): The padded sequences.\n",
    "        seq_len (list): The length of the sequences.\n",
    "\n",
    "    Returns:\n",
    "        dataset (torch.utils.data.Dataset): The dataset.\n",
    "    \"\"\"\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86eb9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(dataset, exp_num_list, batch_size=4):\n",
    "    \"\"\"\n",
    "    Split the dataset into train/val/test with 8:1:1 ratio\n",
    "    \n",
    "    Args:\n",
    "        dataset: TensorDataset\n",
    "        exp_num_list: list of experiment numbers\n",
    "        batch_size: batch size\n",
    "        random_state: random seed\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # required train experiment numbers\n",
    "    required_train_exps = [1, 3, 5, 6, 11, 15, 17, 19, 20, 40, 41, 42]\n",
    "    \n",
    "    # all experiment numbers\n",
    "    all_exps = exp_num_list\n",
    "    total_exps = len(all_exps)\n",
    "    \n",
    "    # batch_size\n",
    "    batch_size = math.ceil(len(dataset)/10)\n",
    "\n",
    "    # 8:1:1 ratio\n",
    "    train_count = int(total_exps * 0.8)\n",
    "    val_count = math.ceil(total_exps * 0.1)\n",
    "    \n",
    "    # remaining experiments\n",
    "    remaining_exps = [exp for exp in all_exps if exp not in required_train_exps]\n",
    "    \n",
    "    # number of experiments to add to train\n",
    "    additional_train_needed = train_count - len(required_train_exps)\n",
    "    \n",
    "    if additional_train_needed < 0:\n",
    "        raise ValueError(\"The number of required train experiments is greater than the total train set. Please adjust required_train_exps.\")\n",
    "    \n",
    "    # shuffle remaining experiments\n",
    "    np.random.shuffle(remaining_exps)\n",
    "    \n",
    "    # split remaining experiments into train, val, test\n",
    "    train_exps = required_train_exps + remaining_exps[:additional_train_needed]\n",
    "    val_exps = remaining_exps[additional_train_needed:additional_train_needed + val_count]\n",
    "    test_exps = remaining_exps[additional_train_needed + val_count:]\n",
    "    \n",
    "    print(f\"Actual split:\")\n",
    "    print(f\"  Train: {sorted(train_exps)} ({len(train_exps)} experiments)\")\n",
    "    print(f\"  Val: {sorted(val_exps)} ({len(val_exps)} experiments)\")  \n",
    "    print(f\"  Test: {sorted(test_exps)} ({len(test_exps)} experiments)\")\n",
    "    \n",
    "    # find indices of each experiment (exp_num_list and dataset have the same order)\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    for idx, exp in enumerate(all_exps):\n",
    "        if exp in train_exps:\n",
    "            train_indices.append(idx)\n",
    "        elif exp in val_exps:\n",
    "            val_indices.append(idx)\n",
    "        elif exp in test_exps:\n",
    "            test_indices.append(idx)\n",
    "    \n",
    "    # split dataset into train, val, test\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_indices)\n",
    "    \n",
    "    # create DataLoader\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nCompleted DataLoader creation:\")\n",
    "    print(f\"  Train: {len(train_subset) if train_subset else 0} sequences\")\n",
    "    print(f\"  Val: {len(val_subset) if val_subset else 0} sequences\")\n",
    "    print(f\"  Test: {len(test_subset) if test_subset else 0} sequences\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bda98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialStateExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    The module based on LSTM to extract hidden dynamics from the sequential pattern of BMED.\n",
    "    The hidden state of each step accumulates the information of all previous steps.\n",
    "\n",
    "    Args:\n",
    "        input_nodes (int): The number of input nodes.\n",
    "        hidden_nodes (int): The number of hidden nodes.\n",
    "        num_layers (int): The number of layers.\n",
    "        dropout (float): The dropout rate.\n",
    "    \n",
    "    Output:\n",
    "        hidden_states: [batch_size, seq_len, hidden_nodes] - hidden state of each step\n",
    "    \"\"\"\n",
    "    def __init__(self, input_nodes, hidden_nodes, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_nodes, hidden_nodes, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_nodes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        Extract the hidden state of each step from the sequential pattern of BMED.\n",
    "\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_nodes] - state sequence of BMED system\n",
    "            seq_len [batch_size] - length of each sequence\n",
    "\n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_nodes] - hidden state of each step\n",
    "        \"\"\"\n",
    "        # check the input shape\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        # Move the seq_len to CPU and transfer to integer\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "\n",
    "        # check the length of sequence\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f'Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths mut be positive')\n",
    "        \n",
    "        # pack the padded sequence\n",
    "        packed_input = pack_padded_sequence(x, seq_len_cpu, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "\n",
    "        # re-pad the sequence\n",
    "        lstm_out, output_lengths = pad_packed_sequence(packed_output, batch_first=True, total_length=x.size(1))\n",
    "\n",
    "        # Normalization and dropout\n",
    "        normed_output = self.layer_norm(lstm_out)\n",
    "        return self.dropout(normed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "29c0d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The module based on MLP to decode the hidden state to the physical change.\n",
    "\n",
    "    Args:\n",
    "        hidden_nodes (int): The number of hidden nodes.\n",
    "        output_nodes (int): The number of output nodes.\n",
    "        num_layers (int): The number of layers.\n",
    "        num_nodes (int): The number of nodes in the hidden layers.\n",
    "        dropout (float): The dropout rate.\n",
    "    \n",
    "    Output:\n",
    "        physical_changes: [batch_size, seq_len, output_nodes] - [dVA, dVB, dNALA, dNAK, dNBK, nI]\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_nodes, output_nodes, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_nodes\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # input layer: hidden_nodes -> num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_nodes, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # hidden layers: num_nodes -> num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # output layer: num_nodes -> output_nodes\n",
    "        self.layers.append(nn.Linear(num_nodes, output_nodes))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Decode the hidden state to the physical change.\n",
    "\n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_nodes] - hidden state of each step\n",
    "\n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, output_nodes] - [dVA, dVB, dNALA, dNAK, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24efe327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    The module based on MLP to apply the physical constraints to the physical changes.\n",
    "\n",
    "    Output:\n",
    "        new_state: [batch_size, seq_len, 12] - new state\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps # prevent division by zero\n",
    "\n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        Apply the physical constraints to the physical changes.\n",
    "\n",
    "        Args:\n",
    "            physical_changes: [batch_size, seq_len, 7] - physical changes\n",
    "            current_state: [batch_size, seq_len, 12] - current state\n",
    "\n",
    "        Returns:\n",
    "            new_state: [batch_size, seq_len, 12] - new state\n",
    "        \"\"\"\n",
    "        # check the input shape\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 12:\n",
    "            raise ValueError(f\"Expected 12 state features, got {current_state.size(-1)}\")\n",
    "        \n",
    "        if physical_changes.size(-1) != 7:\n",
    "            raise ValueError(f\"Expected 7 physical changes, got {physical_changes.size(-1)}\")\n",
    "\n",
    "        \n",
    "        # extract the current state variables (keep the dimension)\n",
    "        V = current_state[..., 0:1]     # Voltage (fixed)\n",
    "        E = current_state[..., 1:2]     # External electrolyte concentration (fixed)\n",
    "        VF = current_state[..., 2:3]    # Feed volume\n",
    "        VA = current_state[..., 3:4]    # Acid volume\n",
    "        VB = current_state[..., 4:5]    # Base volume\n",
    "        CFLA = current_state[..., 5:6]  # LA concentration in Feed tank\n",
    "        CALA = current_state[..., 6:7]  # LA concentration in Acid tank\n",
    "        CBLA = current_state[..., 7:8]  # LA concentration in Base tank\n",
    "        CFK = current_state[..., 8:9]   # K concentration in Feed tank\n",
    "        CAK = current_state[..., 9:10]  # K concentration in Acid tank\n",
    "        CBK = current_state[..., 10:11] # K concentration in Base tank\n",
    "        I = current_state[..., 11:12]   # Current\n",
    "\n",
    "        # calculate the mole of ion species\n",
    "        NFLA = CFLA * VF; NALA = CALA * VA; NBLA = CBLA * VB\n",
    "        NFK = CFK * VF; NAK = CAK * VA; NBK = CBK * VB\n",
    "\n",
    "        # calculate the physical changes\n",
    "        dVA = physical_changes[..., 0:1]    # Acid tank volume change (bidirectional)\n",
    "        dVB = physical_changes[..., 1:2]    # Base tank volume change (bidirectional)\n",
    "        dNALA = physical_changes[..., 2:3]  # LA change in Acid tank (unidirectional)\n",
    "        dNBLA = physical_changes[..., 3:4]  # LA change in Base tank (unidirectional)\n",
    "        dNAK = physical_changes[..., 4:5]   # K change in Acid tank (unidirectional)\n",
    "        dNBK = physical_changes[..., 5:6]   # K change in Base tank (unidirectional)\n",
    "        nI = physical_changes[..., 6:7]     # New current value\n",
    "        \n",
    "        # calculate the new volume\n",
    "        nVF = VF - dVA - dVB  # New Feed tank volume \n",
    "        nVA = VA + dVA        # New Acid tank volume\n",
    "        nVB = VB + dVB        # New Base tank volume\n",
    "\n",
    "        # limit the ion species changes (unidirectional flow only)\n",
    "        dNALA = torch.clamp(dNALA, min=0)\n",
    "        dNBLA = torch.clamp(dNBLA, min=0)\n",
    "        dNAK = torch.clamp(dNAK, min=0)\n",
    "        dNBK = torch.clamp(dNBK, min=0)\n",
    "\n",
    "        # calculate the new mole of ion species\n",
    "        nNFLA = NFLA - dNALA - dNBLA  # New LA mole in Feed tank\n",
    "        nNALA = NALA + dNALA         # New LA mole in Acid tank\n",
    "        nNBLA = NBLA + dNBLA         # New LA mole in Base tank\n",
    "        nNFK = NFK - dNAK - dNBK     # New K mole in Feed tank\n",
    "        nNAK = NAK + dNAK            # New K mole in Acid tank\n",
    "        nNBK = NBK + dNBK            # New K mole in Base tank\n",
    "\n",
    "        # limit the physical changes\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNBLA = torch.clamp(nNBLA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNAK = torch.clamp(nNAK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # calculate the new concentration\n",
    "        nCFLA = nNFLA / nVF  # New LA concentration in Feed tank\n",
    "        nCALA = nNALA / nVA  # New LA concentration in Acid tank\n",
    "        nCBLA = nNBLA / nVB  # New LA concentration in Base tank\n",
    "        nCFK = nNFK / nVF    # New K concentration in Feed tank\n",
    "        nCAK = nNAK / nVA    # New K concentration in Acid tank\n",
    "        nCBK = nNBK / nVB    # New K concentration in Base tank\n",
    "\n",
    "        # assemble the new state\n",
    "        new_state = torch.cat([\n",
    "            V, E,  # fixed: voltage, external electrolyte concentration\n",
    "            nVF, nVA, nVB,  # new volume\n",
    "            nCFLA, nCALA, nCBLA,  # new LA concentration\n",
    "            nCFK, nCAK, nCBK,     # new K concentration\n",
    "            nI  # new current\n",
    "        ], dim=-1)\n",
    "\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40224782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The autoregressive model to predict the state of BMED system.\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = SequentialStateExtractor(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_state, seq_lengths):\n",
    "        \"\"\"\n",
    "        Predict the next step from the all previous steps.\n",
    "\n",
    "        Args:\n",
    "            current_state: [batch_size, seq_len, 12] - current state\n",
    "            seq_lengths: [batch_size] - length of each sequence\n",
    "\n",
    "        Returns:\n",
    "            new_state: [batch_size, seq_len, 12] - new state\n",
    "        \"\"\"\n",
    "        # Extract the hidden state of each step using LSTM\n",
    "        hidden_states = self.state_extractor(current_state, seq_lengths)\n",
    "        # Decode the hidden state to the physical change\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        # Calculate the new state using physical constraints\n",
    "        new_state = self.physics_constraint(physical_changes, current_state)\n",
    "\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa444f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(pred, target, seq_len):\n",
    "    \"\"\"\n",
    "    Calculate the masked MSE loss for the autoregressive model.\n",
    "\n",
    "    Args:\n",
    "        pred: [batch_size, seq_len, 12] - predicted state\n",
    "        target: [batch_size, seq_len, 12] - target state\n",
    "        seq_len: [batch_size] - length of each sequence\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: average loss excluding the masked parts\n",
    "    \"\"\"\n",
    "    # check the input shape\n",
    "    if pred.shape != target.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {pred.shape} vs targets {target.shape}\")\n",
    "\n",
    "    if pred.size(0) != seq_len.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {pred.size(0)} vs sequence lengths {seq_len.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = pred.shape\n",
    "\n",
    "    # Move seq_len to CPU to be compatible with arange.\n",
    "    seq_len_cpu = seq_len.detach().cpu().long()\n",
    "\n",
    "    # Validation check on sequence lengths\n",
    "    if (seq_len_cpu <= 0).any():\n",
    "        invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "        raise ValueError(f'Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.')\n",
    "\n",
    "    # Check if any sequence length exceeds max_len\n",
    "    if (seq_len_cpu > max_len).any():\n",
    "        invalid_lengths = seq_len_cpu[seq_len_cpu > max_len]\n",
    "        raise ValueError(f'Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}')\n",
    "\n",
    "    # Generate mask as long as the sequence length\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_len_cpu[:, None]\n",
    "    mask = mask.float().to(pred.device)\n",
    "\n",
    "    # Calculate the MSE of each feature\n",
    "    loss = F.mse_loss(pred, target, reduction='none')\n",
    "\n",
    "    # Apply the mask to exclude the masked parts\n",
    "    masked_loss_sum = (loss * mask.unsqueeze(-1)).sum()\n",
    "    valid_elements = mask.sum() * features\n",
    "\n",
    "    if valid_elements == 0:\n",
    "        raise ValueError('No valid elements found after masking. Check sequence lengths and data.')\n",
    "    \n",
    "    masked_loss = masked_loss_sum / valid_elements\n",
    "\n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ae9fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_running_data(input_seq, seq_len):\n",
    "    \"\"\"\n",
    "    Prepare the data for free running .\n",
    "\n",
    "    Args:\n",
    "        input_seq: [batch_size, seq_len, 12] - input sequences\n",
    "        seq_lengths: [batch_size] - length of each sequence\n",
    "\n",
    "    Returns:\n",
    "        init: [t0] initial state\n",
    "        targets: [t1, t2, ..., t_n] next states\n",
    "        target_seq_len: length of each target sequence\n",
    "    \"\"\"\n",
    "    # initial state\n",
    "    init = input_seq[:, 0, :]\n",
    "    # target states\n",
    "    targets = input_seq[:, 1:, :]\n",
    "    # length of each target sequence\n",
    "    if (seq_len - 1 < 1).any():\n",
    "        invalid_lengths = seq_len[seq_len - 1 < 1]\n",
    "        raise ValueError(f'The length of target sequence cannot be less than 1. Wrong seq_len: {invalid_lengths.tolist()}')\n",
    "    target_seq_len = seq_len - 1\n",
    "\n",
    "    return init, targets, target_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c09a5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_running_prediction(model, init, targets_shape, device, mode='eval'):\n",
    "    \"\"\"\n",
    "    Free running prediction using only initial state with different modes.\n",
    "    \n",
    "    Args:\n",
    "        model: BMEDAutoregressiveModel\n",
    "        initial_state: [batch_size, 12] - initial state\n",
    "        targets_shape: tuple - shape of targets to match (batch_size, seq_len, features)\n",
    "        device: computation device\n",
    "        mode: 'eval' (evaluation), 'train' (training), 'simulation' (pure inference)\n",
    "        \n",
    "    Returns:\n",
    "        predictions: [batch_size, targets_seq_len, 12] - predicted sequence\n",
    "    \"\"\"\n",
    "    # Set model mode\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "        context_manager = torch.enable_grad()\n",
    "    elif mode in ['eval', 'simulation']:\n",
    "        model.eval()\n",
    "        context_manager = torch.no_grad()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}. Choose from 'train', 'eval', 'simulation'\")\n",
    "    \n",
    "    batch_size = init.size(0)\n",
    "    num_steps = targets_shape[1]  # Use the actual targets sequence length\n",
    "    \n",
    "    # Initialize predictions with initial state\n",
    "    pred = [init.unsqueeze(1)]  # [batch_size, 1, 12]\n",
    "    current_state = init.unsqueeze(1)  # [batch_size, 1, 12]\n",
    "    \n",
    "    with context_manager:\n",
    "        for step in range(num_steps):\n",
    "            # Predict next state using current sequence\n",
    "            seq_len = torch.full((batch_size,), current_state.size(1), device=device)\n",
    "            next_state = model(current_state, seq_len)\n",
    "            \n",
    "            # Take the last predicted state\n",
    "            next_step = next_state[:, -1:, :]  # [batch_size, 1, 12]\n",
    "            pred.append(next_step)\n",
    "            \n",
    "            # Update current state sequence\n",
    "            current_state = torch.cat([current_state, next_step], dim=1)\n",
    "    \n",
    "    # Return all predictions except the initial state\n",
    "    return torch.cat(pred[1:], dim=1)  # [batch_size, num_steps, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8bd5a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_free_running(model, train_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model using free running approach for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: BMEDAutoregressiveModel\n",
    "        train_loader: training data loader\n",
    "        optimizer: optimizer\n",
    "        device: computation device\n",
    "        \n",
    "    Returns:\n",
    "        float: average training loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (input_seq, seq_len) in enumerate(train_loader):\n",
    "        input_seq = input_seq.to(device)\n",
    "        seq_len = seq_len.to(device)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Prepare free running data\n",
    "        init, targets, target_seq_len = free_running_data(input_seq, seq_len)\n",
    "        \n",
    "        # Free running prediction in train mode\n",
    "        pred = free_running_prediction(\n",
    "            model, init, targets.shape, device, mode='train'\n",
    "        )\n",
    "        \n",
    "        # Calculate masked loss\n",
    "        loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "\n",
    "def validate_epoch_free_running(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Validate the model using free running approach for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: BMEDAutoregressiveModel\n",
    "        val_loader: validation data loader\n",
    "        device: computation device\n",
    "        \n",
    "    Returns:\n",
    "        float: average validation loss for the epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_seq, seq_len) in enumerate(val_loader):\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_len = seq_len.to(device)\n",
    "            \n",
    "            # Prepare free running data\n",
    "            init, targets, target_seq_len = free_running_data(input_seq, seq_len)\n",
    "            \n",
    "            # Free running prediction in eval mode\n",
    "            pred = free_running_prediction(\n",
    "                model, init, targets.shape, device, mode='eval'\n",
    "            )\n",
    "            \n",
    "            # Calculate masked loss\n",
    "            loss = masked_mse_loss(pred, targets, target_seq_len)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "lmpjx6tmfq",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_free_running_model(model, train_loader, val_loader, optimizer, scheduler, device, \n",
    "                             num_epochs=200, patience=20, min_epochs=10):\n",
    "    \"\"\"\n",
    "    Complete training loop for free running model.\n",
    "    \n",
    "    Args:\n",
    "        model: BMEDAutoregressiveModel\n",
    "        train_loader: training data loader\n",
    "        val_loader: validation data loader\n",
    "        optimizer: optimizer\n",
    "        scheduler: learning rate scheduler\n",
    "        device: computation device\n",
    "        num_epochs: maximum number of epochs\n",
    "        patience: early stopping patience\n",
    "        min_epochs: minimum epochs before early stopping\n",
    "        \n",
    "    Returns:\n",
    "        dict: training history and best model state\n",
    "    \"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"Starting Free Running Training...\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Max Epochs: {num_epochs}, Patience: {patience}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        train_loss = train_epoch_free_running(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = validate_epoch_free_running(model, val_loader, device)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # Record history\n",
    "        train_history.append(train_loss)\n",
    "        val_history.append(val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0 or epoch < 10:\n",
    "            print(f\"Epoch {epoch+1:3d}/{num_epochs}: \"\n",
    "                  f\"Train Loss = {train_loss:.6f}, \"\n",
    "                  f\"Val Loss = {val_loss:.6f}, \"\n",
    "                  f\"Best Val = {best_val_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch >= min_epochs and patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Training completed!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_history': train_history,\n",
    "        'val_history': val_history,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_model_state': best_model_state,\n",
    "        'final_epoch': epoch + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b63c56fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Dataset created with 39 experiments\n",
      "Max sequence length: 37\n",
      "Experiment numbers: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(27), np.int64(28), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(40), np.int64(41), np.int64(42), np.int64(43)]\n",
      "Actual split:\n",
      "  Train: [1, 3, np.int64(4), 5, 6, np.int64(7), np.int64(8), np.int64(9), np.int64(10), 11, np.int64(13), np.int64(14), 15, 17, np.int64(18), 19, 20, np.int64(21), np.int64(22), np.int64(24), np.int64(27), np.int64(28), np.int64(30), np.int64(32), np.int64(34), np.int64(35), np.int64(37), np.int64(38), 40, 41, 42] (31 experiments)\n",
      "  Val: [np.int64(2), np.int64(16), np.int64(31), np.int64(33)] (4 experiments)\n",
      "  Test: [np.int64(12), np.int64(23), np.int64(25), np.int64(36), np.int64(43)] (5 experiments)\n",
      "\n",
      "Completed DataLoader creation:\n",
      "  Train: 30 sequences\n",
      "  Val: 4 sequences\n",
      "  Test: 5 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load data and create dataloaders\n",
    "print(\"Loading and preprocessing data...\")\n",
    "ndf, exp_num_list = norm_data('BMED_DATA_AG.csv')\n",
    "sequences = seq_data_const(ndf)\n",
    "padded_seq, seq_len, max_seq_len = padded_sequences(sequences)\n",
    "dataset = gen_dataset(padded_seq, seq_len)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} experiments\")\n",
    "print(f\"Max sequence length: {max_seq_len}\")\n",
    "print(f\"Experiment numbers: {sorted(exp_num_list)}\")\n",
    "\n",
    "# Create train/val/test dataloaders with stratified split\n",
    "train_loader, val_loader, test_loader = dataloaders(dataset, exp_num_list, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12e02d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER\n",
      "Model initialized with 289767 parameters\n",
      "Model on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and training setup\n",
    "device = set_device()\n",
    "\n",
    "study = optuna.load_study(study_name=\"bmed_autoregressive_optimization\", storage=\"sqlite:///bmed_optuna_study.db\")\n",
    "best_params = study.best_params\n",
    "\n",
    "# Model parameters\n",
    "state_extractor_params = {\n",
    "    'input_nodes': 12,\n",
    "    'hidden_nodes': best_params['hidden_size'],\n",
    "    'num_layers': best_params['num_layers'],\n",
    "    'dropout': best_params['extractor_dropout']\n",
    "}\n",
    "\n",
    "decoder_params = {\n",
    "    'hidden_nodes': best_params['hidden_size'],\n",
    "    'output_nodes': 7,  # [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "    'num_layers': best_params['decoder_layers'],\n",
    "    'num_nodes': best_params['decoder_nodes'],\n",
    "    'dropout': best_params['decoder_dropout']\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = BMEDAutoregressiveModel(state_extractor_params, decoder_params)\n",
    "model = model.to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c41192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting Free Running Training...\n",
      "Starting Free Running Training...\n",
      "Device: cuda\n",
      "Max Epochs: 10000, Patience: 1500\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/10000: Train Loss = 998972391176944.000000, Val Loss = 85333745664.000000, Best Val = 85333745664.000000\n",
      "Epoch   2/10000: Train Loss = 127570058552.000000, Val Loss = 3725119744.000000, Best Val = 3725119744.000000\n",
      "Epoch   3/10000: Train Loss = 1151549779736.000000, Val Loss = 3725119488.000000, Best Val = 3725119488.000000\n",
      "Epoch   4/10000: Train Loss = 4652270500464.000000, Val Loss = 82155770216448.000000, Best Val = 3725119488.000000\n",
      "Epoch   5/10000: Train Loss = 98349744652288.000000, Val Loss = 82155770216448.000000, Best Val = 3725119488.000000\n",
      "Epoch   6/10000: Train Loss = 107561571975168.000000, Val Loss = 82155770216448.000000, Best Val = 3725119488.000000\n",
      "Epoch   7/10000: Train Loss = 99494431031296.000000, Val Loss = 82155770216448.000000, Best Val = 3725119488.000000\n",
      "Epoch   8/10000: Train Loss = 99418712309760.000000, Val Loss = 78031469150208.000000, Best Val = 3725119488.000000\n",
      "Epoch   9/10000: Train Loss = 89870528151552.000000, Val Loss = 82152230223872.000000, Best Val = 3725119488.000000\n",
      "Epoch  10/10000: Train Loss = 98435685941248.000000, Val Loss = 82152230223872.000000, Best Val = 3725119488.000000\n",
      "Epoch  20/10000: Train Loss = 93302091284480.000000, Val Loss = 32934274793472.000000, Best Val = 3725119488.000000\n",
      "Epoch  30/10000: Train Loss = 99503047180288.000000, Val Loss = 82152230223872.000000, Best Val = 3725119488.000000\n",
      "Epoch  40/10000: Train Loss = 13903433605124.505859, Val Loss = 4.394309, Best Val = 4.394309\n",
      "Epoch  50/10000: Train Loss = 66802647696.500000, Val Loss = 3725119488.000000, Best Val = 0.850390\n",
      "Epoch  60/10000: Train Loss = 63083592618.000000, Val Loss = 3725119488.000000, Best Val = 0.850390\n",
      "Epoch  70/10000: Train Loss = 60475423914.000000, Val Loss = 1940487680.000000, Best Val = 0.850390\n",
      "Epoch  80/10000: Train Loss = 61050386726.000000, Val Loss = 3352630272.000000, Best Val = 0.850390\n",
      "Epoch  90/10000: Train Loss = 23099623658.562500, Val Loss = 0.463566, Best Val = 0.463566\n",
      "Epoch 100/10000: Train Loss = 1365115551.820821, Val Loss = 3659026.250000, Best Val = 0.463566\n",
      "Epoch 110/10000: Train Loss = 64990590276.000000, Val Loss = 3725119488.000000, Best Val = 0.317827\n",
      "Epoch 120/10000: Train Loss = 56915931924.000000, Val Loss = 3360281344.000000, Best Val = 0.317827\n",
      "Epoch 130/10000: Train Loss = 68643857632.000000, Val Loss = 3538744832.000000, Best Val = 0.317827\n",
      "Epoch 140/10000: Train Loss = 58111277336.000000, Val Loss = 3538744832.000000, Best Val = 0.317827\n",
      "Epoch 150/10000: Train Loss = 16124496277.000000, Val Loss = 1117654528.000000, Best Val = 0.317827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start free running training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸš€ Starting Free Running Training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m training_results = \u001b[43mtrain_free_running_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_results[\u001b[33m'\u001b[39m\u001b[33mbest_model_state\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_free_running_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, patience, min_epochs)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     train_loss = \u001b[43mtrain_epoch_free_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m     36\u001b[39m     val_loss = validate_epoch_free_running(model, val_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_epoch_free_running\u001b[39m\u001b[34m(model, train_loader, optimizer, device)\u001b[39m\n\u001b[32m     26\u001b[39m init, targets, target_seq_len = free_running_data(input_seq, seq_len)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Free running prediction in train mode\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m pred = \u001b[43mfree_running_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     31\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Calculate masked loss\u001b[39;00m\n\u001b[32m     34\u001b[39m loss = masked_mse_loss(pred, targets, target_seq_len)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mfree_running_prediction\u001b[39m\u001b[34m(model, init, targets_shape, device, mode)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Predict next state using current sequence\u001b[39;00m\n\u001b[32m     35\u001b[39m     seq_len = torch.full((batch_size,), current_state.size(\u001b[32m1\u001b[39m), device=device)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     next_state = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Take the last predicted state\u001b[39;00m\n\u001b[32m     39\u001b[39m     next_step = next_state[:, -\u001b[32m1\u001b[39m:, :]  \u001b[38;5;66;03m# [batch_size, 1, 12]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mBMEDAutoregressiveModel.forward\u001b[39m\u001b[34m(self, current_state, seq_lengths)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03mPredict the next step from the all previous steps.\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33;03m    new_state: [batch_size, seq_len, 12] - new state\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Extract the hidden state of each step using LSTM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Decode the hidden state to the physical change\u001b[39;00m\n\u001b[32m     25\u001b[39m physical_changes = \u001b[38;5;28mself\u001b[39m.physical_decoder(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mSequentialStateExtractor.forward\u001b[39m\u001b[34m(self, x, seq_len)\u001b[39m\n\u001b[32m     51\u001b[39m packed_output, (hidden, cell) = \u001b[38;5;28mself\u001b[39m.lstm(packed_input)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# re-pad the sequence\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m lstm_out, output_lengths = \u001b[43mpad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Normalization and dropout\u001b[39;00m\n\u001b[32m     57\u001b[39m normed_output = \u001b[38;5;28mself\u001b[39m.layer_norm(lstm_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/nn/utils/rnn.py:412\u001b[39m, in \u001b[36mpad_packed_sequence\u001b[39m\u001b[34m(sequence, batch_first, padding_value, total_length)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    409\u001b[39m     batch_dim = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    411\u001b[39m         padded_output.index_select(batch_dim, unsorted_indices),\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m         lengths[\u001b[43munsorted_indices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[32m    413\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m padded_output, lengths\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Start free running training\n",
    "print(\"\\nðŸš€ Starting Free Running Training...\")\n",
    "training_results = train_free_running_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=10000,\n",
    "    patience=1500,\n",
    "    min_epochs=500\n",
    ")\n",
    "\n",
    "# Load best model\n",
    "if training_results['best_model_state'] is not None:\n",
    "    model.load_state_dict(training_results['best_model_state'])\n",
    "    print(\"âœ… Best model loaded!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No best model found, using current state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e2776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¬ Testing Free Running Simulation on Test Data...\n",
      "Test batch shape: torch.Size([4, 37, 12])\n",
      "Test sequence lengths: tensor([29, 29, 37, 25], device='cuda:0')\n",
      "Initial state shape: torch.Size([4, 12])\n",
      "Targets shape: torch.Size([4, 36, 12])\n",
      "ðŸŽ¯ Running free running simulation...\n",
      "Predictions shape: torch.Size([4, 36, 12])\n",
      "ðŸ“Š Test Loss: 46914347204608.000000\n",
      "âœ… Simulation completed!\n"
     ]
    }
   ],
   "source": [
    "# Test simulation on test data\n",
    "print(\"\\nðŸ”¬ Testing Free Running Simulation on Test Data...\")\n",
    "\n",
    "# Get first batch from test loader for simulation\n",
    "test_batch = next(iter(test_loader))\n",
    "test_input, test_seq_len = test_batch\n",
    "test_input = test_input.to(device)\n",
    "test_seq_len = test_seq_len.to(device)\n",
    "\n",
    "print(f\"Test batch shape: {test_input.shape}\")\n",
    "print(f\"Test sequence lengths: {test_seq_len}\")\n",
    "\n",
    "# Prepare test data for simulation\n",
    "initial_state, targets, target_seq_len = free_running_data(test_input, test_seq_len)\n",
    "\n",
    "print(f\"Initial state shape: {initial_state.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "# Run simulation\n",
    "print(\"ðŸŽ¯ Running free running simulation...\")\n",
    "with torch.no_grad():\n",
    "    predictions = free_running_prediction(\n",
    "        model, initial_state, targets.shape, device, mode='simulation'\n",
    "    )\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "\n",
    "# Calculate test loss\n",
    "test_loss = masked_mse_loss(predictions, targets, target_seq_len)\n",
    "print(f\"ðŸ“Š Test Loss: {test_loss:.6f}\")\n",
    "\n",
    "print(\"âœ… Simulation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
