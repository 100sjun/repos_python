{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    \"\"\"ë°ì´í„° ë¡œë“œ ë° ì •ê·œí™”\"\"\"\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CBLA': {'min':0, 'max': df['CBLA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CAK': {'min':0, 'max': df['CAK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "    return ndf, range_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_const(ndf):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ ë°ì´í„° êµ¬ì„±\"\"\"\n",
    "    sequences = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        sequences.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(sequences):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ íŒ¨ë”© ì²˜ë¦¬\"\"\"\n",
    "    max_seq_len = max([len(seq) for seq in sequences])\n",
    "    seq_len = [len(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return padded_sequences, seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    \"\"\"ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_dataloaders(dataset, k_folds=5, batch_size=4, random_state=87):\n",
    "    \"\"\"K-fold êµì°¨ê²€ì¦ì„ ìœ„í•œ ë°ì´í„°ë¡œë” ìƒì„±\"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "    dataloaders = []\n",
    "    batch_size = math.ceil(len(dataset)/k_folds)\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(kfold.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}: Train size = {len(train_indices)}, Val size = {len(val_indices)}\")\n",
    "        \n",
    "        # Create subsets for train and validation\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        val_subset = Subset(dataset, val_indices)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialStateExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED ì‹œìŠ¤í…œì˜ ì‹œê³„ì—´ íŒ¨í„´ì—ì„œ ìˆ¨ê²¨ì§„ dynamicsë¥¼ ì¶”ì¶œí•˜ëŠ” LSTM ê¸°ë°˜ ëª¨ë“ˆ\n",
    "    ê° ì‹œì ì˜ hidden stateì—ëŠ” í•´ë‹¹ ì‹œì ê¹Œì§€ì˜ ëª¨ë“  ê³¼ê±° ì •ë³´ê°€ ëˆ„ì ë¨\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with improved error handling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        ì‹œê³„ì—´ ìƒíƒœ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê° ì‹œì ì˜ hidden state ì¶”ì¶œ\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size] - BMED ì‹œìŠ¤í…œ ìƒíƒœ ì‹œí€€ìŠ¤\n",
    "            seq_len: [batch_size] - ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´\n",
    "            \n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - ê° ì‹œì ì˜ ëˆ„ì ëœ hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        # ì…ë ¥ ê²€ì¦\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        # seq_lenì„ CPUë¡œ ì´ë™í•˜ê³  ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        \n",
    "        # ì‹œí€€ìŠ¤ ê¸¸ì´ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ë¥¼ packí•˜ì—¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "        packed_input = pack_padded_sequence(\n",
    "            x, seq_len_cpu, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # ë‹¤ì‹œ íŒ¨ë”©ëœ í˜•íƒœë¡œ ë³µì›\n",
    "        lstm_out, output_lengths = pad_packed_sequence(\n",
    "            packed_output, batch_first=True, total_length=x.size(1)\n",
    "        )\n",
    "        \n",
    "        # Normalization and dropout\n",
    "        normalized = self.layer_norm(lstm_out)\n",
    "        return self.dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden stateë¡œë¶€í„° BMED ì‹œìŠ¤í…œì˜ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ê³¼ ìƒˆë¡œìš´ ì „ë¥˜ê°’ì„ ë””ì½”ë”©í•˜ëŠ” MLP\n",
    "    ì¶œë ¥: [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI] - 7ê°œ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # ì²« ë²ˆì§¸ ë ˆì´ì–´: hidden_size â†’ num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # ì¤‘ê°„ ì€ë‹‰ì¸µë“¤: num_nodes â†’ num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # ë§ˆì§€ë§‰ ì¶œë ¥ì¸µ: num_nodes â†’ output_size (7ê°œ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰)\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - ì‹œì ë³„ hidden state\n",
    "            \n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, 7] - ë¬¼ë¦¬ì  ë³€í™”ëŸ‰\n",
    "                [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ì„ ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœë¡œ ë³€í™˜í•˜ë©´ì„œ ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ì„ ì ìš©\n",
    "    Bipolar membrane electrodialysis ì‹œìŠ¤í…œì˜ ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-1):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # division by zero ë°©ì§€\n",
    "        \n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ì„ í˜„ì¬ ìƒíƒœì— ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "        \n",
    "        Args:\n",
    "            physical_changes: [batch, seq, 7] - [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "            current_state: [batch, seq, 12] - í˜„ì¬ BMED ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "                V: ì „ì•• (Voltage) - ì‹¤í—˜ ì„¸íŠ¸ë³„ ê³ ì •ê°’\n",
    "                E: ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„ (External electrolyte concentration) - ì‹¤í—˜ ì„¸íŠ¸ë³„ ê³ ì •ê°’  \n",
    "                VF, VA, VB: Feed, Acid, Base ë¶€í”¼\n",
    "                CFLA, CALA, CBLA: Feed, Acid, Baseì˜ LA ë†ë„\n",
    "                CFK, CAK, CBK: Feed, Acid, Baseì˜ K ë†ë„\n",
    "                I: ì „ë¥˜\n",
    "                \n",
    "        Returns:\n",
    "            next_state: [batch, seq, 12] - ë¬¼ë¦¬ ì œì•½ì´ ì ìš©ëœ ë‹¤ìŒ ìƒíƒœ\n",
    "        \"\"\"\n",
    "        # ì…ë ¥ ì°¨ì› ê²€ì¦\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 12:\n",
    "            raise ValueError(f\"Expected 12 state features, got {current_state.size(-1)}\")\n",
    "            \n",
    "        if physical_changes.size(-1) != 7:\n",
    "            raise ValueError(f\"Expected 7 physical changes, got {physical_changes.size(-1)}\")\n",
    "        \n",
    "        # í˜„ì¬ ìƒíƒœ ë³€ìˆ˜ ì¶”ì¶œ (ì°¨ì› ìœ ì§€)\n",
    "        V = current_state[..., 0:1]     # ì „ì•• (ê³ ì •ê°’)\n",
    "        E = current_state[..., 1:2]     # ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„ (ê³ ì •ê°’)\n",
    "        VF = current_state[..., 2:3]    # Feed ë¶€í”¼\n",
    "        VA = current_state[..., 3:4]    # Acid ë¶€í”¼\n",
    "        VB = current_state[..., 4:5]    # Base ë¶€í”¼\n",
    "        CFLA = current_state[..., 5:6]  # Feed LA ë†ë„\n",
    "        CALA = current_state[..., 6:7]  # Acid LA ë†ë„\n",
    "        CBLA = current_state[..., 7:8]  # Base LA ë†ë„\n",
    "        CFK = current_state[..., 8:9]   # Feed K ë†ë„\n",
    "        CAK = current_state[..., 9:10]  # Acid K ë†ë„\n",
    "        CBK = current_state[..., 10:11] # Base K ë†ë„\n",
    "        I = current_state[..., 11:12]   # ì „ë¥˜\n",
    "\n",
    "        # ë¬¼ì§ˆëŸ‰ ê³„ì‚° (ë†ë„ Ã— ë¶€í”¼)\n",
    "        NFLA = CFLA * VF; NALA = CALA * VA; NBLA = CBLA * VB\n",
    "        NFK = CFK * VF; NAK = CAK * VA; NBK = CBK * VB\n",
    "\n",
    "        # ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ ì¶”ì¶œ\n",
    "        dVA = physical_changes[..., 0:1]    # Acid ë¶€í”¼ ë³€í™”ëŸ‰ (ì–‘ë°©í–¥ ê°€ëŠ¥: ìŒìˆ˜ë©´ Aâ†’F)\n",
    "        dVB = physical_changes[..., 1:2]    # Base ë¶€í”¼ ë³€í™”ëŸ‰ (ì–‘ë°©í–¥ ê°€ëŠ¥: ìŒìˆ˜ë©´ Bâ†’F)\n",
    "        dNALA = physical_changes[..., 2:3]  # Acid LA ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Aë§Œ)\n",
    "        dNBLA = physical_changes[..., 3:4]  # Base LA ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Bë§Œ)\n",
    "        dNAK = physical_changes[..., 4:5]   # Acid K ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Aë§Œ)\n",
    "        dNBK = physical_changes[..., 5:6]   # Base K ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Bë§Œ)\n",
    "        nI = physical_changes[..., 6:7]     # ìƒˆë¡œìš´ ì „ë¥˜ê°’\n",
    "\n",
    "        # ìƒˆë¡œìš´ ë¶€í”¼ ê³„ì‚° (ì–‘ë°©í–¥ íë¦„ í—ˆìš©)\n",
    "        nVF = VF - dVA - dVB  # dVA, dVBê°€ ìŒìˆ˜ë©´ Fë¡œ ì—­ìœ ì…\n",
    "        nVA = VA + dVA        # dVAê°€ ìŒìˆ˜ë©´ Aì—ì„œ Fë¡œ ìœ ì¶œ\n",
    "        nVB = VB + dVB        # dVBê°€ ìŒìˆ˜ë©´ Bì—ì„œ Fë¡œ ìœ ì¶œ\n",
    "        \n",
    "        # ë¬¼ì§ˆ ì´ë™ëŸ‰ì„ ì¼ë°©í–¥ìœ¼ë¡œ ì œí•œ (Fâ†’A, Fâ†’Bë§Œ í—ˆìš©)\n",
    "        dNALA_clipped = torch.clamp(dNALA, min=0)  # ìŒìˆ˜ ì œê±° (ì—­ë°©í–¥ ë¶ˆê°€)\n",
    "        dNBLA_clipped = torch.clamp(dNBLA, min=0)\n",
    "        dNAK_clipped = torch.clamp(dNAK, min=0)\n",
    "        dNBK_clipped = torch.clamp(dNBK, min=0)\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ë¬¼ì§ˆëŸ‰ ê³„ì‚° (ì¼ë°©í–¥ ì´ë™ë§Œ)\n",
    "        nNFLA = NFLA - dNALA_clipped - dNBLA_clipped  # Feedì—ì„œ ìœ ì¶œë§Œ\n",
    "        nNALA = NALA + dNALA_clipped                  # Acidë¡œ ìœ ì…ë§Œ\n",
    "        nNBLA = NBLA + dNBLA_clipped                  # Baseë¡œ ìœ ì…ë§Œ\n",
    "        nNFK = NFK - dNAK_clipped - dNBK_clipped      # Kë„ ë§ˆì°¬ê°€ì§€\n",
    "        nNAK = NAK + dNAK_clipped\n",
    "        nNBK = NBK + dNBK_clipped\n",
    "        \n",
    "        # ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ ì ìš© (ì–‘ìˆ˜ ìœ ì§€)\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        \n",
    "        # ë¬¼ì§ˆëŸ‰ ìŒìˆ˜ ë°©ì§€\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNBLA = torch.clamp(nNBLA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNAK = torch.clamp(nNAK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ë†ë„ ê³„ì‚° (ë†ë„ = ë¬¼ì§ˆëŸ‰ / ë¶€í”¼)\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCBLA = nNBLA / nVB\n",
    "        nCFK = nNFK / nVF\n",
    "        nCAK = nNAK / nVA\n",
    "        nCBK = nNBK / nVB\n",
    "        \n",
    "        # ì „ë¥˜ëŠ” ì–‘ìˆ˜ ì œì•½\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # ìƒˆë¡œìš´ ìƒíƒœ ì¡°ë¦½ (V, EëŠ” ê³ ì •ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "        next_state = torch.cat([\n",
    "            V, E,  # ê³ ì •ê°’: ì „ì••, ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„\n",
    "            nVF, nVA, nVB,  # ìƒˆë¡œìš´ ë¶€í”¼ (ì–‘ë°©í–¥ íë¦„ ë°˜ì˜)\n",
    "            nCFLA, nCALA, nCBLA,  # ìƒˆë¡œìš´ LA ë†ë„\n",
    "            nCFK, nCAK, nCBK,     # ìƒˆë¡œìš´ K ë†ë„\n",
    "            nI  # ìƒˆë¡œìš´ ì „ë¥˜\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED ì‹œìŠ¤í…œì˜ ì‹œê³„ì—´ ìƒíƒœ ì˜ˆì¸¡ì„ ìœ„í•œ ìê¸°íšŒê·€ ëª¨ë¸\n",
    "    \n",
    "    êµ¬ì¡°:\n",
    "    1. SequentialStateExtractor: LSTMìœ¼ë¡œ ì‹œê³„ì—´ íŒ¨í„´ì˜ hidden state ì¶”ì¶œ\n",
    "    2. PhysicalChangeDecoder: Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©  \n",
    "    3. PhysicsConstraintLayer: ë¬¼ë¦¬ ë²•ì¹™ ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = SequentialStateExtractor(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_states, seq_lengths):\n",
    "        \"\"\"\n",
    "        í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ìƒíƒœë“¤ë¡œë¶€í„° ë‹¤ìŒ ìƒíƒœë“¤ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            current_states: [batch, seq_len, 12] - í˜„ì¬ê¹Œì§€ì˜ BMED ì‹œìŠ¤í…œ ìƒíƒœë“¤\n",
    "            seq_lengths: [batch] - ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´\n",
    "            \n",
    "        Returns:\n",
    "            next_states: [batch, seq_len, 12] - ì˜ˆì¸¡ëœ ë‹¤ìŒ ì‹œì  ìƒíƒœë“¤\n",
    "        \"\"\"\n",
    "        # 1. LSTMìœ¼ë¡œ ê° ì‹œì ì˜ hidden state ì¶”ì¶œ (ê³¼ê±° ì •ë³´ ëˆ„ì )\n",
    "        hidden_states = self.state_extractor(current_states, seq_lengths)\n",
    "        \n",
    "        # 2. Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        \n",
    "        # 3. ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ì„ ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "        next_states = self.physics_constraint(physical_changes, current_states)\n",
    "        \n",
    "        return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(predictions, targets, seq_lengths):\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ë§ˆìŠ¤í‚¹ëœ MSE ì†ì‹¤ í•¨ìˆ˜ - device í˜¸í™˜ì„± ë° ì•ˆì •ì„± ê°•í™”\n",
    "    \n",
    "    Args:\n",
    "        predictions: ëª¨ë¸ ì˜ˆì¸¡ê°’ [batch_size, seq_len, features]\n",
    "        targets: ì‹¤ì œ íƒ€ê²Ÿê°’ [batch_size, seq_len, features]  \n",
    "        seq_lengths: ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        masked_loss: íŒ¨ë”© ë¶€ë¶„ì„ ì œì™¸í•œ í‰ê·  MSE ì†ì‹¤\n",
    "    \"\"\"\n",
    "    # ì…ë ¥ ê²€ì¦\n",
    "    if predictions.shape != targets.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {predictions.shape} vs targets {targets.shape}\")\n",
    "    \n",
    "    if predictions.size(0) != seq_lengths.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {predictions.size(0)} vs seq_lengths {seq_lengths.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = predictions.shape\n",
    "    \n",
    "    # seq_lengthsë¥¼ CPUë¡œ ì´ë™í•˜ì—¬ arangeì™€ í˜¸í™˜ë˜ë„ë¡ ì²˜ë¦¬\n",
    "    seq_lengths_cpu = seq_lengths.detach().cpu().long()\n",
    "    \n",
    "    # ì‹œí€€ìŠ¤ ê¸¸ì´ ìœ íš¨ì„± ê²€ì‚¬ - ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜ëŠ” ì¤‘ë‹¨í•´ì•¼ í•¨\n",
    "    if (seq_lengths_cpu <= 0).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu <= 0]\n",
    "        raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "    \n",
    "    # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ê²€ì‚¬\n",
    "    if (seq_lengths_cpu > max_len).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu > max_len]\n",
    "        raise ValueError(f\"Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}\")\n",
    "    \n",
    "    # ë§ˆìŠ¤í¬ ìƒì„±: ì‹¤ì œ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ë§Œ True\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_lengths_cpu[:, None]\n",
    "    mask = mask.float().to(predictions.device)\n",
    "    \n",
    "    # ê° ìš”ì†Œë³„ MSE ê³„ì‚° (reduction='none')\n",
    "    loss = F.mse_loss(predictions, targets, reduction='none')\n",
    "    \n",
    "    # ë§ˆìŠ¤í¬ ì ìš©í•˜ì—¬ íŒ¨ë”© ë¶€ë¶„ ì œê±°\n",
    "    masked_loss_sum = (loss * mask.unsqueeze(-1)).sum()\n",
    "    valid_elements = mask.sum() * features\n",
    "    \n",
    "    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "    if valid_elements == 0:\n",
    "        raise ValueError(\"No valid elements found after masking. Check sequence lengths and data.\")\n",
    "    \n",
    "    masked_loss = masked_loss_sum / valid_elements\n",
    "    \n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_running_prediction_single(model, initial_state, num_steps, device, training=False):\n",
    "    \"\"\"\n",
    "    Free running prediction for a single experiment.\n",
    "    ì´ˆê¸° ìƒíƒœì—ì„œ ì‹œì‘í•´ì„œ ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model: í•™ìŠµëœ ëª¨ë¸\n",
    "        initial_state: ì´ˆê¸° ìƒíƒœ [12] - ì‹œì‘ì \n",
    "        num_steps: ì˜ˆì¸¡í•  ìŠ¤í… ìˆ˜\n",
    "        device: torch device\n",
    "        training: í•™ìŠµ ëª¨ë“œì¸ì§€ ì—¬ë¶€ (Trueë©´ gradient ê³„ì‚°)\n",
    "        \n",
    "    Returns:\n",
    "        predictions: [num_steps, 12] - ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤\n",
    "    \"\"\"\n",
    "    if not training:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Initialize with initial state\n",
    "            current_state = initial_state.unsqueeze(0).unsqueeze(0)  # [1, 1, 12]\n",
    "            predictions = []\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                seq_len = torch.tensor([current_state.size(1)], device=device)\n",
    "                next_state = model(current_state, seq_len)\n",
    "                next_step = next_state[:, -1:, :]  # ë§ˆì§€ë§‰ ì‹œì ë§Œ ì„ íƒ\n",
    "                predictions.append(next_step.squeeze(0).squeeze(0))  # [12]\n",
    "                \n",
    "                # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡ëœ ìƒíƒœë¥¼ ì‚¬ìš© (Free Runningì˜ í•µì‹¬)\n",
    "                current_state = torch.cat([current_state, next_step], dim=1)\n",
    "            \n",
    "            return torch.stack(predictions)  # [num_steps, 12]\n",
    "    else:\n",
    "        # í•™ìŠµ ëª¨ë“œ: gradient ê³„ì‚° í•„ìš”\n",
    "        # Initialize with initial state\n",
    "        current_state = initial_state.unsqueeze(0).unsqueeze(0)  # [1, 1, 12]\n",
    "        predictions = []\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            seq_len = torch.tensor([current_state.size(1)], device=device)\n",
    "            next_state = model(current_state, seq_len)\n",
    "            next_step = next_state[:, -1:, :]  # ë§ˆì§€ë§‰ ì‹œì ë§Œ ì„ íƒ\n",
    "            predictions.append(next_step.squeeze(0).squeeze(0))  # [12]\n",
    "            \n",
    "            # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡ëœ ìƒíƒœë¥¼ ì‚¬ìš© (Free Runningì˜ í•µì‹¬)\n",
    "            # gradientë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ detachí•˜ì§€ ì•ŠìŒ\n",
    "            current_state = torch.cat([current_state, next_step], dim=1)\n",
    "        \n",
    "        return torch.stack(predictions)  # [num_steps, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_free_running_data(input_sequences, seq_lengths):\n",
    "    \"\"\"\n",
    "    Free Runningì„ ìœ„í•œ ì…ë ¥-íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„\n",
    "    \n",
    "    Args:\n",
    "        input_sequences: ì „ì²´ ì‹œí€€ìŠ¤ [batch_size, seq_len, features]\n",
    "        seq_lengths: ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        initial_states: [batch_size, 1, features] - ê° ì‹œí€€ìŠ¤ì˜ ì´ˆê¸° ìƒíƒœ\n",
    "        targets: [batch_size, seq_len-1, features] - ì˜ˆì¸¡í•´ì•¼ í•  íƒ€ê²Ÿë“¤  \n",
    "        target_seq_lengths: íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ (1ì”© ê°ì†Œ)\n",
    "    \"\"\"\n",
    "    # ì´ˆê¸° ìƒíƒœ: ê° ì‹œí€€ìŠ¤ì˜ ì²« ë²ˆì§¸ ì‹œì \n",
    "    initial_states = input_sequences[:, :1, :]  # [batch, 1, features]\n",
    "    \n",
    "    # íƒ€ê²Ÿ: ì²« ë²ˆì§¸ ì‹œì  ì œì™¸í•œ ë‚˜ë¨¸ì§€ [1:]\n",
    "    targets = input_sequences[:, 1:, :]  # [batch, seq_len-1, features]\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ëŠ” 1ì”© ê°ì†Œ (ì²« ì‹œì ì€ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©)\n",
    "    if (seq_lengths - 1 < 1).any():\n",
    "        invalid_lengths = seq_lengths[seq_lengths - 1 < 1]\n",
    "        raise ValueError(f\"íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ 0ë³´ë‹¤ ì‘ì•„ì§ˆ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ëª»ëœ seq_lengths: {invalid_lengths.tolist()}\")\n",
    "    target_seq_lengths = seq_lengths - 1\n",
    "    \n",
    "    return initial_states, targets, target_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_free_running(model, train_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Free running ë°©ì‹ìœ¼ë¡œ í•œ ì—í¬í¬ í•™ìŠµ\n",
    "    \n",
    "    Args:\n",
    "        model: ëª¨ë¸\n",
    "        train_loader: í•™ìŠµ ë°ì´í„°ë¡œë”\n",
    "        optimizer: ì˜µí‹°ë§ˆì´ì €\n",
    "        device: ë””ë°”ì´ìŠ¤\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (input_seq, seq_lengths) in enumerate(train_loader):\n",
    "        try:\n",
    "            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_lengths = seq_lengths.to(device)\n",
    "            \n",
    "            # Free Running ë°ì´í„° ì¤€ë¹„\n",
    "            initial_states, targets, target_seq_lengths = prepare_free_running_data(input_seq, seq_lengths)\n",
    "            \n",
    "            batch_size = initial_states.size(0)\n",
    "            max_len = targets.size(1)  # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´\n",
    "            predictions_list = []\n",
    "            \n",
    "            # ê° ì‹œí€€ìŠ¤ì— ëŒ€í•´ Free Running ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            for i in range(batch_size):\n",
    "                initial_state = initial_states[i, 0, :]  # [features]\n",
    "                num_steps = target_seq_lengths[i].item()\n",
    "                \n",
    "                if num_steps > 0:\n",
    "                    # Free running prediction (training=Trueë¡œ gradient ê³„ì‚°)\n",
    "                    pred_seq = free_running_prediction_single(model, initial_state, num_steps, device, training=True)\n",
    "                    \n",
    "                    # ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©\n",
    "                    if pred_seq.size(0) < max_len:\n",
    "                        padding = torch.zeros(max_len - pred_seq.size(0), pred_seq.size(1), device=device)\n",
    "                        pred_seq = torch.cat([pred_seq, padding], dim=0)\n",
    "                    elif pred_seq.size(0) > max_len:\n",
    "                        pred_seq = pred_seq[:max_len]\n",
    "                    \n",
    "                    predictions_list.append(pred_seq)\n",
    "                else:\n",
    "                    # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
    "                    empty_pred = torch.zeros(max_len, initial_state.size(0), device=device)\n",
    "                    predictions_list.append(empty_pred)\n",
    "            \n",
    "            # ë°°ì¹˜ë¡œ ìŠ¤íƒ\n",
    "            predictions = torch.stack(predictions_list, dim=0)  # [batch, max_len, features]\n",
    "            \n",
    "            # Loss ê³„ì‚° (ë§ˆìŠ¤í¬ ì ìš©)\n",
    "            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Training batch {batch_idx} error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch_free_running(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Free running ë°©ì‹ìœ¼ë¡œ ê²€ì¦\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_seq, seq_lengths in val_loader:\n",
    "            try:\n",
    "                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "                input_seq = input_seq.to(device)\n",
    "                seq_lengths = seq_lengths.to(device)\n",
    "                \n",
    "                # Free Running ë°ì´í„° ì¤€ë¹„\n",
    "                initial_states, targets, target_seq_lengths = prepare_free_running_data(input_seq, seq_lengths)\n",
    "                \n",
    "                batch_size = initial_states.size(0)\n",
    "                max_len = targets.size(1)  # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´\n",
    "                predictions_list = []\n",
    "                \n",
    "                # ê° ì‹œí€€ìŠ¤ì— ëŒ€í•´ Free Running ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "                for i in range(batch_size):\n",
    "                    initial_state = initial_states[i, 0, :]  # [features]\n",
    "                    num_steps = target_seq_lengths[i].item()\n",
    "                    \n",
    "                    if num_steps > 0:\n",
    "                        # Free running prediction (training=Falseë¡œ ê²€ì¦)\n",
    "                        pred_seq = free_running_prediction_single(model, initial_state, num_steps, device, training=False)\n",
    "                        \n",
    "                        # ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©\n",
    "                        if pred_seq.size(0) < max_len:\n",
    "                            padding = torch.zeros(max_len - pred_seq.size(0), pred_seq.size(1), device=device)\n",
    "                            pred_seq = torch.cat([pred_seq, padding], dim=0)\n",
    "                        elif pred_seq.size(0) > max_len:\n",
    "                            pred_seq = pred_seq[:max_len]\n",
    "                        \n",
    "                        predictions_list.append(pred_seq)\n",
    "                    else:\n",
    "                        # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
    "                        empty_pred = torch.zeros(max_len, initial_state.size(0), device=device)\n",
    "                        predictions_list.append(empty_pred)\n",
    "                \n",
    "                # ë°°ì¹˜ë¡œ ìŠ¤íƒ\n",
    "                predictions = torch.stack(predictions_list, dim=0)  # [batch, max_len, features]\n",
    "                \n",
    "                # Loss ê³„ì‚°\n",
    "                loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Validation batch error: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDFreeRunningOptimizer:\n",
    "    \"\"\"\n",
    "    BMED ìê¸°íšŒê·€ ëª¨ë¸ì„ ìœ„í•œ Free Running ê¸°ë°˜ K-fold CV í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloaders, device=None):\n",
    "        self.dataloaders = dataloaders\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ì •ì˜ (Free Runningì— ë§ì¶° ì¡°ì •)\n",
    "        self.param_ranges = {\n",
    "            'hidden_size': {'low': 16, 'high': 256, 'step': 16},  # ë” ë„“ì€ ë²”ìœ„\n",
    "            'num_layers': {'low': 2, 'high': 10},  # ìµœì†Œ 2ì¸µë¶€í„° ì‹œì‘\n",
    "            'extractor_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'decoder_layers': {'low': 2, 'high': 10},  # ìµœì†Œ 2ì¸µë¶€í„° ì‹œì‘\n",
    "            'decoder_nodes': {'low': 16, 'high': 256, 'step': 16},  # ë” ë„“ì€ ë²”ìœ„\n",
    "            'decoder_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'learning_rate': {'low': 1e-5, 'high': 1e-1, 'log': True},  # ë” ë‚®ì€ í•™ìŠµë¥ \n",
    "            'weight_decay': {'low': 1e-7, 'high': 1e-3, 'log': True}\n",
    "        }\n",
    "        \n",
    "        # í•™ìŠµ ì„¤ì • - Free Runningì— ë§ì¶° ì¡°ì • (max_predict_length ì œê±°)\n",
    "        self.train_config = {\n",
    "            'epochs': 300,      # Free Runningì€ ë” ë§ì€ ì—í¬í¬ í•„ìš”\n",
    "            'patience': 30,     # ë” ê´€ëŒ€í•œ early stopping\n",
    "            'min_epochs': 30   # ì¶©ë¶„í•œ í•™ìŠµ ë³´ì¥\n",
    "        }\n",
    "    \n",
    "    def create_model(self, trial):\n",
    "        \"\"\"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§ ë° ëª¨ë¸ ìƒì„±\"\"\"\n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§\n",
    "        params = {}\n",
    "        params['hidden_size'] = trial.suggest_int('hidden_size', **self.param_ranges['hidden_size'])\n",
    "        params['num_layers'] = trial.suggest_int('num_layers', **self.param_ranges['num_layers'])\n",
    "        params['extractor_dropout'] = trial.suggest_float('extractor_dropout', **self.param_ranges['extractor_dropout'])\n",
    "        params['decoder_layers'] = trial.suggest_int('decoder_layers', **self.param_ranges['decoder_layers'])\n",
    "        params['decoder_nodes'] = trial.suggest_int('decoder_nodes', **self.param_ranges['decoder_nodes'])\n",
    "        params['decoder_dropout'] = trial.suggest_float('decoder_dropout', **self.param_ranges['decoder_dropout'])\n",
    "        params['learning_rate'] = trial.suggest_float('learning_rate', **self.param_ranges['learning_rate'])\n",
    "        params['weight_decay'] = trial.suggest_float('weight_decay', **self.param_ranges['weight_decay'])\n",
    "        \n",
    "        # ëª¨ë¸ íŒŒë¼ë¯¸í„° êµ¬ì„±\n",
    "        model_params = {\n",
    "            'state_extractor': {\n",
    "                'input_size': 12,\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'num_layers': params['num_layers'],\n",
    "                'dropout': params['extractor_dropout']\n",
    "            },\n",
    "            'decoder': {\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'output_size': 7,\n",
    "                'num_layers': params['decoder_layers'],\n",
    "                'num_nodes': params['decoder_nodes'],\n",
    "                'dropout': params['decoder_dropout']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„°\n",
    "        optimizer_params = {\n",
    "            'lr': params['learning_rate'],\n",
    "            'weight_decay': params['weight_decay']\n",
    "        }\n",
    "        \n",
    "        return model_params, optimizer_params\n",
    "    \n",
    "    def train_single_fold(self, model_params, optimizer_params, train_loader, val_loader):\n",
    "        \"\"\"ë‹¨ì¼ fold í•™ìŠµ (Free Running ë°©ì‹)\"\"\"\n",
    "        try:\n",
    "            # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "            model = BMEDAutoregressiveModel(model_params['state_extractor'], model_params['decoder']).to(self.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            \n",
    "            for epoch in range(self.train_config['epochs']):\n",
    "                # Free Running í•™ìŠµ (max_predict_length íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "                try:\n",
    "                    train_loss = train_epoch_free_running(model, train_loader, optimizer, self.device)\n",
    "                    \n",
    "                    # Free Running ê²€ì¦ (max_predict_length íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "                    val_loss = validate_epoch_free_running(model, val_loader, self.device)\n",
    "                    \n",
    "                    # Early stopping\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        patience_counter = 0\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                    \n",
    "                    # ìµœì†Œ ì—í¬í¬ í›„ early stopping ì ìš©\n",
    "                    if epoch >= self.train_config['min_epochs'] and patience_counter >= self.train_config['patience']:\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Epoch {epoch} error: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            return best_val_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fold training error: {str(e)}\")\n",
    "            return float('inf')\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna objective í•¨ìˆ˜ - Free Running ê¸°ë°˜\"\"\"\n",
    "        try:\n",
    "            # ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„° ìƒì„±\n",
    "            model_params, optimizer_params = self.create_model(trial)\n",
    "            \n",
    "            # K-fold êµì°¨ê²€ì¦ - ëª¨ë“  fold ì‹¤í–‰\n",
    "            fold_losses = []\n",
    "            for fold_idx, (train_loader, val_loader) in enumerate(self.dataloaders):\n",
    "                print(f\"\\n  Trial {trial.number}: Processing Fold {fold_idx + 1}...\")\n",
    "                fold_loss = self.train_single_fold(\n",
    "                    model_params, optimizer_params, \n",
    "                    train_loader, val_loader\n",
    "                )\n",
    "                \n",
    "                if fold_loss == float('inf'):\n",
    "                    return float('inf')\n",
    "                \n",
    "                fold_losses.append(fold_loss)\n",
    "                print(f\"    Fold {fold_idx + 1} loss: {fold_loss:.6f}\")\n",
    "            \n",
    "            # í‰ê·  ê²€ì¦ ì†ì‹¤ ë°˜í™˜ (ëª¨ë“  fold ì™„ë£Œ)\n",
    "            mean_loss = sum(fold_losses) / len(fold_losses)\n",
    "            print(f\"  Trial {trial.number} completed: Mean loss = {mean_loss:.6f}\")\n",
    "            return mean_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Trial {trial.number} error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return float('inf')\n",
    "\n",
    "def optimize_bmed_free_running(trial, dataloaders):\n",
    "    \"\"\"Optunaë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜\"\"\"\n",
    "    optimizer = BMEDFreeRunningOptimizer(dataloaders)\n",
    "    return optimizer.objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...\n",
      "Fold 1: Train size = 4, Val size = 1\n",
      "Fold 2: Train size = 4, Val size = 1\n",
      "Fold 3: Train size = 4, Val size = 1\n",
      "Fold 4: Train size = 4, Val size = 1\n",
      "Fold 5: Train size = 4, Val size = 1\n",
      "\n",
      "âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
      "- ì‹œí€€ìŠ¤ ê°œìˆ˜: 5\n",
      "- ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 27\n",
      "- K-fold ìˆ˜: 5\n",
      "- ê° foldëŠ” (train_loader, val_loader) íŠœí”Œ\n",
      "- Free Running ê¸°ë°˜ ìµœì í™” ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "print(\"ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ì •ê·œí™”\n",
    "ndf, range_mm = norm_data('BMED_DATA_AG.csv')\n",
    "ndf1 = ndf[ndf['exp'].isin([0,1,2,3,4])]\n",
    "# ì‹œí€€ìŠ¤ ë°ì´í„° êµ¬ì„±\n",
    "seq = seq_data_const(ndf1)\n",
    "pad_seq, seq_len, max_seq_len = padded_sequences(seq)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = gen_dataset(pad_seq, seq_len)\n",
    "\n",
    "# K-fold ë°ì´í„°ë¡œë” ìƒì„±\n",
    "dataloaders = kfold_dataloaders(dataset, k_folds=5, batch_size=6, random_state=42)  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"- ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(seq)}\")\n",
    "print(f\"- ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_seq_len}\")\n",
    "print(f\"- K-fold ìˆ˜: {len(dataloaders)}\")\n",
    "print(f\"- ê° foldëŠ” (train_loader, val_loader) íŠœí”Œ\")\n",
    "print(f\"- Free Running ê¸°ë°˜ ìµœì í™” ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['hidden_size'] = 16\n",
    "params['num_layers'] = 2\n",
    "params['extractor_dropout'] = 0.3\n",
    "params['decoder_layers'] = 2\n",
    "params['decoder_nodes'] = 16\n",
    "params['decoder_dropout'] = 0.3\n",
    "params['learning_rate'] = 1e-4\n",
    "params['weight_decay'] = 1e-5\n",
    "\n",
    "model_params = {\n",
    "    'state_extractor': {\n",
    "        'input_size': 12,\n",
    "        'hidden_size': params['hidden_size'],\n",
    "        'num_layers': params['num_layers'],\n",
    "        'dropout': params['extractor_dropout']\n",
    "    },\n",
    "    'decoder': {\n",
    "        'hidden_size': params['hidden_size'],\n",
    "        'output_size': 7,\n",
    "        'num_layers': params['decoder_layers'],\n",
    "        'num_nodes': params['decoder_nodes'],\n",
    "        'dropout': params['decoder_dropout']\n",
    "    }\n",
    "}\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„°\n",
    "optimizer_params = {\n",
    "    'lr': params['learning_rate'],\n",
    "    'weight_decay': params['weight_decay']\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BMEDAutoregressiveModel(model_params['state_extractor'], model_params['decoder']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
