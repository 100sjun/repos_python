{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'Using device: {device}')\n",
    "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(name):\n",
    "    \"\"\"ë°ì´í„° ë¡œë“œ ë° ì •ê·œí™”\"\"\"\n",
    "    df = pd.read_csv(name)\n",
    "    ndf = pd.DataFrame()\n",
    "    range_mm={\n",
    "        'V': {'min':df['V'].min()*0.8, 'max': df['V'].max()*1.2},\n",
    "        'E': {'min':df['E'].min()*0.8, 'max': df['E'].max()*1.2},\n",
    "        'VF': {'min':df['VF'].min()*0.8, 'max': df['VF'].max()*1.2},\n",
    "        'VA': {'min':df['VA'].min()*0.8, 'max': df['VA'].max()*1.2},\n",
    "        'VB': {'min':df['VB'].min()*0.8, 'max': df['VB'].max()*1.2},\n",
    "        'CFLA': {'min':0, 'max': df['CFLA'].max()*1.2},\n",
    "        'CALA': {'min':0, 'max': df['CALA'].max()*1.2},\n",
    "        'CBLA': {'min':0, 'max': df['CBLA'].max()*1.2},\n",
    "        'CFK': {'min':0, 'max': df['CFK'].max()*1.2},\n",
    "        'CAK': {'min':0, 'max': df['CAK'].max()*1.2},\n",
    "        'CBK': {'min':0, 'max': df['CBK'].max()*1.2},\n",
    "        'I': {'min':0, 'max': df['I'].max()*1.2},\n",
    "    }\n",
    "\n",
    "    ndf['exp'] = df['exp']; ndf['t'] = df['t']\n",
    "\n",
    "    for col in ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']:\n",
    "        if col in range_mm:\n",
    "            ndf[col] = (df[col] - range_mm[col]['min'])/(range_mm[col]['max'] - range_mm[col]['min'])\n",
    "        else:\n",
    "            ndf[col] = df[col]\n",
    "    return ndf, range_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_const(ndf):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ ë°ì´í„° êµ¬ì„±\"\"\"\n",
    "    sequences = []\n",
    "    feature_cols = ['V', 'E', 'VF', 'VA', 'VB', 'CFLA', 'CALA', 'CBLA', 'CFK', 'CAK', 'CBK', 'I']\n",
    "    \n",
    "    for exp in ndf['exp'].unique():\n",
    "        exp_data = ndf[ndf['exp'] == exp].sort_values(by='t')\n",
    "        sequences.append(exp_data[feature_cols].values)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sequences(sequences):\n",
    "    \"\"\"ì‹œí€€ìŠ¤ íŒ¨ë”© ì²˜ë¦¬\"\"\"\n",
    "    max_seq_len = max([len(seq) for seq in sequences])\n",
    "    seq_len = [len(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=-1)\n",
    "\n",
    "    return padded_sequences, seq_len, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(pad_seq, seq_len):\n",
    "    \"\"\"ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    input_tensor = pad_seq.float()\n",
    "    seq_len_tensor = torch.tensor(seq_len)\n",
    "    dataset = TensorDataset(input_tensor, seq_len_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_dataloaders(dataset, k_folds=5, batch_size=4, random_state=87):\n",
    "    \"\"\"K-fold êµì°¨ê²€ì¦ì„ ìœ„í•œ ë°ì´í„°ë¡œë” ìƒì„±\"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "    dataloaders = []\n",
    "    batch_size = math.ceil(len(dataset)/k_folds)\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(kfold.split(range(len(dataset)))):\n",
    "        print(f\"Fold {fold + 1}: Train size = {len(train_indices)}, Val size = {len(val_indices)}\")\n",
    "        \n",
    "        # Create subsets for train and validation\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        val_subset = Subset(dataset, val_indices)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialStateExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED ì‹œìŠ¤í…œì˜ ì‹œê³„ì—´ íŒ¨í„´ì—ì„œ ìˆ¨ê²¨ì§„ dynamicsë¥¼ ì¶”ì¶œí•˜ëŠ” LSTM ê¸°ë°˜ ëª¨ë“ˆ\n",
    "    ê° ì‹œì ì˜ hidden stateì—ëŠ” í•´ë‹¹ ì‹œì ê¹Œì§€ì˜ ëª¨ë“  ê³¼ê±° ì •ë³´ê°€ ëˆ„ì ë¨\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with improved error handling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, seq_len):\n",
    "        \"\"\"\n",
    "        ì‹œê³„ì—´ ìƒíƒœ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê° ì‹œì ì˜ hidden state ì¶”ì¶œ\n",
    "        \n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size] - BMED ì‹œìŠ¤í…œ ìƒíƒœ ì‹œí€€ìŠ¤\n",
    "            seq_len: [batch_size] - ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´\n",
    "            \n",
    "        Returns:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - ê° ì‹œì ì˜ ëˆ„ì ëœ hidden state\n",
    "        \"\"\"\n",
    "        \n",
    "        # ì…ë ¥ ê²€ì¦\n",
    "        if x.size(0) != seq_len.size(0):\n",
    "            raise ValueError(f\"Batch size mismatch: input {x.size(0)} vs seq_len {seq_len.size(0)}\")\n",
    "        \n",
    "        # seq_lenì„ CPUë¡œ ì´ë™í•˜ê³  ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "        seq_len_cpu = seq_len.detach().cpu().long()\n",
    "        \n",
    "        # ì‹œí€€ìŠ¤ ê¸¸ì´ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        if (seq_len_cpu <= 0).any():\n",
    "            invalid_lengths = seq_len_cpu[seq_len_cpu <= 0]\n",
    "            raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "        \n",
    "        # íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ë¥¼ packí•˜ì—¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "        packed_input = pack_padded_sequence(\n",
    "            x, seq_len_cpu, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        \n",
    "        # ë‹¤ì‹œ íŒ¨ë”©ëœ í˜•íƒœë¡œ ë³µì›\n",
    "        lstm_out, output_lengths = pad_packed_sequence(\n",
    "            packed_output, batch_first=True, total_length=x.size(1)\n",
    "        )\n",
    "        \n",
    "        # Normalization and dropout\n",
    "        normalized = self.layer_norm(lstm_out)\n",
    "        return self.dropout(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalChangeDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden stateë¡œë¶€í„° BMED ì‹œìŠ¤í…œì˜ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ê³¼ ìƒˆë¡œìš´ ì „ë¥˜ê°’ì„ ë””ì½”ë”©í•˜ëŠ” MLP\n",
    "    ì¶œë ¥: [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI] - 7ê°œ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, num_nodes=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_nodes is None:\n",
    "            num_nodes = hidden_size\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # ì²« ë²ˆì§¸ ë ˆì´ì–´: hidden_size â†’ num_nodes\n",
    "        self.layers.append(nn.Linear(hidden_size, num_nodes))\n",
    "        self.layers.append(nn.LayerNorm(num_nodes))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # ì¤‘ê°„ ì€ë‹‰ì¸µë“¤: num_nodes â†’ num_nodes\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_nodes, num_nodes))\n",
    "            self.layers.append(nn.LayerNorm(num_nodes))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # ë§ˆì§€ë§‰ ì¶œë ¥ì¸µ: num_nodes â†’ output_size (7ê°œ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰)\n",
    "        self.layers.append(nn.Linear(num_nodes, output_size))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\n",
    "        Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_len, hidden_size] - ì‹œì ë³„ hidden state\n",
    "            \n",
    "        Returns:\n",
    "            physical_changes: [batch_size, seq_len, 7] - ë¬¼ë¦¬ì  ë³€í™”ëŸ‰\n",
    "                [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "        \"\"\"\n",
    "        x = hidden_states\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsConstraintLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ì„ ì‹¤ì œ ì‹œìŠ¤í…œ ìƒíƒœë¡œ ë³€í™˜í•˜ë©´ì„œ ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ì„ ì ìš©\n",
    "    Bipolar membrane electrodialysis ì‹œìŠ¤í…œì˜ ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-1):\n",
    "        super().__init__()\n",
    "        self.eps = eps  # division by zero ë°©ì§€\n",
    "        \n",
    "    def forward(self, physical_changes, current_state):\n",
    "        \"\"\"\n",
    "        ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ì„ í˜„ì¬ ìƒíƒœì— ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "        \n",
    "        Args:\n",
    "            physical_changes: [batch, seq, 7] - [dVA, dVB, dNALA, dNBLA, dNAK, dNBK, nI]\n",
    "            current_state: [batch, seq, 12] - í˜„ì¬ BMED ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "                V: ì „ì•• (Voltage) - ì‹¤í—˜ ì„¸íŠ¸ë³„ ê³ ì •ê°’\n",
    "                E: ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„ (External electrolyte concentration) - ì‹¤í—˜ ì„¸íŠ¸ë³„ ê³ ì •ê°’  \n",
    "                VF, VA, VB: Feed, Acid, Base ë¶€í”¼\n",
    "                CFLA, CALA, CBLA: Feed, Acid, Baseì˜ LA ë†ë„\n",
    "                CFK, CAK, CBK: Feed, Acid, Baseì˜ K ë†ë„\n",
    "                I: ì „ë¥˜\n",
    "                \n",
    "        Returns:\n",
    "            next_state: [batch, seq, 12] - ë¬¼ë¦¬ ì œì•½ì´ ì ìš©ëœ ë‹¤ìŒ ìƒíƒœ\n",
    "        \"\"\"\n",
    "        # ì…ë ¥ ì°¨ì› ê²€ì¦\n",
    "        if physical_changes.dim() != current_state.dim():\n",
    "            raise ValueError(f\"Dimension mismatch: physical_changes {physical_changes.shape} vs current_state {current_state.shape}\")\n",
    "        \n",
    "        if current_state.size(-1) != 12:\n",
    "            raise ValueError(f\"Expected 12 state features, got {current_state.size(-1)}\")\n",
    "            \n",
    "        if physical_changes.size(-1) != 7:\n",
    "            raise ValueError(f\"Expected 7 physical changes, got {physical_changes.size(-1)}\")\n",
    "        \n",
    "        # í˜„ì¬ ìƒíƒœ ë³€ìˆ˜ ì¶”ì¶œ (ì°¨ì› ìœ ì§€)\n",
    "        V = current_state[..., 0:1]     # ì „ì•• (ê³ ì •ê°’)\n",
    "        E = current_state[..., 1:2]     # ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„ (ê³ ì •ê°’)\n",
    "        VF = current_state[..., 2:3]    # Feed ë¶€í”¼\n",
    "        VA = current_state[..., 3:4]    # Acid ë¶€í”¼\n",
    "        VB = current_state[..., 4:5]    # Base ë¶€í”¼\n",
    "        CFLA = current_state[..., 5:6]  # Feed LA ë†ë„\n",
    "        CALA = current_state[..., 6:7]  # Acid LA ë†ë„\n",
    "        CBLA = current_state[..., 7:8]  # Base LA ë†ë„\n",
    "        CFK = current_state[..., 8:9]   # Feed K ë†ë„\n",
    "        CAK = current_state[..., 9:10]  # Acid K ë†ë„\n",
    "        CBK = current_state[..., 10:11] # Base K ë†ë„\n",
    "        I = current_state[..., 11:12]   # ì „ë¥˜\n",
    "\n",
    "        # ë¬¼ì§ˆëŸ‰ ê³„ì‚° (ë†ë„ Ã— ë¶€í”¼)\n",
    "        NFLA = CFLA * VF; NALA = CALA * VA; NBLA = CBLA * VB\n",
    "        NFK = CFK * VF; NAK = CAK * VA; NBK = CBK * VB\n",
    "\n",
    "        # ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ ì¶”ì¶œ\n",
    "        dVA = physical_changes[..., 0:1]    # Acid ë¶€í”¼ ë³€í™”ëŸ‰ (ì–‘ë°©í–¥ ê°€ëŠ¥: ìŒìˆ˜ë©´ Aâ†’F)\n",
    "        dVB = physical_changes[..., 1:2]    # Base ë¶€í”¼ ë³€í™”ëŸ‰ (ì–‘ë°©í–¥ ê°€ëŠ¥: ìŒìˆ˜ë©´ Bâ†’F)\n",
    "        dNALA = physical_changes[..., 2:3]  # Acid LA ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Aë§Œ)\n",
    "        dNBLA = physical_changes[..., 3:4]  # Base LA ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Bë§Œ)\n",
    "        dNAK = physical_changes[..., 4:5]   # Acid K ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Aë§Œ)\n",
    "        dNBK = physical_changes[..., 5:6]   # Base K ë¬¼ì§ˆëŸ‰ ë³€í™”ëŸ‰ (ì¼ë°©í–¥: Fâ†’Bë§Œ)\n",
    "        nI = physical_changes[..., 6:7]     # ìƒˆë¡œìš´ ì „ë¥˜ê°’\n",
    "\n",
    "        # ìƒˆë¡œìš´ ë¶€í”¼ ê³„ì‚° (ì–‘ë°©í–¥ íë¦„ í—ˆìš©)\n",
    "        nVF = VF - dVA - dVB  # dVA, dVBê°€ ìŒìˆ˜ë©´ Fë¡œ ì—­ìœ ì…\n",
    "        nVA = VA + dVA        # dVAê°€ ìŒìˆ˜ë©´ Aì—ì„œ Fë¡œ ìœ ì¶œ\n",
    "        nVB = VB + dVB        # dVBê°€ ìŒìˆ˜ë©´ Bì—ì„œ Fë¡œ ìœ ì¶œ\n",
    "        \n",
    "        # ë¬¼ì§ˆ ì´ë™ëŸ‰ì„ ì¼ë°©í–¥ìœ¼ë¡œ ì œí•œ (Fâ†’A, Fâ†’Bë§Œ í—ˆìš©)\n",
    "        dNALA_clipped = torch.clamp(dNALA, min=0)  # ìŒìˆ˜ ì œê±° (ì—­ë°©í–¥ ë¶ˆê°€)\n",
    "        dNBLA_clipped = torch.clamp(dNBLA, min=0)\n",
    "        dNAK_clipped = torch.clamp(dNAK, min=0)\n",
    "        dNBK_clipped = torch.clamp(dNBK, min=0)\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ë¬¼ì§ˆëŸ‰ ê³„ì‚° (ì¼ë°©í–¥ ì´ë™ë§Œ)\n",
    "        nNFLA = NFLA - dNALA_clipped - dNBLA_clipped  # Feedì—ì„œ ìœ ì¶œë§Œ\n",
    "        nNALA = NALA + dNALA_clipped                  # Acidë¡œ ìœ ì…ë§Œ\n",
    "        nNBLA = NBLA + dNBLA_clipped                  # Baseë¡œ ìœ ì…ë§Œ\n",
    "        nNFK = NFK - dNAK_clipped - dNBK_clipped      # Kë„ ë§ˆì°¬ê°€ì§€\n",
    "        nNAK = NAK + dNAK_clipped\n",
    "        nNBK = NBK + dNBK_clipped\n",
    "        \n",
    "        # ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ ì ìš© (ì–‘ìˆ˜ ìœ ì§€)\n",
    "        nVF = torch.clamp(nVF, min=self.eps)\n",
    "        nVA = torch.clamp(nVA, min=self.eps)\n",
    "        nVB = torch.clamp(nVB, min=self.eps)\n",
    "        \n",
    "        # ë¬¼ì§ˆëŸ‰ ìŒìˆ˜ ë°©ì§€\n",
    "        nNFLA = torch.clamp(nNFLA, min=0)\n",
    "        nNALA = torch.clamp(nNALA, min=0)\n",
    "        nNBLA = torch.clamp(nNBLA, min=0)\n",
    "        nNFK = torch.clamp(nNFK, min=0)\n",
    "        nNAK = torch.clamp(nNAK, min=0)\n",
    "        nNBK = torch.clamp(nNBK, min=0)\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ë†ë„ ê³„ì‚° (ë†ë„ = ë¬¼ì§ˆëŸ‰ / ë¶€í”¼)\n",
    "        nCFLA = nNFLA / nVF\n",
    "        nCALA = nNALA / nVA\n",
    "        nCBLA = nNBLA / nVB\n",
    "        nCFK = nNFK / nVF\n",
    "        nCAK = nNAK / nVA\n",
    "        nCBK = nNBK / nVB\n",
    "        \n",
    "        # ì „ë¥˜ëŠ” ì–‘ìˆ˜ ì œì•½\n",
    "        nI = torch.clamp(nI, min=0)\n",
    "\n",
    "        # ìƒˆë¡œìš´ ìƒíƒœ ì¡°ë¦½ (V, EëŠ” ê³ ì •ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "        next_state = torch.cat([\n",
    "            V, E,  # ê³ ì •ê°’: ì „ì••, ì™¸ë¶€ ì „í•´ì§ˆ ë†ë„\n",
    "            nVF, nVA, nVB,  # ìƒˆë¡œìš´ ë¶€í”¼ (ì–‘ë°©í–¥ íë¦„ ë°˜ì˜)\n",
    "            nCFLA, nCALA, nCBLA,  # ìƒˆë¡œìš´ LA ë†ë„\n",
    "            nCFK, nCAK, nCBK,     # ìƒˆë¡œìš´ K ë†ë„\n",
    "            nI  # ìƒˆë¡œìš´ ì „ë¥˜\n",
    "        ], dim=-1)\n",
    "        \n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDAutoregressiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BMED ì‹œìŠ¤í…œì˜ ì‹œê³„ì—´ ìƒíƒœ ì˜ˆì¸¡ì„ ìœ„í•œ ìê¸°íšŒê·€ ëª¨ë¸\n",
    "    \n",
    "    êµ¬ì¡°:\n",
    "    1. SequentialStateExtractor: LSTMìœ¼ë¡œ ì‹œê³„ì—´ íŒ¨í„´ì˜ hidden state ì¶”ì¶œ\n",
    "    2. PhysicalChangeDecoder: Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©  \n",
    "    3. PhysicsConstraintLayer: ë¬¼ë¦¬ ë²•ì¹™ ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "    \"\"\"\n",
    "    def __init__(self, state_extractor_params, decoder_params):\n",
    "        super().__init__()\n",
    "        self.state_extractor = SequentialStateExtractor(**state_extractor_params)\n",
    "        self.physical_decoder = PhysicalChangeDecoder(**decoder_params)\n",
    "        self.physics_constraint = PhysicsConstraintLayer()\n",
    "\n",
    "    def forward(self, current_states, seq_lengths):\n",
    "        \"\"\"\n",
    "        í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ìƒíƒœë“¤ë¡œë¶€í„° ë‹¤ìŒ ìƒíƒœë“¤ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            current_states: [batch, seq_len, 12] - í˜„ì¬ê¹Œì§€ì˜ BMED ì‹œìŠ¤í…œ ìƒíƒœë“¤\n",
    "            seq_lengths: [batch] - ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´\n",
    "            \n",
    "        Returns:\n",
    "            next_states: [batch, seq_len, 12] - ì˜ˆì¸¡ëœ ë‹¤ìŒ ì‹œì  ìƒíƒœë“¤\n",
    "        \"\"\"\n",
    "        # 1. LSTMìœ¼ë¡œ ê° ì‹œì ì˜ hidden state ì¶”ì¶œ (ê³¼ê±° ì •ë³´ ëˆ„ì )\n",
    "        hidden_states = self.state_extractor(current_states, seq_lengths)\n",
    "        \n",
    "        # 2. Hidden stateë¥¼ ë¬¼ë¦¬ì  ë³€í™”ëŸ‰ìœ¼ë¡œ ë””ì½”ë”©\n",
    "        physical_changes = self.physical_decoder(hidden_states)\n",
    "        \n",
    "        # 3. ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ì„ ì ìš©í•˜ì—¬ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
    "        next_states = self.physics_constraint(physical_changes, current_states)\n",
    "        \n",
    "        return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(predictions, targets, seq_lengths):\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ë§ˆìŠ¤í‚¹ëœ MSE ì†ì‹¤ í•¨ìˆ˜ - device í˜¸í™˜ì„± ë° ì•ˆì •ì„± ê°•í™”\n",
    "    \n",
    "    Args:\n",
    "        predictions: ëª¨ë¸ ì˜ˆì¸¡ê°’ [batch_size, seq_len, features]\n",
    "        targets: ì‹¤ì œ íƒ€ê²Ÿê°’ [batch_size, seq_len, features]  \n",
    "        seq_lengths: ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        masked_loss: íŒ¨ë”© ë¶€ë¶„ì„ ì œì™¸í•œ í‰ê·  MSE ì†ì‹¤\n",
    "    \"\"\"\n",
    "    # ì…ë ¥ ê²€ì¦\n",
    "    if predictions.shape != targets.shape:\n",
    "        raise ValueError(f\"Shape mismatch: predictions {predictions.shape} vs targets {targets.shape}\")\n",
    "    \n",
    "    if predictions.size(0) != seq_lengths.size(0):\n",
    "        raise ValueError(f\"Batch size mismatch: predictions {predictions.size(0)} vs seq_lengths {seq_lengths.size(0)}\")\n",
    "    \n",
    "    batch_size, max_len, features = predictions.shape\n",
    "    \n",
    "    # seq_lengthsë¥¼ CPUë¡œ ì´ë™í•˜ì—¬ arangeì™€ í˜¸í™˜ë˜ë„ë¡ ì²˜ë¦¬\n",
    "    seq_lengths_cpu = seq_lengths.detach().cpu().long()\n",
    "    \n",
    "    # ì‹œí€€ìŠ¤ ê¸¸ì´ ìœ íš¨ì„± ê²€ì‚¬ - ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜ëŠ” ì¤‘ë‹¨í•´ì•¼ í•¨\n",
    "    if (seq_lengths_cpu <= 0).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu <= 0]\n",
    "        raise ValueError(f\"Invalid sequence lengths detected: {invalid_lengths.tolist()}. All sequence lengths must be positive.\")\n",
    "    \n",
    "    # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ê²€ì‚¬\n",
    "    if (seq_lengths_cpu > max_len).any():\n",
    "        invalid_lengths = seq_lengths_cpu[seq_lengths_cpu > max_len]\n",
    "        raise ValueError(f\"Sequence lengths exceed max_len: {invalid_lengths.tolist()} > {max_len}\")\n",
    "    \n",
    "    # ë§ˆìŠ¤í¬ ìƒì„±: ì‹¤ì œ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ë§Œ True\n",
    "    mask = torch.arange(max_len, device='cpu')[None, :] < seq_lengths_cpu[:, None]\n",
    "    mask = mask.float().to(predictions.device)\n",
    "    \n",
    "    # ê° ìš”ì†Œë³„ MSE ê³„ì‚° (reduction='none')\n",
    "    loss = F.mse_loss(predictions, targets, reduction='none')\n",
    "    \n",
    "    # ë§ˆìŠ¤í¬ ì ìš©í•˜ì—¬ íŒ¨ë”© ë¶€ë¶„ ì œê±°\n",
    "    masked_loss_sum = (loss * mask.unsqueeze(-1)).sum()\n",
    "    valid_elements = mask.sum() * features\n",
    "    \n",
    "    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "    if valid_elements == 0:\n",
    "        raise ValueError(\"No valid elements found after masking. Check sequence lengths and data.\")\n",
    "    \n",
    "    masked_loss = masked_loss_sum / valid_elements\n",
    "    \n",
    "    return masked_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_running_prediction_single(model, initial_state, num_steps, device, training=False):\n",
    "    \"\"\"\n",
    "    Free running prediction for a single experiment.\n",
    "    ì´ˆê¸° ìƒíƒœì—ì„œ ì‹œì‘í•´ì„œ ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        model: í•™ìŠµëœ ëª¨ë¸\n",
    "        initial_state: ì´ˆê¸° ìƒíƒœ [12] - ì‹œì‘ì \n",
    "        num_steps: ì˜ˆì¸¡í•  ìŠ¤í… ìˆ˜\n",
    "        device: torch device\n",
    "        training: í•™ìŠµ ëª¨ë“œì¸ì§€ ì—¬ë¶€ (Trueë©´ gradient ê³„ì‚°)\n",
    "        \n",
    "    Returns:\n",
    "        predictions: [num_steps, 12] - ì˜ˆì¸¡ëœ ì‹œí€€ìŠ¤ (ì´ˆê¸°ê°’ ì œì™¸)\n",
    "    \"\"\"\n",
    "    if not training:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Initialize with initial state\n",
    "            current_state = initial_state.unsqueeze(0).unsqueeze(0)  # [1, 1, 12]\n",
    "            predictions = []\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                seq_len = torch.tensor([current_state.size(1)], device=device)\n",
    "                next_state = model(current_state, seq_len)\n",
    "                next_step = next_state[:, -1:, :]  # ë§ˆì§€ë§‰ ì‹œì ë§Œ ì„ íƒ\n",
    "                predictions.append(next_step.squeeze(0).squeeze(0))  # [12]\n",
    "                \n",
    "                # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡ëœ ìƒíƒœë¥¼ ì‚¬ìš© (Free Runningì˜ í•µì‹¬)\n",
    "                current_state = torch.cat([current_state, next_step], dim=1)\n",
    "            \n",
    "            return torch.stack(predictions)  # [num_steps, 12]\n",
    "    else:\n",
    "        # í•™ìŠµ ëª¨ë“œ: gradient ê³„ì‚° í•„ìš”\n",
    "        # Initialize with initial state\n",
    "        current_state = initial_state.unsqueeze(0).unsqueeze(0)  # [1, 1, 12]\n",
    "        predictions = []\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            seq_len = torch.tensor([current_state.size(1)], device=device)\n",
    "            next_state = model(current_state, seq_len)\n",
    "            next_step = next_state[:, -1:, :]  # ë§ˆì§€ë§‰ ì‹œì ë§Œ ì„ íƒ\n",
    "            predictions.append(next_step.squeeze(0).squeeze(0))  # [12]\n",
    "            \n",
    "            # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡ëœ ìƒíƒœë¥¼ ì‚¬ìš© (Free Runningì˜ í•µì‹¬)\n",
    "            # gradientë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ detachí•˜ì§€ ì•ŠìŒ\n",
    "            current_state = torch.cat([current_state, next_step], dim=1)\n",
    "        \n",
    "        return torch.stack(predictions)  # [num_steps, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_free_running_data(input_sequences, seq_lengths):\n",
    "    \"\"\"\n",
    "    Free Runningì„ ìœ„í•œ ì…ë ¥-íƒ€ê²Ÿ ë°ì´í„° ì¤€ë¹„\n",
    "    \n",
    "    Args:\n",
    "        input_sequences: ì „ì²´ ì‹œí€€ìŠ¤ [batch_size, seq_len, features]\n",
    "        seq_lengths: ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ [batch_size]\n",
    "    \n",
    "    Returns:\n",
    "        initial_states: [batch_size, 1, features] - ê° ì‹œí€€ìŠ¤ì˜ ì´ˆê¸° ìƒíƒœ\n",
    "        targets: [batch_size, seq_len-1, features] - ì˜ˆì¸¡í•´ì•¼ í•  íƒ€ê²Ÿë“¤  \n",
    "        target_seq_lengths: íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ (1ì”© ê°ì†Œ)\n",
    "    \"\"\"\n",
    "    # ì´ˆê¸° ìƒíƒœ: ê° ì‹œí€€ìŠ¤ì˜ ì²« ë²ˆì§¸ ì‹œì \n",
    "    initial_states = input_sequences[:, :1, :]  # [batch, 1, features]\n",
    "    \n",
    "    # íƒ€ê²Ÿ: ì²« ë²ˆì§¸ ì‹œì  ì œì™¸í•œ ë‚˜ë¨¸ì§€ [1:]\n",
    "    targets = input_sequences[:, 1:, :]  # [batch, seq_len-1, features]\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ëŠ” 1ì”© ê°ì†Œ (ì²« ì‹œì ì€ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©)\n",
    "    if (seq_lengths - 1 < 1).any():\n",
    "        invalid_lengths = seq_lengths[seq_lengths - 1 < 1]\n",
    "        raise ValueError(f\"íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ 0ë³´ë‹¤ ì‘ì•„ì§ˆ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ëª»ëœ seq_lengths: {invalid_lengths.tolist()}\")\n",
    "    target_seq_lengths = seq_lengths - 1\n",
    "    \n",
    "    return initial_states, targets, target_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_free_running(model, train_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Free running ë°©ì‹ìœ¼ë¡œ í•œ ì—í¬í¬ í•™ìŠµ\n",
    "    \n",
    "    Args:\n",
    "        model: ëª¨ë¸\n",
    "        train_loader: í•™ìŠµ ë°ì´í„°ë¡œë”\n",
    "        optimizer: ì˜µí‹°ë§ˆì´ì €\n",
    "        device: ë””ë°”ì´ìŠ¤\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (input_seq, seq_lengths) in enumerate(train_loader):\n",
    "        try:\n",
    "            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            input_seq = input_seq.to(device)\n",
    "            seq_lengths = seq_lengths.to(device)\n",
    "            \n",
    "            # Free Running ë°ì´í„° ì¤€ë¹„\n",
    "            initial_states, targets, target_seq_lengths = prepare_free_running_data(input_seq, seq_lengths)\n",
    "            \n",
    "            batch_size = initial_states.size(0)\n",
    "            max_len = targets.size(1)  # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´\n",
    "            predictions_list = []\n",
    "            \n",
    "            # ê° ì‹œí€€ìŠ¤ì— ëŒ€í•´ Free Running ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            for i in range(batch_size):\n",
    "                initial_state = initial_states[i, 0, :]  # [features]\n",
    "                num_steps = target_seq_lengths[i].item()\n",
    "                \n",
    "                if num_steps > 0:\n",
    "                    # Free running prediction (training=Trueë¡œ gradient ê³„ì‚°)\n",
    "                    pred_seq = free_running_prediction_single(model, initial_state, num_steps, device, training=True)\n",
    "                    \n",
    "                    # ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©\n",
    "                    if pred_seq.size(0) < max_len:\n",
    "                        padding = torch.zeros(max_len - pred_seq.size(0), pred_seq.size(1), device=device)\n",
    "                        pred_seq = torch.cat([pred_seq, padding], dim=0)\n",
    "                    elif pred_seq.size(0) > max_len:\n",
    "                        pred_seq = pred_seq[:max_len]\n",
    "                    \n",
    "                    predictions_list.append(pred_seq)\n",
    "                else:\n",
    "                    # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
    "                    empty_pred = torch.zeros(max_len, initial_state.size(0), device=device)\n",
    "                    predictions_list.append(empty_pred)\n",
    "            \n",
    "            # ë°°ì¹˜ë¡œ ìŠ¤íƒ\n",
    "            predictions = torch.stack(predictions_list, dim=0)  # [batch, max_len, features]\n",
    "            \n",
    "            # Loss ê³„ì‚° (ë§ˆìŠ¤í¬ ì ìš©)\n",
    "            loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Training batch {batch_idx} error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch_free_running(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Free running ë°©ì‹ìœ¼ë¡œ ê²€ì¦\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_seq, seq_lengths in val_loader:\n",
    "            try:\n",
    "                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "                input_seq = input_seq.to(device)\n",
    "                seq_lengths = seq_lengths.to(device)\n",
    "                \n",
    "                # Free Running ë°ì´í„° ì¤€ë¹„\n",
    "                initial_states, targets, target_seq_lengths = prepare_free_running_data(input_seq, seq_lengths)\n",
    "                \n",
    "                batch_size = initial_states.size(0)\n",
    "                max_len = targets.size(1)  # ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´\n",
    "                predictions_list = []\n",
    "                \n",
    "                # ê° ì‹œí€€ìŠ¤ì— ëŒ€í•´ Free Running ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "                for i in range(batch_size):\n",
    "                    initial_state = initial_states[i, 0, :]  # [features]\n",
    "                    num_steps = target_seq_lengths[i].item()\n",
    "                    \n",
    "                    if num_steps > 0:\n",
    "                        # Free running prediction (training=Falseë¡œ ê²€ì¦)\n",
    "                        pred_seq = free_running_prediction_single(model, initial_state, num_steps, device, training=False)\n",
    "                        \n",
    "                        # ìµœëŒ€ ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©\n",
    "                        if pred_seq.size(0) < max_len:\n",
    "                            padding = torch.zeros(max_len - pred_seq.size(0), pred_seq.size(1), device=device)\n",
    "                            pred_seq = torch.cat([pred_seq, padding], dim=0)\n",
    "                        elif pred_seq.size(0) > max_len:\n",
    "                            pred_seq = pred_seq[:max_len]\n",
    "                        \n",
    "                        predictions_list.append(pred_seq)\n",
    "                    else:\n",
    "                        # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬\n",
    "                        empty_pred = torch.zeros(max_len, initial_state.size(0), device=device)\n",
    "                        predictions_list.append(empty_pred)\n",
    "                \n",
    "                # ë°°ì¹˜ë¡œ ìŠ¤íƒ\n",
    "                predictions = torch.stack(predictions_list, dim=0)  # [batch, max_len, features]\n",
    "                \n",
    "                # Loss ê³„ì‚°\n",
    "                loss = masked_mse_loss(predictions, targets, target_seq_lengths)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Validation batch error: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMEDFreeRunningOptimizer:\n",
    "    \"\"\"\n",
    "    BMED ìê¸°íšŒê·€ ëª¨ë¸ì„ ìœ„í•œ Free Running ê¸°ë°˜ K-fold CV í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloaders, device=None):\n",
    "        self.dataloaders = dataloaders\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ì •ì˜ (Free Runningì— ë§ì¶° ì¡°ì •)\n",
    "        self.param_ranges = {\n",
    "            'hidden_size': {'low': 16, 'high': 128, 'step': 16},  # ë” ë„“ì€ ë²”ìœ„\n",
    "            'num_layers': {'low': 2, 'high': 5},  # ìµœì†Œ 2ì¸µë¶€í„° ì‹œì‘\n",
    "            'extractor_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'decoder_layers': {'low': 2, 'high': 5},  # ìµœì†Œ 2ì¸µë¶€í„° ì‹œì‘\n",
    "            'decoder_nodes': {'low': 16, 'high': 128, 'step': 16},  # ë” ë„“ì€ ë²”ìœ„\n",
    "            'decoder_dropout': {'low': 0.1, 'high': 0.5},\n",
    "            'learning_rate': {'low': 1e-5, 'high': 1e-1, 'log': True},  # ë” ë‚®ì€ í•™ìŠµë¥ \n",
    "            'weight_decay': {'low': 1e-7, 'high': 1e-3, 'log': True}\n",
    "        }\n",
    "        \n",
    "        # í•™ìŠµ ì„¤ì • - Free Runningì— ë§ì¶° ì¡°ì • (max_predict_length ì œê±°)\n",
    "        self.train_config = {\n",
    "            'epochs': 70,      # Free Runningì€ ë” ë§ì€ ì—í¬í¬ í•„ìš”\n",
    "            'patience': 15,     # ë” ê´€ëŒ€í•œ early stopping\n",
    "            'min_epochs': 30   # ì¶©ë¶„í•œ í•™ìŠµ ë³´ì¥\n",
    "        }\n",
    "    \n",
    "    def create_model(self, trial):\n",
    "        \"\"\"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§ ë° ëª¨ë¸ ìƒì„±\"\"\"\n",
    "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§\n",
    "        params = {}\n",
    "        params['hidden_size'] = trial.suggest_int('hidden_size', **self.param_ranges['hidden_size'])\n",
    "        params['num_layers'] = trial.suggest_int('num_layers', **self.param_ranges['num_layers'])\n",
    "        params['extractor_dropout'] = trial.suggest_float('extractor_dropout', **self.param_ranges['extractor_dropout'])\n",
    "        params['decoder_layers'] = trial.suggest_int('decoder_layers', **self.param_ranges['decoder_layers'])\n",
    "        params['decoder_nodes'] = trial.suggest_int('decoder_nodes', **self.param_ranges['decoder_nodes'])\n",
    "        params['decoder_dropout'] = trial.suggest_float('decoder_dropout', **self.param_ranges['decoder_dropout'])\n",
    "        params['learning_rate'] = trial.suggest_float('learning_rate', **self.param_ranges['learning_rate'])\n",
    "        params['weight_decay'] = trial.suggest_float('weight_decay', **self.param_ranges['weight_decay'])\n",
    "        \n",
    "        # ëª¨ë¸ íŒŒë¼ë¯¸í„° êµ¬ì„±\n",
    "        model_params = {\n",
    "            'state_extractor': {\n",
    "                'input_size': 12,\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'num_layers': params['num_layers'],\n",
    "                'dropout': params['extractor_dropout']\n",
    "            },\n",
    "            'decoder': {\n",
    "                'hidden_size': params['hidden_size'],\n",
    "                'output_size': 7,\n",
    "                'num_layers': params['decoder_layers'],\n",
    "                'num_nodes': params['decoder_nodes'],\n",
    "                'dropout': params['decoder_dropout']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„°\n",
    "        optimizer_params = {\n",
    "            'lr': params['learning_rate'],\n",
    "            'weight_decay': params['weight_decay']\n",
    "        }\n",
    "        \n",
    "        return model_params, optimizer_params\n",
    "    \n",
    "    def train_single_fold(self, model_params, optimizer_params, train_loader, val_loader):\n",
    "        \"\"\"ë‹¨ì¼ fold í•™ìŠµ (Free Running ë°©ì‹)\"\"\"\n",
    "        try:\n",
    "            # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "            model = BMEDAutoregressiveModel(model_params['state_extractor'], model_params['decoder']).to(self.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            \n",
    "            for epoch in range(self.train_config['epochs']):\n",
    "                # Free Running í•™ìŠµ (max_predict_length íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "                print(f'epoch: {epoch}')\n",
    "                try:\n",
    "                    train_loss = train_epoch_free_running(model, train_loader, optimizer, self.device)\n",
    "                    \n",
    "                    # Free Running ê²€ì¦ (max_predict_length íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "                    val_loss = validate_epoch_free_running(model, val_loader, self.device)\n",
    "                    \n",
    "                    # Early stopping\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        patience_counter = 0\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                    \n",
    "                    # ìµœì†Œ ì—í¬í¬ í›„ early stopping ì ìš©\n",
    "                    if epoch >= self.train_config['min_epochs'] and patience_counter >= self.train_config['patience']:\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Epoch {epoch} error: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            return best_val_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fold training error: {str(e)}\")\n",
    "            return float('inf')\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna objective í•¨ìˆ˜ - Free Running ê¸°ë°˜\"\"\"\n",
    "        try:\n",
    "            # ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„° ìƒì„±\n",
    "            model_params, optimizer_params = self.create_model(trial)\n",
    "            \n",
    "            # K-fold êµì°¨ê²€ì¦ - ëª¨ë“  fold ì‹¤í–‰\n",
    "            fold_losses = []\n",
    "            for fold_idx, (train_loader, val_loader) in enumerate(self.dataloaders):\n",
    "                fold_loss = self.train_single_fold(\n",
    "                    model_params, optimizer_params, \n",
    "                    train_loader, val_loader\n",
    "                )\n",
    "                print(f'trial: {trial.number}, fold_idx: {fold_idx}')\n",
    "                if fold_loss == float('inf'):\n",
    "                    return float('inf')\n",
    "                \n",
    "                fold_losses.append(fold_loss)\n",
    "            \n",
    "            # í‰ê·  ê²€ì¦ ì†ì‹¤ ë°˜í™˜ (ëª¨ë“  fold ì™„ë£Œ)\n",
    "            mean_loss = sum(fold_losses) / len(fold_losses)\n",
    "            return mean_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Trial {trial.number} error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return float('inf')\n",
    "\n",
    "def optimize_bmed_free_running(trial, dataloaders):\n",
    "    \"\"\"Optunaë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜\"\"\"\n",
    "    optimizer = BMEDFreeRunningOptimizer(dataloaders)\n",
    "    return optimizer.objective(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...\n",
      "Fold 1: Train size = 31, Val size = 8\n",
      "Fold 2: Train size = 31, Val size = 8\n",
      "Fold 3: Train size = 31, Val size = 8\n",
      "Fold 4: Train size = 31, Val size = 8\n",
      "Fold 5: Train size = 32, Val size = 7\n",
      "\n",
      "âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
      "- ì‹œí€€ìŠ¤ ê°œìˆ˜: 39\n",
      "- ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 37\n",
      "- K-fold ìˆ˜: 5\n",
      "- ê° foldëŠ” (train_loader, val_loader) íŠœí”Œ\n",
      "- Free Running ê¸°ë°˜ ìµœì í™” ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "print(\"ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬...\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ì •ê·œí™”\n",
    "ndf, range_mm = norm_data('BMED_DATA_AG.csv')\n",
    "\n",
    "# ì‹œí€€ìŠ¤ ë°ì´í„° êµ¬ì„±\n",
    "seq = seq_data_const(ndf)\n",
    "pad_seq, seq_len, max_seq_len = padded_sequences(seq)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = gen_dataset(pad_seq, seq_len)\n",
    "\n",
    "# K-fold ë°ì´í„°ë¡œë” ìƒì„±\n",
    "dataloaders = kfold_dataloaders(dataset, k_folds=5, batch_size=1, random_state=87)  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"- ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(seq)}\")\n",
    "print(f\"- ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {max_seq_len}\")\n",
    "print(f\"- K-fold ìˆ˜: {len(dataloaders)}\")\n",
    "print(f\"- ê° foldëŠ” (train_loader, val_loader) íŠœí”Œ\")\n",
    "print(f\"- Free Running ê¸°ë°˜ ìµœì í™” ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ BMED Free Running í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 23:56:12,456] A new study created in RDB with name: bmed_autoregressive_free_running_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study ì´ë¦„: bmed_autoregressive_free_running_optimization\n",
      "ì €ì¥ ìœ„ì¹˜: sqlite:///bmed_optuna_study_FR.db\n",
      "ìµœì í™” ë°©ì‹: Free Running + K-fold Cross Validation\n",
      "Teacher Forcingê³¼ ë‹¤ë¥¸ ì :\n",
      "  - ì´ˆê¸° ìƒíƒœë§Œ ì£¼ì–´ì§€ê³  ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\n",
      "  - ì‹¤ì œ inferenceì™€ ë™ì¼í•œ ì¡°ê±´ì—ì„œ í•™ìŠµ\n",
      "  - ë” ë³µì¡í•œ ëª¨ë¸ êµ¬ì¡° í•„ìš” (ì¸µìˆ˜ ì¦ê°€)\n",
      "  - ë” ë‚®ì€ í•™ìŠµë¥ ê³¼ ë” ë§ì€ ì—í¬í¬ ì‚¬ìš©\n",
      "======================================================================\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-08 23:56:56,560] Trial 0 failed with parameters: {'hidden_size': 48, 'num_layers': 5, 'extractor_dropout': 0.39279757672456206, 'decoder_layers': 4, 'decoder_nodes': 32, 'decoder_dropout': 0.16239780813448107, 'learning_rate': 1.7073967431528103e-05, 'weight_decay': 0.0002915443189153752} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1556/181069634.py\", line 33, in <lambda>\n",
      "    lambda trial: optimize_bmed_free_running(trial, dataloaders),\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1556/3559349952.py\", line 138, in optimize_bmed_free_running\n",
      "    return optimizer.objective(trial)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1556/3559349952.py\", line 115, in objective\n",
      "    fold_loss = self.train_single_fold(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1556/3559349952.py\", line 80, in train_single_fold\n",
      "    train_loss = train_epoch_free_running(model, train_loader, optimizer, self.device)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1556/3209576604.py\", line 57, in train_epoch_free_running\n",
      "    loss.backward()\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/sjbaek/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-08 23:56:56,561] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[407]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m device = set_device()\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ìµœì í™” ì‹¤í–‰ - Free Running ì „ìš©\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_bmed_free_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Free Runningì€ ë” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ trial ìˆ˜ ì¡°ì •\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ¯ Free Running ìµœì í™” ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[407]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     29\u001b[39m device = set_device()\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ìµœì í™” ì‹¤í–‰ - Free Running ì „ìš©\u001b[39;00m\n\u001b[32m     32\u001b[39m study.optimize(\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43moptimize_bmed_free_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[32m     34\u001b[39m     n_trials=\u001b[32m10\u001b[39m,  \u001b[38;5;66;03m# Free Runningì€ ë” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ trial ìˆ˜ ì¡°ì •\u001b[39;00m\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ¯ Free Running ìµœì í™” ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[405]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36moptimize_bmed_free_running\u001b[39m\u001b[34m(trial, dataloaders)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Optunaë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m optimizer = BMEDFreeRunningOptimizer(dataloaders)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[405]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mBMEDFreeRunningOptimizer.objective\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    113\u001b[39m fold_losses = []\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (train_loader, val_loader) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataloaders):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     fold_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_single_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial.number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, fold_idx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fold_loss == \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[405]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mBMEDFreeRunningOptimizer.train_single_fold\u001b[39m\u001b[34m(self, model_params, optimizer_params, train_loader, val_loader)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     train_loss = \u001b[43mtrain_epoch_free_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Free Running ê²€ì¦ (max_predict_length íŒŒë¼ë¯¸í„° ì œê±°)\u001b[39;00m\n\u001b[32m     83\u001b[39m     val_loss = validate_epoch_free_running(model, val_loader, \u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[403]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mtrain_epoch_free_running\u001b[39m\u001b[34m(model, train_loader, optimizer, device)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     56\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)  \u001b[38;5;66;03m# ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\u001b[39;00m\n\u001b[32m     59\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torchenv/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# BMED ìê¸°íšŒê·€ ëª¨ë¸ Free Running í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰\n",
    "print(\"ğŸš€ BMED Free Running í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...\")\n",
    "\n",
    "# SQLite ë°ì´í„°ë² ì´ìŠ¤ì— study ê²°ê³¼ ì €ì¥\n",
    "study_name = \"bmed_autoregressive_free_running_optimization\"\n",
    "storage_name = \"sqlite:///bmed_optuna_study_FR.db\"\n",
    "\n",
    "# Optuna study ìƒì„± - Free Running K-fold CV ê¸°ë°˜\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction='minimize',  # ì†ì‹¤ì„ ìµœì†Œí™”\n",
    "    pruner=optuna.pruners.NopPruner(),  # K-fold CVì™€ í˜¸í™˜ì„ ìœ„í•´ pruning ë¹„í™œì„±í™”\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    load_if_exists=True  # ê¸°ì¡´ studyê°€ ìˆìœ¼ë©´ ì´ì–´ì„œ ì‹¤í–‰\n",
    ")\n",
    "\n",
    "print(f\"Study ì´ë¦„: {study_name}\")\n",
    "print(f\"ì €ì¥ ìœ„ì¹˜: {storage_name}\")\n",
    "print(\"ìµœì í™” ë°©ì‹: Free Running + K-fold Cross Validation\")\n",
    "print(\"Teacher Forcingê³¼ ë‹¤ë¥¸ ì :\")\n",
    "print(\"  - ì´ˆê¸° ìƒíƒœë§Œ ì£¼ì–´ì§€ê³  ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\")\n",
    "print(\"  - ì‹¤ì œ inferenceì™€ ë™ì¼í•œ ì¡°ê±´ì—ì„œ í•™ìŠµ\")\n",
    "print(\"  - ë” ë³µì¡í•œ ëª¨ë¸ êµ¬ì¡° í•„ìš” (ì¸µìˆ˜ ì¦ê°€)\")\n",
    "print(\"  - ë” ë‚®ì€ í•™ìŠµë¥ ê³¼ ë” ë§ì€ ì—í¬í¬ ì‚¬ìš©\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = set_device()\n",
    "\n",
    "# ìµœì í™” ì‹¤í–‰ - Free Running ì „ìš©\n",
    "study.optimize(\n",
    "    lambda trial: optimize_bmed_free_running(trial, dataloaders), \n",
    "    n_trials=10,  # Free Runningì€ ë” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ trial ìˆ˜ ì¡°ì •\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¯ Free Running ìµœì í™” ì™„ë£Œ!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "print(\"\\nğŸ“Š ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° (Free Running):\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœì ì˜ ê²€ì¦ ì†ì‹¤: {study.best_value:.6f}\")\n",
    "print(f\"ğŸ“ˆ ì™„ë£Œëœ trial ìˆ˜: {len(study.trials)}\")\n",
    "print(f\"âœ… ì„±ê³µí•œ trial ìˆ˜: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"âŒ ì‹¤íŒ¨í•œ trial ìˆ˜: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œë„ ì €ì¥\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "results_dict = {\n",
    "    'study_name': study_name,\n",
    "    'model_type': 'BMED_Autoregressive_FreeRunning',\n",
    "    'optimization_method': 'Free_Running_K-fold_Cross_Validation',\n",
    "    'best_params': study.best_params,\n",
    "    'best_value': study.best_value,\n",
    "    'n_trials': len(study.trials),\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'hyperparameter_ranges': {\n",
    "        'hidden_size': '32-512 (step 32)',\n",
    "        'num_layers': '2-8',\n",
    "        'decoder_layers': '2-8',\n",
    "        'decoder_nodes': '64-512 (step 32)',\n",
    "        'learning_rate': '1e-5 to 1e-2',\n",
    "        'notes': 'Free Running optimized ranges - higher complexity than Teacher Forcing'\n",
    "    },\n",
    "    'trials': [\n",
    "        {\n",
    "            'number': trial.number,\n",
    "            'value': trial.value,\n",
    "            'params': trial.params,\n",
    "            'state': trial.state.name\n",
    "        }\n",
    "        for trial in study.trials\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('bmed_autoregressive_free_running_optimization_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"  - ë°ì´í„°ë² ì´ìŠ¤: bmed_optuna_study_FR.db\")\n",
    "print(f\"  - JSON íŒŒì¼: bmed_autoregressive_free_running_optimization_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free Running ìµœì í™” ê²°ê³¼ ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“ˆ ìµœì í™” ê²°ê³¼ ì‹œê°í™”...\")\n",
    "\n",
    "# 1. ìµœì í™” ê³¼ì • ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1-1. Optimization History\n",
    "trials = study.trials\n",
    "trial_values = [t.value for t in trials if t.value is not None and t.value != float('inf')]\n",
    "trial_numbers = [t.number for t in trials if t.value is not None and t.value != float('inf')]\n",
    "\n",
    "if trial_values:\n",
    "    axes[0, 0].plot(trial_numbers, trial_values, 'b-', alpha=0.6, linewidth=1)\n",
    "    axes[0, 0].scatter(trial_numbers, trial_values, c='blue', alpha=0.7, s=30)\n",
    "    axes[0, 0].axhline(y=study.best_value, color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Best: {study.best_value:.6f}')\n",
    "    axes[0, 0].set_xlabel('Trial Number')\n",
    "    axes[0, 0].set_ylabel('Validation Loss (Free Running)')\n",
    "    axes[0, 0].set_title('Free Running Optimization History')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_yscale('log')  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ í‘œì‹œ\n",
    "\n",
    "# 1-2. Parameter Importance\n",
    "try:\n",
    "    importance = optuna.importance.get_param_importances(study)\n",
    "    params = list(importance.keys())\n",
    "    values = list(importance.values())\n",
    "    \n",
    "    axes[0, 1].barh(params, values, color='skyblue')\n",
    "    axes[0, 1].set_xlabel('Importance')\n",
    "    axes[0, 1].set_title('Parameter Importance (Free Running)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "except:\n",
    "    axes[0, 1].text(0.5, 0.5, 'Parameter importance\\nnot available\\n(need more completed trials)', \n",
    "                    ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('Parameter Importance (Free Running)')\n",
    "\n",
    "# 1-3. Best Parameters Comparison\n",
    "best_params = study.best_params\n",
    "param_names = ['hidden_size', 'num_layers', 'decoder_layers', 'decoder_nodes']\n",
    "param_values = [best_params.get(name, 0) for name in param_names]\n",
    "\n",
    "bars = axes[1, 0].bar(param_names, param_values, color=['orange', 'green', 'purple', 'brown'])\n",
    "axes[1, 0].set_ylabel('Parameter Value')\n",
    "axes[1, 0].set_title('Best Architecture Parameters (Free Running)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for bar, value in zip(bars, param_values):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                    f'{int(value)}', ha='center', va='bottom')\n",
    "\n",
    "# 1-4. Trial States Distribution\n",
    "states = [t.state.name for t in study.trials]\n",
    "unique_states, counts = np.unique(states, return_counts=True)\n",
    "\n",
    "colors = ['lightgreen', 'lightcoral', 'gold', 'lightblue']\n",
    "wedges, texts, autotexts = axes[1, 1].pie(counts, labels=unique_states, autopct='%1.1f%%', \n",
    "                                          startangle=90, colors=colors[:len(unique_states)])\n",
    "axes[1, 1].set_title('Trial States Distribution (Free Running)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bmed_free_running_optimization_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 2. Teacher Forcing vs Free Running ë¹„êµ (ë§Œì•½ ë‘˜ ë‹¤ ìˆë‹¤ë©´)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ” Free Running í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ì´ ì‹¤í–‰ëœ trial ìˆ˜: {len(study.trials)}\")\n",
    "print(f\"ì„±ê³µí•œ trial ìˆ˜: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"ì‹¤íŒ¨í•œ trial ìˆ˜: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "print(f\"\\nğŸ¯ ìµœì ì˜ ê²€ì¦ ì†ì‹¤: {study.best_value:.6f}\")\n",
    "\n",
    "print(\"\\nğŸ—ï¸ ìµœì  ëª¨ë¸ êµ¬ì¡° (Free Running):\")\n",
    "print(f\"  - LSTM ì€ë‹‰ í¬ê¸°: {study.best_params['hidden_size']}\")\n",
    "print(f\"  - LSTM ë ˆì´ì–´ ìˆ˜: {study.best_params['num_layers']}\")\n",
    "print(f\"  - MLP ë ˆì´ì–´ ìˆ˜: {study.best_params['decoder_layers']}\")\n",
    "print(f\"  - MLP ë…¸ë“œ ìˆ˜: {study.best_params['decoder_nodes']}\")\n",
    "print(f\"  - í•™ìŠµë¥ : {study.best_params['learning_rate']:.2e}\")\n",
    "\n",
    "# 3. ìƒìœ„ 5ê°œ trial ì •ë³´\n",
    "print(f\"\\nğŸ† ìƒìœ„ 5ê°œ trial (Free Running):\")\n",
    "best_trials = sorted([t for t in study.trials if t.value is not None and t.value != float('inf')], \n",
    "                    key=lambda x: x.value)[:5]\n",
    "for i, trial in enumerate(best_trials, 1):\n",
    "    print(f\"  {i}. Trial {trial.number}: Loss = {trial.value:.6f}\")\n",
    "    print(f\"     Hidden: {trial.params.get('hidden_size', 'N/A')}, \"\n",
    "          f\"LSTM Layers: {trial.params.get('num_layers', 'N/A')}, \"\n",
    "          f\"MLP Layers: {trial.params.get('decoder_layers', 'N/A')}\")\n",
    "\n",
    "print(\"\\nâœ… Free Running í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!\")\n",
    "print(\"ğŸš€ ì´ì œ BMED_Autoregressive_Model.ipynbì—ì„œ ì´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… Free Running ëª¨ë¸ í•™ìŠµ ë° ì €ì¥\n",
    "print(\"ğŸ”¨ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… Free Running ëª¨ë¸ í•™ìŠµ...\")\n",
    "\n",
    "# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì„¤ì •\n",
    "best_params = study.best_params\n",
    "final_model_params = {\n",
    "    'state_extractor': {\n",
    "        'input_size': 12,\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'num_layers': best_params['num_layers'],\n",
    "        'dropout': best_params['extractor_dropout']\n",
    "    },\n",
    "    'decoder': {\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'output_size': 7,\n",
    "        'num_layers': best_params['decoder_layers'],\n",
    "        'num_nodes': best_params['decoder_nodes'],\n",
    "        'dropout': best_params['decoder_dropout']\n",
    "    }\n",
    "}\n",
    "\n",
    "final_train_params = {\n",
    "    'epochs': 500,  # ìµœì¢… í•™ìŠµì—ì„œëŠ” ë” ë§ì€ ì—í¬í¬\n",
    "    'patience': 50,\n",
    "    'optimizer': {\n",
    "        'lr': best_params['learning_rate'],\n",
    "        'weight_decay': best_params['weight_decay']\n",
    "    }\n",
    "}\n",
    "\n",
    "# K-foldë¡œ ìµœì¢… í‰ê°€ (Free Running)\n",
    "device = set_device()\n",
    "final_results = []\n",
    "\n",
    "for fold, (train_loader, val_loader) in enumerate(dataloaders):\n",
    "    print(f\"\\n=== Final Free Running Training Fold {fold + 1} ===\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    model = BMEDAutoregressiveModel(final_model_params['state_extractor'], final_model_params['decoder']).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), **final_train_params['optimizer'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(final_train_params['epochs']):\n",
    "        # max_predict_length íŒŒë¼ë¯¸í„° ì œê±°\n",
    "        train_loss = train_epoch_free_running(model, train_loader, optimizer, device)\n",
    "        val_loss = validate_epoch_free_running(model, val_loader, device)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}, Best = {best_val_loss:.6f}\")\n",
    "            \n",
    "        if patience_counter >= final_train_params['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    final_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'model_state': best_model_state\n",
    "    })\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "final_val_losses = [result['best_val_loss'] for result in final_results]\n",
    "final_mean_loss = sum(final_val_losses) / len(final_val_losses)\n",
    "final_std_loss = (sum([(x - final_mean_loss)**2 for x in final_val_losses]) / len(final_val_losses))**0.5\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ ìµœì¢… Free Running ê²°ê³¼ (ì „ì²´ ì‹œí€€ìŠ¤ í•™ìŠµ)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"í‰ê·  ê²€ì¦ ì†ì‹¤: {final_mean_loss:.6f} Â± {final_std_loss:.6f}\")\n",
    "print(f\"ìµœê³  ì„±ëŠ¥ Fold: {min(enumerate(final_val_losses), key=lambda x: x[1])[0] + 1}\")\n",
    "print(f\"ìµœê³  ê²€ì¦ ì†ì‹¤: {min(final_val_losses):.6f}\")\n",
    "\n",
    "for i, result in enumerate(final_results):\n",
    "    print(f\"Fold {i+1}: {result['best_val_loss']:.6f}\")\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "best_fold_idx = min(enumerate(final_val_losses), key=lambda x: x[1])[0]\n",
    "best_model_path = 'best_bmed_autoregressive_FREE_RUNNING_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': final_results[best_fold_idx]['model_state'],\n",
    "    'model_params': final_model_params,\n",
    "    'best_params': best_params,\n",
    "    'val_loss': min(final_val_losses),\n",
    "    'fold': best_fold_idx + 1,\n",
    "    'model_type': 'BMED_Autoregressive_FreeRunning',\n",
    "    'training_method': 'Free_Running_Full_Sequence',\n",
    "    'range_mm': range_mm  # ì •ê·œí™” ë²”ìœ„ë„ í•¨ê»˜ ì €ì¥\n",
    "}, best_model_path)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ìµœê³  ì„±ëŠ¥ Free Running ëª¨ë¸ ì €ì¥: {best_model_path}\")\n",
    "print(\"ğŸ“Š ëª¨ë“  ì‹œí€€ìŠ¤ ê¸¸ì´ì— ëŒ€í•´ ì™„ì „í•œ í•™ìŠµì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"\\nğŸš€ ì´ì œ ì´ ëª¨ë¸ì„ result_processing.ipynbì—ì„œ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“Š Teacher Forcing ê²°ê³¼ì™€ ë¹„êµí•´ë³´ì„¸ìš”!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
