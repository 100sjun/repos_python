{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터베이스 초기화 완료: optimization_results.db\n",
      "사용 가능한 명령: optimize, resume, list, analyze, plot, export, summary\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "# TQDM 경고 제거를 위한 설정 (다른 import보다 먼저)\n",
    "import os\n",
    "os.environ['TQDM_DISABLE'] = '1'\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import sqlite3\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# 추가 warning 제거\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tqdm')\n",
    "warnings.filterwarnings('ignore', message='.*IProgress not found.*')\n",
    "\n",
    "# Optuna 진행 표시줄 비활성화\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# load kinetic data\n",
    "df_kinetic = pd.read_csv('kinetic_data.csv')\n",
    "df_mol = pd.read_csv('kinetic_data.csv').filter(like='mol%')\n",
    "df_time = pd.read_csv('kinetic_data.csv').filter(like='Residence')\n",
    "\n",
    "class OptunaParameterOptimizer:\n",
    "    def __init__(self, db_path='optimization_results.db'):\n",
    "        # define the experimental data\n",
    "        self.exp_list = ['H2', 'CH4', 'C2H6', 'C2H4', 'C2H2', 'C3H8', 'C3H6', 'C4H10', 'C5H12', \n",
    "                        'C', 'CH', 'CH2', 'CH3', 'C2H3', 'C2H5', 'C3H7', 'H',\n",
    "                        'CH3^+', 'CH4^+', 'CH5^+', 'C2H2^+', 'C2H4^+', 'C2H5^+', 'C2H6^+', 'C3H6^+', 'C3H8^+']\n",
    "        self.exp_values = [df_mol.iloc[0].tolist() + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                           df_mol.iloc[1].tolist() + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                           df_mol.iloc[2].tolist() + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                           df_mol.iloc[3].tolist() + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                           df_mol.iloc[4].tolist() + [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "        \n",
    "        # define the file path\n",
    "        self.kinet_path = 'kinet.inp'\n",
    "        self.exe_path = 'run_15kV.exe'\n",
    "        self.db_path = db_path\n",
    "\n",
    "        # dictionary to save the current parameters\n",
    "        self.current_parameters = {}\n",
    "        self.original_parameters = {}\n",
    "        self.load_current_parameters(init=True)\n",
    "        self.original_parameters = self.current_parameters.copy()\n",
    "\n",
    "        # define manipulated variables\n",
    "        self.max_error = 10000\n",
    "        self.parameter_range = 0.5  # 매개변수 변화 범위 (±50%)\n",
    "        self.n_trials = 1000  # 최적화 시도 횟수\n",
    "        \n",
    "        # 데이터베이스 초기화\n",
    "        self.init_database()\n",
    "    \n",
    "    def init_database(self):\n",
    "        \"\"\"데이터베이스 초기화 및 테이블 생성\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 매개변수 개수를 동적으로 확인\n",
    "        param_count = len(self.original_parameters)\n",
    "        \n",
    "        # 매개변수 컬럼을 동적으로 생성\n",
    "        param_columns = []\n",
    "        for i in range(param_count):\n",
    "            param_columns.append(f'f{i} REAL')\n",
    "        \n",
    "        param_columns_str = ', '.join(param_columns)\n",
    "        \n",
    "        # trials 테이블 생성\n",
    "        create_table_sql = f'''\n",
    "        CREATE TABLE IF NOT EXISTS trials (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            trial_number INTEGER NOT NULL,\n",
    "            {param_columns_str},\n",
    "            error REAL NOT NULL,\n",
    "            total_time REAL,\n",
    "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            status TEXT DEFAULT 'COMPLETED',\n",
    "            notes TEXT\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        cursor.execute(create_table_sql)\n",
    "        \n",
    "        # 인덱스 생성 (성능 향상)\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_trial_number ON trials(trial_number)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_error ON trials(error)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON trials(timestamp)')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"데이터베이스 초기화 완료: {self.db_path}\")\n",
    "    \n",
    "    def save_trial_to_db(self, trial_number: int, parameters: Dict[str, float], \n",
    "                        error: float, total_time: float, status: str = 'COMPLETED', \n",
    "                        notes: str = None):\n",
    "        \"\"\"trial 결과를 데이터베이스에 저장\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 매개변수 값들을 순서대로 정렬\n",
    "        param_values = []\n",
    "        for i in range(len(self.original_parameters)):\n",
    "            param_name = f'f{i}'\n",
    "            param_values.append(parameters.get(param_name, None))\n",
    "        \n",
    "        # INSERT SQL 생성\n",
    "        param_placeholders = ', '.join(['?' for _ in range(len(param_values))])\n",
    "        insert_sql = f'''\n",
    "        INSERT INTO trials (trial_number, {', '.join([f'f{i}' for i in range(len(param_values))])}, \n",
    "                           error, total_time, status, notes)\n",
    "        VALUES (?, {param_placeholders}, ?, ?, ?, ?)\n",
    "        '''\n",
    "        \n",
    "        values = [trial_number] + param_values + [error, total_time, status, notes]\n",
    "        \n",
    "        cursor.execute(insert_sql, values)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def get_best_trial_from_db(self):\n",
    "        \"\"\"데이터베이스에서 최고 성능 trial 조회\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "        SELECT * FROM trials \n",
    "        WHERE status = 'COMPLETED' \n",
    "        ORDER BY error ASC \n",
    "        LIMIT 1\n",
    "        ''')\n",
    "        \n",
    "        result = cursor.fetchone()\n",
    "        conn.close()\n",
    "        \n",
    "        if result:\n",
    "            columns = [description[0] for description in cursor.description]\n",
    "            return dict(zip(columns, result))\n",
    "        return None\n",
    "    \n",
    "    def get_trials_summary(self):\n",
    "        \"\"\"데이터베이스에서 trial 요약 통계 조회\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "        SELECT \n",
    "            COUNT(*) as total_trials,\n",
    "            MIN(error) as best_error,\n",
    "            AVG(error) as avg_error,\n",
    "            COUNT(CASE WHEN status = 'COMPLETED' THEN 1 END) as completed_trials,\n",
    "            COUNT(CASE WHEN status = 'FAILED' THEN 1 END) as failed_trials\n",
    "        FROM trials\n",
    "        ''')\n",
    "        \n",
    "        result = cursor.fetchone()\n",
    "        conn.close()\n",
    "        \n",
    "        if result:\n",
    "            columns = ['total_trials', 'best_error', 'avg_error', 'completed_trials', 'failed_trials']\n",
    "            return dict(zip(columns, result))\n",
    "        return None\n",
    "    \n",
    "    def export_trials_to_csv(self, filename='trials_export.csv'):\n",
    "        \"\"\"데이터베이스 결과를 CSV로 내보내기\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        df = pd.read_sql_query('SELECT * FROM trials ORDER BY trial_number', conn)\n",
    "        df.to_csv(filename, index=False)\n",
    "        conn.close()\n",
    "        print(f\"Trial 결과를 {filename}으로 내보냈습니다.\")\n",
    "\n",
    "    def load_current_parameters(self, init=True):\n",
    "        # 시작인 경우 kinet_ori.inp에서 parameter를 불러옴\n",
    "        if init:\n",
    "            with open('kinet_ori.inp', 'r') as f:\n",
    "                content = f.readlines()\n",
    "        else:\n",
    "            # kinet.inp 파일에서 현재 파라미터 값들을 읽어옴\n",
    "            with open(self.kinet_path, 'r') as f:\n",
    "                content = f.readlines()\n",
    "\n",
    "        for line in content:\n",
    "            if \"$ double precision, parameter :: f\" in line:\n",
    "                # f parameter와 값 추출\n",
    "                pattern = r'f(\\d+)\\s*=\\s*([\\d\\.\\+\\-d]+)'\n",
    "                match = re.search(pattern, line)\n",
    "                if match:\n",
    "                    param_name = 'f' + match.group(1)\n",
    "                    value = float(match.group(2).replace('d','e'))\n",
    "                    self.current_parameters[param_name] = value\n",
    "\n",
    "    def modify_parameter(self, param_name: str, new_value: float) -> None:\n",
    "        # modify the parameter value in the kinet.inp file\n",
    "        with open(self.kinet_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # modify the parameter\n",
    "        pattern = rf'(parameter :: {param_name} = )([\\d\\.\\+\\-d]+)'\n",
    "        new_value_str = f'{new_value:.4e}'.replace('e', 'd')\n",
    "        content = re.sub(pattern, f'parameter :: {param_name} = {new_value_str}', content)\n",
    "\n",
    "        with open(self.kinet_path, 'w') as f:\n",
    "            f.write(content)\n",
    "    \n",
    "    def run_preprocessor(self):\n",
    "        process = subprocess.Popen(\n",
    "            './preprocessor.exe',\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            universal_newlines=False)\n",
    "\n",
    "        process.stdin.write(f'{self.kinet_path}\\n'.encode())\n",
    "        process.stdin.flush()\n",
    "        process.stdin.write('.\\n'.encode())\n",
    "        process.stdin.flush()\n",
    "\n",
    "        output, error = process.communicate()\n",
    "        output_str = output.decode('utf-8', errors='ignore') if output else ''\n",
    "        error_str = error.decode('utf-8', errors='ignore') if error else ''\n",
    "        \n",
    "        return output_str, error_str\n",
    "    \n",
    "    def compile_zdp(self):\n",
    "        compile_command = [\n",
    "            'gfortran', '-o', self.exe_path, 'dvode_f90_m.F90', 'zdplaskin_m.F90', 'run_15kV.F90', 'bolsig_x86_64_g.dll'\n",
    "        ]\n",
    "        result = subprocess.run(compile_command, capture_output=True, text=True)\n",
    "    \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"{self.exe_path} 컴파일 실패\")\n",
    "\n",
    "    def run_simulation(self):\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                self.exe_path,    \n",
    "                stdout=subprocess.PIPE,  \n",
    "                stderr=subprocess.STDOUT,  \n",
    "                stdin=subprocess.PIPE,   \n",
    "                universal_newlines=True,\n",
    "                bufsize=1,              \n",
    "            )\n",
    "            \n",
    "            while True:\n",
    "                output = process.stdout.readline()\n",
    "                \n",
    "                if not output:\n",
    "                    break\n",
    "                    \n",
    "                if \"PRESS ENTER TO EXIT\" in output:\n",
    "                    process.kill()\n",
    "                    break\n",
    "\n",
    "                if \"WARNING: BOLSIG+ convergence failed\" in output:\n",
    "                    process.stdin.write('\\n')\n",
    "                    process.stdin.flush()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        return process\n",
    "    \n",
    "    def err_calculation(self):\n",
    "        # read the result file\n",
    "        species = []\n",
    "        with open('qt_species_list.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                comp = line[2:]\n",
    "                species.append(comp.strip())\n",
    "        \n",
    "        df_sp = pd.read_csv('qt_densities.txt', sep=r'\\s+', header=0, names=['Time [s]']+species)\n",
    "        \n",
    "        # calculate the concentration\n",
    "        H2 = (df_sp['H2'])\n",
    "        CH4 = (df_sp['CH4'] + df_sp['CH4(V13)'] + df_sp['CH4(V24)'])\n",
    "        C2H2 = (df_sp['C2H2'] + df_sp['C2H2(V2)'] + df_sp['C2H2(V5)'] + df_sp['C2H2(V13)'])\n",
    "        C2H4 = (df_sp['C2H4'] + df_sp['C2H4(V1)'] + df_sp['C2H4(V2)'])\n",
    "        C2H6 = (df_sp['C2H6'] + df_sp['C2H6(V13)'] + df_sp['C2H6(V24)'])\n",
    "        C3H6 = (df_sp['C3H6'] + df_sp['C3H6(V)'])\n",
    "        C3H8 = (df_sp['C3H8'] + df_sp['C3H8(V1)'] + df_sp['C3H8(V2)'])\n",
    "        C4H10 = (df_sp['C4H9H'])\n",
    "        C5H12 = (df_sp['C5H12'])\n",
    "        C = (df_sp['C'])\n",
    "        CH = (df_sp['CH'])\n",
    "        CH2 = (df_sp['CH2'])\n",
    "        CH3 = (df_sp['CH3'])\n",
    "        C2H3 = (df_sp['C2H3'])\n",
    "        C2H5 = (df_sp['C2H5'])\n",
    "        C3H7 = (df_sp['C3H7'])\n",
    "        H = (df_sp['H'])\n",
    "        CH3_plus = (df_sp['CH3^+'])\n",
    "        CH4_plus = df_sp['CH4^+']\n",
    "        CH5_plus = df_sp['CH5^+']\n",
    "        C2H2_plus = df_sp['C2H2^+']\n",
    "        C2H4_plus = df_sp['C2H4^+']\n",
    "        C2H5_plus = df_sp['C2H5^+']\n",
    "        C2H6_plus = df_sp['C2H6^+']\n",
    "        C3H6_plus = df_sp['C3H6^+']\n",
    "        C3H8_plus = df_sp['C3H8^+']\n",
    "\n",
    "        all_sp = df_sp.sum(axis=1) - df_sp['E']\n",
    "\n",
    "        t0 = abs(df_sp['Time [s]']-5.654867).argmin()\n",
    "        t1 = abs(df_sp['Time [s]']-7.270543).argmin()\n",
    "        t2 = abs(df_sp['Time [s]']-10.17876).argmin()\n",
    "        t3 = abs(df_sp['Time [s]']-16.9646).argmin()\n",
    "        t4 = abs(df_sp['Time [s]']-70).argmin()\n",
    "\n",
    "        sim = []\n",
    "        for t in [t0, t1, t2, t3, t4]:\n",
    "            sim_H2 = float(format(H2.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH4 = float(format(CH4.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H2 = float(format(C2H2.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H4 = float(format(C2H4.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H6 = float(format(C2H6.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C3H6 = float(format(C3H6.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C3H8 = float(format(C3H8.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C4H10 = float(format(C4H10.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C5H12 = float(format(C5H12.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C = float(format(C.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH = float(format(CH.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH2 = float(format(CH2.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH3 = float(format(CH3.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H3 = float(format(C2H3.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H5 = float(format(C2H5.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C3H7 = float(format(C3H7.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_H = float(format(H.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH3_plus = float(format(CH3_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH4_plus = float(format(CH4_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_CH5_plus = float(format(CH5_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H2_plus = float(format(C2H2_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H4_plus = float(format(C2H4_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H5_plus = float(format(C2H5_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C2H6_plus = float(format(C2H6_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C3H6_plus = float(format(C3H6_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "            sim_C3H8_plus = float(format(C3H8_plus.iloc[t]/all_sp.iloc[t]*100, '.6f'))\n",
    "\n",
    "            out_H2 = sim_H2 - 0.5*sim_CH3 - 0.5*sim_CH3_plus - sim_CH2 - 0.5*sim_C2H3 + 0.5*sim_C2H5 + 0.5*sim_C2H5_plus + 0.5*sim_H + 0.5*sim_C3H7 + 0.5*sim_CH5_plus - 1.5*sim_CH\n",
    "            out_CH4 = sim_CH4 + sim_CH3 + sim_CH2 + sim_CH + sim_CH5_plus + sim_CH3_plus + sim_CH4_plus\n",
    "            out_C2H6 = sim_C2H6 + sim_C2H6_plus\n",
    "            out_C2H4 = sim_C2H4 + sim_C2H4_plus + sim_C2H3 + sim_C2H5 + sim_C2H5_plus\n",
    "            out_C2H2 = sim_C2H2 + sim_C2H2_plus\n",
    "            out_C3H8 = sim_C3H8 + sim_C3H8_plus\n",
    "            out_C3H6 = sim_C3H6 + sim_C3H6_plus + sim_C3H7\n",
    "            out_C4H10 = sim_C4H10\n",
    "            out_C5H12 = sim_C5H12\n",
    "            out_C = sim_C\n",
    "            newsim = [out_H2, out_CH4, out_C2H6, out_C2H4, out_C2H2, out_C3H8, out_C3H6, out_C4H10, out_C5H12, out_C]\n",
    "            sim.append(newsim)\n",
    "            \n",
    "        w_factor = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        err = 0\n",
    "        for i in range(len(self.exp_values)):\n",
    "            for j in range(len(self.exp_values[i])):\n",
    "                if j < 10:\n",
    "                    err += w_factor[j] * ((self.exp_values[i][j] - sim[i][j])/self.exp_values[i][j])**2\n",
    "                else:\n",
    "                    err += 0 \n",
    "\n",
    "        return err, df_sp['Time [s]'].iloc[-1]  \n",
    "\n",
    "    def objective(self, trial):\n",
    "        \"\"\"Optuna 목적함수\"\"\"\n",
    "        try:\n",
    "            # 각 매개변수에 대해 탐색 범위 설정\n",
    "            param_values = {}\n",
    "            for param_name, original_value in self.original_parameters.items():\n",
    "                # 로그 스케일로 매개변수 탐색 (원본 값의 ±50% 범위)\n",
    "                low = original_value * (1 - self.parameter_range)\n",
    "                high = original_value * (1 + self.parameter_range)\n",
    "                \n",
    "                # 로그 스케일이 적절한 경우\n",
    "                if original_value > 0:\n",
    "                    param_values[param_name] = trial.suggest_float(\n",
    "                        param_name, low, high, log=True\n",
    "                    )\n",
    "                else:\n",
    "                    param_values[param_name] = trial.suggest_float(\n",
    "                        param_name, low, high\n",
    "                    )\n",
    "            \n",
    "            # 매개변수 적용\n",
    "            for param_name, param_value in param_values.items():\n",
    "                self.modify_parameter(param_name, param_value)\n",
    "            \n",
    "            # 시뮬레이션 실행\n",
    "            self.run_preprocessor()\n",
    "            self.compile_zdp()\n",
    "            self.run_simulation()\n",
    "            \n",
    "            # 오차 계산\n",
    "            error, total_time = self.err_calculation()\n",
    "            \n",
    "            # 시뮬레이션이 제대로 완료되지 않은 경우 패널티\n",
    "            status = 'COMPLETED'\n",
    "            if total_time <= 69.6:\n",
    "                error = self.max_error\n",
    "                status = 'FAILED_TIME'\n",
    "            \n",
    "            # 데이터베이스에 결과 저장\n",
    "            self.save_trial_to_db(\n",
    "                trial_number=trial.number,\n",
    "                parameters=param_values,\n",
    "                error=error,\n",
    "                total_time=total_time,\n",
    "                status=status,\n",
    "                notes=f'Time threshold: {total_time:.2f} > 69.6' if total_time > 69.6 else 'Time threshold not met'\n",
    "            )\n",
    "            \n",
    "            print(f'Trial {trial.number}: error = {error:.6f}, time = {total_time:.2f}, status = {status}')\n",
    "            \n",
    "            return error\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f'Trial {trial.number} failed: {error_msg}')\n",
    "            \n",
    "            # 실패한 trial도 데이터베이스에 저장\n",
    "            self.save_trial_to_db(\n",
    "                trial_number=trial.number,\n",
    "                parameters=param_values if 'param_values' in locals() else {},\n",
    "                error=self.max_error,\n",
    "                total_time=0.0,\n",
    "                status='FAILED_ERROR',\n",
    "                notes=f'Error: {error_msg}'\n",
    "            )\n",
    "            \n",
    "            return self.max_error\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"Optuna를 사용한 최적화 실행\"\"\"\n",
    "        # SQLite storage를 사용하는 Study 생성\n",
    "        storage_url = f'sqlite:///{self.db_path}'\n",
    "        study_name = f'parameter_optimization_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "        \n",
    "        # TPE 샘플러 사용\n",
    "        sampler = TPESampler(n_startup_trials=20)\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            study_name=study_name,\n",
    "            storage=storage_url,\n",
    "            direction='minimize', \n",
    "            sampler=sampler,\n",
    "            load_if_exists=True  # 기존 study가 있으면 이어서 진행\n",
    "        )\n",
    "        \n",
    "        # 초기 매개변수로 첫 번째 trial 설정\n",
    "        print(\"초기 매개변수 평가 중...\")\n",
    "        initial_params = {}\n",
    "        for param_name, value in self.original_parameters.items():\n",
    "            initial_params[param_name] = value\n",
    "        study.enqueue_trial(initial_params)\n",
    "        \n",
    "        # 최적화 실행\n",
    "        print(f\"Optuna 최적화 시작: {self.n_trials}회 시도\")\n",
    "        print(f\"Study name: {study_name}\")\n",
    "        print(f\"Database: {self.db_path}\")\n",
    "        \n",
    "        # 진행 표시줄 비활성화하여 최적화 실행\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, show_progress_bar=False)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(\"\\n최적화 완료!\")\n",
    "        print(f\"최적 오차: {study.best_value:.6f}\")\n",
    "        print(\"최적 매개변수:\")\n",
    "        for param_name, param_value in study.best_params.items():\n",
    "            print(f\"  {param_name}: {param_value:.6e}\")\n",
    "        \n",
    "        # 데이터베이스에서 통계 조회\n",
    "        summary = self.get_trials_summary()\n",
    "        if summary:\n",
    "            print(f\"\\nTrial 통계:\")\n",
    "            print(f\"  총 시도: {summary['total_trials']}\")\n",
    "            print(f\"  성공: {summary['completed_trials']}\")\n",
    "            print(f\"  실패: {summary['failed_trials']}\")\n",
    "            print(f\"  최고 오차: {summary['best_error']:.6f}\")\n",
    "            print(f\"  평균 오차: {summary['avg_error']:.6f}\")\n",
    "        \n",
    "        # 최적 매개변수를 파일에 적용\n",
    "        for param_name, param_value in study.best_params.items():\n",
    "            self.modify_parameter(param_name, param_value)\n",
    "        \n",
    "        return study\n",
    "    \n",
    "    def resume_optimization(self, study_name: str, additional_trials: int = None):\n",
    "        \"\"\"기존 study를 이어서 최적화 실행\"\"\"\n",
    "        storage_url = f'sqlite:///{self.db_path}'\n",
    "        \n",
    "        if additional_trials is None:\n",
    "            additional_trials = self.n_trials\n",
    "        \n",
    "        try:\n",
    "            study = optuna.load_study(\n",
    "                study_name=study_name,\n",
    "                storage=storage_url\n",
    "            )\n",
    "            \n",
    "            print(f\"기존 study 로드됨: {study_name}\")\n",
    "            print(f\"현재까지 {len(study.trials)}개 trial 완료\")\n",
    "            print(f\"추가로 {additional_trials}개 trial 실행\")\n",
    "            \n",
    "            study.optimize(self.objective, n_trials=additional_trials, show_progress_bar=False)\n",
    "            \n",
    "            print(f\"\\n최적화 재개 완료!\")\n",
    "            print(f\"총 trial 수: {len(study.trials)}\")\n",
    "            print(f\"최적 오차: {study.best_value:.6f}\")\n",
    "            \n",
    "            return study\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f\"Study '{study_name}'을 찾을 수 없습니다.\")\n",
    "            print(\"사용 가능한 study 목록:\")\n",
    "            self.list_studies()\n",
    "            return None\n",
    "    \n",
    "    def list_studies(self):\n",
    "        \"\"\"데이터베이스에 저장된 모든 study 목록 조회\"\"\"\n",
    "        storage_url = f'sqlite:///{self.db_path}'\n",
    "        \n",
    "        try:\n",
    "            studies = optuna.get_all_study_summaries(storage=storage_url)\n",
    "            if studies:\n",
    "                print(\"저장된 Study 목록:\")\n",
    "                for study in studies:\n",
    "                    print(f\"  - {study.study_name}: {study.n_trials} trials\")\n",
    "            else:\n",
    "                print(\"저장된 study가 없습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Study 목록 조회 실패: {e}\")\n",
    "    \n",
    "    def analyze_parameters(self, top_n: int = 10):\n",
    "        \"\"\"상위 N개 trial의 매개변수 분석\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        \n",
    "        # 상위 N개 trial 조회\n",
    "        query = f'''\n",
    "        SELECT * FROM trials \n",
    "        WHERE status = 'COMPLETED' \n",
    "        ORDER BY error ASC \n",
    "        LIMIT {top_n}\n",
    "        '''\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"분석할 완료된 trial이 없습니다.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n상위 {len(df)}개 trial 매개변수 분석:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 매개변수 컬럼만 선택\n",
    "        param_cols = [col for col in df.columns if col.startswith('f')]\n",
    "        \n",
    "        for i, row in df.iterrows():\n",
    "            print(f\"Trial {int(row['trial_number'])} (Error: {row['error']:.6f}):\")\n",
    "            for param in param_cols:\n",
    "                if pd.notna(row[param]):\n",
    "                    print(f\"  {param}: {row[param]:.6e}\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        # 매개변수 통계\n",
    "        print(\"\\n매개변수 통계 (상위 trials):\")\n",
    "        param_stats = df[param_cols].describe()\n",
    "        print(param_stats)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plot_optimization_progress(self, output_file: str = 'optimization_progress.html'):\n",
    "        \"\"\"최적화 진행 상황 시각화\"\"\"\n",
    "        try:\n",
    "            import plotly.graph_objects as go\n",
    "            import plotly.express as px\n",
    "            from plotly.subplots import make_subplots\n",
    "            \n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            df = pd.read_sql_query('''\n",
    "                SELECT trial_number, error, timestamp, status\n",
    "                FROM trials \n",
    "                ORDER BY trial_number\n",
    "            ''', conn)\n",
    "            conn.close()\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"시각화할 데이터가 없습니다.\")\n",
    "                return\n",
    "            \n",
    "            # 완료된 trial만 필터링\n",
    "            completed_df = df[df['status'] == 'COMPLETED'].copy()\n",
    "            \n",
    "            if completed_df.empty:\n",
    "                print(\"완료된 trial이 없습니다.\")\n",
    "                return\n",
    "            \n",
    "            # 누적 최소값 계산\n",
    "            completed_df['best_so_far'] = completed_df['error'].cummin()\n",
    "            \n",
    "            # 서브플롯 생성\n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=('최적화 진행 상황', 'Error 분포', 'Trial별 Error', 'Status 분포'),\n",
    "                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                       [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "            )\n",
    "            \n",
    "            # 1. 최적화 진행 상황\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=completed_df['trial_number'], y=completed_df['best_so_far'],\n",
    "                          mode='lines', name='Best Error So Far'),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # 2. Error 분포 히스토그램\n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=completed_df['error'], nbinsx=30, name='Error Distribution'),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            # 3. Trial별 Error 산점도\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=completed_df['trial_number'], y=completed_df['error'],\n",
    "                          mode='markers', name='Trial Errors'),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # 4. Status 분포\n",
    "            status_counts = df['status'].value_counts()\n",
    "            fig.add_trace(\n",
    "                go.Bar(x=status_counts.index, y=status_counts.values, name='Status Count'),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(height=800, showlegend=True, \n",
    "                            title_text=\"매개변수 최적화 분석\")\n",
    "            fig.write_html(output_file)\n",
    "            print(f\"시각화 결과가 {output_file}에 저장되었습니다.\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"시각화를 위해 plotly를 설치하세요: pip install plotly\")\n",
    "        except Exception as e:\n",
    "            print(f\"시각화 생성 실패: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimizer = OptunaParameterOptimizer(db_path='optimization_results.db')\n",
    "    \n",
    "    # 명령행 인자 처리 (간단한 예시)\n",
    "    import sys\n",
    "    \n",
    "    if len(sys.argv) > 1:\n",
    "        command = sys.argv[1]\n",
    "        \n",
    "        if command == 'optimize':\n",
    "            # 새로운 최적화 시작\n",
    "            study = optimizer.optimize()\n",
    "            \n",
    "        elif command == 'resume':\n",
    "            if len(sys.argv) > 2:\n",
    "                study_name = sys.argv[2]\n",
    "                additional_trials = int(sys.argv[3]) if len(sys.argv) > 3 else None\n",
    "                study = optimizer.resume_optimization(study_name, additional_trials)\n",
    "            else:\n",
    "                print(\"사용법: python script.py resume <study_name> [additional_trials]\")\n",
    "                \n",
    "        elif command == 'list':\n",
    "            # Study 목록 조회\n",
    "            optimizer.list_studies()\n",
    "            \n",
    "        elif command == 'analyze':\n",
    "            # 매개변수 분석\n",
    "            top_n = int(sys.argv[2]) if len(sys.argv) > 2 else 10\n",
    "            optimizer.analyze_parameters(top_n)\n",
    "            \n",
    "        elif command == 'plot':\n",
    "            # 시각화\n",
    "            optimizer.plot_optimization_progress()\n",
    "            \n",
    "        elif command == 'export':\n",
    "            # CSV 내보내기\n",
    "            filename = sys.argv[2] if len(sys.argv) > 2 else 'trials_export.csv'\n",
    "            optimizer.export_trials_to_csv(filename)\n",
    "            \n",
    "        elif command == 'summary':\n",
    "            # 통계 요약\n",
    "            summary = optimizer.get_trials_summary()\n",
    "            if summary:\n",
    "                print(\"최적화 통계:\")\n",
    "                for key, value in summary.items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"사용 가능한 명령: optimize, resume, list, analyze, plot, export, summary\")\n",
    "    else:\n",
    "        # 기본: 새로운 최적화 시작\n",
    "        study = optimizer.optimize()\n",
    "        \n",
    "        # 최적화 완료 후 분석\n",
    "        print(\"\\n=== 최적화 완료 후 분석 ===\")\n",
    "        optimizer.analyze_parameters(5)\n",
    "        optimizer.plot_optimization_progress()\n",
    "        optimizer.export_trials_to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
