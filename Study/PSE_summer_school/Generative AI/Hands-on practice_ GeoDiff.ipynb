{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F88mignPnalS"
   },
   "source": [
    "# **🚩Introduction**\n",
    "\n",
    "<img src=\"https://github.com/MinkaiXu/GeoDiff/raw/main/assets/geodiff_framework.png\" width=\"800px\">\n",
    "\n",
    "*   This colab is design to run the pretrained models from [GeoDiff](https://github.com/MinkaiXu/GeoDiff).\n",
    "*   The visualization code is inspired by this PyMol [colab](https://colab.research.google.com/gist/iwatobipen/2ec7faeafe5974501e69fcc98c122922/pymol.ipynb#scrollTo=Hm4kY7CaZSlw).\n",
    "\n",
    "*   The goal is to generate physically accurate molecules. Given the input of a molecule graph (atom and bond structures with their connectivity -- in the form of a 2d graph). What we want to generate is a stable 3d structure of the molecule.\n",
    "\n",
    "*   This colab uses GEOM datasets that have multiple 3d targets per configuration, which provide more compelling targets for generative methods.\n",
    "\n",
    "> [Original colab tutotial](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/geodiff_molecule_conformation.ipynb) made by [natolambert](https://twitter.com/natolambert); **this version was updated for the 2025 KiChe PSE Summer School** by TA [Hayoung Doo](https://github.com/doouv/2025-KIChe-PSE-Summer-School-Tutorial) with academic supervision from [Prof. Jonggeol Na](https://nagroup.ewha.ac.kr/).\n",
    ">\n",
    "> Library: [Hugging Face Diffusers](colab.research.google.com/drive/1oCSVfMhWrqHTeHbKgUSQN9hTKxLzoNyb?pli=1#scrollTo=QiAR1bg1D2yH)\n",
    "\n",
    "---\n",
    "\\\n",
    "<img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-022-01288-4/MediaObjects/41597_2022_1288_Fig1_HTML.png?as=webp\" width=\"600px\">\n",
    "\n",
    "Adapted from [Axelrod, S., Gómez-Bombarelli, R. et al.,Sci Data 9, 185 (2022)](https://www.nature.com/articles/s41597-022-01288-4#citeas)\n",
    "\n",
    "## **🎯 Problem description**\n",
    "\n",
    "*   A single 2D chemical structure can correspond to multiple 3D conformers.\n",
    "\n",
    "*   These conformers must satisfy chemical constraints such as bond lengths, bond angles, steric repulsion, and steric hindrance.\n",
    "\n",
    "*   However, naive sampling often produces a large number of chemically invalid structures.\n",
    "\n",
    "Therefore, the goal is to learn the mapping from a 2D chemical structure to a physically valid distribution of 3D conformers, enabling generation through sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvSuboMSiFi8"
   },
   "source": [
    "# 📥 **Installations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff9SxWnaNId9"
   },
   "source": [
    "### Install Geometric Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g_6zOabItDk"
   },
   "source": [
    "Here we check the **CUDA** and **PyTorch** versions on colab. As of Aug 2025, Colab used python 3.11; install a PyTorch build compatible with python 3.11 (i.e.,≥ 2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1755667670256,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "K0ofXobG5Y-X",
    "outputId": "8c0dd87c-6831-4be7-8f3e-4982025ccc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1755667670299,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "up6x3dxMfizt",
    "outputId": "0201e129-f751-40f2-ba60-6b60b92ed62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📢 PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"\\n📢 PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfthW90vI0nw"
   },
   "source": [
    "Install **PyTorch Geometric (PyG)** that matches the **PyTorch + CUDA** versions printed above.\n",
    "If your versions differ, replace the wheel index at the end of the command\n",
    "(e.g., `torch-2.6.0+cu124.html`) with the one that matches your environment.\n",
    "\n",
    "+) [2025.08.20] torch and cuda version is updated to 2.8.0+cu126\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17425,
     "status": "ok",
     "timestamp": 1755667687762,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "6KCV2Forl8dG",
    "outputId": "8cd4401d-ecba-4649-9673-2106376fd737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (2025.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_geometric) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from requests->torch_geometric) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from requests->torch_geometric) (2025.8.3)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [torch_geometric] [torch_geometric]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 frozenlist-1.7.0 multidict-6.6.4 propcache-0.3.2 torch_geometric-2.6.1 yarl-1.20.1\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/pyg_lib-0.4.0%2Bpt28cu126-cp311-cp311-linux_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_sparse-0.6.18%2Bpt28cu126-cp311-cp311-linux_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_cluster-1.6.3%2Bpt28cu126-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_spline_conv-1.2.2%2Bpt28cu126-cp311-cp311-linux_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from torch_sparse) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from scipy->torch_sparse) (1.23.5)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [torch_cluster]0m [torch_sparse]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pyg_lib-0.4.0+pt28cu126 torch_cluster-1.6.3+pt28cu126 torch_scatter-2.1.2+pt28cu126 torch_sparse-0.6.18+pt28cu126 torch_spline_conv-1.2.2+pt28cu126\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.8.0+cu126.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxv6Mdkalbc"
   },
   "source": [
    "### Install Diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10385,
     "status": "ok",
     "timestamp": 1755667698158,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "mgQA_XN-XGY2"
   },
   "outputs": [],
   "source": [
    "# diffuers & dependencies for diffusers\n",
    "!pip install -q -U diffusers transformers  datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLE7CqlfJNUO"
   },
   "source": [
    "### Install Chemistry-specific Dependencies\n",
    "\n",
    "Install RDKit, a tool for working with and visualizing chemsitry in python (you use this to visualize the generate models later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9754,
     "status": "ok",
     "timestamp": 1755667707914,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "0CPv_NvehRz3",
    "outputId": "28262d9a-e33a-49b6-d628-4f1171a3d7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdkit\n",
      "  Downloading rdkit-2025.3.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from rdkit) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages (from rdkit) (11.3.0)\n",
      "Downloading rdkit-2025.3.5-cp311-cp311-manylinux_2_28_x86_64.whl (36.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2025.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ayJLVBYiTUM"
   },
   "source": [
    "# **🛠️ Create a diffusion model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0rMncVtNSqU"
   },
   "source": [
    "### Model class(es)\n",
    "\n",
    "GeoDiff uses a Graph Field Network (GFN) as its backbone, wrapped within a framework called MoleculeGNN.\n",
    "MoleculeGNN contains both a global and a local branch to capture the overall atomic environment from different perspectives.\n",
    "Each branch employs a distinct type of machine learning potential models: the global branch uses [SchNet](https://arxiv.org/abs/1706.08566), while the local branch is based on the [Graph Isomorphism Network (GIN)](https://arxiv.org/pdf/1810.00826)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3KFC5lM6K5s"
   },
   "source": [
    "### **What is Graph Field Network (GFN)?**\n",
    "*   A graph field network (GFN) is a neural network layer that takes a graph — with nodes, edges, and 3D geometry — and **produces a vector field over the nodes that is equivariant to rotations and translations**.\n",
    "*   It does this by predicting a scalar value for each edge, multiplying it by the unit vector along that edge, and summing over neighbors.\n",
    "*   The result is a per-node 3D vector that changes consistently when the whole molecule is rotated or translated.\n",
    "\n",
    "🔻Below is the schematic diagram of the MoleculeGNN architecture. Let’s map each component to its corresponding part in the code!\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1C6SLpQcz5Fv6SF95XreEIwOjLZvj4GhE\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5FEXz5oXkzt"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1755667707934,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "-3-P4w5sXkRU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjbaek/miniforge3/envs/PSE_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Model adapted from GeoDiff https://github.com/MinkaiXu/GeoDiff\n",
    "# Model inspired by https://github.com/DeepGraphLearning/torchdrug/tree/master/torchdrug/models\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import Embedding, Linear, Module, ModuleList, Sequential\n",
    "\n",
    "from torch_geometric.nn import MessagePassing, radius, radius_graph\n",
    "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj\n",
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import SparseTensor, coalesce\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.models.modeling_utils import ModelMixin\n",
    "from diffusers.utils import BaseOutput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzJQXPN_XrMX"
   },
   "source": [
    "Helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1755667708032,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "oR1Y56QiLY90"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MoleculeGNNOutput(BaseOutput):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
    "            Hidden states output. Output of last layer of model.\n",
    "    \"\"\"\n",
    "\n",
    "    sample: torch.FloatTensor\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer Perceptron. Note there is no activation or dropout in the last layer.\n",
    "    Args:\n",
    "        input_dim (int): input dimension\n",
    "        hidden_dim (list of int): hidden dimensions\n",
    "        activation (str or function, optional): activation function\n",
    "        dropout (float, optional): dropout rate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dims, activation=\"relu\", dropout=0):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.dims = [input_dim] + hidden_dims\n",
    "        if isinstance(activation, str):\n",
    "            self.activation = getattr(F, activation)\n",
    "        else:\n",
    "            print(f\"Warning, activation passed {activation} is not string and ignored\")\n",
    "            self.activation = None\n",
    "        if dropout > 0:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(self.dims) - 1):\n",
    "            self.layers.append(nn.Linear(self.dims[i], self.dims[i + 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i < len(self.layers) - 1:\n",
    "                if self.activation:\n",
    "                    x = self.activation(x)\n",
    "                if self.dropout:\n",
    "                    x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ShiftedSoftplus(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShiftedSoftplus, self).__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softplus(x) - self.shift\n",
    "\n",
    "\n",
    "class CFConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, num_filters, mlp, cutoff, smooth):\n",
    "        super(CFConv, self).__init__(aggr=\"add\")\n",
    "        self.lin1 = Linear(in_channels, num_filters, bias=False)\n",
    "        self.lin2 = Linear(num_filters, out_channels)\n",
    "        self.nn = mlp\n",
    "        self.cutoff = cutoff\n",
    "        self.smooth = smooth\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_length, edge_attr):\n",
    "        if self.smooth:\n",
    "            C = 0.5 * (torch.cos(edge_length * np.pi / self.cutoff) + 1.0)\n",
    "            C = C * (edge_length <= self.cutoff) * (edge_length >= 0.0)  # Modification: cutoff\n",
    "        else:\n",
    "            C = (edge_length <= self.cutoff).float()\n",
    "        W = self.nn(edge_attr) * C.view(-1, 1)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.propagate(edge_index, x=x, W=W)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j: torch.Tensor, W) -> torch.Tensor:\n",
    "        return x_j * W\n",
    "\n",
    "\n",
    "class InteractionBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_gaussians, num_filters, cutoff, smooth):\n",
    "        super(InteractionBlock, self).__init__()\n",
    "        mlp = Sequential(\n",
    "            Linear(num_gaussians, num_filters),\n",
    "            ShiftedSoftplus(),\n",
    "            Linear(num_filters, num_filters),\n",
    "        )\n",
    "        self.conv = CFConv(hidden_channels, hidden_channels, num_filters, mlp, cutoff, smooth)\n",
    "        self.act = ShiftedSoftplus()\n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_length, edge_attr):\n",
    "        x = self.conv(x, edge_index, edge_length, edge_attr)\n",
    "        x = self.act(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SchNetEncoder(Module):\n",
    "    def __init__(\n",
    "        self, hidden_channels=128, num_filters=128, num_interactions=6, edge_channels=100, cutoff=10.0, smooth=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_filters = num_filters\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "        self.embedding = Embedding(100, hidden_channels, max_norm=10.0)\n",
    "\n",
    "        self.interactions = ModuleList()\n",
    "        for _ in range(num_interactions):\n",
    "            block = InteractionBlock(hidden_channels, edge_channels, num_filters, cutoff, smooth)\n",
    "            self.interactions.append(block)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_length, edge_attr, embed_node=True):\n",
    "        if embed_node:\n",
    "            assert z.dim() == 1 and z.dtype == torch.long\n",
    "            h = self.embedding(z)\n",
    "        else:\n",
    "            h = z\n",
    "        for interaction in self.interactions:\n",
    "            h = h + interaction(h, edge_index, edge_length, edge_attr)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class GINEConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Custom class of the graph isomorphism operator from the \"How Powerful are Graph Neural Networks?\n",
    "    https://arxiv.org/abs/1810.00826 paper. Note that this implementation has the added option of a custom activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mlp: Callable, eps: float = 0.0, train_eps: bool = False, activation=\"softplus\", **kwargs):\n",
    "        super(GINEConv, self).__init__(aggr=\"add\", **kwargs)\n",
    "        self.nn = mlp\n",
    "        self.initial_eps = eps\n",
    "\n",
    "        if isinstance(activation, str):\n",
    "            self.activation = getattr(F, activation)\n",
    "        else:\n",
    "            self.activation = None\n",
    "\n",
    "        if train_eps:\n",
    "            self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer(\"eps\", torch.Tensor([eps]))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Union[Tensor, OptPairTensor], edge_index: Adj, edge_attr: OptTensor = None, size: Size = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # Node and edge feature dimensionalites need to match.\n",
    "        if isinstance(edge_index, torch.Tensor):\n",
    "            assert edge_attr is not None\n",
    "            assert x[0].size(-1) == edge_attr.size(-1)\n",
    "        elif isinstance(edge_index, SparseTensor):\n",
    "            assert x[0].size(-1) == edge_index.size(-1)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if x_r is not None:\n",
    "            out += (1 + self.eps) * x_r\n",
    "\n",
    "        return self.nn(out)\n",
    "\n",
    "    def message(self, x_j: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        if self.activation:\n",
    "            return self.activation(x_j + edge_attr)\n",
    "        else:\n",
    "            return x_j + edge_attr\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(nn={})\".format(self.__class__.__name__, self.nn)\n",
    "\n",
    "\n",
    "class GINEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_convs=3, activation=\"relu\", short_cut=True, concat_hidden=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_convs = num_convs\n",
    "        self.short_cut = short_cut\n",
    "        self.concat_hidden = concat_hidden\n",
    "        self.node_emb = nn.Embedding(100, hidden_dim)\n",
    "\n",
    "        if isinstance(activation, str):\n",
    "            self.activation = getattr(F, activation)\n",
    "        else:\n",
    "            self.activation = None\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(self.num_convs):\n",
    "            self.convs.append(\n",
    "                GINEConv(\n",
    "                    MultiLayerPerceptron(hidden_dim, [hidden_dim, hidden_dim], activation=activation),\n",
    "                    activation=activation,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, z, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            data: (torch_geometric.data.Data): batched graph edge_index: bond indices of the original graph (num_node,\n",
    "            hidden) edge_attr: edge feature tensor with shape (num_edge, hidden)\n",
    "        Output:\n",
    "            node_feature: graph feature\n",
    "        \"\"\"\n",
    "\n",
    "        node_attr = self.node_emb(z)  # (num_node, hidden)\n",
    "\n",
    "        hiddens = []\n",
    "        conv_input = node_attr  # (num_node, hidden)\n",
    "\n",
    "        for conv_idx, conv in enumerate(self.convs):\n",
    "            hidden = conv(conv_input, edge_index, edge_attr)\n",
    "            if conv_idx < len(self.convs) - 1 and self.activation is not None:\n",
    "                hidden = self.activation(hidden)\n",
    "            assert hidden.shape == conv_input.shape\n",
    "            if self.short_cut and hidden.shape == conv_input.shape:\n",
    "                hidden += conv_input\n",
    "\n",
    "            hiddens.append(hidden)\n",
    "            conv_input = hidden\n",
    "\n",
    "        if self.concat_hidden:\n",
    "            node_feature = torch.cat(hiddens, dim=-1)\n",
    "        else:\n",
    "            node_feature = hiddens[-1]\n",
    "\n",
    "        return node_feature\n",
    "\n",
    "\n",
    "class MLPEdgeEncoder(Module):\n",
    "    def __init__(self, hidden_dim=100, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bond_emb = Embedding(100, embedding_dim=self.hidden_dim)\n",
    "        self.mlp = MultiLayerPerceptron(1, [self.hidden_dim, self.hidden_dim], activation=activation)\n",
    "\n",
    "    @property\n",
    "    def out_channels(self):\n",
    "        return self.hidden_dim\n",
    "\n",
    "    def forward(self, edge_length, edge_type):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            edge_length: The length of edges, shape=(E, 1). edge_type: The type pf edges, shape=(E,)\n",
    "        Returns:\n",
    "            edge_attr: The representation of edges. (E, 2 * num_gaussians)\n",
    "        \"\"\"\n",
    "        d_emb = self.mlp(edge_length)  # (num_edge, hidden_dim)\n",
    "        edge_attr = self.bond_emb(edge_type)  # (num_edge, hidden_dim)\n",
    "        return d_emb * edge_attr  # (num_edge, hidden)\n",
    "\n",
    "\n",
    "def assemble_atom_pair_feature(node_attr, edge_index, edge_attr):\n",
    "    h_row, h_col = node_attr[edge_index[0]], node_attr[edge_index[1]]\n",
    "    h_pair = torch.cat([h_row * h_col, edge_attr], dim=-1)  # (E, 2H)\n",
    "    return h_pair\n",
    "\n",
    "\n",
    "def _extend_graph_order(num_nodes, edge_index, edge_type, order=3):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_nodes:  Number of atoms.\n",
    "        edge_index: Bond indices of the original graph.\n",
    "        edge_type:  Bond types of the original graph.\n",
    "        order:  Extension order.\n",
    "    Returns:\n",
    "        new_edge_index: Extended edge indices. new_edge_type: Extended edge types.\n",
    "    \"\"\"\n",
    "\n",
    "    def binarize(x):\n",
    "        return torch.where(x > 0, torch.ones_like(x), torch.zeros_like(x))\n",
    "\n",
    "    def get_higher_order_adj_matrix(adj, order):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            adj:        (N, N)\n",
    "            type_mat:   (N, N)\n",
    "        Returns:\n",
    "            Following attributes will be updated:\n",
    "              - edge_index\n",
    "              - edge_type\n",
    "            Following attributes will be added to the data object:\n",
    "              - bond_edge_index: Original edge_index.\n",
    "        \"\"\"\n",
    "        adj_mats = [\n",
    "            torch.eye(adj.size(0), dtype=torch.long, device=adj.device),\n",
    "            binarize(adj + torch.eye(adj.size(0), dtype=torch.long, device=adj.device)),\n",
    "        ]\n",
    "\n",
    "        for i in range(2, order + 1):\n",
    "            adj_mats.append(binarize(adj_mats[i - 1] @ adj_mats[1]))\n",
    "        order_mat = torch.zeros_like(adj)\n",
    "\n",
    "        for i in range(1, order + 1):\n",
    "            order_mat += (adj_mats[i] - adj_mats[i - 1]) * i\n",
    "\n",
    "        return order_mat\n",
    "\n",
    "    num_types = 22\n",
    "    # given from len(BOND_TYPES), where BOND_TYPES = {t: i for i, t in enumerate(BT.names.values())}\n",
    "    # from rdkit.Chem.rdchem import BondType as BT\n",
    "    N = num_nodes\n",
    "    adj = to_dense_adj(edge_index).squeeze(0)\n",
    "    adj_order = get_higher_order_adj_matrix(adj, order)  # (N, N)\n",
    "\n",
    "    type_mat = to_dense_adj(edge_index, edge_attr=edge_type).squeeze(0)  # (N, N)\n",
    "    type_highorder = torch.where(adj_order > 1, num_types + adj_order - 1, torch.zeros_like(adj_order))\n",
    "    assert (type_mat * type_highorder == 0).all()\n",
    "    type_new = type_mat + type_highorder\n",
    "\n",
    "    new_edge_index, new_edge_type = dense_to_sparse(type_new)\n",
    "    _, edge_order = dense_to_sparse(adj_order)\n",
    "\n",
    "    # data.bond_edge_index = data.edge_index  # Save original edges\n",
    "    new_edge_index, new_edge_type = coalesce(new_edge_index, new_edge_type.long(), N, N)  # modify data\n",
    "\n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "\n",
    "def _extend_to_radius_graph(pos, edge_index, edge_type, cutoff, batch, unspecified_type_number=0, is_sidechain=None):\n",
    "    assert edge_type.dim() == 1\n",
    "    N = pos.size(0)\n",
    "\n",
    "    bgraph_adj = torch.sparse.LongTensor(edge_index, edge_type, torch.Size([N, N]))\n",
    "\n",
    "    if is_sidechain is None:\n",
    "        rgraph_edge_index = radius_graph(pos, r=cutoff, batch=batch)  # (2, E_r)\n",
    "    else:\n",
    "        # fetch sidechain and its batch index\n",
    "        is_sidechain = is_sidechain.bool()\n",
    "        dummy_index = torch.arange(pos.size(0), device=pos.device)\n",
    "        sidechain_pos = pos[is_sidechain]\n",
    "        sidechain_index = dummy_index[is_sidechain]\n",
    "        sidechain_batch = batch[is_sidechain]\n",
    "\n",
    "        assign_index = radius(x=pos, y=sidechain_pos, r=cutoff, batch_x=batch, batch_y=sidechain_batch)\n",
    "        r_edge_index_x = assign_index[1]\n",
    "        r_edge_index_y = assign_index[0]\n",
    "        r_edge_index_y = sidechain_index[r_edge_index_y]\n",
    "\n",
    "        rgraph_edge_index1 = torch.stack((r_edge_index_x, r_edge_index_y))  # (2, E)\n",
    "        rgraph_edge_index2 = torch.stack((r_edge_index_y, r_edge_index_x))  # (2, E)\n",
    "        rgraph_edge_index = torch.cat((rgraph_edge_index1, rgraph_edge_index2), dim=-1)  # (2, 2E)\n",
    "        # delete self loop\n",
    "        rgraph_edge_index = rgraph_edge_index[:, (rgraph_edge_index[0] != rgraph_edge_index[1])]\n",
    "\n",
    "    rgraph_adj = torch.sparse.LongTensor(\n",
    "        rgraph_edge_index,\n",
    "        torch.ones(rgraph_edge_index.size(1)).long().to(pos.device) * unspecified_type_number,\n",
    "        torch.Size([N, N]),\n",
    "    )\n",
    "\n",
    "    composed_adj = (bgraph_adj + rgraph_adj).coalesce()  # Sparse (N, N, T)\n",
    "\n",
    "    new_edge_index = composed_adj.indices()\n",
    "    new_edge_type = composed_adj.values().long()\n",
    "\n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "\n",
    "def extend_graph_order_radius(\n",
    "    num_nodes,\n",
    "    pos,\n",
    "    edge_index,\n",
    "    edge_type,\n",
    "    batch,\n",
    "    order=3,\n",
    "    cutoff=10.0,\n",
    "    extend_order=True,\n",
    "    extend_radius=True,\n",
    "    is_sidechain=None,\n",
    "):\n",
    "    if extend_order:\n",
    "        edge_index, edge_type = _extend_graph_order(\n",
    "            num_nodes=num_nodes, edge_index=edge_index, edge_type=edge_type, order=order\n",
    "        )\n",
    "\n",
    "    if extend_radius:\n",
    "        edge_index, edge_type = _extend_to_radius_graph(\n",
    "            pos=pos, edge_index=edge_index, edge_type=edge_type, cutoff=cutoff, batch=batch, is_sidechain=is_sidechain\n",
    "        )\n",
    "\n",
    "    return edge_index, edge_type\n",
    "\n",
    "\n",
    "def get_distance(pos, edge_index):\n",
    "    return (pos[edge_index[0]] - pos[edge_index[1]]).norm(dim=-1)\n",
    "\n",
    "\n",
    "def graph_field_network(score_d, pos, edge_index, edge_length):\n",
    "    \"\"\"\n",
    "    Transformation to make the epsilon predicted from the diffusion model roto-translational equivariant. See equations\n",
    "    5-7 of the GeoDiff Paper https://arxiv.org/pdf/2203.02923.pdf\n",
    "    \"\"\"\n",
    "    N = pos.size(0)\n",
    "    dd_dr = (1.0 / edge_length) * (pos[edge_index[0]] - pos[edge_index[1]])  # (E, 3)\n",
    "    score_pos = scatter_add(dd_dr * score_d, edge_index[0], dim=0, dim_size=N) + scatter_add(\n",
    "        -dd_dr * score_d, edge_index[1], dim=0, dim_size=N\n",
    "    )  # (N, 3)\n",
    "    return score_pos\n",
    "\n",
    "\n",
    "def clip_norm(vec, limit, p=2):\n",
    "    norm = torch.norm(vec, dim=-1, p=2, keepdim=True)\n",
    "    denom = torch.where(norm > limit, limit / norm, torch.ones_like(norm))\n",
    "    return vec * denom\n",
    "\n",
    "\n",
    "def is_local_edge(edge_type):\n",
    "    return edge_type > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWrHJFcYXyUB"
   },
   "source": [
    "Main model class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1755667708129,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "MCeZA1qQXzoK"
   },
   "outputs": [],
   "source": [
    "class MoleculeGNN(ModelMixin, ConfigMixin):\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim=128,\n",
    "        num_convs=6,\n",
    "        num_convs_local=4,\n",
    "        cutoff=10.0,\n",
    "        mlp_act=\"relu\",\n",
    "        edge_order=3,\n",
    "        edge_encoder=\"mlp\",\n",
    "        smooth_conv=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.edge_encoder = edge_encoder\n",
    "        self.edge_order = edge_order\n",
    "\n",
    "        \"\"\"\n",
    "        edge_encoder: Takes both edge type and edge length as input and outputs a vector [Note]: node embedding is done\n",
    "        in SchNetEncoder\n",
    "        \"\"\"\n",
    "        self.edge_encoder_global = MLPEdgeEncoder(hidden_dim, mlp_act)  # get_edge_encoder(config)\n",
    "        self.edge_encoder_local = MLPEdgeEncoder(hidden_dim, mlp_act)  # get_edge_encoder(config)\n",
    "\n",
    "        \"\"\"\n",
    "        The graph neural network that extracts node-wise features.\n",
    "        \"\"\"\n",
    "        self.encoder_global = SchNetEncoder(\n",
    "            hidden_channels=hidden_dim,\n",
    "            num_filters=hidden_dim,\n",
    "            num_interactions=num_convs,\n",
    "            edge_channels=self.edge_encoder_global.out_channels,\n",
    "            cutoff=cutoff,\n",
    "            smooth=smooth_conv,\n",
    "        )\n",
    "        self.encoder_local = GINEncoder(\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_convs=num_convs_local,\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        `output_mlp` takes a mixture of two nodewise features and edge features as input and outputs\n",
    "            gradients w.r.t. edge_length (out_dim = 1).\n",
    "        \"\"\"\n",
    "        self.grad_global_dist_mlp = MultiLayerPerceptron(\n",
    "            2 * hidden_dim, [hidden_dim, hidden_dim // 2, 1], activation=mlp_act\n",
    "        )\n",
    "\n",
    "        self.grad_local_dist_mlp = MultiLayerPerceptron(\n",
    "            2 * hidden_dim, [hidden_dim, hidden_dim // 2, 1], activation=mlp_act\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Incorporate parameters together\n",
    "        \"\"\"\n",
    "        self.model_global = nn.ModuleList([self.edge_encoder_global, self.encoder_global, self.grad_global_dist_mlp])\n",
    "        self.model_local = nn.ModuleList([self.edge_encoder_local, self.encoder_local, self.grad_local_dist_mlp])\n",
    "\n",
    "    def _forward(\n",
    "        self,\n",
    "        atom_type,\n",
    "        pos,\n",
    "        bond_index,\n",
    "        bond_type,\n",
    "        batch,\n",
    "        time_step,  # NOTE, model trained without timestep performed best\n",
    "        edge_index=None,\n",
    "        edge_type=None,\n",
    "        edge_length=None,\n",
    "        return_edges=False,\n",
    "        extend_order=True,\n",
    "        extend_radius=True,\n",
    "        is_sidechain=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            atom_type:  Types of atoms, (N, ).\n",
    "            bond_index: Indices of bonds (not extended, not radius-graph), (2, E).\n",
    "            bond_type:  Bond types, (E, ).\n",
    "            batch:      Node index to graph index, (N, ).\n",
    "        \"\"\"\n",
    "        N = atom_type.size(0)\n",
    "        if edge_index is None or edge_type is None or edge_length is None:\n",
    "            edge_index, edge_type = extend_graph_order_radius(\n",
    "                num_nodes=N,\n",
    "                pos=pos,\n",
    "                edge_index=bond_index,\n",
    "                edge_type=bond_type,\n",
    "                batch=batch,\n",
    "                order=self.edge_order,\n",
    "                cutoff=self.cutoff,\n",
    "                extend_order=extend_order,\n",
    "                extend_radius=extend_radius,\n",
    "                is_sidechain=is_sidechain,\n",
    "            )\n",
    "            edge_length = get_distance(pos, edge_index).unsqueeze(-1)  # (E, 1)\n",
    "        local_edge_mask = is_local_edge(edge_type)  # (E, )\n",
    "\n",
    "        # with the parameterization of NCSNv2\n",
    "        # DDPM loss implicit handle the noise variance scale conditioning\n",
    "        sigma_edge = torch.ones(size=(edge_index.size(1), 1), device=pos.device)  # (E, 1)\n",
    "\n",
    "        # Encoding global\n",
    "        edge_attr_global = self.edge_encoder_global(edge_length=edge_length, edge_type=edge_type)  # Embed edges\n",
    "\n",
    "        # Global\n",
    "        node_attr_global = self.encoder_global(\n",
    "            z=atom_type,\n",
    "            edge_index=edge_index,\n",
    "            edge_length=edge_length,\n",
    "            edge_attr=edge_attr_global,\n",
    "        )\n",
    "        # Assemble pairwise features\n",
    "        h_pair_global = assemble_atom_pair_feature(\n",
    "            node_attr=node_attr_global,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr_global,\n",
    "        )  # (E_global, 2H)\n",
    "        # Invariant features of edges (radius graph, global)\n",
    "        edge_inv_global = self.grad_global_dist_mlp(h_pair_global) * (1.0 / sigma_edge)  # (E_global, 1)\n",
    "\n",
    "        # Encoding local\n",
    "        edge_attr_local = self.edge_encoder_global(edge_length=edge_length, edge_type=edge_type)  # Embed edges\n",
    "        # edge_attr += temb_edge\n",
    "\n",
    "        # Local\n",
    "        node_attr_local = self.encoder_local(\n",
    "            z=atom_type,\n",
    "            edge_index=edge_index[:, local_edge_mask],\n",
    "            edge_attr=edge_attr_local[local_edge_mask],\n",
    "        )\n",
    "        # Assemble pairwise features\n",
    "        h_pair_local = assemble_atom_pair_feature(\n",
    "            node_attr=node_attr_local,\n",
    "            edge_index=edge_index[:, local_edge_mask],\n",
    "            edge_attr=edge_attr_local[local_edge_mask],\n",
    "        )  # (E_local, 2H)\n",
    "\n",
    "        # Invariant features of edges (bond graph, local)\n",
    "        if isinstance(sigma_edge, torch.Tensor):\n",
    "            edge_inv_local = self.grad_local_dist_mlp(h_pair_local) * (\n",
    "                1.0 / sigma_edge[local_edge_mask]\n",
    "            )  # (E_local, 1)\n",
    "        else:\n",
    "            edge_inv_local = self.grad_local_dist_mlp(h_pair_local) * (1.0 / sigma_edge)  # (E_local, 1)\n",
    "\n",
    "        if return_edges:\n",
    "            return edge_inv_global, edge_inv_local, edge_index, edge_type, edge_length, local_edge_mask\n",
    "        else:\n",
    "            return edge_inv_global, edge_inv_local\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sample,\n",
    "        timestep: Union[torch.Tensor, float, int],\n",
    "        return_dict: bool = True,\n",
    "        sigma=1.0,\n",
    "        global_start_sigma=0.5,\n",
    "        w_global=1.0,\n",
    "        extend_order=False,\n",
    "        extend_radius=True,\n",
    "        clip_local=None,\n",
    "        clip_global=1000.0,\n",
    "    ) -> Union[MoleculeGNNOutput, Tuple]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            sample: packed torch geometric object\n",
    "            timestep (`torch.FloatTensor` or `float` or `int): TODO verify type and shape (batch) timesteps\n",
    "            return_dict (`bool`, *optional*, defaults to `True`):\n",
    "                Whether or not to return a [`~models.molecule_gnn.MoleculeGNNOutput`] instead of a plain tuple.\n",
    "        Returns:\n",
    "            [`~models.molecule_gnn.MoleculeGNNOutput`] or `tuple`: [`~models.molecule_gnn.MoleculeGNNOutput`] if\n",
    "            `return_dict` is True, otherwise a `tuple`. When returning a tuple, the first element is the sample tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # unpack sample\n",
    "        atom_type = sample.atom_type\n",
    "        bond_index = sample.edge_index\n",
    "        bond_type = sample.edge_type\n",
    "        num_graphs = sample.num_graphs\n",
    "        pos = sample.pos\n",
    "\n",
    "        timesteps = torch.full(size=(num_graphs,), fill_value=timestep, dtype=torch.long, device=pos.device)\n",
    "\n",
    "        edge_inv_global, edge_inv_local, edge_index, edge_type, edge_length, local_edge_mask = self._forward(\n",
    "            atom_type=atom_type,\n",
    "            pos=sample.pos,\n",
    "            bond_index=bond_index,\n",
    "            bond_type=bond_type,\n",
    "            batch=sample.batch,\n",
    "            time_step=timesteps,\n",
    "            return_edges=True,\n",
    "            extend_order=extend_order,\n",
    "            extend_radius=extend_radius,\n",
    "        )  # (E_global, 1), (E_local, 1)\n",
    "\n",
    "        # Important equation in the paper for equivariant features - eqns 5-7 of GeoDiff\n",
    "        node_eq_local = graph_field_network(\n",
    "            edge_inv_local, pos, edge_index[:, local_edge_mask], edge_length[local_edge_mask]\n",
    "        )\n",
    "        if clip_local is not None:\n",
    "            node_eq_local = clip_norm(node_eq_local, limit=clip_local)\n",
    "\n",
    "        # Global\n",
    "        if sigma < global_start_sigma:\n",
    "            edge_inv_global = edge_inv_global * (1 - local_edge_mask.view(-1, 1).float())\n",
    "            node_eq_global = graph_field_network(edge_inv_global, pos, edge_index, edge_length)\n",
    "            node_eq_global = clip_norm(node_eq_global, limit=clip_global)\n",
    "        else:\n",
    "            node_eq_global = 0\n",
    "\n",
    "        # Sum\n",
    "        eps_pos = node_eq_local + node_eq_global * w_global\n",
    "\n",
    "        if not return_dict:\n",
    "            return (-eps_pos,)\n",
    "\n",
    "        return MoleculeGNNOutput(sample=torch.FloatTensor(-eps_pos).to(pos.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCIrPYSJj9wd"
   },
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdrAr6Ch--Ab"
   },
   "source": [
    "#### Load a model\n",
    "The model used is a design an\n",
    "equivariant convolutional layer, named graph field network (GFN).\n",
    "\n",
    "The warning about `betas` and `alphas` can be ignored, those were moved to the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1755667708647,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "DyCo0nsqjbml",
    "outputId": "66c982a9-d308-431a-a875-3419d6b821b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "An error occurred while trying to fetch fusing/gfn-molecule-gen-drugs: fusing/gfn-molecule-gen-drugs does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "The config attributes {'type': 'diffusion', 'network': 'dualenc', 'beta_schedule': 'sigmoid', 'beta_start': 1e-07, 'beta_end': 0.002, 'num_diffusion_timesteps': 5000} were passed to MoleculeGNN, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "Some weights of the model checkpoint at fusing/gfn-molecule-gen-drugs were not used when initializing MoleculeGNN: \n",
      " ['alphas, betas']\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "model = MoleculeGNN.from_pretrained(\"fusing/gfn-molecule-gen-drugs\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1755667708667,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "nLRyLfOQRSV6",
    "outputId": "88bab2be-fb80-4f94-e1c4-293e5b13530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoleculeGNN(\n",
      "  (edge_encoder_global): MLPEdgeEncoder(\n",
      "    (bond_emb): Embedding(100, 128)\n",
      "    (mlp): MultiLayerPerceptron(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (edge_encoder_local): MLPEdgeEncoder(\n",
      "    (bond_emb): Embedding(100, 128)\n",
      "    (mlp): MultiLayerPerceptron(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_global): SchNetEncoder(\n",
      "    (embedding): Embedding(100, 128, max_norm=10.0)\n",
      "    (interactions): ModuleList(\n",
      "      (0-5): 6 x InteractionBlock(\n",
      "        (conv): CFConv()\n",
      "        (act): ShiftedSoftplus()\n",
      "        (lin): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder_local): GINEncoder(\n",
      "    (node_emb): Embedding(100, 128)\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x GINEConv(nn=MultiLayerPerceptron(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      ))\n",
      "    )\n",
      "  )\n",
      "  (grad_global_dist_mlp): MultiLayerPerceptron(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (grad_local_dist_mlp): MultiLayerPerceptron(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (model_global): ModuleList(\n",
      "    (0): MLPEdgeEncoder(\n",
      "      (bond_emb): Embedding(100, 128)\n",
      "      (mlp): MultiLayerPerceptron(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SchNetEncoder(\n",
      "      (embedding): Embedding(100, 128, max_norm=10.0)\n",
      "      (interactions): ModuleList(\n",
      "        (0-5): 6 x InteractionBlock(\n",
      "          (conv): CFConv()\n",
      "          (act): ShiftedSoftplus()\n",
      "          (lin): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MultiLayerPerceptron(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model_local): ModuleList(\n",
      "    (0): MLPEdgeEncoder(\n",
      "      (bond_emb): Embedding(100, 128)\n",
      "      (mlp): MultiLayerPerceptron(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): GINEncoder(\n",
      "      (node_emb): Embedding(100, 128)\n",
      "      (convs): ModuleList(\n",
      "        (0-3): 4 x GINEConv(nn=MultiLayerPerceptron(\n",
      "          (layers): ModuleList(\n",
      "            (0-1): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "        ))\n",
      "      )\n",
      "    )\n",
      "    (2): MultiLayerPerceptron(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdclRaqoUWUD"
   },
   "source": [
    "The warnings above are because the pre-trained model was uploaded before cleaning the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlOkPySoJ1m9"
   },
   "source": [
    "#### Create scheduler\n",
    "Note, other schedulers are used in the paper for slightly improved performance over DDPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1755667708679,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "nNHnIk9CkAb2"
   },
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1755667708686,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "RnDJdDBztjFF"
   },
   "outputs": [],
   "source": [
    "num_timesteps = 1000\n",
    "scheduler = DDPMScheduler(num_train_timesteps=num_timesteps,beta_schedule=\"sigmoid\",beta_start=1e-7, beta_end=2e-3, clip_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vh3fpSAflkL"
   },
   "source": [
    "### Get a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUNxfK3ln98Q"
   },
   "source": [
    "Load the dataset with torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755667708698,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "ZptVb6timLKn"
   },
   "outputs": [],
   "source": [
    "import torch, pickle\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "torch.serialization.add_safe_globals([Chem.Mol, Chem.rdchem.Mol, nx.Graph, nx.DiGraph]) # For safe-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1755667709154,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "KlrjsSyKmOqn"
   },
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/datasets/fusing/geodiff-example-data/resolve/main/data/molecules.pkl -O molecules.pkl\n",
    "dataset = torch.load(\"molecules.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeWbwP4Pmzvy"
   },
   "source": [
    "Since the `dataset` object is a legacy PyG dataset, it needs to be migrated to the current API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1755667709184,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "pbtShAbYnAs-"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def convert_old_pyg_to_new(old_data):\n",
    "    if isinstance(old_data, Data) and hasattr(old_data.__dict__, '_store'):\n",
    "        return old_data\n",
    "\n",
    "    new_data = Data()\n",
    "\n",
    "    old_dict = getattr(old_data, '__dict__', {})\n",
    "    for key, value in old_dict.items():\n",
    "        if not key.startswith('_') and value is not None:\n",
    "            setattr(new_data, key, value)\n",
    "\n",
    "    # num_nodes inference\n",
    "    if not hasattr(new_data, 'num_nodes') or new_data.num_nodes is None:\n",
    "        # confim in an order of pos_ref-> x-> pos\n",
    "        for attr in ['pos_ref', 'x', 'pos']:\n",
    "            if hasattr(new_data, attr):\n",
    "                tensor = getattr(new_data, attr)\n",
    "                if tensor is not None:\n",
    "                    new_data.num_nodes = int(tensor.size(0))\n",
    "                    break\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1755667709231,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "OQ1pfMEonSkn"
   },
   "outputs": [],
   "source": [
    "dataset = [convert_old_pyg_to_new(data) for data in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZcmy1EvKQRk"
   },
   "source": [
    "Print out one entry of the dataset, it contains molecular formulas, atom types, positions, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755667709237,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "JVjz6iH_H6Eh",
    "outputId": "ca5c3914-0ab3-4e2e-9a7c-d5588a3e3ff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total molecules: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 598], pos=[51, 3], atom_type=[51], edge_type=[598], rdmol=<rdkit.Chem.rdchem.Mol object at 0x746da2729170>, smiles='CC1CCCN(C(=O)C2CCN(S(=O)(=O)c3cccc4nonc34)CC2)C1', nx=Graph with 51 nodes and 54 edges, idx=[1], pos_ref=[255, 3], num_pos_ref=[1], num_nodes_per_graph=[1], bond_edge_index=[2, 108], edge_order=[598], is_bond=[598])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total molecules: {len(dataset)}\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755667709238,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "dsAmeTVW-UyZ"
   },
   "outputs": [],
   "source": [
    "# dataset[0]['pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHNiZAUxNgoy"
   },
   "source": [
    "# **🧠 Run the diffusion process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ1KZrxKqENg"
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1755667709239,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "s240tYueqKKf"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_scatter import scatter_add, scatter_mean\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def repeat_data(data: Data, num_repeat) -> Batch:\n",
    "    datas = [copy.deepcopy(data) for i in range(num_repeat)]\n",
    "    return Batch.from_data_list(datas)\n",
    "\n",
    "def repeat_batch(batch: Batch, num_repeat) -> Batch:\n",
    "    datas = batch.to_data_list()\n",
    "    new_data = []\n",
    "    for i in range(num_repeat):\n",
    "        new_data += copy.deepcopy(datas)\n",
    "    return Batch.from_data_list(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMnQTk0eqT7Z"
   },
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1755667709247,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "WYGkzqgzrHmF"
   },
   "outputs": [],
   "source": [
    "num_samples = 1 # solutions per molecule\n",
    "num_molecules = 3\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "sampling_type = 'ddpm_noisy' #'' # paper also uses \"generalize\" and \"ld\"\n",
    "# constants for inference\n",
    "w_global = 0.5 #0,.3 for qm9\n",
    "global_start_sigma = 0.5\n",
    "eta = 1.0\n",
    "clip_local = None\n",
    "clip_pos = None\n",
    "\n",
    "# constands for data handling\n",
    "save_traj = False\n",
    "save_data = False\n",
    "output_dir = '/content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xD5bJ3SqM7t"
   },
   "source": [
    "#### Generate samples!\n",
    "Note that the 3D representation of a molecule is referred to as the **conformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57223,
     "status": "ok",
     "timestamp": 1755667766471,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "5lsjVUz_n6Nr",
    "outputId": "eab0cb57-7b9d-42e4-df5f-e3580d19da7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11024/2015557481.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sigmas = torch.tensor(1.0 - scheduler.alphas_cumprod).sqrt() / torch.tensor(scheduler.alphas_cumprod).sqrt()\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]/tmp/ipykernel_11024/1239158091.py:348: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:653.)\n",
      "  bgraph_adj = torch.sparse.LongTensor(edge_index, edge_type, torch.Size([N, N]))\n",
      "100%|██████████| 5/5 [00:56<00:00, 11.29s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# define sigmas\n",
    "sigmas = torch.tensor(1.0 - scheduler.alphas_cumprod).sqrt() / torch.tensor(scheduler.alphas_cumprod).sqrt()\n",
    "sigmas = sigmas.to(DEVICE)\n",
    "\n",
    "for count, data in enumerate(tqdm(dataset)):\n",
    "    num_samples = max(data.pos_ref.size(0) // data.num_nodes, 1)\n",
    "\n",
    "    data_input = data.clone()\n",
    "    data_input['pos_ref'] = None\n",
    "    batch = repeat_data(data_input, num_samples).to(DEVICE)\n",
    "\n",
    "    # initial configuration\n",
    "    pos_init = torch.randn(batch.num_nodes, 3).to(DEVICE)\n",
    "\n",
    "    # for logging animation of denoising\n",
    "    pos_traj = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # scale initial sample\n",
    "        pos = pos_init * sigmas[-1]\n",
    "        for t in scheduler.timesteps:\n",
    "            batch.pos = pos\n",
    "\n",
    "            # generate geometry with model, then filter it\n",
    "            epsilon = model.forward(batch, t, sigma=sigmas[t], return_dict=False)[0]\n",
    "\n",
    "            # Update\n",
    "            reconstructed_pos = scheduler.step(epsilon, t, pos)[\"prev_sample\"].to(DEVICE)\n",
    "\n",
    "            pos = reconstructed_pos\n",
    "\n",
    "            if torch.isnan(pos).any():\n",
    "                print(\"NaN detected. Please restart.\")\n",
    "                raise FloatingPointError()\n",
    "\n",
    "            # recenter graph of positions for next iteration\n",
    "            pos = pos - scatter_mean(pos, batch.batch, dim=0)[batch.batch]\n",
    "\n",
    "            # optional clipping\n",
    "            if clip_pos is not None:\n",
    "                pos = torch.clamp(pos, min=-clip_pos, max=clip_pos)\n",
    "            pos_traj.append(pos.clone().cpu())\n",
    "\n",
    "    pos_gen = pos.cpu()\n",
    "    if save_traj:\n",
    "        pos_gen_traj = pos_traj.cpu()\n",
    "        data.pos_gen = torch.stack(pos_gen_traj)\n",
    "    else:\n",
    "        data.pos_gen = pos_gen\n",
    "    results.append(data)\n",
    "\n",
    "\n",
    "if save_data:\n",
    "  save_path = os.path.join(output_dir, 'samples_all.pkl')\n",
    "\n",
    "  with open(save_path, 'wb') as f:\n",
    "      pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnZADgBKrMeJ"
   },
   "source": [
    "Support for third party widgets will remain active for the duration of the session. To disable support:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grgjJFKih-tE"
   },
   "source": [
    "# **👁️ Render the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d47Zxo2OKdgZ"
   },
   "source": [
    "This function allows us to render 3d in colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjaVuR15NqzF"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28rBYa9NKhlz"
   },
   "source": [
    "Here is a helper function for copying the generated tensors into a format used by RDKit & NGLViewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1755667766479,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "LKdKdwxcyTQ6"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def set_rdmol_positions(rdkit_mol, pos):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rdkit_mol:  An `rdkit.Chem.rdchem.Mol` object.\n",
    "        pos: (N_atoms, 3)\n",
    "    \"\"\"\n",
    "    mol = deepcopy(rdkit_mol)\n",
    "    set_rdmol_positions_(mol, pos)\n",
    "    return mol\n",
    "\n",
    "def set_rdmol_positions_(mol, pos):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rdkit_mol:  An `rdkit.Chem.rdchem.Mol` object.\n",
    "        pos: (N_atoms, 3)\n",
    "    \"\"\"\n",
    "    for i in range(pos.shape[0]):\n",
    "        mol.GetConformer(0).SetAtomPosition(i, pos[i].tolist())\n",
    "    return mol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuE10hcpKmzK"
   },
   "source": [
    "Process the generated data to make it easy to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1755667766493,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "KieVE1vc0_Vs",
    "outputId": "cda071e2-0e0b-43b7-ffcd-bc2f587daa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect 5 generated molecules in `mols`\n"
     ]
    }
   ],
   "source": [
    "# the model can generate multiple conformations per 2d geometry\n",
    "num_gen = results[0]['pos_gen'].shape[0]\n",
    "\n",
    "# init storage objects\n",
    "mols_gen = []\n",
    "mols_orig = []\n",
    "for to_process in results:\n",
    "\n",
    "    # store the reference 3d position\n",
    "    to_process['pos_ref'] = to_process['pos_ref'].reshape(-1, to_process['rdmol'].GetNumAtoms(), 3)\n",
    "\n",
    "    # store the generated 3d position\n",
    "    to_process['pos_gen'] = to_process['pos_gen'].reshape(-1, to_process['rdmol'].GetNumAtoms(), 3)\n",
    "\n",
    "    # copy data to new object\n",
    "    new_mol = set_rdmol_positions(to_process.rdmol, to_process['pos_gen'][0])\n",
    "\n",
    "    # append results\n",
    "    mols_gen.append(new_mol)\n",
    "    mols_orig.append(to_process.rdmol)\n",
    "\n",
    "print(f\"collect {len(mols_gen)} generated molecules in `mols`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tin89JwMKp4v"
   },
   "source": [
    "Import tools to visualize the 2d chemical diagram of the molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1755667766499,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "yqV6gllSZn38"
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D as MD2\n",
    "from IPython.display import SVG, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkb8w0_SNtU8"
   },
   "source": [
    "### Viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzCWtf92bG6K"
   },
   "source": [
    "📌 Select a molecule (0–4) by setting `idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755667766500,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "3MZPKQUpudJ1"
   },
   "outputs": [],
   "source": [
    "idx = 2 # int: 0-4\n",
    "assert idx < len(results), \"selected molecule that was not generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rX2kb66vAX5"
   },
   "source": [
    "First, check out the coordinates of the molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1755667766510,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "qFzG9sNAu6ZZ",
    "outputId": "1dfac746-e52a-4932-ce99-ded2c96d2ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "\n",
      "C     -3.887156    0.424324    1.547885\n",
      "C     -2.808707    1.569442    1.694603\n",
      "O     -1.585650    1.032627    2.328805\n",
      "C     -0.311920    1.524078    2.026160\n",
      "C     -0.172670    2.943017    1.759464\n",
      "C      1.130689    3.542332    1.610579\n",
      "C      2.295881    2.725082    1.726214\n",
      "C      2.148298    1.321717    1.944966\n",
      "C      0.867545    0.649365    2.018558\n",
      "N      0.781771   -0.772890    2.048428\n",
      "C     -0.476740   -1.465390    1.493325\n",
      "C     -0.145818   -1.503320   -0.004613\n",
      "C     -0.877446   -1.145517   -1.144066\n",
      "C     -0.180613   -1.089900   -2.434036\n",
      "C      1.154857   -1.559879   -2.507569\n",
      "C      1.938311   -1.861291   -1.331678\n",
      "C      1.293802   -1.732081   -0.090296\n",
      "C      1.903302   -1.596698    1.323396\n",
      "H      2.903534   -1.188381    1.358455\n",
      "H      1.994087   -2.623610    1.885939\n",
      "H      3.015322   -2.114579   -1.426539\n",
      "C      1.854378   -1.845952   -3.941284\n",
      "H      2.472924   -2.874359   -3.926027\n",
      "H      2.624827   -1.027014   -4.105454\n",
      "H      1.165885   -1.892003   -4.796883\n",
      "C     -0.898133   -0.449674   -3.675872\n",
      "H     -1.224408   -1.268719   -4.413067\n",
      "H     -0.230407    0.253918   -4.228827\n",
      "H     -1.841739    0.108473   -3.353142\n",
      "H     -1.958731   -0.813541   -1.112120\n",
      "H     -1.382975   -0.986018    1.761966\n",
      "H     -0.526680   -2.543880    1.979942\n",
      "H      3.058605    0.714555    2.041966\n",
      "H      3.218688    3.073632    1.620051\n",
      "H      1.194451    4.494953    1.366432\n",
      "H     -1.047027    3.471284    1.673110\n",
      "H     -3.059846    2.297055    2.266617\n",
      "H     -2.458667    1.917871    0.639724\n",
      "H     -3.381430   -0.402181    0.807101\n",
      "H     -4.630044    0.766258    1.099441\n",
      "H     -3.930347   -0.073107    2.468350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Chem.MolToXYZFile(mols_gen[idx],'test.xyz')\n",
    "xyz_string = Chem.MolToXYZBlock(mols_gen[idx])\n",
    "print(xyz_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3R4QBQeKttN"
   },
   "source": [
    "This 2D rendering is the equivalent of the **input to the model**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755667766515,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "gkQRWjraaKex",
    "outputId": "b8a79f9f-24c2-4da9-eb2c-eb9ec8b892eb"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\" baseProfile=\"full\" xml:space=\"preserve\" width=\"450px\" height=\"300px\" viewBox=\"0 0 450 300\">\n",
       "<!-- END OF HEADER -->\n",
       "<rect style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"450.0\" height=\"300.0\" x=\"0.0\" y=\"0.0\"> </rect>\n",
       "<path class=\"bond-0 atom-0 atom-1\" d=\"M 348.5,23.0 L 368.3,75.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 368.3,75.7 L 354.5,92.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-1 atom-1 atom-2\" d=\"M 354.5,92.4 L 340.7,109.2\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 336.4,129.2 L 344.3,150.5\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-2 atom-2 atom-3\" d=\"M 344.3,150.5 L 352.3,171.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 352.3,171.7 L 407.8,180.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-3 atom-3 atom-4\" d=\"M 355.7,180.8 L 401.6,188.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-4 atom-4 atom-5\" d=\"M 407.8,180.9 L 427.5,233.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 427.5,233.6 L 391.8,277.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-5 atom-5 atom-6\" d=\"M 417.9,232.0 L 388.4,267.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-6 atom-6 atom-7\" d=\"M 391.8,277.0 L 336.3,267.8\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 336.3,267.8 L 316.6,215.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-7 atom-7 atom-8\" d=\"M 342.5,260.2 L 326.2,216.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 316.6,215.1 L 292.8,211.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-8 atom-8 atom-9\" d=\"M 292.8,211.2 L 269.0,207.2\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 253.2,213.7 L 237.2,229.5\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-9 atom-9 atom-10\" d=\"M 237.2,229.5 L 221.1,245.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-10 atom-10 atom-11\" d=\"M 221.1,245.4 L 171.2,219.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 171.2,219.5 L 118.6,239.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-11 atom-11 atom-12\" d=\"M 163.7,213.3 L 120.1,229.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-12 atom-12 atom-13\" d=\"M 118.6,239.2 L 75.1,203.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-13 atom-13 atom-14\" d=\"M 75.1,203.5 L 22.5,223.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-13 atom-15\" d=\"M 75.1,203.5 L 84.3,148.1\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-14 atom-13 atom-15\" d=\"M 84.2,200.1 L 91.9,154.2\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-15 atom-15 atom-16\" d=\"M 84.3,148.1 L 40.9,112.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-16 atom-15 atom-17\" d=\"M 84.3,148.1 L 137.0,128.3\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17 atom-17 atom-18\" d=\"M 137.0,128.3 L 180.4,164.0\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-17 atom-17 atom-18\" d=\"M 135.4,137.9 L 171.3,167.4\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-18 atom-18 atom-19\" d=\"M 180.4,164.0 L 236.0,155.6\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-19 atom-8 atom-3\" d=\"M 316.6,215.1 L 352.3,171.7\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20 atom-19 atom-9\" d=\"M 236.0,155.6 L 246.1,175.9\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-20 atom-19 atom-9\" d=\"M 246.1,175.9 L 256.2,196.1\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path class=\"bond-21 atom-18 atom-11\" d=\"M 180.4,164.0 L 171.2,219.5\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 367.3,73.0 L 368.3,75.7 L 367.6,76.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 405.0,180.5 L 407.8,180.9 L 408.7,183.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 426.5,230.9 L 427.5,233.6 L 425.7,235.7\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 393.6,274.8 L 391.8,277.0 L 389.0,276.5\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 339.1,268.2 L 336.3,267.8 L 335.3,265.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 221.9,244.6 L 221.1,245.4 L 218.6,244.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 121.2,238.2 L 118.6,239.2 L 116.4,237.4\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 134.3,129.3 L 137.0,128.3 L 139.1,130.1\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path d=\"M 233.2,156.1 L 236.0,155.6 L 236.5,156.6\" style=\"fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-opacity:1;\"/>\n",
       "<path class=\"atom-2\" d=\"M 325.2 119.1 Q 325.2 115.3, 327.1 113.2 Q 329.0 111.0, 332.5 111.0 Q 336.1 111.0, 338.0 113.2 Q 339.9 115.3, 339.9 119.1 Q 339.9 123.0, 337.9 125.2 Q 336.0 127.4, 332.5 127.4 Q 329.0 127.4, 327.1 125.2 Q 325.2 123.0, 325.2 119.1 M 332.5 125.6 Q 335.0 125.6, 336.3 124.0 Q 337.6 122.3, 337.6 119.1 Q 337.6 116.0, 336.3 114.4 Q 335.0 112.8, 332.5 112.8 Q 330.1 112.8, 328.8 114.4 Q 327.5 116.0, 327.5 119.1 Q 327.5 122.3, 328.8 124.0 Q 330.1 125.6, 332.5 125.6 \" fill=\"#FF0000\"/>\n",
       "<path class=\"atom-9\" d=\"M 257.6 198.0 L 262.8 206.4 Q 263.3 207.2, 264.2 208.7 Q 265.0 210.2, 265.1 210.3 L 265.1 198.0 L 267.2 198.0 L 267.2 213.9 L 265.0 213.9 L 259.4 204.7 Q 258.7 203.6, 258.0 202.3 Q 257.4 201.1, 257.2 200.7 L 257.2 213.9 L 255.1 213.9 L 255.1 198.0 L 257.6 198.0 \" fill=\"#0000FF\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc = Chem.MolFromSmiles(dataset[idx]['smiles'])\n",
    "molSize=(450,300)\n",
    "drawer = MD2.MolDraw2DSVG(molSize[0],molSize[1])\n",
    "drawer.DrawMolecule(mc)\n",
    "drawer.FinishDrawing()\n",
    "svg = drawer.GetDrawingText()\n",
    "display(SVG(svg.replace('svg:','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4FDMYMxKw2I"
   },
   "source": [
    "Generate the 3d molecule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 7914,
     "status": "ok",
     "timestamp": 1755667774430,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "SBgIxb_BtK_N"
   },
   "outputs": [],
   "source": [
    "!pip install -q py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1755667774446,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "tUH5h11atLrV",
    "outputId": "bbc62786-99d3-4e57-8bc7-95a85c54e970"
   },
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_17557434444629142\"  style=\"position: relative; width: 400px; height: 400px;\">\n        <p id=\"3dmolwarning_17557434444629142\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdn.jsdelivr.net/npm/3dmol@2.5.2/build/3Dmol-min.js');\n}\n\nvar viewer_17557434444629142 = null;\nvar warn = document.getElementById(\"3dmolwarning_17557434444629142\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_17557434444629142 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17557434444629142\"),{backgroundColor:\"white\"});\nviewer_17557434444629142.zoomTo();\n\tviewer_17557434444629142.addModel(\"41\\n\\nC     -3.887156    0.424324    1.547885\\nC     -2.808707    1.569442    1.694603\\nO     -1.585650    1.032627    2.328805\\nC     -0.311920    1.524078    2.026160\\nC     -0.172670    2.943017    1.759464\\nC      1.130689    3.542332    1.610579\\nC      2.295881    2.725082    1.726214\\nC      2.148298    1.321717    1.944966\\nC      0.867545    0.649365    2.018558\\nN      0.781771   -0.772890    2.048428\\nC     -0.476740   -1.465390    1.493325\\nC     -0.145818   -1.503320   -0.004613\\nC     -0.877446   -1.145517   -1.144066\\nC     -0.180613   -1.089900   -2.434036\\nC      1.154857   -1.559879   -2.507569\\nC      1.938311   -1.861291   -1.331678\\nC      1.293802   -1.732081   -0.090296\\nC      1.903302   -1.596698    1.323396\\nH      2.903534   -1.188381    1.358455\\nH      1.994087   -2.623610    1.885939\\nH      3.015322   -2.114579   -1.426539\\nC      1.854378   -1.845952   -3.941284\\nH      2.472924   -2.874359   -3.926027\\nH      2.624827   -1.027014   -4.105454\\nH      1.165885   -1.892003   -4.796883\\nC     -0.898133   -0.449674   -3.675872\\nH     -1.224408   -1.268719   -4.413067\\nH     -0.230407    0.253918   -4.228827\\nH     -1.841739    0.108473   -3.353142\\nH     -1.958731   -0.813541   -1.112120\\nH     -1.382975   -0.986018    1.761966\\nH     -0.526680   -2.543880    1.979942\\nH      3.058605    0.714555    2.041966\\nH      3.218688    3.073632    1.620051\\nH      1.194451    4.494953    1.366432\\nH     -1.047027    3.471284    1.673110\\nH     -3.059846    2.297055    2.266617\\nH     -2.458667    1.917871    0.639724\\nH     -3.381430   -0.402181    0.807101\\nH     -4.630044    0.766258    1.099441\\nH     -3.930347   -0.073107    2.468350\\n\",\"xyz\");\n\tviewer_17557434444629142.setStyle({\"stick\": {}});\n\tviewer_17557434444629142.zoomTo();\nviewer_17557434444629142.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_17557434444629142\"  style=\"position: relative; width: 400px; height: 400px;\">\n",
       "        <p id=\"3dmolwarning_17557434444629142\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdn.jsdelivr.net/npm/3dmol@2.5.2/build/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_17557434444629142 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_17557434444629142\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_17557434444629142 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17557434444629142\"),{backgroundColor:\"white\"});\n",
       "viewer_17557434444629142.zoomTo();\n",
       "\tviewer_17557434444629142.addModel(\"41\\n\\nC     -3.887156    0.424324    1.547885\\nC     -2.808707    1.569442    1.694603\\nO     -1.585650    1.032627    2.328805\\nC     -0.311920    1.524078    2.026160\\nC     -0.172670    2.943017    1.759464\\nC      1.130689    3.542332    1.610579\\nC      2.295881    2.725082    1.726214\\nC      2.148298    1.321717    1.944966\\nC      0.867545    0.649365    2.018558\\nN      0.781771   -0.772890    2.048428\\nC     -0.476740   -1.465390    1.493325\\nC     -0.145818   -1.503320   -0.004613\\nC     -0.877446   -1.145517   -1.144066\\nC     -0.180613   -1.089900   -2.434036\\nC      1.154857   -1.559879   -2.507569\\nC      1.938311   -1.861291   -1.331678\\nC      1.293802   -1.732081   -0.090296\\nC      1.903302   -1.596698    1.323396\\nH      2.903534   -1.188381    1.358455\\nH      1.994087   -2.623610    1.885939\\nH      3.015322   -2.114579   -1.426539\\nC      1.854378   -1.845952   -3.941284\\nH      2.472924   -2.874359   -3.926027\\nH      2.624827   -1.027014   -4.105454\\nH      1.165885   -1.892003   -4.796883\\nC     -0.898133   -0.449674   -3.675872\\nH     -1.224408   -1.268719   -4.413067\\nH     -0.230407    0.253918   -4.228827\\nH     -1.841739    0.108473   -3.353142\\nH     -1.958731   -0.813541   -1.112120\\nH     -1.382975   -0.986018    1.761966\\nH     -0.526680   -2.543880    1.979942\\nH      3.058605    0.714555    2.041966\\nH      3.218688    3.073632    1.620051\\nH      1.194451    4.494953    1.366432\\nH     -1.047027    3.471284    1.673110\\nH     -3.059846    2.297055    2.266617\\nH     -2.458667    1.917871    0.639724\\nH     -3.381430   -0.402181    0.807101\\nH     -4.630044    0.766258    1.099441\\nH     -3.930347   -0.073107    2.468350\\n\",\"xyz\");\n",
       "\tviewer_17557434444629142.setStyle({\"stick\": {}});\n",
       "\tviewer_17557434444629142.zoomTo();\n",
       "viewer_17557434444629142.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import py3Dmol\n",
    "xyz = Chem.MolToXYZBlock(mols_gen[idx])\n",
    "\n",
    "view = py3Dmol.view(width=400, height=400)\n",
    "view.addModel(xyz, 'xyz')\n",
    "view.setStyle({'stick': {}})\n",
    "view.zoomTo()\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXUFiLMhfb4"
   },
   "source": [
    "# **🧐Denoising trajectory visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17294,
     "status": "ok",
     "timestamp": 1755667791744,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "0mvxbGO-gwKs",
    "outputId": "32b7eb5f-f300-4df3-ce6f-9a9dd6566c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of saved time steps: 22\n"
     ]
    }
   ],
   "source": [
    "data = dataset[idx]\n",
    "\n",
    "num_samples = max(data.pos_ref.size(0) // data.num_nodes, 1)\n",
    "data_input = data.clone()\n",
    "data_input['pos_ref'] = None\n",
    "batch = repeat_data(data_input, num_samples).to(DEVICE)\n",
    "\n",
    "# save more intermediate timesteps\n",
    "save_steps = [999, 950, 900, 850, 800, 750, 700, 600, 650, 500, 400, 300, 200, 150, 100, 75, 50, 30, 20, 10, 5, 0]\n",
    "pos_trajectory = {}\n",
    "noise_levels = {}\n",
    "mol_trajectory = {}\n",
    "\n",
    "# initial configuration\n",
    "pos_init = torch.randn(batch.num_nodes, 3).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # scale initial sample\n",
    "    pos = pos_init * sigmas[-1]\n",
    "\n",
    "    for t in scheduler.timesteps:\n",
    "        batch.pos = pos\n",
    "\n",
    "        # generate geometry with model\n",
    "        epsilon = model.forward(batch, t, sigma=sigmas[t], return_dict=False)[0]\n",
    "\n",
    "        # Update\n",
    "        reconstructed_pos = scheduler.step(epsilon, t, pos)[\"prev_sample\"].to(DEVICE)\n",
    "\n",
    "        pos = reconstructed_pos\n",
    "\n",
    "        if torch.isnan(pos).any():\n",
    "            print(\"NaN detected. Please restart.\")\n",
    "            raise FloatingPointError()\n",
    "\n",
    "        # recenter graph of positions\n",
    "        pos = pos - scatter_mean(pos, batch.batch, dim=0)[batch.batch]\n",
    "\n",
    "        # optional clipping\n",
    "        if clip_pos is not None:\n",
    "            pos = torch.clamp(pos, min=-clip_pos, max=clip_pos)\n",
    "\n",
    "        # save the chosen timestep\n",
    "        if t.item() in save_steps:\n",
    "            pos_trajectory[t.item()] = pos.clone().cpu()\n",
    "            noise_levels[t.item()] = sigmas[t].item()\n",
    "\n",
    "            mol_at_t = set_rdmol_positions(data.rdmol, pos.clone().cpu().numpy())\n",
    "            mol_trajectory[t.item()] = mol_at_t\n",
    "\n",
    "print(f\"number of saved time steps: {len(pos_trajectory)}\")\n",
    "\n",
    "pos_gen = pos.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1755667791745,
     "user": {
      "displayName": "­두하영(공과대학 화공신소재공학과)",
      "userId": "16311539983993153182"
     },
     "user_tz": -540
    },
    "id": "rX34ejJBjiRY"
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(step_idx=(0, len(mol_trajectory)-1, 1))\n",
    "def show_denoising_step_rdkit(step_idx=0):\n",
    "    all_steps = sorted(mol_trajectory.keys(), reverse=True)\n",
    "    step = all_steps[step_idx]\n",
    "\n",
    "    # RDKit\n",
    "    mol = mol_trajectory[step]\n",
    "    xyz_block = Chem.MolToXYZBlock(mol)\n",
    "\n",
    "    view = py3Dmol.view(width=600, height=500)\n",
    "    view.addModel(xyz_block, 'xyz')\n",
    "    view.setStyle({'stick': {'radius': 0.15}, 'sphere': {'radius': 0.25}})\n",
    "    view.setBackgroundColor('white')\n",
    "    view.zoomTo()\n",
    "\n",
    "    print(f\"Timestep: {step}, Noise level: σ = {noise_levels.get(step, 0):.3f}\")\n",
    "    view.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PSE_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
