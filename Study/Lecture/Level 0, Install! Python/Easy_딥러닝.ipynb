{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI의 분류\n",
    "AI: 규칙 기반 알고리즘\n",
    "- 규칙을 인간이 정함: 조건문 겁나 설정하는거\n",
    "\n",
    "ML: 데이터를 기반으로 한 AI\n",
    "- 데이터를 이용해서 학습, AI가 규칙성을 스스로 깨닫는 것\n",
    "- 처음보는 데이터도 인식이 가능한지가 중요함\n",
    "\n",
    "DL: DNN을 이용한 ML\n",
    "- 인공 신경망을 이용하는데 깊은 DNN을 이용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망 구조\n",
    "입력 - 모델 - 출력\n",
    "- 입력과 출력 모두 숫자로 이루어져 있음\n",
    "\n",
    "CNN\n",
    "- 행렬로 되어 있음 : 이미지도 2x2의 RGB 값으로 이루어져있음\n",
    "- RGB가 각각 channel임, size = 3 x 5 x 5 (3 x 5 by 5, 5 by 5는 이미지 해상도), 채널 + 행 + 열\n",
    "\n",
    "RNN\n",
    "- 입력 - 모델 - 출력\n",
    "- 입력과 출력 모두 숫자는건 동일함\n",
    "- 문장을 tokenization - token을 숫자로 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도학습 비지도 학습 강화학습\n",
    "- 지도, 비지도, 강화학습 모두 ML영역인 경우 DL 인 경우가 있음\n",
    "\n",
    "#### 지도학습\n",
    "- 정답을 알고 있음 (label)\n",
    "- 회귀, 분류\n",
    "- 둘다 활용하는 경우도 있음: classification + localization (위치까지)\n",
    "- CNN에 분류를 위한 0,1과 함께 위치정보 (x,y,w,h)까지 나오게 하면 됨\n",
    "- 출력 정보를 계속 추가할수록 있음: instance sementation (픽셀 단위로 분류를 하게 됨) 학습데이터를 배경 0, 개 1, 고양이 2, 오리 3과 같이 학습데이터를 준비해서 행렬로 준비하면 됨\n",
    "- pose estimation: 사람의 사진을 주면 사람의 머리, 어깨 등등을 인식하게 하는 것 (머리 (x,y) 어깨 (x,y) 출력으로 하게 하고) rule base로 위치별 연결을 하게 함\n",
    "\n",
    "#### 비지도학습\n",
    "- 정답을 모른다.\n",
    "- 군집화 (k-means, DBSCAN)\n",
    "- 차원축소 (데이터 전처리: PCA, SVD.. )\n",
    "\n",
    "#### 자기지도 학습\n",
    "- 정답을 만드는 학습데이터 비용이 큼\n",
    "- 진짜 풀려고 했던 문제 말고 가짜 문제를 새롭게 정의해서 먼저 풀어 본다\n",
    "- 예제 (알고리즘의 하나의 예시), context prediction\n",
    "    - 이미지에서 작은 영역 patch를 랜덤하게 잡음\n",
    "    - patch 주변에 상대적으로 벗어난 patch를 잡음\n",
    "    - label이 없는 데이터를 이용할 수 있음 (지도학습과 다름!)\n",
    "    - 타겟 patch와 주변의 patch 1개를 선정해서 입력\n",
    "    - 상대적인 위치를 출력하도록 학습을 우선함\n",
    "    - 이후 지도학습 수행 시 학습이 잘됨\n",
    "- 가짜 문제로 사전학습을 풀고 나서 지도학습을 수행\n",
    "- 왜 잘될까?\n",
    "    - 이미지의 연속성을 학습함으로써 모델이 이미지를 받아들일 준비를 함\n",
    "- 데이터 안에서 self로 만든 정답 (label, 내가 새롭게 정의한 가짜 문제에 대한 정답), 그래서 이름이 자기지도 학습\n",
    "    - pretext task를 학습해서 pre-training\n",
    "    - downstream task(분류)를 풀기 위해 transfer learning\n",
    "        - 실제 문제와 가짜 문제가 다르므로 살짝 수정 (layer 마지막을 보통 수정)\n",
    "    - pretext task로 context prediction 제안\n",
    "- Contrastive learning (대조 학습)\n",
    "    - 사진 1의 일부를 떼서 1번 patch로 정의\n",
    "    - CNN 모델에 넣고 나온 출력을 1'으로 정의 (벡터임)\n",
    "    - 사진 1로부터 일부를 떼서 2번 patch로 정의\n",
    "    - CNN 모델에 넣고 나온 출력을 2'으로 정의 (벡터임)\n",
    "    - 사진 2로부터 일부를 떼서 3번 patch로 정의\n",
    "    - 사진 2로부터 일부를 떼서 3번 patch로 정의\n",
    "    - CNN 모델에 넣고 나온 출력을 3'으로 정의 (벡터임)\n",
    "    - 사진 2로부터 일부를 떼서 4번 patch로 정의\n",
    "    - CNN 모델에 넣고 나온 출력을 4'으로 정의 (벡터임)\n",
    "    - 1'과 2'의 결과는 유사하게, 2'과 3'의 결과는 다르게 학습하도록 문제를 정의함\n",
    "    - 출처가 같은 사진은 비슷한 값이 나오게끔 하고, 출처가 다른 사진은 최대한 먼값이 나오게끔 하는 기법\n",
    "- 사실 GPT와 BERT도 자기지도 학습임\n",
    "\n",
    "#### 강화학습\n",
    "- 내가 원하는 행동을 하게끔 강화하게 하는 방식\n",
    "- 알파고: 승점을 먹는 방식에 대해 reward를 줌\n",
    "- 용어 정리\n",
    "    - Agent: 행동의 주체, 강아지, 남친\n",
    "    - Action: 행동, 손 했을 때 손을 내미는 행동, 맛집 제안\n",
    "    - Reward: 간식, 여친의 칭찬\n",
    "    - Environment: 설계된 환경, 주인의 의지 (간식을 주는 시점, 얼마나 줄지), 여친\n",
    "    - State: 맛집의 좌표\n",
    "    - Q-function: 위치마다 행동을 했을때 승점을 얻을 수 있는 기대값 Q(state, action)\n",
    "    - Episode: Try 순서 (몇 번째 여친?)\n",
    "    - Q-learning: 이동하고 나서 이전 state에 대한 점수를 업데이트 하는 것\n",
    "    - Exploration: 탐험, epsilon-Greedy, 기존의 학습된 state에서의 reward에 의존하지 않고 random하게 새로운 루트를 찾게 끔함\n",
    "    - discount factor: 좋고 나쁨을 얘기해 줌, Q-learning으로 reward의 값을 가져올 때 route가 지날수록 discount 값을 적용하게 해서 멀리 돌아갈수록 q값이 작게 느껴지도록 하는 것\n",
    "- 강화학습은 맛집 찾기다\n",
    "    - 여자친구와 1주년임\n",
    "    - CU 도시락은 reward -100\n",
    "    - 맛집은 reward +100\n",
    "    - KB헤븐 (김밥천국) reward -10\n",
    "    - 첫 여친인 경우: Episode 1\n",
    "        - Q-function이 다 0임\n",
    "        - CU에 도달하여 뺨 맞고 헤어짐\n",
    "    - 두번째 여친의 경우: Episode 2\n",
    "        - KB헤븐 가서 뺨 맞고 헤어짐\n",
    "    - 세번째 여친의 경우: Episode 3\n",
    "        - 맛집에 도달 - 여친의 칭찬을 get\n",
    "    - 네번째 여친의 경우: Episode 4\n",
    "        - 맛집의 가까운 곳으로 가는 route 중에 가고 보니 reward가 좋으면 그 값을 route에 적용시킴\n",
    "    - 1000번째 여친: Episode 1000\n",
    "        - 기존의 경험치값에 의존하지 않고 fully random하게 움직임\n",
    "        - 탐험 알고리즘\n",
    "        - \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공신경망과 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인간의 신경\n",
    "- 자극을 전달 받고\n",
    "- 전달할지 말지 정하고\n",
    "    - 들어온 자극에 대해서 나가는 자극을 출력하는 핵\n",
    "    - 0포함 음수는 전달을 안하고\n",
    "    - 양수는 1이 출력해서 전달을 함\n",
    "- 자극을 전달\n",
    "- bias: 신경의 민감도를 조절해 줌\n",
    "- weight: 각 자극마다 강도를 정해줌\n",
    "- 예시\n",
    "    - 출력을 정색하는 것\n",
    "    - 입력은 손바닥 자극, 뒷통수 자극\n",
    "    - 집에서 손바닥을 침 - 자극에서 전달 X - 정색 안함\n",
    "    - 친구 만나서 하이파이브 함 - 자극에서 전달 o - 정색함\n",
    "        - 좀 이상한데?\n",
    "        - bias가 조절해서 다시 할땐 자극에서 전달 X로 함\n",
    "    - 친구가 만나서 손으로 뒷통수를 때림 - 자극에서 전달 o - 정색함\n",
    "\n",
    "### 인공신경\n",
    "- 노드와 엣지로 구성됨\n",
    "- weight, bias와 함께 더하고 activation function이 결정\n",
    "    - 여러 activation이 존재\n",
    "        - unit step function\n",
    "- 주어진 입력에 대해 원하는 출력이 나오도록 weight과 bias를 잘 정해줘야 함\n",
    "- AI가 weight과 bias를 알아내기 때문에 AI가 학습한다는 의미임\n",
    "\n",
    "### 인공신경망\n",
    "- 여러개의 신경을 쓴다는 것은 각 connection마다 weight이 달라야 함\n",
    "    - 너무 node가 많으면 중복되거나 쓸데 없는 학습이 일어남 -> 과적합\n",
    "- 곱하고 더하고 activation - 곱하고 더하고 activation - 반복\n",
    "- input layer: 데이터가 들어오는 층\n",
    "- output layer: 데이터가 나가는 층\n",
    "- hidden layer: input과 output layer의 사이\n",
    "- 모든 노드가 연결된 층을 fully connected layer라고 부름\n",
    "- 모든 layer가 FC layer인 신경망을 multilayer perceptron (MLP)라고 부름\n",
    "- 인공신경망도 일종의 함수다\n",
    "    - 먼가 들어가서 먼가 튀어나옴\n",
    "    - 수 많은 데이터를 마구 때려 넣어서 이 입력에는 이 출력이 나와야 한다고 주입식 교육을 시킴\n",
    "    - AI는 주입식 교육을 통해 입력과 출력을 연결하는 함수를 알아내서 새로운 데이터에 대해서도 적절한 출력을 뱉게 된다. \n",
    "    - 학습은 함수를 찾는 과정임: 정확힌 weight과 bias를 찾아내는거다\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀\n",
    "- 입력과 출력 간의 관계를 (선형으로 놓고) 알아내는 것\n",
    "    - 처음 보는 입력에 대해서도 적절한 출력을 얻기 위함\n",
    "    - 사실 분류나 회귀나 똑같은거임\n",
    "    - 결국 알아야 하는건 최적의 weight과 bias를 알아내야 함\n",
    "- 선형 회귀에서 weight은 a, bias는 b : ax + b\n",
    "### 최적의 a, b 찾기\n",
    "- loss를 최소화 하는 a, b가 바로 최적의 a,b\n",
    "    - loss: 내가 풀고 싶은 문제에 맞게 잘 정의해서 줄여야 하는 것\n",
    "    - AI의 예측을 y', 실제 값을 y라고 하면 (y- y')^2\n",
    "    - 제곱을 안하면 에러간 보정이 됨 (MSE: mean squared error)\n",
    "    - 절대값을 안쓰는 이유? (MAE: mean absolute error)\n",
    "        - a의 값을 x축, loss를 y축이라고 하면 절대값은 V형태, 제곱은 U형태가 됨\n",
    "        - 제곱의 경우 a의 값이 이상적인 값보다 멀어질수록 loss가 제곱으로 커짐\n",
    "        - 절대값은 a의 값이 이상값보다 멀어지면 loss가 선형적으로 커짐\n",
    "        - loss에 민감한 함수가 제곱임\n",
    "        - **outlier가 있으면** 오히려 절대값이 loss인 경우가 나을지도 모름\n",
    "- GPT3는 1750억개의 parameter가 있음, 일일히 parameter를 바꿀 수 없음\n",
    "    - Gradient descent가 필요함!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "- 일단 처음 parameter a, b를 아무렇게나 잡음\n",
    "- 현재 a,b 위치에서 loss를 줄여나가는 방향으로 나아가자\n",
    "- 어떻게 나가는 방향을 정하냐?\n",
    "    - gradient는 항상 가장 가파른 방향을 향한다\n",
    "    - 가장 벗어나는 방향을 향하므로 gradient의 반대방향으로 가주면 loss가 가장 줄어드는 방향으로 가겠죠?\n",
    "- 근데 그냥 gradient의 반대로 가면 step이 너무 큼\n",
    "    - 그래서 step의 크기를 줄이기 위해서 learning rate라는 개념이 적용됨\n",
    "    - x2 + y2의 함수에서 [1, 1]과 [-1, -1]이 왔다가 갔다함 -> learning rate를 적용하면 [0, 0]으로 수렴하게 됨\n",
    "- 우리가 줄이고 싶은건 loss니까 loss를 parameter (weight과 bias)를 기준으로 편미분해서 gradient를 얻고 그 반대 방향으로 가면서 learning rate를 적용해서 step을 조절하는게 gradient descent고 이게 바로 DL이다\n",
    "- initial state는 어떻게 잡음?\n",
    "    - random하게 0 근처로 잡는게 좋다 (수학적으로 증명됨)\n",
    "- 단점\n",
    "    - 너무 신중하게 방향을 고려함\n",
    "        - 모든 데이터의 loss를 고려해서 계산됨\n",
    "        - 연산이 많이 듦\n",
    "    - local minimum에 빠질 수 밖에 없는 알고리즘임\n",
    "        - global minimum을 찾을 수 없음 (local이 겁나 많음)\n",
    "        - 좋은 local minimum에 빠지게 하는 방법? 좋은 initial 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Initialization\n",
    "- LeCun\n",
    "    - Uniform distribution에서 뽑기\n",
    "    - 평균과 분산이 정해지면 분포가 정해짐 (정규)\n",
    "    - N(0, 1/N_in)\n",
    "- N_in\n",
    "    - N_in은 나가는 layer의 node 수\n",
    "- N_out\n",
    "    - N_out은 들어오는 layer의 node 수\n",
    "- Kaiming (ReLu에서 많이 사용)\n",
    "    - N(0, 2/N_in)\n",
    "- Xavier (Kaiming보다 작아서 Sigmoid나 tanh에 사용)\n",
    "    - N(0, 2/(N_in + N_out))\n",
    "- node가 너무 많으면 weight의 분산이 커지니까 node의 수를 분산의 역수로 잡게 되는거임\n",
    "- 전부 0이나 1로 초기화 하면 무슨 문제가 생길까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent의 두 가지 치명적 단점\n",
    "- 너무 신중해\n",
    "    - 데이터가 많아지면 모든 데이터의 loss를 계산하고 미분도 해야하니까 한 step 하는데 오래걸림\n",
    "- local minimum에 빠질 수 밖에 없어\n",
    "    - 왜냐면 weight initialization을 0 근처로 잡는데 처음 만난 local minimum이 가장 좋을 수 있을까? 거의 없음\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD: Stochastic Gradient Descent\n",
    "- GD의 문제를 완화한 것\n",
    "- SGD는 랜덤하게 데이터 하나씩 뽑아서 loss를 만든다\n",
    "#### 주머니 예시\n",
    "- 에러의 제곱이 주머니에 있음\n",
    "- step에서 데이터 에러 하나를 뽑아서 업데이트함\n",
    "- 이미 뽑은거 말고 나머지 중에 데이터 에러를 뽑아서 업데이트함\n",
    "- 다했으면 주머니에 다시 다 넣는다 (비복원 추출)\n",
    "- 충분히 수렴할때까지: 미분의 기울기가 많이 줄었을때\n",
    "#### 장점\n",
    "- 덜 신중하지만 빠름\n",
    "- 하지만 바로 loss의 최소지점으로 직행하지 못함\n",
    "- local minimum으로부터 탈출의 기회가 되기도 함\n",
    "    - loss 최소화 과정에서 왔다리 갔다리 하면서 더 좋은 local minimum으로 넘어갈 수도 잇음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini-batch SGD\n",
    "- SGD는 하나씩만 보니까 너무 성급하게 방향을 결정 (불필요한 경박스런 움직임이 많다)\n",
    "- mini-batch size 만큼 데이터의 에러를 여러개 뽑아서 SGD를 수행\n",
    "- CPU 연산: 데이터 에러마다 1개씩 연산\n",
    "- GPU 연산: 데이터 에러를 여러개 동시에 연산한다\n",
    "- batch size는 최대 8K까지 키우자\n",
    "    - batch size를 키울수록 일반적인 GD에 가까워짐\n",
    "    - 너무 신중하다? 오래 걸리는건 GPU로 해결이됨\n",
    "    - 하지만 local minimum으로 빠짐\n",
    "    - learning rate도 같이 키우고 warmup도 해야함\n",
    "        - Linear Scaling Rule: BS가 두배되면 LR도 두배\n",
    "        - 32개의 데이터로 계산된 GD를 2번 수행한 것과 64개의 데이터로 계산된 GD로 업데이트 된 weight이 비슷해지려면 learning rate을 2배로 키우면 될것이다라는 이론\n",
    "        - warm up이란? learning rate을 0부터 점점 높여주는 단계\n",
    "            - gradient가 들쭉날쭉한걸 방지해줌\n",
    "## Epoch & Batch size\n",
    "- Epoch: 전체 데이터를 몇 번 반복해서 풀거냐\n",
    "- batch size: 몇개씩 풀거냐\n",
    "- learning rate: 얼만큼 갈거냐\n",
    "위를 hyperparameter라고 함\n",
    "## parameter vs hyperparameters\n",
    "- parameter: AI가 알아내는 변수\n",
    "    - weight\n",
    "    - bias\n",
    "- hyperparameter: user가 정해줘야 하는 변수\n",
    "    - epoch, batch size\n",
    "    - initial weight\n",
    "    - learning rate & learning rate schedueling\n",
    "    - model architecture (layer 수, node수, activation function 종류)\n",
    "    - loss 함수 뭘쓸지\n",
    "    - 최적화 기법 뭘쓸지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "- gradient는 contour에 수직하다, 접선에 수직한 방향이 가장 가파른 기울기다\n",
    "    - loss의 contour 접선은 수식적으로 생각하면 loss가 유지되는 방향이기 때문임\n",
    "- 이 때문에 순간적인 gradient를 따라가다보니까 너무 왔다리 갔다리 함\n",
    "- momentum \n",
    "    - 좌우 방향은 상쇄됨\n",
    "    - 앞 방향은 빨리 가게 함\n",
    "    - graident를 누적하게 해서 위를 구현함: 왔다갔다하는 방향은 상쇄, 진행방향으로는 누적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp (Root mean square propagation)\n",
    "- gradient의 크기만 누적함\n",
    "    - 특정 방향에 대해만 gradient가 가파르면 다른쪽을 보정하는 방식을 차용\n",
    "    - learning rate을 각 파라미터 별로 다르게 줘서 평준화를 해 공평한 탐색 실시\n",
    "    - 가파른 쪽은 조심, 완만한쪽은 과감\n",
    "    - local minimum 회피가 가능함 (local에 빠지지 않고 탐색영역을 넓히게 됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam (Adaptive Moment Estimation)\n",
    "- gradient term이 분자에 momentum, 분모에 RMSProp이 들어감\n",
    "- gradient를 누적하되, 이전의 gradient는 점점 가중치를 줄임\n",
    "    - exponential moving average (EMA)\n",
    "- vector의 제곱은 안되지만 elementwise square임\n",
    "- 크기를 분모에 넣어서 크기의 누적으로써 탐색의 평준화가 가능하게 함\n",
    "- epsilon이 분모에 들어가는데 분모가 0이되지 않게 함\n",
    "- 초반 시점의 scale을 맞춰주는 항이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 데이터\n",
    "- Training: 처음엔 정답 알려주면서 훈련, 그 다음에 처음볻는 데이터를 보여주면서 잘하나 테스트\n",
    "- 일단, TEst 데이터가 학습 때 사용되면 안됨\n",
    "    - 학습 후 처음보는 데이터가 되어야 함\n",
    "    - AI가 처음보는 데이터에 대해서 잘하는지 볼 수 없음\n",
    "- Train 데이터만으로는 몇 Epoch에 멈춰야할지 애매함\n",
    "- 적당히 학습해야 좋은 것\n",
    "    - AI가 정답을 외워버리면 안됨\n",
    "- Test loss를 보고 epoch를 정해도 안됨\n",
    "    - Test 데이터에 또 과적합된 모델이 됨\n",
    "    - 왜냐하면 Test 데이터가 무한정하지 않기 때문임\n",
    "- val data는 train 중에 데이터를 떼서 같이 학습함\n",
    "    - 학습에 직접 관여하지 않음\n",
    "    - epoch를 정함\n",
    "    - train loss와 달리 계속 줄어들지 않음\n",
    "    - hyperparameter 선정을 위해 필요한 데이터임\n",
    "- test는 모델 완성 후 테스트만을 위해 이용해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation\n",
    "- 데이터가 너무 적게 있음, training data가 너무 적어서 일부를 validation을 쓰기 너무 곤란함\n",
    "    - 왜?: 편향됨, 데이터가 너무 적어버리니까\n",
    "- cross validation: 각기 다른 train, validation 조합의 데이터로 여러개의 모델을 만든다\n",
    "    - 평균 val loss를 구하고 가장 val loss 평균이 작은 hyperparameter set을 고르는데 사용함\n",
    "- CV 이후에는 모든 train data를 이용해서 학습을 진행 or 5개의 모델 진행한걸 앙상블함 (예, majority vote)\n",
    "    - 다수결 : 분류 모델의 경우는 고양이와 강아지의 선택을 다수결 따름\n",
    "    - soft vote: 선택의 확률의 평균을 따름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Activation\n",
    "#### 인공신경망 계산구조\n",
    "[x1 x2][[w1 w2][w3 w4][w5 w6]] +[b1 b2 b3]와 같은 계싼\n",
    "여기서 weight vector는 input layer x output layer의 형태이다\n",
    "- 행렬 곱하고 벡터 더하고 activation의 반복이다\n",
    "#### activation 설정\n",
    "- 깊게 깊게 만들면 엄청 복잡한 함수도 나타낼 수 있따.\n",
    "    - linear activation만 쓰면 아무리 깊게 만들어도 FC layer 1층 이상 만들어 낼 수 없다\n",
    "        -다단 linear activation은 사실상 ax + b 형태로 다시 정리할 수 있음\n",
    "    - 즉 비선형 activation이 필요함, 없으면 깊어지는 효과를 전혀 누리지 못함\n",
    "- linear activation은 어디서 써야 하는가?\n",
    "    - 선형회귀 마지막층에 linear activation\n",
    "    - 정보손실을 막기 위해서\n",
    "        - mobilenet v2 개념\n",
    "            - 5 node - 2 node - 7 node가 있는 layer에서 2 node로 가는 과정에서 비선형 activation은 정보 손실이 발생 (Relu는 음수값 모두 손실)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "- 깊은 곳 weight에 대한 편미분은 어떻게 구하나? chain rule로\n",
    "- 인공신경망 출력층의 결과를 통해 loss를 계산하는데 \n",
    "    - dL/dw2 = dL/d나2 d나2/d들2 d들2/dw2 + ~~(다른 path)\n",
    "    - dL/dw2 = 2(y-y')^2*f'2(들2)*나1\n",
    "        - 들2 = 나1*W2 + ...\n",
    "    - 들1 = 나0*W1 + ...\n",
    "    - 각 패스에 대한 chain rule항을 다 더해주어야 한다\n",
    "    - 미분항으로 보면, loss 미분 - 액티 미분 - 웨잇 미분 - 액티 미분 - 웨잇미분.... 형태로 반복됨\n",
    "- forward propagation을 통해 한번 해서 값들을 구해놓고 (액티 미분 값들을 위해서, 들값 나값을 계산)\n",
    "- backpropagation을 통해 미분 값을 구한다 -> 그리고 SGD 사용해서 학습!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진 분류\n",
    "#### 이진분류 문제 풀기\n",
    "- 입력: 키와 몸무게 & 출력:1 (빼야하는지) or 0 (쪄야 하는지)\n",
    "- step1. 데이터 모으기\n",
    "- step2. 모델 만들기\n",
    "    - unit step function 이용해서 분류해보자 (2 x 1 구조)\n",
    "    - hidden layer 없이 unit step function을 activation으로 사용하면 **퍼셉트론**이라 함\n",
    "- step3. 모델 학습시키기\n",
    "    - 분류 경계가 선형이 된다 - 선형 분류\n",
    "    - ax + by + c >0을 만족해야 함 -> y> -a/bx - c/b의 조건을 만족한다\n",
    "- step4. 모델 테스트\n",
    "    - 결과가 3D로 출력됨\n",
    "        - 1을 만족하는 평면 xy와 0을 만족하는 평면 xy가 존재하고 그 경계가 선형 분류 방정식임\n",
    "- 문제: 미분이 불가함, 너무 빡빡하게 분류한다.\n",
    "#### unit step function을 조금 부드럽게 - sigmoid\n",
    "- 전구간 미분 가능\n",
    "- 좀더 부드러운 출력\n",
    "- f = 1/(1+exp(-x))\n",
    "- 확률 혹은 정도로 해석 가능 (0~1 값이므로)\n",
    "- sigmoid를 선택하게 되면 1과 0의 경계가 너무 가파르지 않은 경계를 찾게 됨\n",
    "#### sigmoid 기반 이진 분류\n",
    "- 입력을 3x100x100인 (강아지 or 공야이) 사진이라고 하고 곧바로 출력 층으로 연결한다고 하자\n",
    "- 총 파라미터 개수: 이것이 gradient 길이 -> loss만 잘 정의하면 됨\n",
    "    - 10000 x 3 + 1(bias) = 30001개\n",
    "- 이 신경망이 사진을 입력 받아 강아지일 확률을 출력하게끔 만들어보자\n",
    "    - 강아지 사진을 넣었을 때 0에 가까운 값이 나올 수록 loss가 크다고 정의하면 됨\n",
    "    - loss로 출력의 의미를 컨트롤한다\n",
    "    - 다시 말해 강아지면 1, 고양이면 0이 나오도록 loss를 장 정의하면 됨\n",
    "- 신경망 출력을 q, 정답을 y라고 하면 (강아지 y = 1, 고양이 y= 0)\n",
    "    - sigmoid를 썼기 때문에 q를 maximize하도록 목적함수를 세우면 됨\n",
    "    - if 강아지 사진 maximize q, elif 고양이 사진 maximize 1-q\n",
    "    - 한줄로 바꾸면 **q^y(1-q)^(1-y)를 maximize하면 됨**\n",
    "- q1^y1*(1-q1)^(1-y1): 첫 번째 사진에 대해 AI가 예측한 해당 동물일 확률 P(y1)\n",
    "- batch size가 2이면 데이터를 뽑는 각각의 시행은 독립시행이므로 곱한 확률로 키워야 함 P(y1교y2) = P(y1)P(y2)\n",
    "- 근데 batch size가 커지면 커질수록 P값이 0에 수렴하게 됨 (underflow 문제)\n",
    "    - log를 취해서 해결함\n",
    "    - - Sigma_n(qn^yn(1-qn)^(1-yn)) = loss (Binary Cross Entropy)\n",
    "    - 로그를 취해도 되는 이유: 단조증가 함수\n",
    "        - 로그를 취하고 줄이는 것과 로그를 취하지 않고 줄이는 것과 정확히 같은 방향이기 때문임 \n",
    "- 위의 내용을 logistic regression이라함 (분류도 사실 regression임임)\n",
    "    - logistic function (= sigmoid function)을 썼기 때문에 logistic regression이라 부름\n",
    "- LEVEL2: logistic regression은 logit(log-adds = log(q/1-q))을 linear regression으로 구한 것으로도 해석 가능, loss 값을 얻기 위해 sigmoid를 통과시켜서 logit을 확률로 바꾼 것이다\n",
    "    - logit = log-odds = log(odds)\n",
    "    - odds(승산) = q/(1-q), 승리확률/패배확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE vs BCE\n",
    "- MSE를 이용해서 minimize (q1-1)^2을 loss로 두면 안되나?\n",
    "- log q1이 훨씬 더 민감함 (q vs loss의 그래프를 그리면 -log q가 이차함수보다 0 근처에서 무한대로 발산함 -> loss가 커짐)\n",
    "- output layer의 weight에 대해 loss function의 개형이 MSE는 non-convex, -log q1은 convex이다.\n",
    "    - 아래로 볼록 convex\n",
    "    - loss 함수가 convex면 global optimization을 찾는다는 의미\n",
    "    - input layer에서는 둘다 non-convex임\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE (Maximum Likelihood Estimation)\n",
    "#### 딥러닝의 뿌리 이론\n",
    "- Likelihood?\n",
    "    - A라는 주머니에 검은돌 1개 흰색돌 1개\n",
    "    - B라는 주머니에 검은돌 2개 흰색돌 1개\n",
    "    - 조건부확률률\n",
    "        - P(검|A) = 0.5, P(흰|A) = 0.5\n",
    "        - P(검|B) = 1/3, P(흰|B) = 2/3\n",
    "        - 조건을 중심으로 묶으면 조건문\n",
    "    - Likelihood (우도)\n",
    "        - P(검|A) = 0.5, P(검|B) = 2/3\n",
    "        - P(흰|A) = 0.5, P(흰|B) = 2/3\n",
    "        - 사건을 중심으로 묶으면 우도\n",
    "    - 확률 분포가 아님, 왜냐 합이 1이 아님\n",
    "    - 조건부 확률 값인건 맞는데 확률 분포는 아닌 (합이 !=1 ) 그런 것!\n",
    "    - 왜쓰냐? 앞의 항 (measurement, 관측)을 보고 그 속에 숨겨져 있는 뒤의 항을 알아낼 수 잇음\n",
    "    - 검은 돌을 꺼냈을때 A 주머니에서 꺼냈을까? B 주머니에서 꺼냈을까?\n",
    "    - 마치 썸녀와의 카톡을 보고 그녀의 마음을 추측하는 것과 같음\n",
    "        - 답장 빈도를 보고 마음이 있는지 없는지 판단\n",
    "        - 답장 빈도는 이미 주어진 것임임\n",
    "    - 뒤의 항이 뭐길래 measurement가 이렇게 나왔을 까?\n",
    "- 이진분류에선 P(y1) = q1^y1(1-q1)^(1-y1) 이게 likelihood임\n",
    "    - P(y1) = P(y1|w)로, 사실 w를 가지고 표현된 확률 값\n",
    "    - 우리는 weight을 알고 싶기 때문에 P가 커지는 y1을 찾고 싶은 것\n",
    "- 검은돌을 보고 주머니를 바꿔가면서 가장 검은돌 확률이 큰 주머니를 선택했듯이 강아지 label을 보고 weight을 바꿔가면서 가장 강아지일 확률을 크게하는 weight을 선택하는 것\n",
    "- x1이 들어갔을때 y1과 비슷한 값이 출력 나오게끔 학습 하자! 라고 해석할 수도 있지만 x1이 들어갔을때 y1에 대한 \"확률\"을 키우자!라고 해석할 수 도 잇음\n",
    "#### 베르누이 분포\n",
    "- 동전의 앞면의 확률이 q, 뒷면이 1-q일때 q^y(1-q)^(1-y)의 분포를 갖는다\n",
    "- likelihood가 보니 베르누이 분포 식임\n",
    "- 데이터가 여러개면 독립시행이라 분포의 곱 - 여기에 -log를 취한게 바로 BCE loss 인 것\n",
    "    - 왜 likelihoold=베르누이 분포식 -> likelihood는 그냥 식 자체만 놓고 보면 확률 분포 식과 같은 놈인데, 앞의 것이 아닌 뒤의 것을 함수로 본 것일뿐! 따라서 식을 세울 땐 그냥 y1의 확률 분포만 생각하자\n",
    "- BCE와 MSE 비교를 다시 해보면\n",
    "    - y1이 따르는 분포를 베르누이로 가정하고, 신경망이 'y=1일 확률 q1'을 잘 출력하게끔 NLL (Negative Log-Likelihood)를 loss로 삼고 학습\n",
    "    - y1이 따른느 분포를 가우시안으로 가정하고, 신경망이 'y1의 평균 y1''을 잘 출력하게끔 NLL을 loss로 삼고 학습\n",
    "    - 잘 출력한다 => label 값이 나오게 한다\n",
    "- MSE의 Gaussian 식을 NLL 취하면 (y-y')^2이 나오게 됨 (나머진 상수)\n",
    "- MAE는 Laplacian distribution을 따름\n",
    "#### 인공신경망은 MLE 기계다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 분류\n",
    "#### 이번엔 3개 동물 분류 (강아지, 고양이, 소) 분류\n",
    "- 이진분류에서는 값이 1개면 됬음, 강아지 이거나 아니거나\n",
    "- 이젠 각각의 확률이 필요함\n",
    "- 이젠 parameter가 90001개 필요함\n",
    "- 출력 노드의 수를 늘려서 각 노드가 각 동물을 담당하게 하자\n",
    "    - 각 노드가 각 동물을 담당하게 하자: 출력의 의미는 loss로 컨트롤\n",
    "    - 정답은 강아지 [1,0,0], 고양이 [0,1,0], 소 [0,0,1]로 두자 (one-hot encoding)\n",
    "    - 머신의 출력으로 확률 분포 값이 나오게 하자\n",
    "- 확률 분포가 출력될 수 있도록 activation을 softmax로 활용이 필요함\n",
    "    - softmax는 모든 추력 노드를 받아서 확률값을 뱉게 한다\n",
    "    - q1 = e1/(e1+e2+e3), q2 = e2/ ~\n",
    "    - 합이 1이고 모두 양수임\n",
    "    - exp가 아니라 절대값을 이용하게 되면 다른 값이 들어가도 부호만 다르다면 같은 값으로 인식, softmax는 부호가 반대인것도 인식함\n",
    "    - sigmoid는 일단 합이 1이 아님, 중간값이 출력되면 애매함 -> multi-lable classification엔 이용됨 (이 사진엔 어떤 동물이 있냐), 각각의 노드에 sigmoid를 달아서 계산함\n",
    "- MLE로 생각했을때 label의 분포가 multinoulli 분포를 따른다고 가정 (categorical 분포라고 부름)\n",
    "    - q1^y1q2^y2q3^y3\n",
    "    - cross entropy: -y1logq1 - y2logq2 - y3logq3\n",
    "    - entropy = -y1logy1 - y2logy2 - y3logy3\n",
    "    - E <= CE가 성립, CE를 줄이면 E에 수렴함\n",
    "    - q가 인공신경망의 출력이므로 q를 줄여서 label값 y에 가깝게 하는 loss인 CE를 이용\n",
    "- NLL로 전개해보면 L = sigma(CE)\n",
    "    - one-hot인거 고려하면 0 <= -logqj (j는 해당 동물의 인덱스) 즉, 한놈만 팬다 -> 하나를 맞추면 나머지는 알아서 확률이 줄어들므로\n",
    "- 이진분류를 가정해서 다시 돌아가서 수식적으로 정리하면 BCE loss와 동일하게 됨\n",
    "- multinomial logstic regression (혹은 softmax regression)이라 함\n",
    "- pytorch 안에 nn.CrossEntropy 안에는 softmax가 포함되어 있음\n",
    "    - 모델에 softmax를 포함시키면 중복되므로 포함시키면 안됨\n",
    "    - loss에서만 softmax를 구해서 분포를 계산하게 하는게 맞음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공신경망 문제 풀기\n",
    "- step1: 입, 출력 정하기\n",
    "    - 문제정의: 내가 어떤 문제를 풀 것인가?: 회귀, 다중 분류, multi-label 분류 ...\n",
    "- step2: model 만들고\n",
    "    - 이런 문제를 풀기에 어떤 모델이 적합할까?: MLP, CNN, RNN\n",
    "- step3: loss 정의하고\n",
    "    - 회귀면 MSE, 이진분류면 BCE, 다중 분류면 CE\n",
    "    - label의 분포는 무엇으로 가정할 것인가\n",
    "- step4: weight 최적화: SGD? ADAM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Approximation Theorem (보편 근사 정리)\n",
    "- MLP 행렬 곱하기 벡터 더하고 activation 이런 함수임\n",
    "    - 굳이 이런 형태로 함수를 표현해야 하는 이유\n",
    "    - 히든 layer 한 층만 있어도 어떤 연속 함수든 나타낼 수 있다\n",
    "        - hidden layer는 non-linear activation, 출력층은 linear activation, 노드 개수는 제한 X\n",
    "- 어떤 연속 함수든 f(xw1 + b1)w2 + b2의 형태로 다 표현할 수 있다\n",
    "    - 즉 train loss를 딱 0으로 만들어 버릴 수 있다\n",
    "- 모든 것을 스텝 function으로 각 point를 매칭할 수 있으므로\n",
    "- 왜 DNN으로 가냐면 node를 무한히 갈 수 없으므로\n",
    "    - 연속합수를 매칭할 수 있다는거지 이렇게 훈련해도 되는건 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing Gradient (기울기소실)와 ReLU\n",
    "- DNN을 무턱대고 깊게 만들면\n",
    "    - vanishing gradient 문제 발생\n",
    "    - overfitting 문제 발생\n",
    "        + loss landscape이 꼬불해지는 문제\n",
    "- layer가 많으면 입력층에 가까울수록 미분이 사라진다\n",
    "    - 주범은 sigmoid다\n",
    "    - 앞이 학습이 안되도 뒤가 잘되면 되는거 아닌가?\n",
    "        - 재료 - 사원 - 부장 - 임원\n",
    "        - 사원의 출력으로 부장이 작업 - 부장의 출력으로 임원이 작업해서 출력\n",
    "        - 임원은 loss에 가까워서 학습이 잘되는데, 내려갈수록 학습이 안됨 - 학습을 해도 input을 가공하는게 안되서 뒤쪽 node가 실력이 좋아도 loss가 잘 안줄어들게 된다.\n",
    "    - gradient 소실 - update가 안됨 - 앞단에 이상한 weight 분포 - 깊은게 독이됨\n",
    "    - 앞에서 입력 데이터를 망쳐놓으면 뒤에서 손쓸 방법이 없다\n",
    "    - 데이터에 다가가지도 못함 - underfitting\n",
    "- ReLu가 나옴\n",
    "    - 음수를 아예 죽여버리는 문제 해결, Leaky ReLu (기울기 0.01x) -> 기울기마저 학습하는 Parameteric ReLu\n",
    "    - vanishing gradient가 항상 좋은건 아님 노드가 적게되면 layer를 넘어가면서 정보 손실이 심함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "- Vanishing gradient 해결함\n",
    "- batch size =5 라고 하고 특정 node에 input이 들어간다면\n",
    "    - 전부 양수로 들어간다면: 이 경우에 대해서는 linear activation 문제는 없음 - vanishing gradient는 해결하지만 non-linearity를 살리지 못함\n",
    "    - 전부 음수로 들어간다면: 이 경우에는 nonlinearity도 없고 vanishing gradient도 해결 못함\n",
    "    - 그래서 적절하게 들어가면 좋을 거 같아 - 재배치하되, 얘네 순서는 유지시키자 - Batch 단위의 normalization\n",
    "    - 평균 0 분산 1이면 ReLu에 대해서는 비선형성 확보가 되지만 sigmoid의 경우 선형구간에 데이터가 몰릴 수도 잇음(그래프 개형 확인)\n",
    "    - 어디로 이동시킬지도 학습시키면 된다!\n",
    "- 어디에(평균), 얼만큼 세게 뿌릴지 (분산)을 학습시키자 (마치 모래알) how?\n",
    "- 정규화: 데이터-평균/편차\n",
    "- a(X-X^/sigx) + b에서 평균이 b, 분산이 a2인데 얘네를 학습 파라미터로 넣고 계산 시킨다\n",
    "    - nonlinearity를 얼마나 살리면서 vanishing gradient를 얼마나 살릴지를 AI가 정해라!\n",
    "- Training 때와 Test때 다르게 동작해야 함\n",
    "    - training 당시에 moving average때 a와 b를 끌고 오다가, test 때는 정해놓은 a와 b를 이용함\n",
    "- 단 Batch size에 따라 영향을 받는다는 단점이 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization\n",
    "- Layer 축에 대해서 정규화를 실시함\n",
    "- batch size가 5인 경우 batch normalization은 5개의 들 값을 기준으로 정규화\n",
    "- layer에 node가 3개인 경우 3개의 들 값을 기준으로 정규화\n",
    "- Batch size에 상관없이 가능함, 매 데이터 마다 정규화 값 (X, X^, sig) 달라짐\n",
    "- 노드당 두개 파라미터 추가\n",
    "- LN은 trainig과 test 때 똑같은 방식으로 계산함\n",
    "- 이미지 데이터에는 BN을 자연어 처리쪽에서는 LN을 주로 사용\n",
    "    - pad 토큰 때문임\n",
    "    - batch 데이터 마다 pad된 데이터에선 0이 계속 찍히니까 문제임\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Landscape이 꼬불해지는 문제\n",
    "- BN, ReLU콤비로 vanishing gradient 해결 했는데 그래도 너무 깊으면 학습이 안됨 - 오히려 underfitting\n",
    "- loss의 모양이 이상해짐 -> ResNet의 skip-connection이 대표적인 해결 방안 중 하나   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "- training 때 잘하는데 test때 못하는것\n",
    "- 모델의 경량화\n",
    "    - 모델을 다시 만든다\n",
    "- data augmentation\n",
    "    - 데이터가 적을때는 모델을 바꾼다고 해결되지 않음\n",
    "    - 일단 모든 문제에선 데이터를 많이 확보하는게 중요함\n",
    "    - 이미지 경우\n",
    "        - 강아지 사진을 돌려도 강아지임\n",
    "        - 잘라도 강아지야\n",
    "        - 밝아도 강아지야\n",
    "        - 채도가 높아도 강아지야\n",
    "        - 좌우 반전해도 강아지야\n",
    "        - 짜부시켜도 강아지야\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "- 노드를 일부 가려보면서 학습시키자\n",
    "    - 서로 다른 network를 여러 개 사용해서 학습하는 셈\n",
    "    - test때는 얘네를 평균내서 앙상블하자\n",
    "- 적용\n",
    "    - layer 별로 dropout을 적용, node마다 살릴 확율 p 정함\n",
    "    - 네트워크 통과할때마다 살릴 노드 다시 고름 + 데이터 마다 다시 정함\n",
    "- test 때는 다 살리고 계산함, 대신 노드의 출력에 p를 곱함\n",
    "- 노드가 필요이상 많으면 - loss를 잘 줄이지만 기계적으로 정답을 맞춤 - overfitting- 몇명 연차 보내서 훈련 - 각 노드가 의미 있는 특징을 뽑음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "- loss에 weight 크기를 더해서 같이 고려하려 함\n",
    "- L 대신 L + lambda||w||를 loss로 사용\n",
    "    - || ||는 vector의 크기를 의미함함\n",
    "- p가 2면 l2-regularization, p가 1이면 l1-regularization\n",
    "- p가 2면 w의 절대값의 제곱의 합\n",
    "- p가 1이면 w의 절대값의 합\n",
    "- lambda는 hyperparameter\n",
    "    - 0이면 기존과 동일\n",
    "    - lambda가 커질수록 weight을 줄이려고만 함\n",
    "- loss를 줄이는데 별 영향이 없는 weight는 0으로 -> 모델 경량화\n",
    "- 어느정도 수렴하고 나서도 계속 학습시켜보니 weight가 자꾸 커지더라\n",
    "- 처음엔 L을 많이 고려하다가 L을 어느정도 줄였으면 L이 도로 너무 커지지 않은 선에서 lp를 줄임\n",
    "- 직관\n",
    "    - weight 크기도 같이 고려해서 쓸데없이 큰 애들은 망치로 좀 두들겨 줌\n",
    "    - l2: 작은 애들은 살살 때리고, 큰 애들은 팍팍 때려\n",
    "    - l1: 기울기가 일정해서 크건 작건 다 똑같은 힘으로 두드려\n",
    "    - 몇개 connection을 없애는 효과 - 중요한 connection만 살린다는 마인드\n",
    "- MAP (Maximum A Posteriori) 해석\n",
    "    - regularization은 p(y|w)가 아니라 p(w|y)를 최대화하는 개념\n",
    "    - p(y|w): likelihood = p(w,y)/p(w)\n",
    "    - p(w|y): posterior = p(w,y)/p(y)\n",
    "    - 일병 베이지안룰\n",
    "    - p(w|y) = p(w,y)/p(y) = p(y|w)p(w)/p(y) = p(y|w)p(w) (왜냐하면 우리는 w를 바꿔가면서 학습하므로 p(y)는 상수)\n",
    "    - -logp(y|w) - p(w) (p(w) = w^2/sig)\n",
    "    - p(w)는 prior distribution임, 학습할때 좋은 weight의 분포는 평균이 0인 확률분포 (L1은 laplacian, L2는 Gaussian)\n",
    "    - lambda는 1/2sig와 동일한데 lambda가 작다는건 분산이 크다 -> weight가 큰 놈이 존재할 수 있다는 의미\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting 방지법\n",
    "- 모델을 단순하게\n",
    "- data 수집을 더 하거나 data augmentation\n",
    "- validation data 기준, 가장 성능 좋을 때 모델 저장\n",
    "- dropout, dropconnect\n",
    "- regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행렬의 곱셈과 네 가지 관점 (열공간 (column space))\n",
    "- 행렬의 곱셈은 행렬과 vector의 곱을 쌓는 것이다\n",
    "- 왼쪽 행렬의 열과 오른쪽 행렬의 행의 size가 같아야 함\n",
    "    - 위가 만족하면 계속 늘어나도 상관없음\n",
    "    - m x k와 k x n을 기준으로 하면 m x n이 생김\n",
    "- 교환법칙이 성립하지 않음\n",
    "- 여러번 곱하면\n",
    "    - 4x3 3x5 5x2를 곱하면 4x2가 생김\n",
    "#### 관점1: 내적으로 바라보기\n",
    "A = [a1.T, a2.T, a3.T] (보통 벡터를 열로 나타내서 행으로 하려면 Transpose)\n",
    "B = [b1, b2, b3]\n",
    "AB = [[a1.Tb1 a1.Tb2 a1.Tb3],[...],[...]]\n",
    "#### 관점2: rank-1 matrix의 합\n",
    "AB = [a1, a2, a3][b1.T, b2.T, b3.T] = a1b1.T + a2b2.T+ a3b3.T\n",
    "- rank01 matrix를 알아야 할 듯\n",
    "#### 관점3: column space로 바라보개\n",
    "Ax = [a1 a2 a3] [x1 x2 x3].T = a1x1 + a2x2 + a3x3\n",
    "- 벡터의 스칼라배의 합으로 표현됨\n",
    "- 어차피 다시 벡터가 됨\n",
    "- x1, x2, x3의 조합을 다 바꿔봤을때 나타나는 공간/영역을 column space라고 함\n",
    "#### 관점4: Row space로 바라보기\n",
    "xTA = [x1, x2, x3] [a1 a2 a3].T = x1a1T + x2a2T + x3a3T (트랜스포머 관점!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내적과 정사영 직관적 설명\n",
    "- 내적은 두 벡터가 얼마나 닮았는지 \n",
    "- dot product = scalar product보다 inner product가 더 넓은 의미임\n",
    "- a.Txb = b.Txb\n",
    "- a.Txb = ||a||||b|| cosO\n",
    "    - ||a||: a vecotr의 크기\n",
    "    - sqrt(성분 제곱 합)\n",
    "    - ||a||cosO x ||b||\n",
    "    - ||b| cosO x ||a||\n",
    "        - a vector를 b vector에 정사영한 크기에 b vector의 크기로 곱한 것 <-> 역도 가능\n",
    "        - a.Txa = ||a|| ||a|| = ||a||^2\n",
    "        - a vector의 크기를 그래서 ||a|| = sqrt(a.Txa)로 표현 가능\n",
    "        - a의 unit vector는 a/sqrt(a.Txa)로 표현 가능 -> normalize\n",
    "#### 내적은 닮은 정도이다\n",
    "- 내적의 값이 가장 크려면 방향이 같이야 함\n",
    "- 두 vector가 수직이면 내적이 0이다 -> 가장 안닮았다\n",
    "- 방향이 반대면 내적이 음수임\n",
    "#### 정사영된 벡터를 구하는 방법\n",
    "- a = [1 3]을 b = [5 1]에 정사영하면\n",
    "    - 정사영 벡터의 크기 = a.T x b = ||a||||b||cosO\n",
    "    - b의 방향만 곱하자 = b의 unit vector = b/sqrt(b.T x b)\n",
    "    - a.T x b / b.T/b *b\n",
    "- 기하학적인 방법\n",
    "    - b x x'이라고 가정\n",
    "    - a - b는 b vector를 반대로 돌린 것, 기하학적으로는 b벡터 끝점부터 a벡터 끝점으로 이어지는 벡터가 a - b 벡터임\n",
    "    - a - bx'이라는 벡터로 표현됨\n",
    "    - 그렇다면 bx'과 a-bx'은 수직이 성립해야 bx'이 정사영된 벡터라 할 수 잇음\n",
    "    - (a-bx').T x bx' = 0\n",
    "    - a.Txb - b.Tbx' = 0 \n",
    "    - x' = a.Tb / b.T/b\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
