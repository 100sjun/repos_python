{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34563dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import random, jit, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5a4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "ds = tfds.load('mnist', split='train', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3185326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 샘플 수: 60000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess(image, label):\n",
    "    image = jnp.array(image, dtype=jnp.float32) / 255.0\n",
    "    label = jnp.array(label, dtype=jnp.int32)\n",
    "    return image.reshape(-1), label\n",
    "\n",
    "# 데이터 변환\n",
    "train_data = [(preprocess(image, label)) for image, label in tfds.as_numpy(ds)]\n",
    "print(f'훈련 데이터 샘플 수: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397b9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 정의\n",
    "\n",
    "## 파라미터 초기화 함수\n",
    "def init_params(layer_sizes, key):\n",
    "    params = []\n",
    "    for n_in, n_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "        key, subkey = random.split(key)\n",
    "        weights = random.normal(subkey, (n_in, n_out)) * 0.01\n",
    "        biases = jnp.zeros(n_out)\n",
    "        params.append((weights, biases))\n",
    "    return params\n",
    "\n",
    "## MLP 모델 함수\n",
    "def predict(params, x):\n",
    "    for w, b in params[:-1]:\n",
    "        x = jnp.dot(x, w) + b\n",
    "        x = jnp.maximum(x, 0) # ReLu 활성화 함수\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(x, final_w) + final_b\n",
    "    return logits - jax.scipy.special.logsumexp(logits, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec4fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 및 정확도 계산\n",
    "\n",
    "## 손실함수\n",
    "def cross_entropy_loss(params, x, y):\n",
    "    logits = predict(params, x)\n",
    "    one_hot = jax.nn.one_hot(y, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot * logits, axis=1))\n",
    "\n",
    "## 정확도 계산 함수\n",
    "def accuracy(params, x, y):\n",
    "    logits = predict(params, x)\n",
    "    predictions = jnp.argmax(logits, axis=1)\n",
    "    return jnp.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af0b4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프 정의\n",
    "\n",
    "## 훈련단계\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "# 모델 초기화\n",
    "params = init_params([784, 128, 10], key)\n",
    "\n",
    "# 기울기 계산 함수\n",
    "grad_loss = jit(grad(cross_entropy_loss))\n",
    "\n",
    "# 파라미터 업데이트 함수\n",
    "@jit\n",
    "def update(params, x, y, lr):\n",
    "    grads = grad_loss(params, x, y)\n",
    "    return [(w - lr * dw, b - lr * db) for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a307866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0188, Accuracy: 0.6354\n",
      "Epoch 2, Loss: 0.9221, Accuracy: 0.8125\n",
      "Epoch 3, Loss: 0.5631, Accuracy: 0.8854\n",
      "Epoch 4, Loss: 0.4253, Accuracy: 0.9167\n",
      "Epoch 5, Loss: 0.3521, Accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 미니배치 학습\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        batch = train_data[i:i + batch_size]\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        x_batch = jnp.stack(x_batch)\n",
    "        y_batch = jnp.array(y_batch)\n",
    "\n",
    "        # 파라미터 업데이트\n",
    "        params = update(params, x_batch, y_batch, learning_rate)\n",
    "\n",
    "    # 에포크별 손실 및 정확도 출력\n",
    "    train_loss = cross_entropy_loss(params, x_batch, y_batch)\n",
    "    train_acc = accuracy(params, x_batch, y_batch)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ec43e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.8828\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과 평가\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "ds_test = tfds.load('mnist', split='test', as_supervised=True)\n",
    "test_data = [(preprocess(image, label)) for image, label in tfds.as_numpy(ds_test)]\n",
    "\n",
    "# 평가\n",
    "x_test, y_test = zip(*test_data)\n",
    "x_test = jnp.stack(x_test)\n",
    "y_test = jnp.array(y_test)\n",
    "\n",
    "test_acc = accuracy(params, x_test, y_test)\n",
    "print(f\"테스트 정확도: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
