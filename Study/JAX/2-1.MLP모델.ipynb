{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66085f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0de46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 불러오기\n",
    "ds = tfds.load('mnist', split='train', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c95ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 샘플 수: 60000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess(image, label):\n",
    "    image = jnp.array(image, dtype=jnp.float32) / 255.0\n",
    "    label = jnp.array(label, dtype=jnp.int32)\n",
    "    return image.reshape(-1), label\n",
    "\n",
    "# 데이터 변환\n",
    "train_data = [(preprocess(image, label)) for image, label in tfds.as_numpy(ds)]\n",
    "print(f'훈련 데이터 샘플 수: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 정의 (Flax 사용)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    hidden_dim: int\n",
    "    output_dim: int = 10\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(self.hidden_dim)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(self.output_dim)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e640455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "key = jax.random.PRNGKey(42)\n",
    "model = MLP(hidden_dim=128, output_dim=10)\n",
    "\n",
    "# 더미 입력으로 파라미터 초기화\n",
    "dummy_x = jnp.ones((1, 784))\n",
    "params = model.init(key, dummy_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bedb6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의 (Optax 사용)\n",
    "learning_rate = 0.01\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1fb7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 및 정확도 계산 (Optax 사용)\n",
    "\n",
    "## 손실함수\n",
    "def loss_fn(params, x, y):\n",
    "    logits = model.apply(params, x)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits, y\n",
    "    ).mean()\n",
    "    return loss\n",
    "\n",
    "## 정확도 계산 함수\n",
    "def accuracy_fn(params, x, y):\n",
    "    logits = model.apply(params, x)\n",
    "    predictions = jnp.argmax(logits, axis=1)\n",
    "    return jnp.mean(predictions == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e74fa1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프 정의\n",
    "\n",
    "## 훈련단계\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# 파라미터 업데이트 함수 (JIT 컴파일)\n",
    "@jax.jit\n",
    "def update_step(params, opt_state, x, y):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9de1364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0697, Accuracy: 0.9896\n",
      "Epoch 2, Loss: 0.0392, Accuracy: 0.9896\n",
      "Epoch 3, Loss: 0.0302, Accuracy: 1.0000\n",
      "Epoch 4, Loss: 0.0144, Accuracy: 1.0000\n",
      "Epoch 5, Loss: 0.0502, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 미니배치 학습\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        batch = train_data[i:i + batch_size]\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        x_batch = jnp.stack(x_batch)\n",
    "        y_batch = jnp.array(y_batch)\n",
    "\n",
    "        # 파라미터 업데이트\n",
    "        params, opt_state, loss = update_step(params, opt_state, x_batch, y_batch)\n",
    "\n",
    "    # 에포크별 손실 및 정확도 출력\n",
    "    train_acc = accuracy_fn(params, x_batch, y_batch)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}, Accuracy: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f64ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.9714\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과 평가\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "ds_test = tfds.load('mnist', split='test', as_supervised=True)\n",
    "test_data = [(preprocess(image, label)) for image, label in tfds.as_numpy(ds_test)]\n",
    "\n",
    "# 평가\n",
    "x_test, y_test = zip(*test_data)\n",
    "x_test = jnp.stack(x_test)\n",
    "y_test = jnp.array(y_test)\n",
    "\n",
    "test_acc = accuracy_fn(params, x_test, y_test)\n",
    "print(f\"테스트 정확도: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
