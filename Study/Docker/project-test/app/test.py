import torch

print("ğŸ”¥ PyTorch version:", torch.__version__)
print("ğŸ§  CUDA available:", torch.cuda.is_available())

if torch.cuda.is_available():
    print("ğŸš€ CUDA version (detected by torch):", torch.version.cuda)
    print("ğŸ¯ Current device index:", torch.cuda.current_device())
    print("ğŸ“› GPU name:", torch.cuda.get_device_name(torch.cuda.current_device()))
    print("ğŸ“ˆ Total GPU memory:", torch.cuda.get_device_properties(0).total_memory / (1024 ** 3), "GB")
else:
    print("âš ï¸ CUDA is NOT available. CPU-only mode.")